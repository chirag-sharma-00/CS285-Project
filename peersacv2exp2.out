


LOGGING TO:  /home/harvey/Documents/cs285/CS285-Project/cs285/scripts/../../data/peersac_v2_2agents_eps0.6_HalfCheetah-v4_12-12-2022_13-52-17 



########################
logging outputs to  /home/harvey/Documents/cs285/CS285-Project/cs285/scripts/../../data/peersac_v2_2agents_eps0.6_HalfCheetah-v4_12-12-2022_13-52-17
########################
Using GPU id 0


********** Iteration 0 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -32.58100509643555
Agent0_Eval_StdReturn : 38.008583068847656
Agent0_Eval_MaxReturn : 18.935745239257812
Agent0_Eval_MinReturn : -95.31880187988281
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -68.51490020751953
Agent0_Train_StdReturn : 35.8519172668457
Agent0_Train_MaxReturn : 10.17027473449707
Agent0_Train_MinReturn : -109.59283447265625
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1500
Agent0_TimeSinceStart : 1.7730662822723389
Agent0_Critic_Loss : 1.7086536884307861
Agent0_Actor_Loss : -0.34447938203811646
Agent0_Alpha_Loss : 0.9863041639328003
Agent0_Temperature : 0.09997000449985415
Agent0_Initial_DataCollection_AverageReturn : -68.51490020751953
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -52.60877227783203
Agent1_Eval_StdReturn : 36.110774993896484
Agent1_Eval_MaxReturn : -6.442377090454102
Agent1_Eval_MinReturn : -109.24239349365234
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -41.37040710449219
Agent1_Train_StdReturn : 23.476428985595703
Agent1_Train_MaxReturn : -3.7883758544921875
Agent1_Train_MinReturn : -74.03202819824219
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1500
Agent1_TimeSinceStart : 3.4499616622924805
Agent1_Critic_Loss : 0.9887043237686157
Agent1_Actor_Loss : -0.48759517073631287
Agent1_Alpha_Loss : 0.9798400402069092
Agent1_Temperature : 0.09997000449985614
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 1 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 2 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 3 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 4 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 5 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 6 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 7 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 8 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 9 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 10 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -16.689105987548828
Agent0_Eval_StdReturn : 30.834503173828125
Agent0_Eval_MaxReturn : 41.04553985595703
Agent0_Eval_MinReturn : -65.38418579101562
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -31.46488380432129
Agent0_Train_StdReturn : 26.753488540649414
Agent0_Train_MaxReturn : 5.917475700378418
Agent0_Train_MinReturn : -66.07237243652344
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 16500
Agent0_TimeSinceStart : 20.33057165145874
Agent0_Critic_Loss : 0.9285090565681458
Agent0_Actor_Loss : -0.3657960593700409
Agent0_Alpha_Loss : 0.9829058647155762
Agent0_Temperature : 0.09967056271390533
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -35.15570068359375
Agent1_Eval_StdReturn : 32.02640914916992
Agent1_Eval_MaxReturn : 16.7863712310791
Agent1_Eval_MinReturn : -91.48548889160156
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -44.53758239746094
Agent1_Train_StdReturn : 29.685022354125977
Agent1_Train_MaxReturn : 3.7171268463134766
Agent1_Train_MinReturn : -86.65126037597656
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 16500
Agent1_TimeSinceStart : 22.019412755966187
Agent1_Critic_Loss : 0.9182092547416687
Agent1_Actor_Loss : -0.5095957517623901
Agent1_Alpha_Loss : 0.9861770272254944
Agent1_Temperature : 0.09967042435579129
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 11 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 12 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 13 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 14 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 15 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 16 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 17 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 18 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 19 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 20 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -43.38697052001953
Agent0_Eval_StdReturn : 43.672325134277344
Agent0_Eval_MaxReturn : 9.642265319824219
Agent0_Eval_MinReturn : -116.5941162109375
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -33.40008544921875
Agent0_Train_StdReturn : 29.175334930419922
Agent0_Train_MaxReturn : 5.264189720153809
Agent0_Train_MinReturn : -82.53800964355469
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 31500
Agent0_TimeSinceStart : 39.42465615272522
Agent0_Critic_Loss : 0.8994090557098389
Agent0_Actor_Loss : -0.4210008978843689
Agent0_Alpha_Loss : 0.9935859441757202
Agent0_Temperature : 0.09937206042805405
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -53.96504592895508
Agent1_Eval_StdReturn : 43.379947662353516
Agent1_Eval_MaxReturn : 35.547664642333984
Agent1_Eval_MinReturn : -129.4097137451172
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -43.527915954589844
Agent1_Train_StdReturn : 28.746292114257812
Agent1_Train_MaxReturn : -4.636443138122559
Agent1_Train_MinReturn : -84.09095764160156
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 31500
Agent1_TimeSinceStart : 41.11091732978821
Agent1_Critic_Loss : 0.6898341774940491
Agent1_Actor_Loss : -0.5222538709640503
Agent1_Alpha_Loss : 0.9894306063652039
Agent1_Temperature : 0.099371725422022
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 21 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 22 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 23 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 24 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 25 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 26 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 27 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 28 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 29 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 30 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -30.686840057373047
Agent0_Eval_StdReturn : 31.976219177246094
Agent0_Eval_MaxReturn : 15.554892539978027
Agent0_Eval_MinReturn : -95.71600341796875
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -21.32683753967285
Agent0_Train_StdReturn : 34.12836456298828
Agent0_Train_MaxReturn : 11.6461181640625
Agent0_Train_MinReturn : -90.47835540771484
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 46500
Agent0_TimeSinceStart : 57.93119692802429
Agent0_Critic_Loss : 0.9358377456665039
Agent0_Actor_Loss : -0.4118671715259552
Agent0_Alpha_Loss : 0.9876188039779663
Agent0_Temperature : 0.09907424650166567
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -44.66895294189453
Agent1_Eval_StdReturn : 20.377052307128906
Agent1_Eval_MaxReturn : -7.406425476074219
Agent1_Eval_MinReturn : -80.6243667602539
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -56.577049255371094
Agent1_Train_StdReturn : 40.68922805786133
Agent1_Train_MaxReturn : 34.70890426635742
Agent1_Train_MinReturn : -114.0631103515625
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 46500
Agent1_TimeSinceStart : 59.60778999328613
Agent1_Critic_Loss : 0.8305315971374512
Agent1_Actor_Loss : -0.6114243268966675
Agent1_Alpha_Loss : 0.9846721887588501
Agent1_Temperature : 0.09907396921446175
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 31 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 32 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 33 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 34 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 35 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 36 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 37 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 38 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 39 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 40 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -58.8385124206543
Agent0_Eval_StdReturn : 36.875389099121094
Agent0_Eval_MaxReturn : 18.561731338500977
Agent0_Eval_MinReturn : -121.34124755859375
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -39.41211700439453
Agent0_Train_StdReturn : 31.211196899414062
Agent0_Train_MaxReturn : -1.5024425983428955
Agent0_Train_MinReturn : -102.93386840820312
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 61500
Agent0_TimeSinceStart : 76.5825412273407
Agent0_Critic_Loss : 0.7919868230819702
Agent0_Actor_Loss : -0.5017924904823303
Agent0_Alpha_Loss : 0.9837807416915894
Agent0_Temperature : 0.09877775447740954
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -33.764705657958984
Agent1_Eval_StdReturn : 31.169116973876953
Agent1_Eval_MaxReturn : 19.466182708740234
Agent1_Eval_MinReturn : -88.51805877685547
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -40.04237747192383
Agent1_Train_StdReturn : 34.22526931762695
Agent1_Train_MaxReturn : 4.663270950317383
Agent1_Train_MinReturn : -94.31086730957031
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 61500
Agent1_TimeSinceStart : 78.28941249847412
Agent1_Critic_Loss : 0.6820058822631836
Agent1_Actor_Loss : -0.61720871925354
Agent1_Alpha_Loss : 0.9784646034240723
Agent1_Temperature : 0.09877766513343532
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 41 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 42 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 43 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 44 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 45 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 46 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 47 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 48 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 49 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 50 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -40.2404670715332
Agent0_Eval_StdReturn : 33.054996490478516
Agent0_Eval_MaxReturn : 16.798763275146484
Agent0_Eval_MinReturn : -94.64860534667969
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -30.507116317749023
Agent0_Train_StdReturn : 30.74982261657715
Agent0_Train_MaxReturn : 18.7569522857666
Agent0_Train_MinReturn : -62.976890563964844
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 76500
Agent0_TimeSinceStart : 95.93417024612427
Agent0_Critic_Loss : 0.6696636080741882
Agent0_Actor_Loss : -0.5484128594398499
Agent0_Alpha_Loss : 0.9705269932746887
Agent0_Temperature : 0.09848284407898429
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -53.2364387512207
Agent1_Eval_StdReturn : 24.130664825439453
Agent1_Eval_MaxReturn : -16.806747436523438
Agent1_Eval_MinReturn : -85.96865844726562
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -26.66131019592285
Agent1_Train_StdReturn : 29.699268341064453
Agent1_Train_MaxReturn : 14.08652114868164
Agent1_Train_MinReturn : -82.72666931152344
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 76500
Agent1_TimeSinceStart : 97.6868667602539
Agent1_Critic_Loss : 0.6656782627105713
Agent1_Actor_Loss : -0.5844562649726868
Agent1_Alpha_Loss : 0.9852499961853027
Agent1_Temperature : 0.09848294805177957
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 51 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 52 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 53 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 54 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 55 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 56 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 57 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 58 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 59 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 60 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -35.65120315551758
Agent0_Eval_StdReturn : 31.44137191772461
Agent0_Eval_MaxReturn : 23.047245025634766
Agent0_Eval_MinReturn : -85.97941589355469
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -38.31502151489258
Agent0_Train_StdReturn : 28.90235710144043
Agent0_Train_MaxReturn : 2.0544748306274414
Agent0_Train_MinReturn : -85.96635437011719
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 91500
Agent0_TimeSinceStart : 115.34842538833618
Agent0_Critic_Loss : 0.6167566180229187
Agent0_Actor_Loss : -0.47789350152015686
Agent0_Alpha_Loss : 0.9705895185470581
Agent0_Temperature : 0.098189541619117
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -41.05083084106445
Agent1_Eval_StdReturn : 27.44729995727539
Agent1_Eval_MaxReturn : 9.700028419494629
Agent1_Eval_MinReturn : -77.75328826904297
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -42.59264373779297
Agent1_Train_StdReturn : 38.720054626464844
Agent1_Train_MaxReturn : 16.075944900512695
Agent1_Train_MinReturn : -99.79830932617188
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 91500
Agent1_TimeSinceStart : 117.1087257862091
Agent1_Critic_Loss : 0.65437912940979
Agent1_Actor_Loss : -0.5650622844696045
Agent1_Alpha_Loss : 0.9698150753974915
Agent1_Temperature : 0.09818927610808836
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 61 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 62 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 63 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 64 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 65 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 66 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 67 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 68 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 69 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 70 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -42.301429748535156
Agent0_Eval_StdReturn : 29.974374771118164
Agent0_Eval_MaxReturn : 3.220546007156372
Agent0_Eval_MinReturn : -87.86973571777344
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -36.35492706298828
Agent0_Train_StdReturn : 33.5159797668457
Agent0_Train_MaxReturn : 16.33430290222168
Agent0_Train_MinReturn : -90.46331024169922
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 106500
Agent0_TimeSinceStart : 137.58129477500916
Agent0_Critic_Loss : 0.6099430322647095
Agent0_Actor_Loss : -0.44114047288894653
Agent0_Alpha_Loss : 0.9626094698905945
Agent0_Temperature : 0.09789790917272123
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -30.946880340576172
Agent1_Eval_StdReturn : 22.71921157836914
Agent1_Eval_MaxReturn : -9.417581558227539
Agent1_Eval_MinReturn : -77.97965240478516
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -45.5745849609375
Agent1_Train_StdReturn : 29.953134536743164
Agent1_Train_MaxReturn : 1.3580138683319092
Agent1_Train_MinReturn : -109.576171875
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 106500
Agent1_TimeSinceStart : 139.3420708179474
Agent1_Critic_Loss : 0.6073858737945557
Agent1_Actor_Loss : -0.6296950578689575
Agent1_Alpha_Loss : 0.9604669213294983
Agent1_Temperature : 0.09789768644588068
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 71 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 72 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 73 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 74 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 75 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 76 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 77 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 78 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 79 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 80 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -62.808631896972656
Agent0_Eval_StdReturn : 35.297332763671875
Agent0_Eval_MaxReturn : -15.811286926269531
Agent0_Eval_MinReturn : -143.87709045410156
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -43.05418014526367
Agent0_Train_StdReturn : 19.3426513671875
Agent0_Train_MaxReturn : -6.720730304718018
Agent0_Train_MinReturn : -81.23765563964844
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 121500
Agent0_TimeSinceStart : 157.07906436920166
Agent0_Critic_Loss : 0.5835055112838745
Agent0_Actor_Loss : -0.5252723693847656
Agent0_Alpha_Loss : 0.9503120183944702
Agent0_Temperature : 0.09760916401928038
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -24.958459854125977
Agent1_Eval_StdReturn : 27.208646774291992
Agent1_Eval_MaxReturn : 24.621746063232422
Agent1_Eval_MinReturn : -60.690956115722656
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -33.3482780456543
Agent1_Train_StdReturn : 36.72779083251953
Agent1_Train_MaxReturn : 21.165443420410156
Agent1_Train_MinReturn : -120.62956237792969
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 121500
Agent1_TimeSinceStart : 158.84851360321045
Agent1_Critic_Loss : 0.518913745880127
Agent1_Actor_Loss : -0.6498725414276123
Agent1_Alpha_Loss : 0.943537175655365
Agent1_Temperature : 0.09760873286741864
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 81 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 82 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 83 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 84 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 85 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 86 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 87 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 88 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 89 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 90 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -31.816173553466797
Agent0_Eval_StdReturn : 20.06867027282715
Agent0_Eval_MaxReturn : -2.968216896057129
Agent0_Eval_MinReturn : -70.93370056152344
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -36.282325744628906
Agent0_Train_StdReturn : 26.2726993560791
Agent0_Train_MaxReturn : 3.581322193145752
Agent0_Train_MinReturn : -90.8082504272461
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 136500
Agent0_TimeSinceStart : 176.55088829994202
Agent0_Critic_Loss : 0.642711877822876
Agent0_Actor_Loss : -0.513516902923584
Agent0_Alpha_Loss : 0.9266514778137207
Agent0_Temperature : 0.0973241800307909
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -29.841506958007812
Agent1_Eval_StdReturn : 22.054649353027344
Agent1_Eval_MaxReturn : 1.825150966644287
Agent1_Eval_MinReturn : -77.45494842529297
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -38.693397521972656
Agent1_Train_StdReturn : 21.353191375732422
Agent1_Train_MaxReturn : -12.157110214233398
Agent1_Train_MinReturn : -76.73856353759766
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 136500
Agent1_TimeSinceStart : 178.3128204345703
Agent1_Critic_Loss : 0.5489075183868408
Agent1_Actor_Loss : -0.6440353393554688
Agent1_Alpha_Loss : 0.9441635608673096
Agent1_Temperature : 0.09732333462396554
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 91 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 92 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 93 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 94 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 95 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 96 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 97 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 98 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 99 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 100 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -15.971872329711914
Agent0_Eval_StdReturn : 23.232730865478516
Agent0_Eval_MaxReturn : 36.32105255126953
Agent0_Eval_MinReturn : -51.40620803833008
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -14.955472946166992
Agent0_Train_StdReturn : 7.823017597198486
Agent0_Train_MaxReturn : -4.583125114440918
Agent0_Train_MinReturn : -33.780364990234375
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 151500
Agent0_TimeSinceStart : 196.08457136154175
Agent0_Critic_Loss : 0.4893245995044708
Agent0_Actor_Loss : -0.5655577182769775
Agent0_Alpha_Loss : 0.8904958367347717
Agent0_Temperature : 0.09704442372504056
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -34.597801208496094
Agent1_Eval_StdReturn : 25.833707809448242
Agent1_Eval_MaxReturn : 5.16425895690918
Agent1_Eval_MinReturn : -83.5369873046875
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -22.46956443786621
Agent1_Train_StdReturn : 18.913043975830078
Agent1_Train_MaxReturn : 11.918903350830078
Agent1_Train_MinReturn : -49.00717544555664
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 151500
Agent1_TimeSinceStart : 197.85919451713562
Agent1_Critic_Loss : 0.5424003601074219
Agent1_Actor_Loss : -0.7103419303894043
Agent1_Alpha_Loss : 0.8896846175193787
Agent1_Temperature : 0.09704238637090877
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 101 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 102 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 103 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 104 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 105 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 106 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 107 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 108 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 109 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 110 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -25.219778060913086
Agent0_Eval_StdReturn : 7.050567626953125
Agent0_Eval_MaxReturn : -14.076716423034668
Agent0_Eval_MinReturn : -38.16297149658203
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -25.479724884033203
Agent0_Train_StdReturn : 14.440329551696777
Agent0_Train_MaxReturn : -4.266221046447754
Agent0_Train_MinReturn : -48.500640869140625
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 166500
Agent0_TimeSinceStart : 215.851975440979
Agent0_Critic_Loss : 0.42267897725105286
Agent0_Actor_Loss : -0.6505429744720459
Agent0_Alpha_Loss : 0.8280765414237976
Agent0_Temperature : 0.09677335163045972
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -27.1691951751709
Agent1_Eval_StdReturn : 18.080652236938477
Agent1_Eval_MaxReturn : 14.577960968017578
Agent1_Eval_MinReturn : -52.738792419433594
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -18.316091537475586
Agent1_Train_StdReturn : 10.535684585571289
Agent1_Train_MaxReturn : -2.3949880599975586
Agent1_Train_MinReturn : -39.09020233154297
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 166500
Agent1_TimeSinceStart : 217.64722871780396
Agent1_Critic_Loss : 0.4074627161026001
Agent1_Actor_Loss : -0.6965429186820984
Agent1_Alpha_Loss : 0.8484166860580444
Agent1_Temperature : 0.09676935401429941
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 111 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 112 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 113 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 114 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 115 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 116 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 117 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 118 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 119 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 120 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -26.1876220703125
Agent0_Eval_StdReturn : 9.185425758361816
Agent0_Eval_MaxReturn : -4.072622299194336
Agent0_Eval_MinReturn : -36.80658721923828
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -20.970348358154297
Agent0_Train_StdReturn : 7.33211088180542
Agent0_Train_MaxReturn : -9.294639587402344
Agent0_Train_MinReturn : -35.894351959228516
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 181500
Agent0_TimeSinceStart : 235.71756172180176
Agent0_Critic_Loss : 0.47973179817199707
Agent0_Actor_Loss : -0.5085757374763489
Agent0_Alpha_Loss : 0.7924610376358032
Agent0_Temperature : 0.09651302484826114
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -28.571578979492188
Agent1_Eval_StdReturn : 15.67301082611084
Agent1_Eval_MaxReturn : -6.633373260498047
Agent1_Eval_MinReturn : -49.0264892578125
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -22.619464874267578
Agent1_Train_StdReturn : 16.6622314453125
Agent1_Train_MaxReturn : 10.88422679901123
Agent1_Train_MinReturn : -49.32700729370117
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 181500
Agent1_TimeSinceStart : 237.513254404068
Agent1_Critic_Loss : 0.3865857720375061
Agent1_Actor_Loss : -0.6094276309013367
Agent1_Alpha_Loss : 0.7905857563018799
Agent1_Temperature : 0.09650630689851261
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 121 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 122 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 123 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 124 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 125 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 126 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 127 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 128 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 129 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 130 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -29.115625381469727
Agent0_Eval_StdReturn : 8.576529502868652
Agent0_Eval_MaxReturn : -15.763483047485352
Agent0_Eval_MinReturn : -40.35884475708008
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -26.51810646057129
Agent0_Train_StdReturn : 11.818973541259766
Agent0_Train_MaxReturn : -9.958226203918457
Agent0_Train_MinReturn : -52.94584655761719
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 196500
Agent0_TimeSinceStart : 255.6707100868225
Agent0_Critic_Loss : 0.47612708806991577
Agent0_Actor_Loss : -0.44914478063583374
Agent0_Alpha_Loss : 0.7840332984924316
Agent0_Temperature : 0.09626406079707081
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -27.29128074645996
Agent1_Eval_StdReturn : 13.655793190002441
Agent1_Eval_MaxReturn : -4.681344985961914
Agent1_Eval_MinReturn : -42.6507568359375
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -23.106441497802734
Agent1_Train_StdReturn : 10.708494186401367
Agent1_Train_MaxReturn : -7.691933631896973
Agent1_Train_MinReturn : -44.8114013671875
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 196500
Agent1_TimeSinceStart : 257.4782156944275
Agent1_Critic_Loss : 0.43622690439224243
Agent1_Actor_Loss : -0.5283331274986267
Agent1_Alpha_Loss : 0.7868212461471558
Agent1_Temperature : 0.09625311512311743
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 131 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 132 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 133 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 134 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 135 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 136 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 137 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 138 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 139 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 140 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -29.546222686767578
Agent0_Eval_StdReturn : 18.41615867614746
Agent0_Eval_MaxReturn : 0.7386660575866699
Agent0_Eval_MinReturn : -57.929237365722656
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -35.402950286865234
Agent0_Train_StdReturn : 7.742053985595703
Agent0_Train_MaxReturn : -24.472274780273438
Agent0_Train_MinReturn : -49.71193313598633
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 211500
Agent0_TimeSinceStart : 275.7325601577759
Agent0_Critic_Loss : 0.4160386919975281
Agent0_Actor_Loss : -0.3890208601951599
Agent0_Alpha_Loss : 0.7785576581954956
Agent0_Temperature : 0.09601954992581022
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -18.591421127319336
Agent1_Eval_StdReturn : 7.362422943115234
Agent1_Eval_MaxReturn : -4.786919593811035
Agent1_Eval_MinReturn : -31.342670440673828
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -25.78216552734375
Agent1_Train_StdReturn : 12.29578971862793
Agent1_Train_MaxReturn : -14.406673431396484
Agent1_Train_MinReturn : -53.54553985595703
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 211500
Agent1_TimeSinceStart : 277.5494728088379
Agent1_Critic_Loss : 0.3540774881839752
Agent1_Actor_Loss : -0.5932399034500122
Agent1_Alpha_Loss : 0.8204249143600464
Agent1_Temperature : 0.0960039532199791
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 141 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 142 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 143 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 144 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 145 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 146 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 147 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 148 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 149 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 150 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -36.290489196777344
Agent0_Eval_StdReturn : 12.122954368591309
Agent0_Eval_MaxReturn : -17.19602394104004
Agent0_Eval_MinReturn : -58.9616813659668
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -30.171382904052734
Agent0_Train_StdReturn : 10.661962509155273
Agent0_Train_MaxReturn : -12.430803298950195
Agent0_Train_MinReturn : -46.9097900390625
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 226500
Agent0_TimeSinceStart : 295.8952353000641
Agent0_Critic_Loss : 0.3709831237792969
Agent0_Actor_Loss : -0.449302613735199
Agent0_Alpha_Loss : 0.80012047290802
Agent0_Temperature : 0.09577423490148626
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -23.413631439208984
Agent1_Eval_StdReturn : 13.766435623168945
Agent1_Eval_MaxReturn : 3.851543426513672
Agent1_Eval_MinReturn : -43.74663543701172
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -22.44600486755371
Agent1_Train_StdReturn : 10.01215648651123
Agent1_Train_MaxReturn : -3.7045631408691406
Agent1_Train_MinReturn : -35.42446517944336
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 226500
Agent1_TimeSinceStart : 297.7143621444702
Agent1_Critic_Loss : 0.343717098236084
Agent1_Actor_Loss : -0.6993119716644287
Agent1_Alpha_Loss : 0.8084455728530884
Agent1_Temperature : 0.09575292996005902
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 151 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 152 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 153 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 154 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 155 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 156 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 157 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 158 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 159 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 160 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -28.8646183013916
Agent0_Eval_StdReturn : 10.096835136413574
Agent0_Eval_MaxReturn : -19.3649959564209
Agent0_Eval_MinReturn : -56.64392852783203
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -22.04267692565918
Agent0_Train_StdReturn : 12.488983154296875
Agent0_Train_MaxReturn : -6.148839950561523
Agent0_Train_MinReturn : -52.58303451538086
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 241500
Agent0_TimeSinceStart : 316.10994005203247
Agent0_Critic_Loss : 0.4022432565689087
Agent0_Actor_Loss : -0.4916233420372009
Agent0_Alpha_Loss : 0.8159464001655579
Agent0_Temperature : 0.09552433609581007
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -26.6223087310791
Agent1_Eval_StdReturn : 10.387969970703125
Agent1_Eval_MaxReturn : -7.464611053466797
Agent1_Eval_MinReturn : -41.601898193359375
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -21.869455337524414
Agent1_Train_StdReturn : 10.593989372253418
Agent1_Train_MaxReturn : -0.659977912902832
Agent1_Train_MinReturn : -36.14313888549805
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 241500
Agent1_TimeSinceStart : 317.94179463386536
Agent1_Critic_Loss : 0.506170392036438
Agent1_Actor_Loss : -0.6434035301208496
Agent1_Alpha_Loss : 0.8449909687042236
Agent1_Temperature : 0.09549852897058167
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 161 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 162 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 163 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 164 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 165 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 166 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 167 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 168 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 169 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 170 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -28.3478946685791
Agent0_Eval_StdReturn : 12.097359657287598
Agent0_Eval_MaxReturn : -8.141843795776367
Agent0_Eval_MinReturn : -53.37613296508789
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -20.984989166259766
Agent0_Train_StdReturn : 7.032236576080322
Agent0_Train_MaxReturn : -11.254098892211914
Agent0_Train_MinReturn : -36.411277770996094
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 256500
Agent0_TimeSinceStart : 336.411767244339
Agent0_Critic_Loss : 0.32909929752349854
Agent0_Actor_Loss : -0.2907380759716034
Agent0_Alpha_Loss : 0.805544376373291
Agent0_Temperature : 0.09527055262663903
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -26.716049194335938
Agent1_Eval_StdReturn : 18.02027702331543
Agent1_Eval_MaxReturn : -1.6649909019470215
Agent1_Eval_MinReturn : -53.732566833496094
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -21.871097564697266
Agent1_Train_StdReturn : 10.348637580871582
Agent1_Train_MaxReturn : -10.057432174682617
Agent1_Train_MinReturn : -46.746124267578125
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 256500
Agent1_TimeSinceStart : 338.2486126422882
Agent1_Critic_Loss : 0.3049764335155487
Agent1_Actor_Loss : -0.509197473526001
Agent1_Alpha_Loss : 0.8098715543746948
Agent1_Temperature : 0.09524205356263774
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 171 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 172 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 173 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 174 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 175 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 176 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 177 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 178 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 179 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 180 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -20.903034210205078
Agent0_Eval_StdReturn : 14.032318115234375
Agent0_Eval_MaxReturn : 3.3147029876708984
Agent0_Eval_MinReturn : -49.04443359375
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -20.160114288330078
Agent0_Train_StdReturn : 9.439260482788086
Agent0_Train_MaxReturn : -9.385672569274902
Agent0_Train_MinReturn : -35.05316162109375
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 271500
Agent0_TimeSinceStart : 356.77348470687866
Agent0_Critic_Loss : 0.3051438331604004
Agent0_Actor_Loss : -0.41357260942459106
Agent0_Alpha_Loss : 0.7938680052757263
Agent0_Temperature : 0.09501581242244875
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -10.24060344696045
Agent1_Eval_StdReturn : 14.10252857208252
Agent1_Eval_MaxReturn : 18.755321502685547
Agent1_Eval_MinReturn : -23.795623779296875
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -26.04498291015625
Agent1_Train_StdReturn : 7.652140140533447
Agent1_Train_MaxReturn : -12.314702987670898
Agent1_Train_MinReturn : -35.219146728515625
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 271500
Agent1_TimeSinceStart : 358.60892820358276
Agent1_Critic_Loss : 0.28917181491851807
Agent1_Actor_Loss : -0.5309678316116333
Agent1_Alpha_Loss : 0.8087109327316284
Agent1_Temperature : 0.09498527083960473
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 181 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 182 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 183 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 184 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 185 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 186 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 187 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 188 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 189 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 190 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -22.07309341430664
Agent0_Eval_StdReturn : 17.41485023498535
Agent0_Eval_MaxReturn : 16.022737503051758
Agent0_Eval_MinReturn : -53.82146453857422
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -20.78061866760254
Agent0_Train_StdReturn : 7.108293056488037
Agent0_Train_MaxReturn : -10.481598854064941
Agent0_Train_MinReturn : -34.160282135009766
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 286500
Agent0_TimeSinceStart : 377.2302665710449
Agent0_Critic_Loss : 0.3493771553039551
Agent0_Actor_Loss : -0.4460321068763733
Agent0_Alpha_Loss : 0.792611837387085
Agent0_Temperature : 0.09476177702826037
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -21.250818252563477
Agent1_Eval_StdReturn : 17.112085342407227
Agent1_Eval_MaxReturn : 2.936591148376465
Agent1_Eval_MinReturn : -57.40129470825195
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -23.527307510375977
Agent1_Train_StdReturn : 11.507820129394531
Agent1_Train_MaxReturn : -6.4306960105896
Agent1_Train_MinReturn : -44.05596923828125
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 286500
Agent1_TimeSinceStart : 379.0775234699249
Agent1_Critic_Loss : 0.2741531431674957
Agent1_Actor_Loss : -0.5251791477203369
Agent1_Alpha_Loss : 0.8031151294708252
Agent1_Temperature : 0.0947278543345802
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 191 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 192 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 193 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 194 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 195 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 196 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 197 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 198 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 199 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 200 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -22.63446044921875
Agent0_Eval_StdReturn : 18.28514289855957
Agent0_Eval_MaxReturn : 16.823040008544922
Agent0_Eval_MinReturn : -45.415611267089844
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -24.533475875854492
Agent0_Train_StdReturn : 13.873749732971191
Agent0_Train_MaxReturn : 1.956168293952942
Agent0_Train_MinReturn : -47.155662536621094
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 301500
Agent0_TimeSinceStart : 397.7046604156494
Agent0_Critic_Loss : 0.25342071056365967
Agent0_Actor_Loss : -0.3998657166957855
Agent0_Alpha_Loss : 0.8027217388153076
Agent0_Temperature : 0.0945089726878936
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -14.98442554473877
Agent1_Eval_StdReturn : 11.627592086791992
Agent1_Eval_MaxReturn : 5.136971473693848
Agent1_Eval_MinReturn : -35.057132720947266
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -30.824270248413086
Agent1_Train_StdReturn : 18.609464645385742
Agent1_Train_MaxReturn : -3.0300283432006836
Agent1_Train_MinReturn : -62.83955383300781
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 301500
Agent1_TimeSinceStart : 399.56114983558655
Agent1_Critic_Loss : 0.2948990762233734
Agent1_Actor_Loss : -0.5183458924293518
Agent1_Alpha_Loss : 0.8067147135734558
Agent1_Temperature : 0.09447066897513634
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 201 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 202 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 203 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 204 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 205 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 206 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 207 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 208 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 209 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 210 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -18.87903594970703
Agent0_Eval_StdReturn : 7.918452739715576
Agent0_Eval_MaxReturn : -9.302515029907227
Agent0_Eval_MinReturn : -32.12144470214844
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -17.578004837036133
Agent0_Train_StdReturn : 14.806057929992676
Agent0_Train_MaxReturn : 7.91201114654541
Agent0_Train_MinReturn : -40.94824981689453
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 316500
Agent0_TimeSinceStart : 418.24011635780334
Agent0_Critic_Loss : 0.2367618829011917
Agent0_Actor_Loss : -0.3572932481765747
Agent0_Alpha_Loss : 0.7698644399642944
Agent0_Temperature : 0.09425573323588293
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -15.902830123901367
Agent1_Eval_StdReturn : 11.921513557434082
Agent1_Eval_MaxReturn : 4.802982330322266
Agent1_Eval_MinReturn : -34.1939811706543
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -13.949444770812988
Agent1_Train_StdReturn : 13.60876750946045
Agent1_Train_MaxReturn : -0.8086349964141846
Agent1_Train_MinReturn : -39.97772216796875
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 316500
Agent1_TimeSinceStart : 420.0943274497986
Agent1_Critic_Loss : 0.24425888061523438
Agent1_Actor_Loss : -0.5100332498550415
Agent1_Alpha_Loss : 0.7880580425262451
Agent1_Temperature : 0.09421482217058028
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 211 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 212 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 213 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 214 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 215 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 216 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 217 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 218 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 219 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 220 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -19.852983474731445
Agent0_Eval_StdReturn : 13.062447547912598
Agent0_Eval_MaxReturn : 0.5471076965332031
Agent0_Eval_MinReturn : -44.43468475341797
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -10.51824951171875
Agent0_Train_StdReturn : 13.686287879943848
Agent0_Train_MaxReturn : 9.06671142578125
Agent0_Train_MinReturn : -43.84870529174805
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 331500
Agent0_TimeSinceStart : 438.84655141830444
Agent0_Critic_Loss : 0.22993463277816772
Agent0_Actor_Loss : -0.32326486706733704
Agent0_Alpha_Loss : 0.7727056741714478
Agent0_Temperature : 0.09400257219076734
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -13.518315315246582
Agent1_Eval_StdReturn : 8.753687858581543
Agent1_Eval_MaxReturn : -2.456515312194824
Agent1_Eval_MinReturn : -31.088951110839844
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -16.9912166595459
Agent1_Train_StdReturn : 17.14722442626953
Agent1_Train_MaxReturn : 13.464906692504883
Agent1_Train_MinReturn : -46.179771423339844
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 331500
Agent1_TimeSinceStart : 440.7153444290161
Agent1_Critic_Loss : 0.3080263137817383
Agent1_Actor_Loss : -0.49696362018585205
Agent1_Alpha_Loss : 0.7716308832168579
Agent1_Temperature : 0.09396000113583818
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 221 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 222 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 223 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 224 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 225 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 226 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 227 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 228 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 229 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 230 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -14.924173355102539
Agent0_Eval_StdReturn : 9.780835151672363
Agent0_Eval_MaxReturn : 2.5503711700439453
Agent0_Eval_MinReturn : -31.565834045410156
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -17.19369125366211
Agent0_Train_StdReturn : 12.975512504577637
Agent0_Train_MaxReturn : -0.8702702522277832
Agent0_Train_MinReturn : -43.016151428222656
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 346500
Agent0_TimeSinceStart : 459.53977489471436
Agent0_Critic_Loss : 0.29223567247390747
Agent0_Actor_Loss : -0.3110634386539459
Agent0_Alpha_Loss : 0.7835279703140259
Agent0_Temperature : 0.0937491307583831
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -20.145458221435547
Agent1_Eval_StdReturn : 24.956756591796875
Agent1_Eval_MaxReturn : 20.042255401611328
Agent1_Eval_MinReturn : -59.37761688232422
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -12.942392349243164
Agent1_Train_StdReturn : 12.004321098327637
Agent1_Train_MaxReturn : 11.952781677246094
Agent1_Train_MinReturn : -28.743526458740234
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 346500
Agent1_TimeSinceStart : 461.40892219543457
Agent1_Critic_Loss : 0.2807984948158264
Agent1_Actor_Loss : -0.5160170793533325
Agent1_Alpha_Loss : 0.8086038827896118
Agent1_Temperature : 0.09370543584577096
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 231 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 232 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 233 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 234 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 235 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 236 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 237 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 238 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 239 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 240 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -25.90419578552246
Agent0_Eval_StdReturn : 25.319076538085938
Agent0_Eval_MaxReturn : 0.1861124038696289
Agent0_Eval_MinReturn : -75.75120544433594
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -27.240936279296875
Agent0_Train_StdReturn : 11.350386619567871
Agent0_Train_MaxReturn : -11.811573028564453
Agent0_Train_MinReturn : -46.82594299316406
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 361500
Agent0_TimeSinceStart : 480.26983666419983
Agent0_Critic_Loss : 0.23605187237262726
Agent0_Actor_Loss : -0.3597260117530823
Agent0_Alpha_Loss : 0.8051731586456299
Agent0_Temperature : 0.09349390746452166
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -26.179798126220703
Agent1_Eval_StdReturn : 14.059050559997559
Agent1_Eval_MaxReturn : -5.650448799133301
Agent1_Eval_MinReturn : -46.27350616455078
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -34.50747299194336
Agent1_Train_StdReturn : 15.769944190979004
Agent1_Train_MaxReturn : -10.437248229980469
Agent1_Train_MinReturn : -64.09263610839844
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 361500
Agent1_TimeSinceStart : 482.13782143592834
Agent1_Critic_Loss : 0.2416575849056244
Agent1_Actor_Loss : -0.5448768138885498
Agent1_Alpha_Loss : 0.8088729381561279
Agent1_Temperature : 0.09344887388935827
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 241 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 242 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 243 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 244 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 245 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 246 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 247 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 248 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 249 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 250 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -32.3735466003418
Agent0_Eval_StdReturn : 23.46923828125
Agent0_Eval_MaxReturn : -3.795340061187744
Agent0_Eval_MinReturn : -66.66313171386719
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -23.691837310791016
Agent0_Train_StdReturn : 21.325847625732422
Agent0_Train_MaxReturn : 0.9577248096466064
Agent0_Train_MinReturn : -76.80816650390625
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 376500
Agent0_TimeSinceStart : 501.03020119667053
Agent0_Critic_Loss : 0.2850643992424011
Agent0_Actor_Loss : -0.40922874212265015
Agent0_Alpha_Loss : 0.7994428873062134
Agent0_Temperature : 0.09323730557665216
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -18.46457862854004
Agent1_Eval_StdReturn : 17.27296257019043
Agent1_Eval_MaxReturn : 7.694613456726074
Agent1_Eval_MinReturn : -46.92676544189453
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -18.39484977722168
Agent1_Train_StdReturn : 15.374832153320312
Agent1_Train_MaxReturn : 11.0388822555542
Agent1_Train_MinReturn : -37.22166442871094
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 376500
Agent1_TimeSinceStart : 502.9115500450134
Agent1_Critic_Loss : 0.20400278270244598
Agent1_Actor_Loss : -0.5923650860786438
Agent1_Alpha_Loss : 0.8086287975311279
Agent1_Temperature : 0.09319086599320837
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 251 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 252 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 253 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 254 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 255 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 256 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 257 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 258 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 259 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 260 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -16.169286727905273
Agent0_Eval_StdReturn : 18.694875717163086
Agent0_Eval_MaxReturn : 17.32999610900879
Agent0_Eval_MinReturn : -39.41497039794922
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -27.217754364013672
Agent0_Train_StdReturn : 22.933446884155273
Agent0_Train_MaxReturn : 16.09127426147461
Agent0_Train_MinReturn : -65.10749816894531
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 391500
Agent0_TimeSinceStart : 521.8427772521973
Agent0_Critic_Loss : 0.26176387071609497
Agent0_Actor_Loss : -0.36986789107322693
Agent0_Alpha_Loss : 0.8022457957267761
Agent0_Temperature : 0.09298062918509852
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -28.7261962890625
Agent1_Eval_StdReturn : 14.294690132141113
Agent1_Eval_MaxReturn : -4.822025299072266
Agent1_Eval_MinReturn : -44.01750183105469
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -14.6421480178833
Agent1_Train_StdReturn : 18.195409774780273
Agent1_Train_MaxReturn : 12.734899520874023
Agent1_Train_MinReturn : -41.474700927734375
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 391500
Agent1_TimeSinceStart : 523.7203834056854
Agent1_Critic_Loss : 0.34178680181503296
Agent1_Actor_Loss : -0.5325272679328918
Agent1_Alpha_Loss : 0.7996779680252075
Agent1_Temperature : 0.09293297388760471
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 261 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 262 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 263 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 264 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 265 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 266 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 267 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 268 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 269 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 270 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -8.830592155456543
Agent0_Eval_StdReturn : 23.973060607910156
Agent0_Eval_MaxReturn : 37.04143524169922
Agent0_Eval_MinReturn : -38.170684814453125
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -17.002735137939453
Agent0_Train_StdReturn : 23.8173770904541
Agent0_Train_MaxReturn : 24.592941284179688
Agent0_Train_MinReturn : -72.58917999267578
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 406500
Agent0_TimeSinceStart : 542.6548237800598
Agent0_Critic_Loss : 0.2818711996078491
Agent0_Actor_Loss : -0.38809651136398315
Agent0_Alpha_Loss : 0.8022894263267517
Agent0_Temperature : 0.09272166702710759
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -14.469942092895508
Agent1_Eval_StdReturn : 15.369505882263184
Agent1_Eval_MaxReturn : 8.262344360351562
Agent1_Eval_MinReturn : -44.58076477050781
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -34.48859405517578
Agent1_Train_StdReturn : 10.63591480255127
Agent1_Train_MaxReturn : -19.773975372314453
Agent1_Train_MinReturn : -49.332862854003906
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 406500
Agent1_TimeSinceStart : 544.5366389751434
Agent1_Critic_Loss : 0.3110955059528351
Agent1_Actor_Loss : -0.5391139984130859
Agent1_Alpha_Loss : 0.7952686548233032
Agent1_Temperature : 0.09267566039814082
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 271 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 272 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 273 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 274 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 275 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 276 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 277 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 278 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 279 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 280 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -29.437118530273438
Agent0_Eval_StdReturn : 20.271406173706055
Agent0_Eval_MaxReturn : 10.233766555786133
Agent0_Eval_MinReturn : -58.559478759765625
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -31.374256134033203
Agent0_Train_StdReturn : 15.896149635314941
Agent0_Train_MaxReturn : -7.286345481872559
Agent0_Train_MinReturn : -59.03761672973633
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 421500
Agent0_TimeSinceStart : 563.5055584907532
Agent0_Critic_Loss : 0.28867489099502563
Agent0_Actor_Loss : -0.5071629285812378
Agent0_Alpha_Loss : 0.7861278057098389
Agent0_Temperature : 0.09246285321439318
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -10.922975540161133
Agent1_Eval_StdReturn : 14.061430931091309
Agent1_Eval_MaxReturn : 20.354406356811523
Agent1_Eval_MinReturn : -27.05632972717285
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -20.547046661376953
Agent1_Train_StdReturn : 12.871415138244629
Agent1_Train_MaxReturn : -2.233945846557617
Agent1_Train_MinReturn : -48.56040954589844
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 421500
Agent1_TimeSinceStart : 565.3925993442535
Agent1_Critic_Loss : 0.3357458710670471
Agent1_Actor_Loss : -0.5688297748565674
Agent1_Alpha_Loss : 0.8170811533927917
Agent1_Temperature : 0.09241842820853413
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 281 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 282 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 283 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 284 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 285 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 286 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 287 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 288 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 289 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 290 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -21.71173858642578
Agent0_Eval_StdReturn : 20.16192054748535
Agent0_Eval_MaxReturn : 8.067686080932617
Agent0_Eval_MinReturn : -60.01726531982422
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -12.716248512268066
Agent0_Train_StdReturn : 15.684078216552734
Agent0_Train_MaxReturn : 13.780726432800293
Agent0_Train_MinReturn : -39.08708572387695
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 436500
Agent0_TimeSinceStart : 584.3384535312653
Agent0_Critic_Loss : 0.36568909883499146
Agent0_Actor_Loss : -0.4024902582168579
Agent0_Alpha_Loss : 0.7912461757659912
Agent0_Temperature : 0.09220505289547207
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -18.578733444213867
Agent1_Eval_StdReturn : 20.833667755126953
Agent1_Eval_MaxReturn : 10.416316986083984
Agent1_Eval_MinReturn : -47.876953125
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -9.056354522705078
Agent1_Train_StdReturn : 20.778688430786133
Agent1_Train_MaxReturn : 30.503755569458008
Agent1_Train_MinReturn : -57.969764709472656
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 436500
Agent1_TimeSinceStart : 586.2252404689789
Agent1_Critic_Loss : 0.3315914273262024
Agent1_Actor_Loss : -0.5646544694900513
Agent1_Alpha_Loss : 0.8037965297698975
Agent1_Temperature : 0.09216186992626155
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 291 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 292 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 293 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 294 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 295 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 296 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 297 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 298 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 299 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 300 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -34.59016799926758
Agent0_Eval_StdReturn : 21.419849395751953
Agent0_Eval_MaxReturn : 6.754779815673828
Agent0_Eval_MinReturn : -64.0755844116211
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -33.80540084838867
Agent0_Train_StdReturn : 21.685056686401367
Agent0_Train_MaxReturn : 17.6574764251709
Agent0_Train_MinReturn : -59.10113525390625
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 451500
Agent0_TimeSinceStart : 605.2391273975372
Agent0_Critic_Loss : 0.4129416346549988
Agent0_Actor_Loss : -0.49102622270584106
Agent0_Alpha_Loss : 0.796013355255127
Agent0_Temperature : 0.09194853124628809
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -10.005633354187012
Agent1_Eval_StdReturn : 12.078459739685059
Agent1_Eval_MaxReturn : 3.9682111740112305
Agent1_Eval_MinReturn : -35.50504684448242
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -20.95986557006836
Agent1_Train_StdReturn : 22.98246192932129
Agent1_Train_MaxReturn : 12.024311065673828
Agent1_Train_MinReturn : -64.5975570678711
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 451500
Agent1_TimeSinceStart : 607.1321306228638
Agent1_Critic_Loss : 0.34250202775001526
Agent1_Actor_Loss : -0.7133606672286987
Agent1_Alpha_Loss : 0.8033043146133423
Agent1_Temperature : 0.09190538604575317
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 301 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 302 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 303 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 304 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 305 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 306 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 307 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 308 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 309 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 310 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -23.66707420349121
Agent0_Eval_StdReturn : 27.774991989135742
Agent0_Eval_MaxReturn : 49.110782623291016
Agent0_Eval_MinReturn : -54.02532958984375
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -10.997737884521484
Agent0_Train_StdReturn : 14.079773902893066
Agent0_Train_MaxReturn : 12.485090255737305
Agent0_Train_MinReturn : -33.356773376464844
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 466500
Agent0_TimeSinceStart : 626.237850189209
Agent0_Critic_Loss : 0.3596513867378235
Agent0_Actor_Loss : -0.44656991958618164
Agent0_Alpha_Loss : 0.7941880226135254
Agent0_Temperature : 0.09169201659203208
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -17.326358795166016
Agent1_Eval_StdReturn : 12.931768417358398
Agent1_Eval_MaxReturn : 7.1074981689453125
Agent1_Eval_MinReturn : -39.98247528076172
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -16.466020584106445
Agent1_Train_StdReturn : 15.030253410339355
Agent1_Train_MaxReturn : 1.9387803077697754
Agent1_Train_MinReturn : -52.482086181640625
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 466500
Agent1_TimeSinceStart : 628.1414203643799
Agent1_Critic_Loss : 0.3420843482017517
Agent1_Actor_Loss : -0.5461178421974182
Agent1_Alpha_Loss : 0.7913745641708374
Agent1_Temperature : 0.09164863405718413
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 311 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 312 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 313 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 314 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 315 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 316 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 317 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 318 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 319 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 320 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -31.417682647705078
Agent0_Eval_StdReturn : 28.419633865356445
Agent0_Eval_MaxReturn : 19.038705825805664
Agent0_Eval_MinReturn : -82.7593994140625
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -22.13536262512207
Agent0_Train_StdReturn : 20.31511116027832
Agent0_Train_MaxReturn : 13.119131088256836
Agent0_Train_MinReturn : -68.36769104003906
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 481500
Agent0_TimeSinceStart : 647.2783689498901
Agent0_Critic_Loss : 0.29098325967788696
Agent0_Actor_Loss : -0.5146277546882629
Agent0_Alpha_Loss : 0.8125776052474976
Agent0_Temperature : 0.09143475735888251
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -17.696311950683594
Agent1_Eval_StdReturn : 14.26098918914795
Agent1_Eval_MaxReturn : -2.1612377166748047
Agent1_Eval_MinReturn : -44.31068420410156
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -21.889663696289062
Agent1_Train_StdReturn : 17.780359268188477
Agent1_Train_MaxReturn : 14.946634292602539
Agent1_Train_MinReturn : -44.348960876464844
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 481500
Agent1_TimeSinceStart : 649.1857762336731
Agent1_Critic_Loss : 0.3347543478012085
Agent1_Actor_Loss : -0.530648946762085
Agent1_Alpha_Loss : 0.7899632453918457
Agent1_Temperature : 0.09139414588491951
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 321 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 322 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 323 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 324 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 325 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 326 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 327 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 328 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 329 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 330 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -13.853536605834961
Agent0_Eval_StdReturn : 10.978808403015137
Agent0_Eval_MaxReturn : 1.097726583480835
Agent0_Eval_MinReturn : -39.02105712890625
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -21.37209129333496
Agent0_Train_StdReturn : 12.435802459716797
Agent0_Train_MaxReturn : 2.9026975631713867
Agent0_Train_MinReturn : -37.473655700683594
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 496500
Agent0_TimeSinceStart : 668.3846950531006
Agent0_Critic_Loss : 0.364053338766098
Agent0_Actor_Loss : -0.43641215562820435
Agent0_Alpha_Loss : 0.7984566688537598
Agent0_Temperature : 0.09117750254860199
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -28.643169403076172
Agent1_Eval_StdReturn : 12.299561500549316
Agent1_Eval_MaxReturn : -0.6921176910400391
Agent1_Eval_MinReturn : -45.07029342651367
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -13.716038703918457
Agent1_Train_StdReturn : 13.222245216369629
Agent1_Train_MaxReturn : 13.246891021728516
Agent1_Train_MinReturn : -37.61188507080078
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 496500
Agent1_TimeSinceStart : 670.3024034500122
Agent1_Critic_Loss : 0.30364638566970825
Agent1_Actor_Loss : -0.5524756908416748
Agent1_Alpha_Loss : 0.7668384909629822
Agent1_Temperature : 0.0911413077359803
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 331 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 332 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 333 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 334 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 335 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 336 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 337 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 338 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 339 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 340 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -16.699501037597656
Agent0_Eval_StdReturn : 9.909378051757812
Agent0_Eval_MaxReturn : 1.2883856296539307
Agent0_Eval_MinReturn : -29.67685890197754
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -21.01651954650879
Agent0_Train_StdReturn : 19.729534149169922
Agent0_Train_MaxReturn : 17.028488159179688
Agent0_Train_MinReturn : -47.02600860595703
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 511500
Agent0_TimeSinceStart : 689.6058554649353
Agent0_Critic_Loss : 0.3548048734664917
Agent0_Actor_Loss : -0.4590376615524292
Agent0_Alpha_Loss : 0.7978923320770264
Agent0_Temperature : 0.09092027129809074
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -22.357769012451172
Agent1_Eval_StdReturn : 11.360347747802734
Agent1_Eval_MaxReturn : -4.440496444702148
Agent1_Eval_MinReturn : -38.65544891357422
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -21.732654571533203
Agent1_Train_StdReturn : 18.92816162109375
Agent1_Train_MaxReturn : -0.8032045364379883
Agent1_Train_MinReturn : -55.81163787841797
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 511500
Agent1_TimeSinceStart : 691.5172843933105
Agent1_Critic_Loss : 0.3377198576927185
Agent1_Actor_Loss : -0.6431119441986084
Agent1_Alpha_Loss : 0.7759073972702026
Agent1_Temperature : 0.0908904100462731
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 341 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 342 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 343 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 344 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 345 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 346 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 347 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 348 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 349 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 350 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -4.153913497924805
Agent0_Eval_StdReturn : 12.193614959716797
Agent0_Eval_MaxReturn : 21.66075325012207
Agent0_Eval_MinReturn : -21.997146606445312
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -14.222528457641602
Agent0_Train_StdReturn : 14.218676567077637
Agent0_Train_MaxReturn : 14.104767799377441
Agent0_Train_MinReturn : -39.28284454345703
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 526500
Agent0_TimeSinceStart : 710.8119065761566
Agent0_Critic_Loss : 0.34077340364456177
Agent0_Actor_Loss : -0.5019431114196777
Agent0_Alpha_Loss : 0.7869362831115723
Agent0_Temperature : 0.09066433068811589
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -13.386344909667969
Agent1_Eval_StdReturn : 19.744380950927734
Agent1_Eval_MaxReturn : 8.834539413452148
Agent1_Eval_MinReturn : -65.77220153808594
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -8.794768333435059
Agent1_Train_StdReturn : 18.36956787109375
Agent1_Train_MaxReturn : 23.716754913330078
Agent1_Train_MinReturn : -47.69325637817383
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 526500
Agent1_TimeSinceStart : 712.7343831062317
Agent1_Critic_Loss : 0.3689189553260803
Agent1_Actor_Loss : -0.6566136479377747
Agent1_Alpha_Loss : 0.7724124193191528
Agent1_Temperature : 0.09063995155955484
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 351 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 352 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 353 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 354 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 355 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 356 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 357 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 358 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 359 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 360 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -16.44986343383789
Agent0_Eval_StdReturn : 15.780421257019043
Agent0_Eval_MaxReturn : 9.349910736083984
Agent0_Eval_MinReturn : -41.21128463745117
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -17.655296325683594
Agent0_Train_StdReturn : 23.781408309936523
Agent0_Train_MaxReturn : 15.003175735473633
Agent0_Train_MinReturn : -72.5113754272461
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 541500
Agent0_TimeSinceStart : 732.0401847362518
Agent0_Critic_Loss : 0.39002901315689087
Agent0_Actor_Loss : -0.4405617117881775
Agent0_Alpha_Loss : 0.7692112922668457
Agent0_Temperature : 0.09041051134873464
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -25.666629791259766
Agent1_Eval_StdReturn : 18.788358688354492
Agent1_Eval_MaxReturn : 0.9185059070587158
Agent1_Eval_MinReturn : -63.547035217285156
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -21.906633377075195
Agent1_Train_StdReturn : 17.64780616760254
Agent1_Train_MaxReturn : 3.2173635959625244
Agent1_Train_MinReturn : -57.8816032409668
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 541500
Agent1_TimeSinceStart : 733.9575321674347
Agent1_Critic_Loss : 0.4044039249420166
Agent1_Actor_Loss : -0.6130666732788086
Agent1_Alpha_Loss : 0.7905219793319702
Agent1_Temperature : 0.09038983668668177
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 361 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 362 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 363 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 364 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 365 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 366 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 367 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 368 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 369 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 370 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -11.848169326782227
Agent0_Eval_StdReturn : 14.4962797164917
Agent0_Eval_MaxReturn : 19.852718353271484
Agent0_Eval_MinReturn : -33.47821044921875
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -18.74610710144043
Agent0_Train_StdReturn : 13.413089752197266
Agent0_Train_MaxReturn : -0.6261987686157227
Agent0_Train_MinReturn : -41.45829391479492
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 556500
Agent0_TimeSinceStart : 753.2812507152557
Agent0_Critic_Loss : 0.37975212931632996
Agent0_Actor_Loss : -0.48528385162353516
Agent0_Alpha_Loss : 0.7741063833236694
Agent0_Temperature : 0.09015817034974007
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -21.17336654663086
Agent1_Eval_StdReturn : 12.437556266784668
Agent1_Eval_MaxReturn : -4.257059097290039
Agent1_Eval_MinReturn : -46.392066955566406
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -24.025014877319336
Agent1_Train_StdReturn : 11.52939510345459
Agent1_Train_MaxReturn : 1.300985336303711
Agent1_Train_MinReturn : -42.473731994628906
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 556500
Agent1_TimeSinceStart : 755.2054183483124
Agent1_Critic_Loss : 0.3060595989227295
Agent1_Actor_Loss : -0.566693902015686
Agent1_Alpha_Loss : 0.7835659980773926
Agent1_Temperature : 0.09013892324698351
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 371 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 372 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 373 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 374 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 375 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 376 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 377 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 378 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 379 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 380 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -17.205615997314453
Agent0_Eval_StdReturn : 17.84322738647461
Agent0_Eval_MaxReturn : 10.081826210021973
Agent0_Eval_MinReturn : -45.98017883300781
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -21.011051177978516
Agent0_Train_StdReturn : 19.58672523498535
Agent0_Train_MaxReturn : 5.105833530426025
Agent0_Train_MinReturn : -70.44924926757812
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 571500
Agent0_TimeSinceStart : 774.5847904682159
Agent0_Critic_Loss : 0.3739166855812073
Agent0_Actor_Loss : -0.5036987662315369
Agent0_Alpha_Loss : 0.7726805806159973
Agent0_Temperature : 0.08990801559716165
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -18.540536880493164
Agent1_Eval_StdReturn : 15.035844802856445
Agent1_Eval_MaxReturn : 10.492572784423828
Agent1_Eval_MinReturn : -43.19024658203125
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -18.82219886779785
Agent1_Train_StdReturn : 11.81616497039795
Agent1_Train_MaxReturn : -1.5960254669189453
Agent1_Train_MinReturn : -47.12820053100586
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 571500
Agent1_TimeSinceStart : 776.5142097473145
Agent1_Critic_Loss : 0.3474060297012329
Agent1_Actor_Loss : -0.596429705619812
Agent1_Alpha_Loss : 0.7833575010299683
Agent1_Temperature : 0.08988793224384166
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 381 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 382 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 383 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 384 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 385 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 386 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 387 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 388 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 389 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 390 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -20.137584686279297
Agent0_Eval_StdReturn : 13.073507308959961
Agent0_Eval_MaxReturn : -0.683132529258728
Agent0_Eval_MinReturn : -50.57395935058594
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -11.995019912719727
Agent0_Train_StdReturn : 10.08627700805664
Agent0_Train_MaxReturn : 4.721505165100098
Agent0_Train_MinReturn : -28.57563591003418
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 586500
Agent0_TimeSinceStart : 795.9799644947052
Agent0_Critic_Loss : 0.3902644217014313
Agent0_Actor_Loss : -0.4018877148628235
Agent0_Alpha_Loss : 0.7900694012641907
Agent0_Temperature : 0.08965989056868252
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -17.409055709838867
Agent1_Eval_StdReturn : 13.260212898254395
Agent1_Eval_MaxReturn : 4.634934425354004
Agent1_Eval_MinReturn : -36.963802337646484
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -17.839876174926758
Agent1_Train_StdReturn : 10.526339530944824
Agent1_Train_MaxReturn : 7.396707534790039
Agent1_Train_MinReturn : -30.656475067138672
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 586500
Agent1_TimeSinceStart : 797.9171953201294
Agent1_Critic_Loss : 0.43882375955581665
Agent1_Actor_Loss : -0.5723514556884766
Agent1_Alpha_Loss : 0.7577643990516663
Agent1_Temperature : 0.08963883002653408
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 391 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 392 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 393 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 394 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 395 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 396 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 397 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 398 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 399 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 400 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -17.62435531616211
Agent0_Eval_StdReturn : 18.412839889526367
Agent0_Eval_MaxReturn : 13.095370292663574
Agent0_Eval_MinReturn : -38.604087829589844
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -22.292800903320312
Agent0_Train_StdReturn : 18.095966339111328
Agent0_Train_MaxReturn : 2.425783157348633
Agent0_Train_MinReturn : -54.41737365722656
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 601500
Agent0_TimeSinceStart : 817.3553600311279
Agent0_Critic_Loss : 0.39566004276275635
Agent0_Actor_Loss : -0.3166046738624573
Agent0_Alpha_Loss : 0.769904375076294
Agent0_Temperature : 0.08941200655405554
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -16.353412628173828
Agent1_Eval_StdReturn : 11.514243125915527
Agent1_Eval_MaxReturn : 9.819938659667969
Agent1_Eval_MinReturn : -30.96038055419922
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -19.040437698364258
Agent1_Train_StdReturn : 12.022290229797363
Agent1_Train_MaxReturn : -1.4261598587036133
Agent1_Train_MinReturn : -46.15287399291992
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 601500
Agent1_TimeSinceStart : 819.2856957912445
Agent1_Critic_Loss : 0.3825071156024933
Agent1_Actor_Loss : -0.6050965189933777
Agent1_Alpha_Loss : 0.7576438188552856
Agent1_Temperature : 0.08939212123128376
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 401 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 402 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 403 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 404 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 405 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 406 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 407 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 408 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 409 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 410 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -19.976444244384766
Agent0_Eval_StdReturn : 21.967714309692383
Agent0_Eval_MaxReturn : 0.9853954315185547
Agent0_Eval_MinReturn : -76.84526062011719
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -16.282039642333984
Agent0_Train_StdReturn : 13.395174026489258
Agent0_Train_MaxReturn : -2.58232045173645
Agent0_Train_MinReturn : -45.96685028076172
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 616500
Agent0_TimeSinceStart : 838.7264592647552
Agent0_Critic_Loss : 0.3884899914264679
Agent0_Actor_Loss : -0.3891936242580414
Agent0_Alpha_Loss : 0.7911587953567505
Agent0_Temperature : 0.08916457549145464
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -19.632448196411133
Agent1_Eval_StdReturn : 16.680057525634766
Agent1_Eval_MaxReturn : -2.3615670204162598
Agent1_Eval_MinReturn : -66.13249969482422
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -14.008397102355957
Agent1_Train_StdReturn : 14.737716674804688
Agent1_Train_MaxReturn : 13.702550888061523
Agent1_Train_MinReturn : -35.670310974121094
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 616500
Agent1_TimeSinceStart : 840.6651430130005
Agent1_Critic_Loss : 0.39274489879608154
Agent1_Actor_Loss : -0.6214008331298828
Agent1_Alpha_Loss : 0.760277509689331
Agent1_Temperature : 0.08914685960371213
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 411 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 412 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 413 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 414 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 415 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 416 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 417 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 418 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 419 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 420 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -19.600772857666016
Agent0_Eval_StdReturn : 11.237957000732422
Agent0_Eval_MaxReturn : 0.44670701026916504
Agent0_Eval_MinReturn : -41.458648681640625
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -15.6837739944458
Agent0_Train_StdReturn : 15.869152069091797
Agent0_Train_MaxReturn : 18.90491485595703
Agent0_Train_MinReturn : -39.85868453979492
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 631500
Agent0_TimeSinceStart : 860.0768001079559
Agent0_Critic_Loss : 0.4036877751350403
Agent0_Actor_Loss : -0.49033477902412415
Agent0_Alpha_Loss : 0.7720290422439575
Agent0_Temperature : 0.0889152114329401
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -12.742067337036133
Agent1_Eval_StdReturn : 14.053691864013672
Agent1_Eval_MaxReturn : 20.04946517944336
Agent1_Eval_MinReturn : -27.94371223449707
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -19.853849411010742
Agent1_Train_StdReturn : 18.55593490600586
Agent1_Train_MaxReturn : 11.074519157409668
Agent1_Train_MinReturn : -55.2587890625
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 631500
Agent1_TimeSinceStart : 862.0058152675629
Agent1_Critic_Loss : 0.41961216926574707
Agent1_Actor_Loss : -0.525293231010437
Agent1_Alpha_Loss : 0.7829804420471191
Agent1_Temperature : 0.08890076673768592
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 421 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 422 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 423 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 424 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 425 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 426 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 427 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 428 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 429 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 430 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -18.859359741210938
Agent0_Eval_StdReturn : 16.78538703918457
Agent0_Eval_MaxReturn : -1.0152215957641602
Agent0_Eval_MinReturn : -52.45621871948242
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -14.761053085327148
Agent0_Train_StdReturn : 14.811735153198242
Agent0_Train_MaxReturn : 2.9678471088409424
Agent0_Train_MinReturn : -38.066322326660156
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 646500
Agent0_TimeSinceStart : 881.4553167819977
Agent0_Critic_Loss : 0.39037036895751953
Agent0_Actor_Loss : -0.6049894094467163
Agent0_Alpha_Loss : 0.779627799987793
Agent0_Temperature : 0.08866467462090748
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -14.896084785461426
Agent1_Eval_StdReturn : 16.43863296508789
Agent1_Eval_MaxReturn : 23.345733642578125
Agent1_Eval_MinReturn : -33.608543395996094
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -14.448293685913086
Agent1_Train_StdReturn : 13.875933647155762
Agent1_Train_MaxReturn : 8.857091903686523
Agent1_Train_MinReturn : -39.956787109375
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 646500
Agent1_TimeSinceStart : 883.3853077888489
Agent1_Critic_Loss : 0.45110681653022766
Agent1_Actor_Loss : -0.6109698414802551
Agent1_Alpha_Loss : 0.7768856287002563
Agent1_Temperature : 0.08865400535421578
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 431 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 432 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 433 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 434 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 435 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 436 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 437 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 438 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 439 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 440 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -13.227884292602539
Agent0_Eval_StdReturn : 15.364706993103027
Agent0_Eval_MaxReturn : 23.924396514892578
Agent0_Eval_MinReturn : -28.492385864257812
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -19.591472625732422
Agent0_Train_StdReturn : 20.840801239013672
Agent0_Train_MaxReturn : 14.157011985778809
Agent0_Train_MinReturn : -61.999847412109375
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 661500
Agent0_TimeSinceStart : 902.8354535102844
Agent0_Critic_Loss : 0.46709296107292175
Agent0_Actor_Loss : -0.7017835974693298
Agent0_Alpha_Loss : 0.7942085862159729
Agent0_Temperature : 0.08841460475468842
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -13.075879096984863
Agent1_Eval_StdReturn : 20.52445411682129
Agent1_Eval_MaxReturn : 12.46137523651123
Agent1_Eval_MinReturn : -51.30586242675781
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -22.693880081176758
Agent1_Train_StdReturn : 22.451892852783203
Agent1_Train_MaxReturn : 10.459871292114258
Agent1_Train_MinReturn : -63.16377258300781
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 661500
Agent1_TimeSinceStart : 904.7677223682404
Agent1_Critic_Loss : 0.38806796073913574
Agent1_Actor_Loss : -0.524726152420044
Agent1_Alpha_Loss : 0.7926880121231079
Agent1_Temperature : 0.08840570352979484
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 441 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 442 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 443 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 444 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 445 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 446 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 447 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 448 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 449 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 450 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -19.42804718017578
Agent0_Eval_StdReturn : 25.699687957763672
Agent0_Eval_MaxReturn : 22.035892486572266
Agent0_Eval_MinReturn : -56.99649429321289
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -15.820162773132324
Agent0_Train_StdReturn : 20.13653564453125
Agent0_Train_MaxReturn : 19.937034606933594
Agent0_Train_MinReturn : -45.627479553222656
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 676500
Agent0_TimeSinceStart : 924.2944316864014
Agent0_Critic_Loss : 0.40684232115745544
Agent0_Actor_Loss : -0.48494261503219604
Agent0_Alpha_Loss : 0.7726725339889526
Agent0_Temperature : 0.08816531436393063
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -13.033653259277344
Agent1_Eval_StdReturn : 10.772171974182129
Agent1_Eval_MaxReturn : 8.231582641601562
Agent1_Eval_MinReturn : -28.726879119873047
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -13.276847839355469
Agent1_Train_StdReturn : 11.299575805664062
Agent1_Train_MaxReturn : 10.525200843811035
Agent1_Train_MinReturn : -25.208179473876953
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 676500
Agent1_TimeSinceStart : 926.2336761951447
Agent1_Critic_Loss : 0.3484123945236206
Agent1_Actor_Loss : -0.6895925998687744
Agent1_Alpha_Loss : 0.7883237600326538
Agent1_Temperature : 0.0881571810036805
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 451 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 452 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 453 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 454 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 455 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 456 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 457 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 458 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 459 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 460 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -20.875125885009766
Agent0_Eval_StdReturn : 23.436134338378906
Agent0_Eval_MaxReturn : 14.034128189086914
Agent0_Eval_MinReturn : -71.99649047851562
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -19.717660903930664
Agent0_Train_StdReturn : 15.26095199584961
Agent0_Train_MaxReturn : 9.128549575805664
Agent0_Train_MinReturn : -35.50041198730469
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 691500
Agent0_TimeSinceStart : 945.7470135688782
Agent0_Critic_Loss : 0.3935311436653137
Agent0_Actor_Loss : -0.551895260810852
Agent0_Alpha_Loss : 0.7881442308425903
Agent0_Temperature : 0.08791563422130853
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -14.918339729309082
Agent1_Eval_StdReturn : 19.501955032348633
Agent1_Eval_MaxReturn : 21.53673553466797
Agent1_Eval_MinReturn : -43.60742950439453
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -9.23992919921875
Agent1_Train_StdReturn : 10.54200267791748
Agent1_Train_MaxReturn : 9.749228477478027
Agent1_Train_MinReturn : -22.846637725830078
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 691500
Agent1_TimeSinceStart : 947.6863696575165
Agent1_Critic_Loss : 0.5095545649528503
Agent1_Actor_Loss : -0.6350686550140381
Agent1_Alpha_Loss : 0.7856808304786682
Agent1_Temperature : 0.08790930751343
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 461 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 462 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 463 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 464 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 465 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 466 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 467 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 468 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 469 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 470 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -14.931729316711426
Agent0_Eval_StdReturn : 17.193357467651367
Agent0_Eval_MaxReturn : 2.019618511199951
Agent0_Eval_MinReturn : -58.25473403930664
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -21.851428985595703
Agent0_Train_StdReturn : 19.9017276763916
Agent0_Train_MaxReturn : 15.214674949645996
Agent0_Train_MinReturn : -50.060157775878906
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 706500
Agent0_TimeSinceStart : 967.1840229034424
Agent0_Critic_Loss : 0.39611005783081055
Agent0_Actor_Loss : -0.5248307585716248
Agent0_Alpha_Loss : 0.7838223576545715
Agent0_Temperature : 0.08766508926548162
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -18.742097854614258
Agent1_Eval_StdReturn : 17.17107391357422
Agent1_Eval_MaxReturn : 9.221521377563477
Agent1_Eval_MinReturn : -40.96721267700195
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -25.33680534362793
Agent1_Train_StdReturn : 12.94883918762207
Agent1_Train_MaxReturn : -6.701727867126465
Agent1_Train_MinReturn : -44.2752571105957
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 706500
Agent1_TimeSinceStart : 969.1120185852051
Agent1_Critic_Loss : 0.3334636092185974
Agent1_Actor_Loss : -0.5242506861686707
Agent1_Alpha_Loss : 0.7774423360824585
Agent1_Temperature : 0.08766237886004485
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 471 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 472 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 473 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 474 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 475 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 476 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 477 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 478 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 479 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 480 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -23.78609275817871
Agent0_Eval_StdReturn : 18.49661636352539
Agent0_Eval_MaxReturn : 0.9484844207763672
Agent0_Eval_MinReturn : -51.99486541748047
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -12.40347671508789
Agent0_Train_StdReturn : 15.29958438873291
Agent0_Train_MaxReturn : 12.419658660888672
Agent0_Train_MinReturn : -39.66883850097656
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 721500
Agent0_TimeSinceStart : 988.6510560512543
Agent0_Critic_Loss : 0.3393387794494629
Agent0_Actor_Loss : -0.5197559595108032
Agent0_Alpha_Loss : 0.7707560062408447
Agent0_Temperature : 0.08741485047024433
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -10.29857063293457
Agent1_Eval_StdReturn : 12.376964569091797
Agent1_Eval_MaxReturn : 7.8498663902282715
Agent1_Eval_MinReturn : -31.393306732177734
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -15.596531867980957
Agent1_Train_StdReturn : 21.202184677124023
Agent1_Train_MaxReturn : 8.717048645019531
Agent1_Train_MinReturn : -56.5689697265625
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 721500
Agent1_TimeSinceStart : 990.5943219661713
Agent1_Critic_Loss : 0.38059645891189575
Agent1_Actor_Loss : -0.6510242223739624
Agent1_Alpha_Loss : 0.7745919227600098
Agent1_Temperature : 0.08741458597638774
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 481 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 482 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 483 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 484 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 485 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 486 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 487 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 488 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 489 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 490 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -20.412885665893555
Agent0_Eval_StdReturn : 30.73226547241211
Agent0_Eval_MaxReturn : 14.237833023071289
Agent0_Eval_MinReturn : -80.90066528320312
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -16.785369873046875
Agent0_Train_StdReturn : 12.144124984741211
Agent0_Train_MaxReturn : 2.1561331748962402
Agent0_Train_MinReturn : -41.600547790527344
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 736500
Agent0_TimeSinceStart : 1010.1329102516174
Agent0_Critic_Loss : 0.4278745651245117
Agent0_Actor_Loss : -0.5988946557044983
Agent0_Alpha_Loss : 0.7916018962860107
Agent0_Temperature : 0.08716571562196235
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -18.930660247802734
Agent1_Eval_StdReturn : 19.136878967285156
Agent1_Eval_MaxReturn : 7.560704231262207
Agent1_Eval_MinReturn : -54.6314697265625
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -22.34537124633789
Agent1_Train_StdReturn : 23.068138122558594
Agent1_Train_MaxReturn : 9.989339828491211
Agent1_Train_MinReturn : -73.86368560791016
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 736500
Agent1_TimeSinceStart : 1012.0681669712067
Agent1_Critic_Loss : 0.39950913190841675
Agent1_Actor_Loss : -0.631294846534729
Agent1_Alpha_Loss : 0.783039927482605
Agent1_Temperature : 0.08716657103035659
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 491 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 492 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 493 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 494 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 495 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 496 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 497 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 498 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 499 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 500 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -14.513646125793457
Agent0_Eval_StdReturn : 25.21091651916504
Agent0_Eval_MaxReturn : 34.1112174987793
Agent0_Eval_MinReturn : -53.276100158691406
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -7.904667854309082
Agent0_Train_StdReturn : 18.204347610473633
Agent0_Train_MaxReturn : 16.774856567382812
Agent0_Train_MinReturn : -36.465476989746094
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 751500
Agent0_TimeSinceStart : 1031.5878219604492
Agent0_Critic_Loss : 0.4307962954044342
Agent0_Actor_Loss : -0.5263699293136597
Agent0_Alpha_Loss : 0.7721030712127686
Agent0_Temperature : 0.08691630177667954
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -3.890847682952881
Agent1_Eval_StdReturn : 6.658429145812988
Agent1_Eval_MaxReturn : 5.788137912750244
Agent1_Eval_MinReturn : -12.60276985168457
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -15.982345581054688
Agent1_Train_StdReturn : 17.49322509765625
Agent1_Train_MaxReturn : 24.030515670776367
Agent1_Train_MinReturn : -48.55230712890625
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 751500
Agent1_TimeSinceStart : 1033.5348944664001
Agent1_Critic_Loss : 0.4685179591178894
Agent1_Actor_Loss : -0.6289372444152832
Agent1_Alpha_Loss : 0.7864287495613098
Agent1_Temperature : 0.08691976618126014
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 501 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 502 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 503 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 504 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 505 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 506 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 507 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 508 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 509 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 510 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -14.334981918334961
Agent0_Eval_StdReturn : 19.021223068237305
Agent0_Eval_MaxReturn : 9.262336730957031
Agent0_Eval_MinReturn : -47.81731414794922
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -15.389147758483887
Agent0_Train_StdReturn : 10.438002586364746
Agent0_Train_MaxReturn : 8.755430221557617
Agent0_Train_MinReturn : -30.389728546142578
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 766500
Agent0_TimeSinceStart : 1053.0298628807068
Agent0_Critic_Loss : 0.4994024634361267
Agent0_Actor_Loss : -0.5041120052337646
Agent0_Alpha_Loss : 0.7885651588439941
Agent0_Temperature : 0.08666821987739493
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -25.249629974365234
Agent1_Eval_StdReturn : 20.489383697509766
Agent1_Eval_MaxReturn : 9.976041793823242
Agent1_Eval_MinReturn : -56.2510986328125
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -7.796441078186035
Agent1_Train_StdReturn : 14.888113021850586
Agent1_Train_MaxReturn : 12.95469856262207
Agent1_Train_MinReturn : -37.818321228027344
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 766500
Agent1_TimeSinceStart : 1054.9653832912445
Agent1_Critic_Loss : 0.39899444580078125
Agent1_Actor_Loss : -0.7259325981140137
Agent1_Alpha_Loss : 0.781425952911377
Agent1_Temperature : 0.08667333761133296
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 511 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 512 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 513 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 514 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 515 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 516 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 517 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 518 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 519 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 520 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -16.776954650878906
Agent0_Eval_StdReturn : 16.08435821533203
Agent0_Eval_MaxReturn : 7.742480754852295
Agent0_Eval_MinReturn : -46.644287109375
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -11.837955474853516
Agent0_Train_StdReturn : 13.489106178283691
Agent0_Train_MaxReturn : 6.1932759284973145
Agent0_Train_MinReturn : -31.199195861816406
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 781500
Agent0_TimeSinceStart : 1074.475533246994
Agent0_Critic_Loss : 0.4918518364429474
Agent0_Actor_Loss : -0.5338878631591797
Agent0_Alpha_Loss : 0.7863858342170715
Agent0_Temperature : 0.08641993590167112
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -30.010473251342773
Agent1_Eval_StdReturn : 17.753280639648438
Agent1_Eval_MaxReturn : 0.5066537857055664
Agent1_Eval_MinReturn : -53.64421081542969
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -25.949153900146484
Agent1_Train_StdReturn : 14.034697532653809
Agent1_Train_MaxReturn : -6.471985816955566
Agent1_Train_MinReturn : -49.16902160644531
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 781500
Agent1_TimeSinceStart : 1076.4096312522888
Agent1_Critic_Loss : 0.5016757249832153
Agent1_Actor_Loss : -0.5902674794197083
Agent1_Alpha_Loss : 0.7863718271255493
Agent1_Temperature : 0.08642691138597193
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 521 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 522 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 523 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 524 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 525 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 526 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 527 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 528 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 529 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 530 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -21.7619686126709
Agent0_Eval_StdReturn : 17.25685691833496
Agent0_Eval_MaxReturn : 9.160436630249023
Agent0_Eval_MinReturn : -53.1319580078125
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -13.526644706726074
Agent0_Train_StdReturn : 15.382420539855957
Agent0_Train_MaxReturn : 6.0567626953125
Agent0_Train_MinReturn : -47.56563949584961
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 796500
Agent0_TimeSinceStart : 1095.892995595932
Agent0_Critic_Loss : 0.5159310102462769
Agent0_Actor_Loss : -0.48805731534957886
Agent0_Alpha_Loss : 0.7825620770454407
Agent0_Temperature : 0.08617250518479455
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -19.598310470581055
Agent1_Eval_StdReturn : 21.38932228088379
Agent1_Eval_MaxReturn : 14.471403121948242
Agent1_Eval_MinReturn : -45.67906188964844
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -18.42459487915039
Agent1_Train_StdReturn : 15.237044334411621
Agent1_Train_MaxReturn : -0.2380084991455078
Agent1_Train_MinReturn : -49.20746994018555
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 796500
Agent1_TimeSinceStart : 1097.8282930850983
Agent1_Critic_Loss : 0.5236517190933228
Agent1_Actor_Loss : -0.7281553745269775
Agent1_Alpha_Loss : 0.7897605895996094
Agent1_Temperature : 0.0861799999507498
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 531 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 532 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 533 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 534 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 535 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 536 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 537 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 538 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 539 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 540 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -10.694601058959961
Agent0_Eval_StdReturn : 10.684357643127441
Agent0_Eval_MaxReturn : 2.824723243713379
Agent0_Eval_MinReturn : -37.37053298950195
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -10.751474380493164
Agent0_Train_StdReturn : 12.367990493774414
Agent0_Train_MaxReturn : 14.343315124511719
Agent0_Train_MinReturn : -31.819372177124023
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 811500
Agent0_TimeSinceStart : 1117.3392865657806
Agent0_Critic_Loss : 0.47882118821144104
Agent0_Actor_Loss : -0.4997652769088745
Agent0_Alpha_Loss : 0.7820830941200256
Agent0_Temperature : 0.08592631998750107
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -19.179283142089844
Agent1_Eval_StdReturn : 9.743865966796875
Agent1_Eval_MaxReturn : -9.907432556152344
Agent1_Eval_MinReturn : -41.66950225830078
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -17.465648651123047
Agent1_Train_StdReturn : 23.249792098999023
Agent1_Train_MaxReturn : 20.29754638671875
Agent1_Train_MinReturn : -62.98292541503906
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 811500
Agent1_TimeSinceStart : 1119.2823333740234
Agent1_Critic_Loss : 0.7062333226203918
Agent1_Actor_Loss : -0.7197225093841553
Agent1_Alpha_Loss : 0.7853997349739075
Agent1_Temperature : 0.08593295091363501
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 541 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 542 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 543 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 544 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 545 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 546 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 547 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 548 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 549 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 550 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -27.10080909729004
Agent0_Eval_StdReturn : 18.79487419128418
Agent0_Eval_MaxReturn : -4.4282941818237305
Agent0_Eval_MinReturn : -69.01715850830078
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -20.214031219482422
Agent0_Train_StdReturn : 11.153538703918457
Agent0_Train_MaxReturn : 3.1899752616882324
Agent0_Train_MinReturn : -36.0400505065918
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 826500
Agent0_TimeSinceStart : 1138.809139251709
Agent0_Critic_Loss : 0.5076723098754883
Agent0_Actor_Loss : -0.5924091339111328
Agent0_Alpha_Loss : 0.7901421785354614
Agent0_Temperature : 0.0856800047431566
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -20.468753814697266
Agent1_Eval_StdReturn : 23.431377410888672
Agent1_Eval_MaxReturn : 11.443513870239258
Agent1_Eval_MinReturn : -59.19902038574219
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -15.684804916381836
Agent1_Train_StdReturn : 17.643177032470703
Agent1_Train_MaxReturn : 7.252008438110352
Agent1_Train_MinReturn : -42.00849151611328
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 826500
Agent1_TimeSinceStart : 1140.748306274414
Agent1_Critic_Loss : 0.5406312346458435
Agent1_Actor_Loss : -0.6626356840133667
Agent1_Alpha_Loss : 0.7771177887916565
Agent1_Temperature : 0.08568790003665867
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 551 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 552 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 553 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 554 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 555 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 556 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 557 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 558 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 559 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 560 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -10.856356620788574
Agent0_Eval_StdReturn : 21.13762855529785
Agent0_Eval_MaxReturn : 30.50897216796875
Agent0_Eval_MinReturn : -39.9981689453125
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -7.493853569030762
Agent0_Train_StdReturn : 15.713570594787598
Agent0_Train_MaxReturn : 16.650094985961914
Agent0_Train_MinReturn : -44.23994064331055
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 841500
Agent0_TimeSinceStart : 1160.3220257759094
Agent0_Critic_Loss : 0.5150788426399231
Agent0_Actor_Loss : -0.5479227900505066
Agent0_Alpha_Loss : 0.7794061303138733
Agent0_Temperature : 0.08543500076141688
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -17.081655502319336
Agent1_Eval_StdReturn : 10.340754508972168
Agent1_Eval_MaxReturn : 6.368247032165527
Agent1_Eval_MinReturn : -32.11155319213867
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -13.199785232543945
Agent1_Train_StdReturn : 20.65049171447754
Agent1_Train_MaxReturn : 12.870691299438477
Agent1_Train_MinReturn : -48.464866638183594
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 841500
Agent1_TimeSinceStart : 1162.2615115642548
Agent1_Critic_Loss : 0.658190131187439
Agent1_Actor_Loss : -0.7022883296012878
Agent1_Alpha_Loss : 0.7833274006843567
Agent1_Temperature : 0.08544442366225824
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 561 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 562 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 563 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 564 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 565 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 566 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 567 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 568 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 569 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 570 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -7.917021751403809
Agent0_Eval_StdReturn : 15.537736892700195
Agent0_Eval_MaxReturn : 16.76669692993164
Agent0_Eval_MinReturn : -35.23849868774414
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -11.094697952270508
Agent0_Train_StdReturn : 14.59049129486084
Agent0_Train_MaxReturn : 13.929101943969727
Agent0_Train_MinReturn : -37.77021789550781
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 856500
Agent0_TimeSinceStart : 1181.8608598709106
Agent0_Critic_Loss : 0.4672778248786926
Agent0_Actor_Loss : -0.5096803307533264
Agent0_Alpha_Loss : 0.7793806791305542
Agent0_Temperature : 0.08519124642065495
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -20.33612060546875
Agent1_Eval_StdReturn : 7.0080976486206055
Agent1_Eval_MaxReturn : -8.762984275817871
Agent1_Eval_MinReturn : -33.9891357421875
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -15.303979873657227
Agent1_Train_StdReturn : 11.162581443786621
Agent1_Train_MaxReturn : 2.080373764038086
Agent1_Train_MinReturn : -32.36736297607422
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 856500
Agent1_TimeSinceStart : 1183.8131334781647
Agent1_Critic_Loss : 0.5048006772994995
Agent1_Actor_Loss : -0.6152321100234985
Agent1_Alpha_Loss : 0.7570710182189941
Agent1_Temperature : 0.08520282047098336
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 571 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 572 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 573 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 574 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 575 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 576 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 577 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 578 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 579 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 580 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -17.965681076049805
Agent0_Eval_StdReturn : 15.070311546325684
Agent0_Eval_MaxReturn : 7.228653907775879
Agent0_Eval_MinReturn : -43.70570373535156
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -8.301798820495605
Agent0_Train_StdReturn : 9.400897026062012
Agent0_Train_MaxReturn : 11.03385066986084
Agent0_Train_MinReturn : -21.782691955566406
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 871500
Agent0_TimeSinceStart : 1203.4238810539246
Agent0_Critic_Loss : 0.5708181858062744
Agent0_Actor_Loss : -0.5846831798553467
Agent0_Alpha_Loss : 0.7725229263305664
Agent0_Temperature : 0.0849478730720243
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -10.95566177368164
Agent1_Eval_StdReturn : 11.932312965393066
Agent1_Eval_MaxReturn : 5.020627975463867
Agent1_Eval_MinReturn : -30.77415657043457
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -8.346047401428223
Agent1_Train_StdReturn : 20.454267501831055
Agent1_Train_MaxReturn : 41.64658737182617
Agent1_Train_MinReturn : -37.19621276855469
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 871500
Agent1_TimeSinceStart : 1205.3718655109406
Agent1_Critic_Loss : 0.6191519498825073
Agent1_Actor_Loss : -0.763810932636261
Agent1_Alpha_Loss : 0.750056803226471
Agent1_Temperature : 0.08496363496660701
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 581 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 582 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 583 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 584 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 585 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 586 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 587 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 588 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 589 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 590 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -15.859667778015137
Agent0_Eval_StdReturn : 16.234914779663086
Agent0_Eval_MaxReturn : 5.07524299621582
Agent0_Eval_MinReturn : -52.09171676635742
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -10.689359664916992
Agent0_Train_StdReturn : 13.056059837341309
Agent0_Train_MaxReturn : 7.183826446533203
Agent0_Train_MinReturn : -28.092544555664062
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 886500
Agent0_TimeSinceStart : 1225.0176141262054
Agent0_Critic_Loss : 0.46581071615219116
Agent0_Actor_Loss : -0.5632685422897339
Agent0_Alpha_Loss : 0.7796280384063721
Agent0_Temperature : 0.08470651120533126
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -15.803781509399414
Agent1_Eval_StdReturn : 15.620857238769531
Agent1_Eval_MaxReturn : 5.487699031829834
Agent1_Eval_MinReturn : -47.04423141479492
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -15.331230163574219
Agent1_Train_StdReturn : 6.211780071258545
Agent1_Train_MaxReturn : -3.1791248321533203
Agent1_Train_MinReturn : -23.196775436401367
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 886500
Agent1_TimeSinceStart : 1226.9799118041992
Agent1_Critic_Loss : 0.6237125396728516
Agent1_Actor_Loss : -0.6838277578353882
Agent1_Alpha_Loss : 0.7664633393287659
Agent1_Temperature : 0.08472570528116947
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 591 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 592 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 593 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 594 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 595 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 596 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 597 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 598 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 599 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 600 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -16.733299255371094
Agent0_Eval_StdReturn : 10.616755485534668
Agent0_Eval_MaxReturn : -1.8078007698059082
Agent0_Eval_MinReturn : -35.62833786010742
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -12.63737678527832
Agent0_Train_StdReturn : 15.41231632232666
Agent0_Train_MaxReturn : 12.143095016479492
Agent0_Train_MinReturn : -44.051937103271484
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 901500
Agent0_TimeSinceStart : 1246.6411859989166
Agent0_Critic_Loss : 0.5000241994857788
Agent0_Actor_Loss : -0.6112868785858154
Agent0_Alpha_Loss : 0.7701322436332703
Agent0_Temperature : 0.08446584815473109
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -10.733138084411621
Agent1_Eval_StdReturn : 13.201155662536621
Agent1_Eval_MaxReturn : 15.610371589660645
Agent1_Eval_MinReturn : -25.60657501220703
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -19.307592391967773
Agent1_Train_StdReturn : 17.359161376953125
Agent1_Train_MaxReturn : 23.729568481445312
Agent1_Train_MinReturn : -37.722564697265625
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 901500
Agent1_TimeSinceStart : 1248.59316945076
Agent1_Critic_Loss : 0.6257579922676086
Agent1_Actor_Loss : -0.5934855937957764
Agent1_Alpha_Loss : 0.7593859434127808
Agent1_Temperature : 0.08448831464929608
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 601 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 602 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 603 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 604 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 605 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 606 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 607 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 608 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 609 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 610 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -12.94428539276123
Agent0_Eval_StdReturn : 17.783979415893555
Agent0_Eval_MaxReturn : 12.997884750366211
Agent0_Eval_MinReturn : -44.64665985107422
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -20.72538948059082
Agent0_Train_StdReturn : 13.627620697021484
Agent0_Train_MaxReturn : 1.5374469757080078
Agent0_Train_MinReturn : -46.435115814208984
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 916500
Agent0_TimeSinceStart : 1268.244791984558
Agent0_Critic_Loss : 0.6575592756271362
Agent0_Actor_Loss : -0.5874159336090088
Agent0_Alpha_Loss : 0.7834722995758057
Agent0_Temperature : 0.08422507229789687
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -16.058866500854492
Agent1_Eval_StdReturn : 12.41718864440918
Agent1_Eval_MaxReturn : 1.3622586727142334
Agent1_Eval_MinReturn : -43.48389434814453
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -9.422894477844238
Agent1_Train_StdReturn : 12.825884819030762
Agent1_Train_MaxReturn : 11.865260124206543
Agent1_Train_MinReturn : -36.00737762451172
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 916500
Agent1_TimeSinceStart : 1270.210296869278
Agent1_Critic_Loss : 0.6760923862457275
Agent1_Actor_Loss : -0.8177477121353149
Agent1_Alpha_Loss : 0.7742232084274292
Agent1_Temperature : 0.08425151829380208
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 611 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 612 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 613 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 614 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 615 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 616 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 617 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 618 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 619 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 620 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -11.466951370239258
Agent0_Eval_StdReturn : 9.966744422912598
Agent0_Eval_MaxReturn : -0.5121870040893555
Agent0_Eval_MinReturn : -27.477420806884766
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -6.868640899658203
Agent0_Train_StdReturn : 13.170366287231445
Agent0_Train_MaxReturn : 9.545185089111328
Agent0_Train_MinReturn : -40.07073974609375
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 931500
Agent0_TimeSinceStart : 1289.8598515987396
Agent0_Critic_Loss : 0.5925977230072021
Agent0_Actor_Loss : -0.5455197095870972
Agent0_Alpha_Loss : 0.7596611976623535
Agent0_Temperature : 0.0839848360383313
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -17.4682674407959
Agent1_Eval_StdReturn : 14.346803665161133
Agent1_Eval_MaxReturn : -2.2940478324890137
Agent1_Eval_MinReturn : -46.041927337646484
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -11.329055786132812
Agent1_Train_StdReturn : 14.721920013427734
Agent1_Train_MaxReturn : 19.40625
Agent1_Train_MinReturn : -30.179302215576172
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 931500
Agent1_TimeSinceStart : 1291.8086495399475
Agent1_Critic_Loss : 0.6487200856208801
Agent1_Actor_Loss : -0.8339424133300781
Agent1_Alpha_Loss : 0.7622144222259521
Agent1_Temperature : 0.08401336852963377
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 621 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 622 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 623 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 624 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 625 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 626 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 627 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 628 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 629 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 630 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -12.695671081542969
Agent0_Eval_StdReturn : 12.081082344055176
Agent0_Eval_MaxReturn : 8.37240982055664
Agent0_Eval_MinReturn : -30.372386932373047
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -21.690088272094727
Agent0_Train_StdReturn : 17.96774673461914
Agent0_Train_MaxReturn : 0.5587887763977051
Agent0_Train_MinReturn : -54.8952751159668
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 946500
Agent0_TimeSinceStart : 1311.5052049160004
Agent0_Critic_Loss : 0.6336269974708557
Agent0_Actor_Loss : -0.7071835994720459
Agent0_Alpha_Loss : 0.7536292672157288
Agent0_Temperature : 0.0837456197936511
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -11.083611488342285
Agent1_Eval_StdReturn : 7.880646705627441
Agent1_Eval_MaxReturn : -1.5969960689544678
Agent1_Eval_MinReturn : -31.451139450073242
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -19.68031120300293
Agent1_Train_StdReturn : 12.355145454406738
Agent1_Train_MaxReturn : 6.7083353996276855
Agent1_Train_MinReturn : -42.10831832885742
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 946500
Agent1_TimeSinceStart : 1313.4524037837982
Agent1_Critic_Loss : 0.7437644600868225
Agent1_Actor_Loss : -0.6465713977813721
Agent1_Alpha_Loss : 0.7756650447845459
Agent1_Temperature : 0.08377469498504661
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 631 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 632 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 633 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 634 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 635 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 636 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 637 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 638 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 639 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 640 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -15.710803031921387
Agent0_Eval_StdReturn : 12.179352760314941
Agent0_Eval_MaxReturn : 10.616983413696289
Agent0_Eval_MinReturn : -33.75432586669922
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -16.879192352294922
Agent0_Train_StdReturn : 22.10559844970703
Agent0_Train_MaxReturn : 10.646232604980469
Agent0_Train_MinReturn : -66.3825454711914
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 961500
Agent0_TimeSinceStart : 1333.1121866703033
Agent0_Critic_Loss : 0.5394467711448669
Agent0_Actor_Loss : -0.7453135251998901
Agent0_Alpha_Loss : 0.7722079753875732
Agent0_Temperature : 0.0835073068019309
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -18.518808364868164
Agent1_Eval_StdReturn : 16.580453872680664
Agent1_Eval_MaxReturn : 2.5234851837158203
Agent1_Eval_MinReturn : -46.69172286987305
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -21.90793228149414
Agent1_Train_StdReturn : 13.55798625946045
Agent1_Train_MaxReturn : -6.078652858734131
Agent1_Train_MinReturn : -46.17750549316406
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 961500
Agent1_TimeSinceStart : 1335.0681042671204
Agent1_Critic_Loss : 0.6659697890281677
Agent1_Actor_Loss : -0.7374945878982544
Agent1_Alpha_Loss : 0.776980996131897
Agent1_Temperature : 0.08353563318019491
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 641 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 642 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 643 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 644 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 645 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 646 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 647 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 648 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 649 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 650 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -14.951184272766113
Agent0_Eval_StdReturn : 14.88510799407959
Agent0_Eval_MaxReturn : 7.307082176208496
Agent0_Eval_MinReturn : -39.766475677490234
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -20.00259017944336
Agent0_Train_StdReturn : 16.94331932067871
Agent0_Train_MaxReturn : -1.3454256057739258
Agent0_Train_MinReturn : -55.796634674072266
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 976500
Agent0_TimeSinceStart : 1354.7557275295258
Agent0_Critic_Loss : 0.6533994078636169
Agent0_Actor_Loss : -0.6331635117530823
Agent0_Alpha_Loss : 0.7644267082214355
Agent0_Temperature : 0.08326975923516707
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -11.478757858276367
Agent1_Eval_StdReturn : 11.765989303588867
Agent1_Eval_MaxReturn : 6.780707359313965
Agent1_Eval_MinReturn : -29.692138671875
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -10.948481559753418
Agent1_Train_StdReturn : 16.470792770385742
Agent1_Train_MaxReturn : 16.35126495361328
Agent1_Train_MinReturn : -37.7554817199707
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 976500
Agent1_TimeSinceStart : 1356.7121696472168
Agent1_Critic_Loss : 0.7075092792510986
Agent1_Actor_Loss : -0.6390426158905029
Agent1_Alpha_Loss : 0.7804238796234131
Agent1_Temperature : 0.08329651519023698
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 651 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 652 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 653 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 654 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 655 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 656 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 657 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 658 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 659 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 660 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -4.21898889541626
Agent0_Eval_StdReturn : 9.205902099609375
Agent0_Eval_MaxReturn : 11.458770751953125
Agent0_Eval_MinReturn : -21.818214416503906
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -4.197646617889404
Agent0_Train_StdReturn : 21.260560989379883
Agent0_Train_MaxReturn : 39.54447937011719
Agent0_Train_MinReturn : -50.188880920410156
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 991500
Agent0_TimeSinceStart : 1376.3558115959167
Agent0_Critic_Loss : 0.6298233866691589
Agent0_Actor_Loss : -0.5649089813232422
Agent0_Alpha_Loss : 0.7699682712554932
Agent0_Temperature : 0.08303253264869874
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -20.10640525817871
Agent1_Eval_StdReturn : 22.337379455566406
Agent1_Eval_MaxReturn : 13.590217590332031
Agent1_Eval_MinReturn : -62.59346008300781
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -29.101818084716797
Agent1_Train_StdReturn : 28.44843864440918
Agent1_Train_MaxReturn : 16.252092361450195
Agent1_Train_MinReturn : -89.87881469726562
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 991500
Agent1_TimeSinceStart : 1378.299080133438
Agent1_Critic_Loss : 0.6263264417648315
Agent1_Actor_Loss : -0.8233432173728943
Agent1_Alpha_Loss : 0.7748788595199585
Agent1_Temperature : 0.08305742423469886
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 661 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 662 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 663 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 664 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 665 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 666 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 667 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 668 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 669 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 670 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -6.939528465270996
Agent0_Eval_StdReturn : 9.068865776062012
Agent0_Eval_MaxReturn : 8.876797676086426
Agent0_Eval_MinReturn : -19.29499053955078
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -8.699640274047852
Agent0_Train_StdReturn : 17.250282287597656
Agent0_Train_MaxReturn : 30.227399826049805
Agent0_Train_MinReturn : -40.6070556640625
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1006500
Agent0_TimeSinceStart : 1398.0712225437164
Agent0_Critic_Loss : 0.6438653469085693
Agent0_Actor_Loss : -0.585671067237854
Agent0_Alpha_Loss : 0.7696785926818848
Agent0_Temperature : 0.08279622519725664
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -9.687605857849121
Agent1_Eval_StdReturn : 14.46047306060791
Agent1_Eval_MaxReturn : 14.627235412597656
Agent1_Eval_MinReturn : -30.42053985595703
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -2.4290335178375244
Agent1_Train_StdReturn : 15.12467098236084
Agent1_Train_MaxReturn : 19.931781768798828
Agent1_Train_MinReturn : -28.422651290893555
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1006500
Agent1_TimeSinceStart : 1400.0391314029694
Agent1_Critic_Loss : 0.5879642963409424
Agent1_Actor_Loss : -0.7406772375106812
Agent1_Alpha_Loss : 0.7848378419876099
Agent1_Temperature : 0.08281868464545745
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 671 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 672 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 673 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 674 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 675 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 676 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 677 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 678 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 679 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 680 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -13.125452995300293
Agent0_Eval_StdReturn : 21.152812957763672
Agent0_Eval_MaxReturn : 16.30868148803711
Agent0_Eval_MinReturn : -69.11656951904297
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -15.412384033203125
Agent0_Train_StdReturn : 12.49785041809082
Agent0_Train_MaxReturn : 0.16976022720336914
Agent0_Train_MinReturn : -42.57850646972656
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1021500
Agent0_TimeSinceStart : 1419.8741617202759
Agent0_Critic_Loss : 0.5335162878036499
Agent0_Actor_Loss : -0.6882231831550598
Agent0_Alpha_Loss : 0.7640416622161865
Agent0_Temperature : 0.08256061457359491
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -17.856021881103516
Agent1_Eval_StdReturn : 11.267338752746582
Agent1_Eval_MaxReturn : 0.33519434928894043
Agent1_Eval_MinReturn : -34.28894805908203
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -7.964243412017822
Agent1_Train_StdReturn : 9.269270896911621
Agent1_Train_MaxReturn : 10.134136199951172
Agent1_Train_MinReturn : -20.013748168945312
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1021500
Agent1_TimeSinceStart : 1421.836426973343
Agent1_Critic_Loss : 0.7080850601196289
Agent1_Actor_Loss : -0.6334947347640991
Agent1_Alpha_Loss : 0.7819128036499023
Agent1_Temperature : 0.08258036638068589
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 681 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 682 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 683 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 684 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 685 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 686 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 687 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 688 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 689 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 690 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -10.314730644226074
Agent0_Eval_StdReturn : 19.50446128845215
Agent0_Eval_MaxReturn : 22.19564437866211
Agent0_Eval_MinReturn : -44.842681884765625
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -5.123166084289551
Agent0_Train_StdReturn : 17.81913948059082
Agent0_Train_MaxReturn : 16.757291793823242
Agent0_Train_MinReturn : -42.884681701660156
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1036500
Agent0_TimeSinceStart : 1441.5742886066437
Agent0_Critic_Loss : 0.557409405708313
Agent0_Actor_Loss : -0.7094197273254395
Agent0_Alpha_Loss : 0.7691879868507385
Agent0_Temperature : 0.0823250009063405
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -7.825743675231934
Agent1_Eval_StdReturn : 13.625067710876465
Agent1_Eval_MaxReturn : 17.58975601196289
Agent1_Eval_MinReturn : -34.74309158325195
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -19.083805084228516
Agent1_Train_StdReturn : 16.78592300415039
Agent1_Train_MaxReturn : 6.286169052124023
Agent1_Train_MinReturn : -47.89531326293945
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1036500
Agent1_TimeSinceStart : 1443.5376217365265
Agent1_Critic_Loss : 0.6250892281532288
Agent1_Actor_Loss : -0.6626651287078857
Agent1_Alpha_Loss : 0.7762489318847656
Agent1_Temperature : 0.0823438138265931
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 691 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 692 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 693 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 694 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 695 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 696 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 697 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 698 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 699 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 700 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -12.581324577331543
Agent0_Eval_StdReturn : 15.422002792358398
Agent0_Eval_MaxReturn : 14.93863582611084
Agent0_Eval_MinReturn : -36.196632385253906
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -13.920916557312012
Agent0_Train_StdReturn : 10.321903228759766
Agent0_Train_MaxReturn : 6.82619047164917
Agent0_Train_MinReturn : -26.218923568725586
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1051500
Agent0_TimeSinceStart : 1463.2276997566223
Agent0_Critic_Loss : 0.5918079614639282
Agent0_Actor_Loss : -0.6278588771820068
Agent0_Alpha_Loss : 0.77642822265625
Agent0_Temperature : 0.0820892330964672
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -17.564056396484375
Agent1_Eval_StdReturn : 16.777273178100586
Agent1_Eval_MaxReturn : 1.0375196933746338
Agent1_Eval_MinReturn : -58.475364685058594
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -15.982874870300293
Agent1_Train_StdReturn : 16.631526947021484
Agent1_Train_MaxReturn : 5.012343406677246
Agent1_Train_MinReturn : -50.700321197509766
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1051500
Agent1_TimeSinceStart : 1465.1918053627014
Agent1_Critic_Loss : 0.6420948505401611
Agent1_Actor_Loss : -0.7872040271759033
Agent1_Alpha_Loss : 0.7718448638916016
Agent1_Temperature : 0.08210864254596081
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 701 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 702 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 703 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 704 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 705 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 706 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 707 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 708 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 709 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 710 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -23.610477447509766
Agent0_Eval_StdReturn : 22.871400833129883
Agent0_Eval_MaxReturn : 12.559700012207031
Agent0_Eval_MinReturn : -70.50496673583984
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -6.400660514831543
Agent0_Train_StdReturn : 22.502912521362305
Agent0_Train_MaxReturn : 30.804946899414062
Agent0_Train_MinReturn : -41.520198822021484
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1066500
Agent0_TimeSinceStart : 1484.8906140327454
Agent0_Critic_Loss : 0.7137014865875244
Agent0_Actor_Loss : -0.639297604560852
Agent0_Alpha_Loss : 0.7619972229003906
Agent0_Temperature : 0.0818522988496331
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -12.579885482788086
Agent1_Eval_StdReturn : 16.892732620239258
Agent1_Eval_MaxReturn : 17.123077392578125
Agent1_Eval_MinReturn : -48.05352020263672
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -16.279943466186523
Agent1_Train_StdReturn : 16.080446243286133
Agent1_Train_MaxReturn : 13.693243980407715
Agent1_Train_MinReturn : -30.92578887939453
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1066500
Agent1_TimeSinceStart : 1486.8574876785278
Agent1_Critic_Loss : 0.7015179395675659
Agent1_Actor_Loss : -0.8198579549789429
Agent1_Alpha_Loss : 0.7583490610122681
Agent1_Temperature : 0.08187382731971067
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 711 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 712 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 713 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 714 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 715 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 716 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 717 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 718 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 719 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 720 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -35.374656677246094
Agent0_Eval_StdReturn : 23.266536712646484
Agent0_Eval_MaxReturn : -2.1989760398864746
Agent0_Eval_MinReturn : -75.24349975585938
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -18.301959991455078
Agent0_Train_StdReturn : 21.15044593811035
Agent0_Train_MaxReturn : 7.86512565612793
Agent0_Train_MinReturn : -51.8487548828125
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1081500
Agent0_TimeSinceStart : 1506.5792050361633
Agent0_Critic_Loss : 0.5985660552978516
Agent0_Actor_Loss : -0.7762481570243835
Agent0_Alpha_Loss : 0.7764366269111633
Agent0_Temperature : 0.0816150911741947
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -16.22689437866211
Agent1_Eval_StdReturn : 14.902009010314941
Agent1_Eval_MaxReturn : 0.699864387512207
Agent1_Eval_MinReturn : -46.976104736328125
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -11.074004173278809
Agent1_Train_StdReturn : 15.660433769226074
Agent1_Train_MaxReturn : 11.204364776611328
Agent1_Train_MinReturn : -36.55290222167969
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1081500
Agent1_TimeSinceStart : 1508.5502860546112
Agent1_Critic_Loss : 0.6438397169113159
Agent1_Actor_Loss : -0.9880567789077759
Agent1_Alpha_Loss : 0.7510092258453369
Agent1_Temperature : 0.08163966682405703
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 721 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 722 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 723 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 724 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 725 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 726 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 727 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 728 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 729 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 730 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -29.152393341064453
Agent0_Eval_StdReturn : 29.57630729675293
Agent0_Eval_MaxReturn : 12.16895866394043
Agent0_Eval_MinReturn : -78.8507308959961
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -12.450254440307617
Agent0_Train_StdReturn : 24.70742416381836
Agent0_Train_MaxReturn : 25.329639434814453
Agent0_Train_MinReturn : -45.44435119628906
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1096500
Agent0_TimeSinceStart : 1528.2574355602264
Agent0_Critic_Loss : 0.8106931447982788
Agent0_Actor_Loss : -0.7732675075531006
Agent0_Alpha_Loss : 0.7712045907974243
Agent0_Temperature : 0.081377602306695
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -14.292379379272461
Agent1_Eval_StdReturn : 12.40388298034668
Agent1_Eval_MaxReturn : 8.501640319824219
Agent1_Eval_MinReturn : -40.072792053222656
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -11.910776138305664
Agent1_Train_StdReturn : 17.22313690185547
Agent1_Train_MaxReturn : 8.945563316345215
Agent1_Train_MinReturn : -39.588958740234375
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1096500
Agent1_TimeSinceStart : 1530.220021724701
Agent1_Critic_Loss : 0.7613534927368164
Agent1_Actor_Loss : -0.821627140045166
Agent1_Alpha_Loss : 0.7591258883476257
Agent1_Temperature : 0.08140655131957643
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 731 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 732 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 733 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 734 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 735 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 736 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 737 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 738 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 739 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 740 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -19.621984481811523
Agent0_Eval_StdReturn : 22.610414505004883
Agent0_Eval_MaxReturn : 7.658884048461914
Agent0_Eval_MinReturn : -60.43291473388672
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -17.111248016357422
Agent0_Train_StdReturn : 17.999711990356445
Agent0_Train_MaxReturn : 18.12259864807129
Agent0_Train_MinReturn : -48.72380828857422
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1111500
Agent0_TimeSinceStart : 1549.9176824092865
Agent0_Critic_Loss : 0.679745078086853
Agent0_Actor_Loss : -0.7016181945800781
Agent0_Alpha_Loss : 0.7789795994758606
Agent0_Temperature : 0.08114096202455216
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -18.6118221282959
Agent1_Eval_StdReturn : 14.144076347351074
Agent1_Eval_MaxReturn : 3.0453648567199707
Agent1_Eval_MinReturn : -38.046607971191406
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -6.806725978851318
Agent1_Train_StdReturn : 14.410191535949707
Agent1_Train_MaxReturn : 24.5355224609375
Agent1_Train_MinReturn : -27.11695098876953
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1111500
Agent1_TimeSinceStart : 1551.8999395370483
Agent1_Critic_Loss : 0.6334279775619507
Agent1_Actor_Loss : -0.7731486558914185
Agent1_Alpha_Loss : 0.7673468589782715
Agent1_Temperature : 0.08117355388496197
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 741 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 742 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 743 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 744 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 745 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 746 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 747 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 748 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 749 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 750 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -31.195642471313477
Agent0_Eval_StdReturn : 28.91629981994629
Agent0_Eval_MaxReturn : 0.5760641098022461
Agent0_Eval_MinReturn : -88.50198364257812
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -17.97779083251953
Agent0_Train_StdReturn : 21.993608474731445
Agent0_Train_MaxReturn : 8.503923416137695
Agent0_Train_MinReturn : -77.40342712402344
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1126500
Agent0_TimeSinceStart : 1571.6181926727295
Agent0_Critic_Loss : 0.7528769373893738
Agent0_Actor_Loss : -0.7085973024368286
Agent0_Alpha_Loss : 0.7645021080970764
Agent0_Temperature : 0.08090578876337678
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -7.177611351013184
Agent1_Eval_StdReturn : 13.773558616638184
Agent1_Eval_MaxReturn : 22.332048416137695
Agent1_Eval_MinReturn : -28.00418472290039
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -5.504899024963379
Agent1_Train_StdReturn : 17.488739013671875
Agent1_Train_MaxReturn : 28.423873901367188
Agent1_Train_MinReturn : -30.508140563964844
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1126500
Agent1_TimeSinceStart : 1573.589055776596
Agent1_Critic_Loss : 1.2266618013381958
Agent1_Actor_Loss : -0.7881240248680115
Agent1_Alpha_Loss : 0.7693197131156921
Agent1_Temperature : 0.08094121782592023
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 751 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 752 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 753 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 754 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 755 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 756 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 757 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 758 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 759 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 760 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -20.46597671508789
Agent0_Eval_StdReturn : 15.01645565032959
Agent0_Eval_MaxReturn : -1.2619876861572266
Agent0_Eval_MinReturn : -57.254913330078125
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -10.88150691986084
Agent0_Train_StdReturn : 16.992074966430664
Agent0_Train_MaxReturn : 18.176620483398438
Agent0_Train_MinReturn : -31.991024017333984
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1141500
Agent0_TimeSinceStart : 1593.3673586845398
Agent0_Critic_Loss : 0.7784530520439148
Agent0_Actor_Loss : -0.616187572479248
Agent0_Alpha_Loss : 0.7686223983764648
Agent0_Temperature : 0.08067332877751585
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -9.932123184204102
Agent1_Eval_StdReturn : 12.857192993164062
Agent1_Eval_MaxReturn : 4.000186920166016
Agent1_Eval_MinReturn : -35.008392333984375
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -25.755294799804688
Agent1_Train_StdReturn : 23.525123596191406
Agent1_Train_MaxReturn : 2.7319231033325195
Agent1_Train_MinReturn : -75.97659301757812
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1141500
Agent1_TimeSinceStart : 1595.3323955535889
Agent1_Critic_Loss : 0.9130638241767883
Agent1_Actor_Loss : -0.8334023952484131
Agent1_Alpha_Loss : 0.7594473361968994
Agent1_Temperature : 0.08070982853121195
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 761 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 762 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 763 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 764 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 765 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 766 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 767 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 768 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 769 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 770 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -13.426406860351562
Agent0_Eval_StdReturn : 11.146951675415039
Agent0_Eval_MaxReturn : -0.08875703811645508
Agent0_Eval_MinReturn : -34.47095489501953
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -18.883892059326172
Agent0_Train_StdReturn : 13.414751052856445
Agent0_Train_MaxReturn : 2.636075973510742
Agent0_Train_MinReturn : -43.00537109375
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1156500
Agent0_TimeSinceStart : 1615.2291073799133
Agent0_Critic_Loss : 0.9878892302513123
Agent0_Actor_Loss : -0.7482775449752808
Agent0_Alpha_Loss : 0.7527958154678345
Agent0_Temperature : 0.08044377891753295
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -7.957898139953613
Agent1_Eval_StdReturn : 19.940387725830078
Agent1_Eval_MaxReturn : 32.01667022705078
Agent1_Eval_MinReturn : -40.08042526245117
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -13.176191329956055
Agent1_Train_StdReturn : 14.435381889343262
Agent1_Train_MaxReturn : 5.393584251403809
Agent1_Train_MinReturn : -52.45796585083008
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1156500
Agent1_TimeSinceStart : 1617.2000427246094
Agent1_Critic_Loss : 0.9655924439430237
Agent1_Actor_Loss : -0.9341767430305481
Agent1_Alpha_Loss : 0.7589448094367981
Agent1_Temperature : 0.08047979544835851
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 771 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 772 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 773 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 774 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 775 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 776 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 777 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 778 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 779 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 780 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -3.795236587524414
Agent0_Eval_StdReturn : 9.890043258666992
Agent0_Eval_MaxReturn : 17.659320831298828
Agent0_Eval_MinReturn : -17.79446029663086
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -13.608589172363281
Agent0_Train_StdReturn : 6.479608535766602
Agent0_Train_MaxReturn : -0.28619933128356934
Agent0_Train_MinReturn : -23.07335662841797
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1171500
Agent0_TimeSinceStart : 1637.103732585907
Agent0_Critic_Loss : 0.7849146127700806
Agent0_Actor_Loss : -0.5583111047744751
Agent0_Alpha_Loss : 0.7355921268463135
Agent0_Temperature : 0.08021744800537309
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -18.366792678833008
Agent1_Eval_StdReturn : 23.644514083862305
Agent1_Eval_MaxReturn : 14.989288330078125
Agent1_Eval_MinReturn : -53.41913604736328
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -9.110135078430176
Agent1_Train_StdReturn : 11.900182723999023
Agent1_Train_MaxReturn : 16.836044311523438
Agent1_Train_MinReturn : -25.639633178710938
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1171500
Agent1_TimeSinceStart : 1639.0737974643707
Agent1_Critic_Loss : 0.7650361061096191
Agent1_Actor_Loss : -0.8591817021369934
Agent1_Alpha_Loss : 0.7533645629882812
Agent1_Temperature : 0.08025133390574081
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 781 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 782 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 783 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 784 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 785 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 786 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 787 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 788 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 789 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 790 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -2.727992534637451
Agent0_Eval_StdReturn : 15.325855255126953
Agent0_Eval_MaxReturn : 21.567888259887695
Agent0_Eval_MinReturn : -34.44384002685547
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -10.78449821472168
Agent0_Train_StdReturn : 14.991409301757812
Agent0_Train_MaxReturn : 13.080888748168945
Agent0_Train_MinReturn : -40.936134338378906
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1186500
Agent0_TimeSinceStart : 1659.011959552765
Agent0_Critic_Loss : 0.943146824836731
Agent0_Actor_Loss : -0.6340826749801636
Agent0_Alpha_Loss : 0.7424752712249756
Agent0_Temperature : 0.07999368199400711
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -9.010022163391113
Agent1_Eval_StdReturn : 17.471895217895508
Agent1_Eval_MaxReturn : 18.780353546142578
Agent1_Eval_MinReturn : -32.54744338989258
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -13.855552673339844
Agent1_Train_StdReturn : 19.98378562927246
Agent1_Train_MaxReturn : 22.72886848449707
Agent1_Train_MinReturn : -47.65247344970703
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1186500
Agent1_TimeSinceStart : 1660.9975254535675
Agent1_Critic_Loss : 0.8927640914916992
Agent1_Actor_Loss : -0.8683830499649048
Agent1_Alpha_Loss : 0.7436788082122803
Agent1_Temperature : 0.08002463062281048
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 791 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 792 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 793 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 794 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 795 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 796 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 797 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 798 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 799 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 800 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -12.008943557739258
Agent0_Eval_StdReturn : 13.940594673156738
Agent0_Eval_MaxReturn : 8.39854621887207
Agent0_Eval_MinReturn : -36.500457763671875
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -16.77198600769043
Agent0_Train_StdReturn : 15.071233749389648
Agent0_Train_MaxReturn : -0.3060340881347656
Agent0_Train_MinReturn : -44.50452423095703
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1201500
Agent0_TimeSinceStart : 1680.886307001114
Agent0_Critic_Loss : 0.6861767768859863
Agent0_Actor_Loss : -0.8502951860427856
Agent0_Alpha_Loss : 0.7408121824264526
Agent0_Temperature : 0.07976996682641249
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -9.003747940063477
Agent1_Eval_StdReturn : 19.19068145751953
Agent1_Eval_MaxReturn : 23.268104553222656
Agent1_Eval_MinReturn : -49.91004180908203
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -12.704530715942383
Agent1_Train_StdReturn : 14.743815422058105
Agent1_Train_MaxReturn : 4.154818534851074
Agent1_Train_MinReturn : -48.63246154785156
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1201500
Agent1_TimeSinceStart : 1682.8653841018677
Agent1_Critic_Loss : 0.962290346622467
Agent1_Actor_Loss : -0.9304301738739014
Agent1_Alpha_Loss : 0.741479754447937
Agent1_Temperature : 0.07980052554030985
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 801 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 802 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 803 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 804 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 805 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 806 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 807 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 808 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 809 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 810 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -16.838329315185547
Agent0_Eval_StdReturn : 14.921545028686523
Agent0_Eval_MaxReturn : 5.23796272277832
Agent0_Eval_MinReturn : -35.97307586669922
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -14.127062797546387
Agent0_Train_StdReturn : 18.08334732055664
Agent0_Train_MaxReturn : 18.460926055908203
Agent0_Train_MinReturn : -48.96293640136719
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1216500
Agent0_TimeSinceStart : 1702.7391126155853
Agent0_Critic_Loss : 0.7774394750595093
Agent0_Actor_Loss : -0.8605591058731079
Agent0_Alpha_Loss : 0.7427137494087219
Agent0_Temperature : 0.07954754837028524
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -8.330997467041016
Agent1_Eval_StdReturn : 9.435765266418457
Agent1_Eval_MaxReturn : 12.959741592407227
Agent1_Eval_MinReturn : -23.741195678710938
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -3.64776349067688
Agent1_Train_StdReturn : 9.676138877868652
Agent1_Train_MaxReturn : 13.747069358825684
Agent1_Train_MinReturn : -18.714935302734375
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1216500
Agent1_TimeSinceStart : 1704.7212965488434
Agent1_Critic_Loss : 0.8450015783309937
Agent1_Actor_Loss : -0.8366804718971252
Agent1_Alpha_Loss : 0.7369234561920166
Agent1_Temperature : 0.07957756634362902
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 811 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 812 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 813 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 814 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 815 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 816 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 817 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 818 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 819 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 820 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -26.49686622619629
Agent0_Eval_StdReturn : 20.812931060791016
Agent0_Eval_MaxReturn : 0.5930824279785156
Agent0_Eval_MinReturn : -64.4088134765625
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -7.611119747161865
Agent0_Train_StdReturn : 17.24712562561035
Agent0_Train_MaxReturn : 25.295473098754883
Agent0_Train_MinReturn : -47.31867599487305
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1231500
Agent0_TimeSinceStart : 1724.565992116928
Agent0_Critic_Loss : 0.8808774948120117
Agent0_Actor_Loss : -0.787966787815094
Agent0_Alpha_Loss : 0.7294992804527283
Agent0_Temperature : 0.07932676676254627
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -18.183032989501953
Agent1_Eval_StdReturn : 18.003950119018555
Agent1_Eval_MaxReturn : 6.750616550445557
Agent1_Eval_MinReturn : -56.559566497802734
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : 0.05693311616778374
Agent1_Train_StdReturn : 9.743096351623535
Agent1_Train_MaxReturn : 12.602914810180664
Agent1_Train_MinReturn : -18.789756774902344
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1231500
Agent1_TimeSinceStart : 1726.5275552272797
Agent1_Critic_Loss : 0.7218862175941467
Agent1_Actor_Loss : -1.0289109945297241
Agent1_Alpha_Loss : 0.7442799806594849
Agent1_Temperature : 0.0793552751448918
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 821 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 822 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 823 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 824 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 825 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 826 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 827 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 828 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 829 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 830 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -11.632295608520508
Agent0_Eval_StdReturn : 12.078277587890625
Agent0_Eval_MaxReturn : 12.59589672088623
Agent0_Eval_MinReturn : -25.93134880065918
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -14.622610092163086
Agent0_Train_StdReturn : 10.94298267364502
Agent0_Train_MaxReturn : 4.174557685852051
Agent0_Train_MinReturn : -33.39490509033203
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1246500
Agent0_TimeSinceStart : 1746.361080646515
Agent0_Critic_Loss : 0.6740458011627197
Agent0_Actor_Loss : -0.7697207927703857
Agent0_Alpha_Loss : 0.7295504212379456
Agent0_Temperature : 0.07910714876843747
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -8.886743545532227
Agent1_Eval_StdReturn : 16.734312057495117
Agent1_Eval_MaxReturn : 16.070175170898438
Agent1_Eval_MinReturn : -41.2557373046875
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -14.969537734985352
Agent1_Train_StdReturn : 15.999038696289062
Agent1_Train_MaxReturn : 6.873287200927734
Agent1_Train_MinReturn : -43.53984069824219
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1246500
Agent1_TimeSinceStart : 1748.3285899162292
Agent1_Critic_Loss : 0.937712550163269
Agent1_Actor_Loss : -1.0814460515975952
Agent1_Alpha_Loss : 0.7531269192695618
Agent1_Temperature : 0.07913300672936256
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 831 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 832 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 833 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 834 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 835 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 836 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 837 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 838 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 839 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 840 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -9.161808013916016
Agent0_Eval_StdReturn : 9.867920875549316
Agent0_Eval_MaxReturn : 15.527299880981445
Agent0_Eval_MinReturn : -18.098615646362305
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -6.922369956970215
Agent0_Train_StdReturn : 17.237655639648438
Agent0_Train_MaxReturn : 20.854509353637695
Agent0_Train_MinReturn : -47.75648498535156
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1261500
Agent0_TimeSinceStart : 1768.2079842090607
Agent0_Critic_Loss : 0.7612685561180115
Agent0_Actor_Loss : -0.6755419969558716
Agent0_Alpha_Loss : 0.7309253215789795
Agent0_Temperature : 0.07888733401936693
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -9.42836856842041
Agent1_Eval_StdReturn : 11.689385414123535
Agent1_Eval_MaxReturn : 11.585412979125977
Agent1_Eval_MinReturn : -25.70182228088379
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -18.78097152709961
Agent1_Train_StdReturn : 15.762837409973145
Agent1_Train_MaxReturn : 1.4339799880981445
Agent1_Train_MinReturn : -39.010528564453125
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1261500
Agent1_TimeSinceStart : 1770.16779255867
Agent1_Critic_Loss : 0.6899999380111694
Agent1_Actor_Loss : -0.9723137617111206
Agent1_Alpha_Loss : 0.757503867149353
Agent1_Temperature : 0.0789098843529464
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 841 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 842 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 843 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 844 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 845 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 846 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 847 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 848 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 849 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 850 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -1.9235572814941406
Agent0_Eval_StdReturn : 9.63398551940918
Agent0_Eval_MaxReturn : 14.252154350280762
Agent0_Eval_MinReturn : -15.715551376342773
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -1.6402511596679688
Agent0_Train_StdReturn : 15.556614875793457
Agent0_Train_MaxReturn : 24.906478881835938
Agent0_Train_MinReturn : -31.161060333251953
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1276500
Agent0_TimeSinceStart : 1790.0791528224945
Agent0_Critic_Loss : 0.8121520280838013
Agent0_Actor_Loss : -0.7493395209312439
Agent0_Alpha_Loss : 0.7304858565330505
Agent0_Temperature : 0.07866746085359266
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -10.431772232055664
Agent1_Eval_StdReturn : 15.051170349121094
Agent1_Eval_MaxReturn : 10.733263969421387
Agent1_Eval_MinReturn : -43.013389587402344
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -19.829116821289062
Agent1_Train_StdReturn : 25.746707916259766
Agent1_Train_MaxReturn : 9.740511894226074
Agent1_Train_MinReturn : -70.34642028808594
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1276500
Agent1_TimeSinceStart : 1792.0587375164032
Agent1_Critic_Loss : 1.0024523735046387
Agent1_Actor_Loss : -0.9855443239212036
Agent1_Alpha_Loss : 0.7408530712127686
Agent1_Temperature : 0.07868736280743246
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 851 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 852 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 853 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 854 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 855 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 856 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 857 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 858 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 859 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 860 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -4.959744453430176
Agent0_Eval_StdReturn : 13.277884483337402
Agent0_Eval_MaxReturn : 16.464609146118164
Agent0_Eval_MinReturn : -26.0407772064209
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -4.753462791442871
Agent0_Train_StdReturn : 17.423133850097656
Agent0_Train_MaxReturn : 22.450990676879883
Agent0_Train_MinReturn : -35.96463394165039
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1291500
Agent0_TimeSinceStart : 1811.9555041790009
Agent0_Critic_Loss : 0.9873168468475342
Agent0_Actor_Loss : -0.8183072805404663
Agent0_Alpha_Loss : 0.7324491739273071
Agent0_Temperature : 0.07844790380828404
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -1.4734351634979248
Agent1_Eval_StdReturn : 14.993071556091309
Agent1_Eval_MaxReturn : 13.594819068908691
Agent1_Eval_MinReturn : -25.114669799804688
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -19.458932876586914
Agent1_Train_StdReturn : 17.58684539794922
Agent1_Train_MaxReturn : 10.478435516357422
Agent1_Train_MinReturn : -51.752906799316406
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1291500
Agent1_TimeSinceStart : 1813.9400751590729
Agent1_Critic_Loss : 0.6789230108261108
Agent1_Actor_Loss : -1.0317678451538086
Agent1_Alpha_Loss : 0.7471731305122375
Agent1_Temperature : 0.0784660537820051
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 861 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 862 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 863 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 864 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 865 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 866 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 867 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 868 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 869 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 870 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -14.081216812133789
Agent0_Eval_StdReturn : 7.301386833190918
Agent0_Eval_MaxReturn : -3.615449905395508
Agent0_Eval_MinReturn : -26.7843017578125
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -11.020401000976562
Agent0_Train_StdReturn : 16.977617263793945
Agent0_Train_MaxReturn : 8.31516170501709
Agent0_Train_MinReturn : -43.211647033691406
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1306500
Agent0_TimeSinceStart : 1833.8801410198212
Agent0_Critic_Loss : 0.9097304344177246
Agent0_Actor_Loss : -0.9445905089378357
Agent0_Alpha_Loss : 0.7314879894256592
Agent0_Temperature : 0.0782287051690446
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -24.589794158935547
Agent1_Eval_StdReturn : 15.303278923034668
Agent1_Eval_MaxReturn : -6.66609001159668
Agent1_Eval_MinReturn : -51.108619689941406
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -4.635954856872559
Agent1_Train_StdReturn : 6.849098205566406
Agent1_Train_MaxReturn : 2.3691296577453613
Agent1_Train_MinReturn : -21.102081298828125
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1306500
Agent1_TimeSinceStart : 1835.860524892807
Agent1_Critic_Loss : 0.7831120491027832
Agent1_Actor_Loss : -0.9531000852584839
Agent1_Alpha_Loss : 0.7458714246749878
Agent1_Temperature : 0.0782453681576405
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 871 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 872 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 873 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 874 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 875 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 876 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 877 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 878 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 879 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 880 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -6.9841156005859375
Agent0_Eval_StdReturn : 9.872000694274902
Agent0_Eval_MaxReturn : 6.607314109802246
Agent0_Eval_MinReturn : -33.81673812866211
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -10.456318855285645
Agent0_Train_StdReturn : 8.832435607910156
Agent0_Train_MaxReturn : 1.8804212808609009
Agent0_Train_MinReturn : -23.183286666870117
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1321500
Agent0_TimeSinceStart : 1855.8122053146362
Agent0_Critic_Loss : 0.7803401350975037
Agent0_Actor_Loss : -0.8805267810821533
Agent0_Alpha_Loss : 0.7354398965835571
Agent0_Temperature : 0.07801008994524344
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -15.960453987121582
Agent1_Eval_StdReturn : 16.832469940185547
Agent1_Eval_MaxReturn : 8.871285438537598
Agent1_Eval_MinReturn : -40.77473068237305
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -10.1568021774292
Agent1_Train_StdReturn : 15.67337703704834
Agent1_Train_MaxReturn : 6.26672887802124
Agent1_Train_MinReturn : -50.768951416015625
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1321500
Agent1_TimeSinceStart : 1857.790240764618
Agent1_Critic_Loss : 1.148870825767517
Agent1_Actor_Loss : -1.0026233196258545
Agent1_Alpha_Loss : 0.7391926646232605
Agent1_Temperature : 0.07802619781114986
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 881 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 882 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 883 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 884 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 885 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 886 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 887 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 888 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 889 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 890 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -7.762010097503662
Agent0_Eval_StdReturn : 7.660887241363525
Agent0_Eval_MaxReturn : 11.572547912597656
Agent0_Eval_MinReturn : -19.006078720092773
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -1.699806571006775
Agent0_Train_StdReturn : 13.729389190673828
Agent0_Train_MaxReturn : 19.624309539794922
Agent0_Train_MinReturn : -33.352294921875
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1336500
Agent0_TimeSinceStart : 1877.6893055438995
Agent0_Critic_Loss : 0.5945420861244202
Agent0_Actor_Loss : -0.7552732229232788
Agent0_Alpha_Loss : 0.7332068681716919
Agent0_Temperature : 0.07779197847540817
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -17.908512115478516
Agent1_Eval_StdReturn : 13.552848815917969
Agent1_Eval_MaxReturn : 0.563471794128418
Agent1_Eval_MinReturn : -43.10826873779297
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -28.277151107788086
Agent1_Train_StdReturn : 30.515222549438477
Agent1_Train_MaxReturn : 15.575252532958984
Agent1_Train_MinReturn : -81.1595458984375
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1336500
Agent1_TimeSinceStart : 1879.666291475296
Agent1_Critic_Loss : 1.0312089920043945
Agent1_Actor_Loss : -0.7864325046539307
Agent1_Alpha_Loss : 0.7392966151237488
Agent1_Temperature : 0.07780758058342047
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 891 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 892 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 893 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 894 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 895 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 896 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 897 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 898 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 899 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 900 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -15.713276863098145
Agent0_Eval_StdReturn : 20.874847412109375
Agent0_Eval_MaxReturn : 14.335335731506348
Agent0_Eval_MinReturn : -59.23120880126953
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -10.012346267700195
Agent0_Train_StdReturn : 19.300579071044922
Agent0_Train_MaxReturn : 12.856512069702148
Agent0_Train_MinReturn : -50.36187744140625
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1351500
Agent0_TimeSinceStart : 1899.5862543582916
Agent0_Critic_Loss : 0.9723014831542969
Agent0_Actor_Loss : -0.8230780363082886
Agent0_Alpha_Loss : 0.7506700754165649
Agent0_Temperature : 0.07757366796884985
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -19.869760513305664
Agent1_Eval_StdReturn : 24.400630950927734
Agent1_Eval_MaxReturn : 13.072311401367188
Agent1_Eval_MinReturn : -70.82682800292969
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -20.239213943481445
Agent1_Train_StdReturn : 27.129215240478516
Agent1_Train_MaxReturn : 28.128034591674805
Agent1_Train_MinReturn : -74.76495361328125
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1351500
Agent1_TimeSinceStart : 1901.5523822307587
Agent1_Critic_Loss : 0.8510634899139404
Agent1_Actor_Loss : -1.0983489751815796
Agent1_Alpha_Loss : 0.751544713973999
Agent1_Temperature : 0.07758978626202978
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 901 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 902 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 903 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 904 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 905 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 906 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 907 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 908 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 909 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 910 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -21.6943416595459
Agent0_Eval_StdReturn : 25.330364227294922
Agent0_Eval_MaxReturn : 11.80364990234375
Agent0_Eval_MinReturn : -66.07615661621094
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -14.863632202148438
Agent0_Train_StdReturn : 30.864055633544922
Agent0_Train_MaxReturn : 63.012962341308594
Agent0_Train_MinReturn : -51.99676513671875
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1366500
Agent0_TimeSinceStart : 1921.3994085788727
Agent0_Critic_Loss : 0.9027328491210938
Agent0_Actor_Loss : -0.9740374088287354
Agent0_Alpha_Loss : 0.75672447681427
Agent0_Temperature : 0.07735472911395119
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -21.793201446533203
Agent1_Eval_StdReturn : 21.341461181640625
Agent1_Eval_MaxReturn : 6.234418869018555
Agent1_Eval_MinReturn : -57.806610107421875
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -22.058635711669922
Agent1_Train_StdReturn : 16.415491104125977
Agent1_Train_MaxReturn : 3.003878116607666
Agent1_Train_MinReturn : -52.69645309448242
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1366500
Agent1_TimeSinceStart : 1923.3625557422638
Agent1_Critic_Loss : 0.9578192234039307
Agent1_Actor_Loss : -1.0074357986450195
Agent1_Alpha_Loss : 0.7352396249771118
Agent1_Temperature : 0.07737166707891222
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 911 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 912 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 913 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 914 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 915 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 916 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 917 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 918 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 919 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 920 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -29.83944320678711
Agent0_Eval_StdReturn : 18.24435043334961
Agent0_Eval_MaxReturn : 2.5212016105651855
Agent0_Eval_MinReturn : -70.68692016601562
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -14.577234268188477
Agent0_Train_StdReturn : 20.75189781188965
Agent0_Train_MaxReturn : 23.314449310302734
Agent0_Train_MinReturn : -51.94148254394531
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1381500
Agent0_TimeSinceStart : 1943.160394668579
Agent0_Critic_Loss : 0.9853072166442871
Agent0_Actor_Loss : -1.0118634700775146
Agent0_Alpha_Loss : 0.7444819211959839
Agent0_Temperature : 0.0771358050497222
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -29.724227905273438
Agent1_Eval_StdReturn : 19.41074562072754
Agent1_Eval_MaxReturn : 3.279153823852539
Agent1_Eval_MinReturn : -64.843505859375
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -20.850765228271484
Agent1_Train_StdReturn : 15.911526679992676
Agent1_Train_MaxReturn : 5.636395454406738
Agent1_Train_MinReturn : -46.41920852661133
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1381500
Agent1_TimeSinceStart : 1945.118170261383
Agent1_Critic_Loss : 1.2232565879821777
Agent1_Actor_Loss : -1.011035680770874
Agent1_Alpha_Loss : 0.7395861148834229
Agent1_Temperature : 0.07715385871766753
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 921 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 922 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 923 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 924 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 925 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 926 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 927 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 928 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 929 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 930 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -36.75139236450195
Agent0_Eval_StdReturn : 22.945785522460938
Agent0_Eval_MaxReturn : 6.061384677886963
Agent0_Eval_MinReturn : -82.98402404785156
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -29.355182647705078
Agent0_Train_StdReturn : 19.73727798461914
Agent0_Train_MaxReturn : 7.9190497398376465
Agent0_Train_MinReturn : -61.254600524902344
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1396500
Agent0_TimeSinceStart : 1964.9051797389984
Agent0_Critic_Loss : 0.8539975881576538
Agent0_Actor_Loss : -0.8555874824523926
Agent0_Alpha_Loss : 0.7399411201477051
Agent0_Temperature : 0.0769177590675172
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -23.71405029296875
Agent1_Eval_StdReturn : 19.945758819580078
Agent1_Eval_MaxReturn : 5.877020835876465
Agent1_Eval_MinReturn : -64.7071533203125
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -26.833383560180664
Agent1_Train_StdReturn : 27.67584228515625
Agent1_Train_MaxReturn : 4.663156509399414
Agent1_Train_MinReturn : -90.16543579101562
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1396500
Agent1_TimeSinceStart : 1966.8736598491669
Agent1_Critic_Loss : 1.2396318912506104
Agent1_Actor_Loss : -1.1134761571884155
Agent1_Alpha_Loss : 0.7340062856674194
Agent1_Temperature : 0.0769375171107857
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 931 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 932 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 933 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 934 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 935 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 936 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 937 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 938 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 939 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 940 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -18.851848602294922
Agent0_Eval_StdReturn : 18.6751766204834
Agent0_Eval_MaxReturn : 1.076493263244629
Agent0_Eval_MinReturn : -69.6573486328125
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -26.656940460205078
Agent0_Train_StdReturn : 24.83890724182129
Agent0_Train_MaxReturn : 12.418512344360352
Agent0_Train_MinReturn : -78.63006591796875
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1411500
Agent0_TimeSinceStart : 1986.7174534797668
Agent0_Critic_Loss : 1.4165310859680176
Agent0_Actor_Loss : -0.982062041759491
Agent0_Alpha_Loss : 0.7399687767028809
Agent0_Temperature : 0.07670108497676029
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -11.653099060058594
Agent1_Eval_StdReturn : 21.548274993896484
Agent1_Eval_MaxReturn : 13.205820083618164
Agent1_Eval_MinReturn : -59.38897705078125
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -23.628610610961914
Agent1_Train_StdReturn : 17.82310676574707
Agent1_Train_MaxReturn : 3.91323184967041
Agent1_Train_MinReturn : -58.596866607666016
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1411500
Agent1_TimeSinceStart : 1988.6938235759735
Agent1_Critic_Loss : 0.9898573160171509
Agent1_Actor_Loss : -1.0627719163894653
Agent1_Alpha_Loss : 0.7267397046089172
Agent1_Temperature : 0.07672204655387899
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 941 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 942 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 943 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 944 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 945 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 946 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 947 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 948 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 949 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 950 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -42.97074890136719
Agent0_Eval_StdReturn : 22.46388816833496
Agent0_Eval_MaxReturn : 0.028277873992919922
Agent0_Eval_MinReturn : -69.37860107421875
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -20.176794052124023
Agent0_Train_StdReturn : 28.645418167114258
Agent0_Train_MaxReturn : 25.177997589111328
Agent0_Train_MinReturn : -70.6672134399414
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1426500
Agent0_TimeSinceStart : 2008.4752728939056
Agent0_Critic_Loss : 1.454372763633728
Agent0_Actor_Loss : -0.9436842799186707
Agent0_Alpha_Loss : 0.7313710451126099
Agent0_Temperature : 0.07648566251642895
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -21.598651885986328
Agent1_Eval_StdReturn : 14.683320045471191
Agent1_Eval_MaxReturn : -1.7919787168502808
Agent1_Eval_MinReturn : -41.61299514770508
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -19.473567962646484
Agent1_Train_StdReturn : 22.677871704101562
Agent1_Train_MaxReturn : 9.14894962310791
Agent1_Train_MinReturn : -67.19966888427734
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1426500
Agent1_TimeSinceStart : 2010.4488067626953
Agent1_Critic_Loss : 1.233298897743225
Agent1_Actor_Loss : -1.0698161125183105
Agent1_Alpha_Loss : 0.7304216623306274
Agent1_Temperature : 0.07650775848092653
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 951 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 952 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 953 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 954 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 955 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 956 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 957 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 958 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 959 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 960 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -6.7694501876831055
Agent0_Eval_StdReturn : 20.622257232666016
Agent0_Eval_MaxReturn : 21.298940658569336
Agent0_Eval_MinReturn : -53.46172332763672
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -12.038111686706543
Agent0_Train_StdReturn : 17.289073944091797
Agent0_Train_MaxReturn : 24.48956871032715
Agent0_Train_MinReturn : -37.60933303833008
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1441500
Agent0_TimeSinceStart : 2030.2827322483063
Agent0_Critic_Loss : 1.0496305227279663
Agent0_Actor_Loss : -0.8428078889846802
Agent0_Alpha_Loss : 0.7342259883880615
Agent0_Temperature : 0.07627147902428252
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -11.182028770446777
Agent1_Eval_StdReturn : 13.026851654052734
Agent1_Eval_MaxReturn : 7.154577255249023
Agent1_Eval_MinReturn : -34.21156692504883
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -8.601944923400879
Agent1_Train_StdReturn : 21.370643615722656
Agent1_Train_MaxReturn : 10.8250093460083
Agent1_Train_MinReturn : -68.2270736694336
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1441500
Agent1_TimeSinceStart : 2032.264254808426
Agent1_Critic_Loss : 1.322322130203247
Agent1_Actor_Loss : -0.9294431209564209
Agent1_Alpha_Loss : 0.7180795669555664
Agent1_Temperature : 0.07629468948670093
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 961 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 962 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 963 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 964 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 965 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 966 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 967 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 968 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 969 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 970 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -12.77966022491455
Agent0_Eval_StdReturn : 18.75456428527832
Agent0_Eval_MaxReturn : 28.461206436157227
Agent0_Eval_MinReturn : -38.1671257019043
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -35.59154510498047
Agent0_Train_StdReturn : 28.93619728088379
Agent0_Train_MaxReturn : 10.492059707641602
Agent0_Train_MinReturn : -72.55291748046875
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1456500
Agent0_TimeSinceStart : 2052.166655063629
Agent0_Critic_Loss : 1.5017735958099365
Agent0_Actor_Loss : -1.0140202045440674
Agent0_Alpha_Loss : 0.7396183013916016
Agent0_Temperature : 0.0760576140145004
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : 1.3491226434707642
Agent1_Eval_StdReturn : 7.602552890777588
Agent1_Eval_MaxReturn : 11.024698257446289
Agent1_Eval_MinReturn : -15.883914947509766
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -17.691741943359375
Agent1_Train_StdReturn : 8.832107543945312
Agent1_Train_MaxReturn : -1.6772785186767578
Agent1_Train_MinReturn : -29.615264892578125
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1456500
Agent1_TimeSinceStart : 2054.146268606186
Agent1_Critic_Loss : 1.454913854598999
Agent1_Actor_Loss : -1.0117971897125244
Agent1_Alpha_Loss : 0.7117824554443359
Agent1_Temperature : 0.076082814507535
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 971 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 972 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 973 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 974 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 975 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 976 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 977 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 978 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 979 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 980 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -14.850308418273926
Agent0_Eval_StdReturn : 22.639184951782227
Agent0_Eval_MaxReturn : 16.573945999145508
Agent0_Eval_MinReturn : -47.68504333496094
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -6.904338836669922
Agent0_Train_StdReturn : 15.613605499267578
Agent0_Train_MaxReturn : 22.342754364013672
Agent0_Train_MinReturn : -25.662487030029297
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1471500
Agent0_TimeSinceStart : 2074.0431854724884
Agent0_Critic_Loss : 1.0893226861953735
Agent0_Actor_Loss : -0.9673972129821777
Agent0_Alpha_Loss : 0.7261925935745239
Agent0_Temperature : 0.07584439357644575
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -17.461626052856445
Agent1_Eval_StdReturn : 15.573498725891113
Agent1_Eval_MaxReturn : 10.259119033813477
Agent1_Eval_MinReturn : -47.37226867675781
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -10.176528930664062
Agent1_Train_StdReturn : 9.356266021728516
Agent1_Train_MaxReturn : 5.5391669273376465
Agent1_Train_MinReturn : -23.78585433959961
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1471500
Agent1_TimeSinceStart : 2076.03453040123
Agent1_Critic_Loss : 1.4235605001449585
Agent1_Actor_Loss : -0.9820315837860107
Agent1_Alpha_Loss : 0.7157513499259949
Agent1_Temperature : 0.07587316817305888
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 981 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 982 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 983 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 984 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 985 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 986 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 987 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 988 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 989 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 990 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -10.176345825195312
Agent0_Eval_StdReturn : 15.154152870178223
Agent0_Eval_MaxReturn : 10.959372520446777
Agent0_Eval_MinReturn : -36.69731521606445
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -22.76410675048828
Agent0_Train_StdReturn : 27.761825561523438
Agent0_Train_MaxReturn : 4.431607246398926
Agent0_Train_MinReturn : -87.8451156616211
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1486500
Agent0_TimeSinceStart : 2095.998549222946
Agent0_Critic_Loss : 1.4769470691680908
Agent0_Actor_Loss : -1.1012787818908691
Agent0_Alpha_Loss : 0.7199384570121765
Agent0_Temperature : 0.07563241611155931
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -7.780575752258301
Agent1_Eval_StdReturn : 13.079330444335938
Agent1_Eval_MaxReturn : 25.394493103027344
Agent1_Eval_MinReturn : -22.819442749023438
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -9.256680488586426
Agent1_Train_StdReturn : 8.667986869812012
Agent1_Train_MaxReturn : 4.472594261169434
Agent1_Train_MinReturn : -23.936355590820312
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1486500
Agent1_TimeSinceStart : 2097.989100456238
Agent1_Critic_Loss : 0.9163000583648682
Agent1_Actor_Loss : -1.0974459648132324
Agent1_Alpha_Loss : 0.7001011371612549
Agent1_Temperature : 0.07566575673897234
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 991 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 992 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 993 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer.../home/harvey/anaconda3/envs/285final/lib/python3.7/site-packages/gym/core.py:318: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  "Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future."
/home/harvey/anaconda3/envs/285final/lib/python3.7/site-packages/gym/wrappers/step_api_compatibility.py:40: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  "Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future."
/home/harvey/anaconda3/envs/285final/lib/python3.7/site-packages/gym/core.py:257: DeprecationWarning: [33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.[0m
  "Function `env.seed(seed)` is marked as deprecated and will be removed in the future. "


Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 994 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 995 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 996 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 997 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 998 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 999 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...
./peersacv2_2ndrun.sh: 8: --seed: not found



LOGGING TO:  /home/harvey/Documents/cs285/CS285-Project/cs285/scripts/../../data/peersac_v2_3agents_eps0.6_HalfCheetah-v4_12-12-2022_14-27-35 



########################
logging outputs to  /home/harvey/Documents/cs285/CS285-Project/cs285/scripts/../../data/peersac_v2_3agents_eps0.6_HalfCheetah-v4_12-12-2022_14-27-35
########################
Using GPU id 0


********** Iteration 0 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -32.58100509643555
Agent0_Eval_StdReturn : 38.008583068847656
Agent0_Eval_MaxReturn : 18.935745239257812
Agent0_Eval_MinReturn : -95.31880187988281
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -68.51490020751953
Agent0_Train_StdReturn : 35.8519172668457
Agent0_Train_MaxReturn : 10.17027473449707
Agent0_Train_MinReturn : -109.59283447265625
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1500
Agent0_TimeSinceStart : 2.1275830268859863
Agent0_Critic_Loss : 1.7086536884307861
Agent0_Actor_Loss : -0.34447938203811646
Agent0_Alpha_Loss : 0.9863041639328003
Agent0_Temperature : 0.09997000449985415
Agent0_Initial_DataCollection_AverageReturn : -68.51490020751953
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -52.60877227783203
Agent1_Eval_StdReturn : 36.110774993896484
Agent1_Eval_MaxReturn : -6.442377090454102
Agent1_Eval_MinReturn : -109.24239349365234
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -41.37040710449219
Agent1_Train_StdReturn : 23.476428985595703
Agent1_Train_MaxReturn : -3.7883758544921875
Agent1_Train_MinReturn : -74.03202819824219
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1500
Agent1_TimeSinceStart : 4.129160165786743
Agent1_Critic_Loss : 0.9887043237686157
Agent1_Actor_Loss : -0.48759517073631287
Agent1_Alpha_Loss : 0.9798400402069092
Agent1_Temperature : 0.09997000449985614
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 1 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 2 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 3 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 4 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 5 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 6 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 7 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 8 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 9 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 10 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -16.689105987548828
Agent0_Eval_StdReturn : 30.834503173828125
Agent0_Eval_MaxReturn : 41.04553985595703
Agent0_Eval_MinReturn : -65.38418579101562
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -31.46488380432129
Agent0_Train_StdReturn : 26.753488540649414
Agent0_Train_MaxReturn : 5.917475700378418
Agent0_Train_MinReturn : -66.07237243652344
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 16500
Agent0_TimeSinceStart : 24.33222460746765
Agent0_Critic_Loss : 0.9285090565681458
Agent0_Actor_Loss : -0.3657960593700409
Agent0_Alpha_Loss : 0.9829058647155762
Agent0_Temperature : 0.09967056271390533
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -35.15570068359375
Agent1_Eval_StdReturn : 32.02640914916992
Agent1_Eval_MaxReturn : 16.7863712310791
Agent1_Eval_MinReturn : -91.48548889160156
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -44.53758239746094
Agent1_Train_StdReturn : 29.685022354125977
Agent1_Train_MaxReturn : 3.7171268463134766
Agent1_Train_MinReturn : -86.65126037597656
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 16500
Agent1_TimeSinceStart : 26.351503372192383
Agent1_Critic_Loss : 0.9182092547416687
Agent1_Actor_Loss : -0.5095957517623901
Agent1_Alpha_Loss : 0.9861770272254944
Agent1_Temperature : 0.09967042435579129
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 11 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 12 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 13 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 14 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 15 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 16 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 17 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 18 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 19 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 20 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -43.38697052001953
Agent0_Eval_StdReturn : 43.672325134277344
Agent0_Eval_MaxReturn : 9.642265319824219
Agent0_Eval_MinReturn : -116.5941162109375
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -33.40008544921875
Agent0_Train_StdReturn : 29.175334930419922
Agent0_Train_MaxReturn : 5.264189720153809
Agent0_Train_MinReturn : -82.53800964355469
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 31500
Agent0_TimeSinceStart : 46.671963691711426
Agent0_Critic_Loss : 0.8994090557098389
Agent0_Actor_Loss : -0.4210008978843689
Agent0_Alpha_Loss : 0.9935859441757202
Agent0_Temperature : 0.09937206042805405
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -53.96504592895508
Agent1_Eval_StdReturn : 43.379947662353516
Agent1_Eval_MaxReturn : 35.547664642333984
Agent1_Eval_MinReturn : -129.4097137451172
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -43.527915954589844
Agent1_Train_StdReturn : 28.746292114257812
Agent1_Train_MaxReturn : -4.636443138122559
Agent1_Train_MinReturn : -84.09095764160156
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 31500
Agent1_TimeSinceStart : 48.70334458351135
Agent1_Critic_Loss : 0.6898341774940491
Agent1_Actor_Loss : -0.5222538709640503
Agent1_Alpha_Loss : 0.9894306063652039
Agent1_Temperature : 0.099371725422022
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 21 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 22 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 23 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 24 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 25 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 26 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 27 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 28 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 29 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 30 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -30.686840057373047
Agent0_Eval_StdReturn : 31.976219177246094
Agent0_Eval_MaxReturn : 15.554892539978027
Agent0_Eval_MinReturn : -95.71600341796875
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -21.32683753967285
Agent0_Train_StdReturn : 34.12836456298828
Agent0_Train_MaxReturn : 11.6461181640625
Agent0_Train_MinReturn : -90.47835540771484
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 46500
Agent0_TimeSinceStart : 69.1089940071106
Agent0_Critic_Loss : 0.9358377456665039
Agent0_Actor_Loss : -0.4118671715259552
Agent0_Alpha_Loss : 0.9876188039779663
Agent0_Temperature : 0.09907424650166567
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -44.66895294189453
Agent1_Eval_StdReturn : 20.377052307128906
Agent1_Eval_MaxReturn : -7.406425476074219
Agent1_Eval_MinReturn : -80.6243667602539
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -56.577049255371094
Agent1_Train_StdReturn : 40.68922805786133
Agent1_Train_MaxReturn : 34.70890426635742
Agent1_Train_MinReturn : -114.0631103515625
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 46500
Agent1_TimeSinceStart : 71.13976621627808
Agent1_Critic_Loss : 0.8305315971374512
Agent1_Actor_Loss : -0.6114243268966675
Agent1_Alpha_Loss : 0.9846721887588501
Agent1_Temperature : 0.09907396921446175
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 31 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 32 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 33 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 34 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 35 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 36 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 37 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 38 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 39 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 40 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -58.8385124206543
Agent0_Eval_StdReturn : 36.875389099121094
Agent0_Eval_MaxReturn : 18.561731338500977
Agent0_Eval_MinReturn : -121.34124755859375
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -39.41211700439453
Agent0_Train_StdReturn : 31.211196899414062
Agent0_Train_MaxReturn : -1.5024425983428955
Agent0_Train_MinReturn : -102.93386840820312
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 61500
Agent0_TimeSinceStart : 91.68075728416443
Agent0_Critic_Loss : 0.7919868230819702
Agent0_Actor_Loss : -0.5017924904823303
Agent0_Alpha_Loss : 0.9837807416915894
Agent0_Temperature : 0.09877775447740954
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -33.764705657958984
Agent1_Eval_StdReturn : 31.169116973876953
Agent1_Eval_MaxReturn : 19.466182708740234
Agent1_Eval_MinReturn : -88.51805877685547
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -40.04237747192383
Agent1_Train_StdReturn : 34.22526931762695
Agent1_Train_MaxReturn : 4.663270950317383
Agent1_Train_MinReturn : -94.31086730957031
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 61500
Agent1_TimeSinceStart : 93.73238921165466
Agent1_Critic_Loss : 0.6820058822631836
Agent1_Actor_Loss : -0.61720871925354
Agent1_Alpha_Loss : 0.9784646034240723
Agent1_Temperature : 0.09877766513343532
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 41 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 42 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 43 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 44 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 45 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 46 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 47 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 48 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 49 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 50 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -40.2404670715332
Agent0_Eval_StdReturn : 33.054996490478516
Agent0_Eval_MaxReturn : 16.798763275146484
Agent0_Eval_MinReturn : -94.64860534667969
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -30.507116317749023
Agent0_Train_StdReturn : 30.74982261657715
Agent0_Train_MaxReturn : 18.7569522857666
Agent0_Train_MinReturn : -62.976890563964844
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 76500
Agent0_TimeSinceStart : 114.31027722358704
Agent0_Critic_Loss : 0.6696636080741882
Agent0_Actor_Loss : -0.5484128594398499
Agent0_Alpha_Loss : 0.9705269932746887
Agent0_Temperature : 0.09848284407898429
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -53.2364387512207
Agent1_Eval_StdReturn : 24.130664825439453
Agent1_Eval_MaxReturn : -16.806747436523438
Agent1_Eval_MinReturn : -85.96865844726562
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -26.66131019592285
Agent1_Train_StdReturn : 29.699268341064453
Agent1_Train_MaxReturn : 14.08652114868164
Agent1_Train_MinReturn : -82.72666931152344
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 76500
Agent1_TimeSinceStart : 116.36222052574158
Agent1_Critic_Loss : 0.6656782627105713
Agent1_Actor_Loss : -0.5844562649726868
Agent1_Alpha_Loss : 0.9852499961853027
Agent1_Temperature : 0.09848294805177957
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 51 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 52 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 53 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 54 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 55 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 56 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 57 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 58 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 59 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 60 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -35.65120315551758
Agent0_Eval_StdReturn : 31.44137191772461
Agent0_Eval_MaxReturn : 23.047245025634766
Agent0_Eval_MinReturn : -85.97941589355469
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -38.31502151489258
Agent0_Train_StdReturn : 28.90235710144043
Agent0_Train_MaxReturn : 2.0544748306274414
Agent0_Train_MinReturn : -85.96635437011719
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 91500
Agent0_TimeSinceStart : 136.95614862442017
Agent0_Critic_Loss : 0.6167566180229187
Agent0_Actor_Loss : -0.47789350152015686
Agent0_Alpha_Loss : 0.9705895185470581
Agent0_Temperature : 0.098189541619117
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -41.05083084106445
Agent1_Eval_StdReturn : 27.44729995727539
Agent1_Eval_MaxReturn : 9.700028419494629
Agent1_Eval_MinReturn : -77.75328826904297
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -42.59264373779297
Agent1_Train_StdReturn : 38.720054626464844
Agent1_Train_MaxReturn : 16.075944900512695
Agent1_Train_MinReturn : -99.79830932617188
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 91500
Agent1_TimeSinceStart : 139.0035116672516
Agent1_Critic_Loss : 0.65437912940979
Agent1_Actor_Loss : -0.5650622844696045
Agent1_Alpha_Loss : 0.9698150753974915
Agent1_Temperature : 0.09818927610808836
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 61 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 62 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 63 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 64 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 65 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 66 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 67 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 68 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 69 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 70 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -42.301429748535156
Agent0_Eval_StdReturn : 29.974374771118164
Agent0_Eval_MaxReturn : 3.220546007156372
Agent0_Eval_MinReturn : -87.86973571777344
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -36.35492706298828
Agent0_Train_StdReturn : 33.5159797668457
Agent0_Train_MaxReturn : 16.33430290222168
Agent0_Train_MinReturn : -90.46331024169922
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 106500
Agent0_TimeSinceStart : 159.574609041214
Agent0_Critic_Loss : 0.6099430322647095
Agent0_Actor_Loss : -0.44114047288894653
Agent0_Alpha_Loss : 0.9626094698905945
Agent0_Temperature : 0.09789790917272123
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -30.946880340576172
Agent1_Eval_StdReturn : 22.71921157836914
Agent1_Eval_MaxReturn : -9.417581558227539
Agent1_Eval_MinReturn : -77.97965240478516
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -45.5745849609375
Agent1_Train_StdReturn : 29.953134536743164
Agent1_Train_MaxReturn : 1.3580138683319092
Agent1_Train_MinReturn : -109.576171875
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 106500
Agent1_TimeSinceStart : 161.62234020233154
Agent1_Critic_Loss : 0.6073858737945557
Agent1_Actor_Loss : -0.6296950578689575
Agent1_Alpha_Loss : 0.9604669213294983
Agent1_Temperature : 0.09789768644588068
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 71 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 72 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 73 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 74 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 75 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 76 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 77 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 78 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 79 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 80 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -62.808631896972656
Agent0_Eval_StdReturn : 35.297332763671875
Agent0_Eval_MaxReturn : -15.811286926269531
Agent0_Eval_MinReturn : -143.87709045410156
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -43.05418014526367
Agent0_Train_StdReturn : 19.3426513671875
Agent0_Train_MaxReturn : -6.720730304718018
Agent0_Train_MinReturn : -81.23765563964844
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 121500
Agent0_TimeSinceStart : 182.2307894229889
Agent0_Critic_Loss : 0.5835055112838745
Agent0_Actor_Loss : -0.5252723693847656
Agent0_Alpha_Loss : 0.9503120183944702
Agent0_Temperature : 0.09760916401928038
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -24.958459854125977
Agent1_Eval_StdReturn : 27.208646774291992
Agent1_Eval_MaxReturn : 24.621746063232422
Agent1_Eval_MinReturn : -60.690956115722656
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -33.3482780456543
Agent1_Train_StdReturn : 36.72779083251953
Agent1_Train_MaxReturn : 21.165443420410156
Agent1_Train_MinReturn : -120.62956237792969
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 121500
Agent1_TimeSinceStart : 184.2843153476715
Agent1_Critic_Loss : 0.518913745880127
Agent1_Actor_Loss : -0.6498725414276123
Agent1_Alpha_Loss : 0.943537175655365
Agent1_Temperature : 0.09760873286741864
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 81 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 82 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 83 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 84 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 85 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 86 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 87 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 88 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 89 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 90 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -31.816173553466797
Agent0_Eval_StdReturn : 20.06867027282715
Agent0_Eval_MaxReturn : -2.968216896057129
Agent0_Eval_MinReturn : -70.93370056152344
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -36.282325744628906
Agent0_Train_StdReturn : 26.2726993560791
Agent0_Train_MaxReturn : 3.581322193145752
Agent0_Train_MinReturn : -90.8082504272461
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 136500
Agent0_TimeSinceStart : 204.9743139743805
Agent0_Critic_Loss : 0.642711877822876
Agent0_Actor_Loss : -0.513516902923584
Agent0_Alpha_Loss : 0.9266514778137207
Agent0_Temperature : 0.0973241800307909
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -29.841506958007812
Agent1_Eval_StdReturn : 22.054649353027344
Agent1_Eval_MaxReturn : 1.825150966644287
Agent1_Eval_MinReturn : -77.45494842529297
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -38.693397521972656
Agent1_Train_StdReturn : 21.353191375732422
Agent1_Train_MaxReturn : -12.157110214233398
Agent1_Train_MinReturn : -76.73856353759766
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 136500
Agent1_TimeSinceStart : 207.02917408943176
Agent1_Critic_Loss : 0.5489075183868408
Agent1_Actor_Loss : -0.6440353393554688
Agent1_Alpha_Loss : 0.9441635608673096
Agent1_Temperature : 0.09732333462396554
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 91 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 92 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 93 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 94 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 95 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 96 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 97 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 98 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 99 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 100 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -15.971872329711914
Agent0_Eval_StdReturn : 23.232730865478516
Agent0_Eval_MaxReturn : 36.32105255126953
Agent0_Eval_MinReturn : -51.40620803833008
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -14.955472946166992
Agent0_Train_StdReturn : 7.823017597198486
Agent0_Train_MaxReturn : -4.583125114440918
Agent0_Train_MinReturn : -33.780364990234375
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 151500
Agent0_TimeSinceStart : 227.72644352912903
Agent0_Critic_Loss : 0.4893245995044708
Agent0_Actor_Loss : -0.5655577182769775
Agent0_Alpha_Loss : 0.8904958367347717
Agent0_Temperature : 0.09704442372504056
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -34.597801208496094
Agent1_Eval_StdReturn : 25.833707809448242
Agent1_Eval_MaxReturn : 5.16425895690918
Agent1_Eval_MinReturn : -83.5369873046875
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -22.46956443786621
Agent1_Train_StdReturn : 18.913043975830078
Agent1_Train_MaxReturn : 11.918903350830078
Agent1_Train_MinReturn : -49.00717544555664
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 151500
Agent1_TimeSinceStart : 229.80021691322327
Agent1_Critic_Loss : 0.5424003601074219
Agent1_Actor_Loss : -0.7103419303894043
Agent1_Alpha_Loss : 0.8896846175193787
Agent1_Temperature : 0.09704238637090877
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 101 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 102 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 103 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 104 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 105 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 106 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 107 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 108 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 109 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 110 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -25.219778060913086
Agent0_Eval_StdReturn : 7.050567626953125
Agent0_Eval_MaxReturn : -14.076716423034668
Agent0_Eval_MinReturn : -38.16297149658203
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -25.479724884033203
Agent0_Train_StdReturn : 14.440329551696777
Agent0_Train_MaxReturn : -4.266221046447754
Agent0_Train_MinReturn : -48.500640869140625
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 166500
Agent0_TimeSinceStart : 250.7555124759674
Agent0_Critic_Loss : 0.42267897725105286
Agent0_Actor_Loss : -0.6505429744720459
Agent0_Alpha_Loss : 0.8280765414237976
Agent0_Temperature : 0.09677335163045972
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -27.1691951751709
Agent1_Eval_StdReturn : 18.080652236938477
Agent1_Eval_MaxReturn : 14.577960968017578
Agent1_Eval_MinReturn : -52.738792419433594
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -18.316091537475586
Agent1_Train_StdReturn : 10.535684585571289
Agent1_Train_MaxReturn : -2.3949880599975586
Agent1_Train_MinReturn : -39.09020233154297
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 166500
Agent1_TimeSinceStart : 252.8701090812683
Agent1_Critic_Loss : 0.4074627161026001
Agent1_Actor_Loss : -0.6965429186820984
Agent1_Alpha_Loss : 0.8484166860580444
Agent1_Temperature : 0.09676935401429941
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 111 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 112 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 113 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 114 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 115 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 116 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 117 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 118 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 119 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 120 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -26.1876220703125
Agent0_Eval_StdReturn : 9.185425758361816
Agent0_Eval_MaxReturn : -4.072622299194336
Agent0_Eval_MinReturn : -36.80658721923828
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -20.970348358154297
Agent0_Train_StdReturn : 7.33211088180542
Agent0_Train_MaxReturn : -9.294639587402344
Agent0_Train_MinReturn : -35.894351959228516
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 181500
Agent0_TimeSinceStart : 274.15286326408386
Agent0_Critic_Loss : 0.47973179817199707
Agent0_Actor_Loss : -0.5085757374763489
Agent0_Alpha_Loss : 0.7924610376358032
Agent0_Temperature : 0.09651302484826114
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -28.571578979492188
Agent1_Eval_StdReturn : 15.67301082611084
Agent1_Eval_MaxReturn : -6.633373260498047
Agent1_Eval_MinReturn : -49.0264892578125
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -22.619464874267578
Agent1_Train_StdReturn : 16.6622314453125
Agent1_Train_MaxReturn : 10.88422679901123
Agent1_Train_MinReturn : -49.32700729370117
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 181500
Agent1_TimeSinceStart : 276.26550102233887
Agent1_Critic_Loss : 0.3865857720375061
Agent1_Actor_Loss : -0.6094276309013367
Agent1_Alpha_Loss : 0.7905857563018799
Agent1_Temperature : 0.09650630689851261
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 121 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 122 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 123 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 124 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 125 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 126 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 127 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 128 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 129 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 130 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -29.115625381469727
Agent0_Eval_StdReturn : 8.576529502868652
Agent0_Eval_MaxReturn : -15.763483047485352
Agent0_Eval_MinReturn : -40.35884475708008
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -26.51810646057129
Agent0_Train_StdReturn : 11.818973541259766
Agent0_Train_MaxReturn : -9.958226203918457
Agent0_Train_MinReturn : -52.94584655761719
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 196500
Agent0_TimeSinceStart : 297.5556468963623
Agent0_Critic_Loss : 0.47612708806991577
Agent0_Actor_Loss : -0.44914478063583374
Agent0_Alpha_Loss : 0.7840332984924316
Agent0_Temperature : 0.09626406079707081
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -27.29128074645996
Agent1_Eval_StdReturn : 13.655793190002441
Agent1_Eval_MaxReturn : -4.681344985961914
Agent1_Eval_MinReturn : -42.6507568359375
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -23.106441497802734
Agent1_Train_StdReturn : 10.708494186401367
Agent1_Train_MaxReturn : -7.691933631896973
Agent1_Train_MinReturn : -44.8114013671875
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 196500
Agent1_TimeSinceStart : 299.6666829586029
Agent1_Critic_Loss : 0.43622690439224243
Agent1_Actor_Loss : -0.5283331274986267
Agent1_Alpha_Loss : 0.7868212461471558
Agent1_Temperature : 0.09625311512311743
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 131 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 132 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 133 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 134 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 135 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 136 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 137 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 138 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 139 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 140 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -29.546222686767578
Agent0_Eval_StdReturn : 18.41615867614746
Agent0_Eval_MaxReturn : 0.7386660575866699
Agent0_Eval_MinReturn : -57.929237365722656
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -35.402950286865234
Agent0_Train_StdReturn : 7.742053985595703
Agent0_Train_MaxReturn : -24.472274780273438
Agent0_Train_MinReturn : -49.71193313598633
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 211500
Agent0_TimeSinceStart : 320.875794172287
Agent0_Critic_Loss : 0.4160386919975281
Agent0_Actor_Loss : -0.3890208601951599
Agent0_Alpha_Loss : 0.7785576581954956
Agent0_Temperature : 0.09601954992581022
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -18.591421127319336
Agent1_Eval_StdReturn : 7.362422943115234
Agent1_Eval_MaxReturn : -4.786919593811035
Agent1_Eval_MinReturn : -31.342670440673828
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -25.78216552734375
Agent1_Train_StdReturn : 12.29578971862793
Agent1_Train_MaxReturn : -14.406673431396484
Agent1_Train_MinReturn : -53.54553985595703
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 211500
Agent1_TimeSinceStart : 322.9828839302063
Agent1_Critic_Loss : 0.3540774881839752
Agent1_Actor_Loss : -0.5932399034500122
Agent1_Alpha_Loss : 0.8204249143600464
Agent1_Temperature : 0.0960039532199791
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 141 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 142 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 143 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 144 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 145 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 146 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 147 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 148 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 149 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 150 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -36.290489196777344
Agent0_Eval_StdReturn : 12.122954368591309
Agent0_Eval_MaxReturn : -17.19602394104004
Agent0_Eval_MinReturn : -58.9616813659668
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -30.171382904052734
Agent0_Train_StdReturn : 10.661962509155273
Agent0_Train_MaxReturn : -12.430803298950195
Agent0_Train_MinReturn : -46.9097900390625
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 226500
Agent0_TimeSinceStart : 344.14001965522766
Agent0_Critic_Loss : 0.3709831237792969
Agent0_Actor_Loss : -0.449302613735199
Agent0_Alpha_Loss : 0.80012047290802
Agent0_Temperature : 0.09577423490148626
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -23.413631439208984
Agent1_Eval_StdReturn : 13.766435623168945
Agent1_Eval_MaxReturn : 3.851543426513672
Agent1_Eval_MinReturn : -43.74663543701172
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -22.44600486755371
Agent1_Train_StdReturn : 10.01215648651123
Agent1_Train_MaxReturn : -3.7045631408691406
Agent1_Train_MinReturn : -35.42446517944336
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 226500
Agent1_TimeSinceStart : 346.2312080860138
Agent1_Critic_Loss : 0.343717098236084
Agent1_Actor_Loss : -0.6993119716644287
Agent1_Alpha_Loss : 0.8084455728530884
Agent1_Temperature : 0.09575292996005902
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 151 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 152 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 153 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 154 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 155 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 156 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 157 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 158 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 159 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 160 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -28.8646183013916
Agent0_Eval_StdReturn : 10.096835136413574
Agent0_Eval_MaxReturn : -19.3649959564209
Agent0_Eval_MinReturn : -56.64392852783203
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -22.04267692565918
Agent0_Train_StdReturn : 12.488983154296875
Agent0_Train_MaxReturn : -6.148839950561523
Agent0_Train_MinReturn : -52.58303451538086
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 241500
Agent0_TimeSinceStart : 367.291296005249
Agent0_Critic_Loss : 0.4022432565689087
Agent0_Actor_Loss : -0.4916233420372009
Agent0_Alpha_Loss : 0.8159464001655579
Agent0_Temperature : 0.09552433609581007
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -26.6223087310791
Agent1_Eval_StdReturn : 10.387969970703125
Agent1_Eval_MaxReturn : -7.464611053466797
Agent1_Eval_MinReturn : -41.601898193359375
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -21.869455337524414
Agent1_Train_StdReturn : 10.593989372253418
Agent1_Train_MaxReturn : -0.659977912902832
Agent1_Train_MinReturn : -36.14313888549805
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 241500
Agent1_TimeSinceStart : 369.38128566741943
Agent1_Critic_Loss : 0.506170392036438
Agent1_Actor_Loss : -0.6434035301208496
Agent1_Alpha_Loss : 0.8449909687042236
Agent1_Temperature : 0.09549852897058167
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 161 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 162 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 163 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 164 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 165 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 166 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 167 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 168 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 169 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 170 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -28.3478946685791
Agent0_Eval_StdReturn : 12.097359657287598
Agent0_Eval_MaxReturn : -8.141843795776367
Agent0_Eval_MinReturn : -53.37613296508789
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -20.984989166259766
Agent0_Train_StdReturn : 7.032236576080322
Agent0_Train_MaxReturn : -11.254098892211914
Agent0_Train_MinReturn : -36.411277770996094
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 256500
Agent0_TimeSinceStart : 390.45253562927246
Agent0_Critic_Loss : 0.32909929752349854
Agent0_Actor_Loss : -0.2907380759716034
Agent0_Alpha_Loss : 0.805544376373291
Agent0_Temperature : 0.09527055262663903
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -26.716049194335938
Agent1_Eval_StdReturn : 18.02027702331543
Agent1_Eval_MaxReturn : -1.6649909019470215
Agent1_Eval_MinReturn : -53.732566833496094
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -21.871097564697266
Agent1_Train_StdReturn : 10.348637580871582
Agent1_Train_MaxReturn : -10.057432174682617
Agent1_Train_MinReturn : -46.746124267578125
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 256500
Agent1_TimeSinceStart : 392.4420871734619
Agent1_Critic_Loss : 0.3049764335155487
Agent1_Actor_Loss : -0.509197473526001
Agent1_Alpha_Loss : 0.8098715543746948
Agent1_Temperature : 0.09524205356263774
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 171 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 172 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 173 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 174 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 175 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 176 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 177 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 178 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 179 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 180 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -20.903034210205078
Agent0_Eval_StdReturn : 14.032318115234375
Agent0_Eval_MaxReturn : 3.3147029876708984
Agent0_Eval_MinReturn : -49.04443359375
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -20.160114288330078
Agent0_Train_StdReturn : 9.439260482788086
Agent0_Train_MaxReturn : -9.385672569274902
Agent0_Train_MinReturn : -35.05316162109375
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 271500
Agent0_TimeSinceStart : 412.9269332885742
Agent0_Critic_Loss : 0.3051438331604004
Agent0_Actor_Loss : -0.41357260942459106
Agent0_Alpha_Loss : 0.7938680052757263
Agent0_Temperature : 0.09501581242244875
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -10.24060344696045
Agent1_Eval_StdReturn : 14.10252857208252
Agent1_Eval_MaxReturn : 18.755321502685547
Agent1_Eval_MinReturn : -23.795623779296875
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -26.04498291015625
Agent1_Train_StdReturn : 7.652140140533447
Agent1_Train_MaxReturn : -12.314702987670898
Agent1_Train_MinReturn : -35.219146728515625
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 271500
Agent1_TimeSinceStart : 414.9675874710083
Agent1_Critic_Loss : 0.28917181491851807
Agent1_Actor_Loss : -0.5309678316116333
Agent1_Alpha_Loss : 0.8087109327316284
Agent1_Temperature : 0.09498527083960473
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 181 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 182 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 183 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 184 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 185 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 186 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 187 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 188 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 189 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 190 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -22.07309341430664
Agent0_Eval_StdReturn : 17.41485023498535
Agent0_Eval_MaxReturn : 16.022737503051758
Agent0_Eval_MinReturn : -53.82146453857422
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -20.78061866760254
Agent0_Train_StdReturn : 7.108293056488037
Agent0_Train_MaxReturn : -10.481598854064941
Agent0_Train_MinReturn : -34.160282135009766
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 286500
Agent0_TimeSinceStart : 435.63867712020874
Agent0_Critic_Loss : 0.3493771553039551
Agent0_Actor_Loss : -0.4460321068763733
Agent0_Alpha_Loss : 0.792611837387085
Agent0_Temperature : 0.09476177702826037
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -21.250818252563477
Agent1_Eval_StdReturn : 17.112085342407227
Agent1_Eval_MaxReturn : 2.936591148376465
Agent1_Eval_MinReturn : -57.40129470825195
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -23.527307510375977
Agent1_Train_StdReturn : 11.507820129394531
Agent1_Train_MaxReturn : -6.4306960105896
Agent1_Train_MinReturn : -44.05596923828125
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 286500
Agent1_TimeSinceStart : 437.6892874240875
Agent1_Critic_Loss : 0.2741531431674957
Agent1_Actor_Loss : -0.5251791477203369
Agent1_Alpha_Loss : 0.8031151294708252
Agent1_Temperature : 0.0947278543345802
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 191 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 192 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 193 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 194 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 195 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 196 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 197 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 198 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 199 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 200 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -22.63446044921875
Agent0_Eval_StdReturn : 18.28514289855957
Agent0_Eval_MaxReturn : 16.823040008544922
Agent0_Eval_MinReturn : -45.415611267089844
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -24.533475875854492
Agent0_Train_StdReturn : 13.873749732971191
Agent0_Train_MaxReturn : 1.956168293952942
Agent0_Train_MinReturn : -47.155662536621094
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 301500
Agent0_TimeSinceStart : 458.40357089042664
Agent0_Critic_Loss : 0.25342071056365967
Agent0_Actor_Loss : -0.3998657166957855
Agent0_Alpha_Loss : 0.8027217388153076
Agent0_Temperature : 0.0945089726878936
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -14.98442554473877
Agent1_Eval_StdReturn : 11.627592086791992
Agent1_Eval_MaxReturn : 5.136971473693848
Agent1_Eval_MinReturn : -35.057132720947266
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -30.824270248413086
Agent1_Train_StdReturn : 18.609464645385742
Agent1_Train_MaxReturn : -3.0300283432006836
Agent1_Train_MinReturn : -62.83955383300781
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 301500
Agent1_TimeSinceStart : 460.4585933685303
Agent1_Critic_Loss : 0.2948990762233734
Agent1_Actor_Loss : -0.5183458924293518
Agent1_Alpha_Loss : 0.8067147135734558
Agent1_Temperature : 0.09447066897513634
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 201 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 202 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 203 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 204 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 205 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 206 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 207 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 208 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 209 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 210 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -18.87903594970703
Agent0_Eval_StdReturn : 7.918452739715576
Agent0_Eval_MaxReturn : -9.302515029907227
Agent0_Eval_MinReturn : -32.12144470214844
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -17.578004837036133
Agent0_Train_StdReturn : 14.806057929992676
Agent0_Train_MaxReturn : 7.91201114654541
Agent0_Train_MinReturn : -40.94824981689453
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 316500
Agent0_TimeSinceStart : 481.2346053123474
Agent0_Critic_Loss : 0.2367618829011917
Agent0_Actor_Loss : -0.3572932481765747
Agent0_Alpha_Loss : 0.7698644399642944
Agent0_Temperature : 0.09425573323588293
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -15.902830123901367
Agent1_Eval_StdReturn : 11.921513557434082
Agent1_Eval_MaxReturn : 4.802982330322266
Agent1_Eval_MinReturn : -34.1939811706543
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -13.949444770812988
Agent1_Train_StdReturn : 13.60876750946045
Agent1_Train_MaxReturn : -0.8086349964141846
Agent1_Train_MinReturn : -39.97772216796875
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 316500
Agent1_TimeSinceStart : 483.30131459236145
Agent1_Critic_Loss : 0.24425888061523438
Agent1_Actor_Loss : -0.5100332498550415
Agent1_Alpha_Loss : 0.7880580425262451
Agent1_Temperature : 0.09421482217058028
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 211 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 212 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 213 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 214 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 215 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 216 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 217 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 218 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 219 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 220 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -19.852983474731445
Agent0_Eval_StdReturn : 13.062447547912598
Agent0_Eval_MaxReturn : 0.5471076965332031
Agent0_Eval_MinReturn : -44.43468475341797
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -10.51824951171875
Agent0_Train_StdReturn : 13.686287879943848
Agent0_Train_MaxReturn : 9.06671142578125
Agent0_Train_MinReturn : -43.84870529174805
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 331500
Agent0_TimeSinceStart : 504.1364531517029
Agent0_Critic_Loss : 0.22993463277816772
Agent0_Actor_Loss : -0.32326486706733704
Agent0_Alpha_Loss : 0.7727056741714478
Agent0_Temperature : 0.09400257219076734
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -13.518315315246582
Agent1_Eval_StdReturn : 8.753687858581543
Agent1_Eval_MaxReturn : -2.456515312194824
Agent1_Eval_MinReturn : -31.088951110839844
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -16.9912166595459
Agent1_Train_StdReturn : 17.14722442626953
Agent1_Train_MaxReturn : 13.464906692504883
Agent1_Train_MinReturn : -46.179771423339844
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 331500
Agent1_TimeSinceStart : 506.19957280158997
Agent1_Critic_Loss : 0.3080263137817383
Agent1_Actor_Loss : -0.49696362018585205
Agent1_Alpha_Loss : 0.7716308832168579
Agent1_Temperature : 0.09396000113583818
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 221 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 222 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 223 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 224 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 225 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 226 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 227 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 228 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 229 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 230 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -14.924173355102539
Agent0_Eval_StdReturn : 9.780835151672363
Agent0_Eval_MaxReturn : 2.5503711700439453
Agent0_Eval_MinReturn : -31.565834045410156
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -17.19369125366211
Agent0_Train_StdReturn : 12.975512504577637
Agent0_Train_MaxReturn : -0.8702702522277832
Agent0_Train_MinReturn : -43.016151428222656
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 346500
Agent0_TimeSinceStart : 526.968612909317
Agent0_Critic_Loss : 0.29223567247390747
Agent0_Actor_Loss : -0.3110634386539459
Agent0_Alpha_Loss : 0.7835279703140259
Agent0_Temperature : 0.0937491307583831
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -20.145458221435547
Agent1_Eval_StdReturn : 24.956756591796875
Agent1_Eval_MaxReturn : 20.042255401611328
Agent1_Eval_MinReturn : -59.37761688232422
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -12.942392349243164
Agent1_Train_StdReturn : 12.004321098327637
Agent1_Train_MaxReturn : 11.952781677246094
Agent1_Train_MinReturn : -28.743526458740234
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 346500
Agent1_TimeSinceStart : 529.0362708568573
Agent1_Critic_Loss : 0.2807984948158264
Agent1_Actor_Loss : -0.5160170793533325
Agent1_Alpha_Loss : 0.8086038827896118
Agent1_Temperature : 0.09370543584577096
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 231 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 232 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 233 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 234 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 235 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 236 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 237 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 238 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 239 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 240 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -25.90419578552246
Agent0_Eval_StdReturn : 25.319076538085938
Agent0_Eval_MaxReturn : 0.1861124038696289
Agent0_Eval_MinReturn : -75.75120544433594
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -27.240936279296875
Agent0_Train_StdReturn : 11.350386619567871
Agent0_Train_MaxReturn : -11.811573028564453
Agent0_Train_MinReturn : -46.82594299316406
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 361500
Agent0_TimeSinceStart : 549.830527305603
Agent0_Critic_Loss : 0.23605187237262726
Agent0_Actor_Loss : -0.3597260117530823
Agent0_Alpha_Loss : 0.8051731586456299
Agent0_Temperature : 0.09349390746452166
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -26.179798126220703
Agent1_Eval_StdReturn : 14.059050559997559
Agent1_Eval_MaxReturn : -5.650448799133301
Agent1_Eval_MinReturn : -46.27350616455078
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -34.50747299194336
Agent1_Train_StdReturn : 15.769944190979004
Agent1_Train_MaxReturn : -10.437248229980469
Agent1_Train_MinReturn : -64.09263610839844
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 361500
Agent1_TimeSinceStart : 551.8895988464355
Agent1_Critic_Loss : 0.2416575849056244
Agent1_Actor_Loss : -0.5448768138885498
Agent1_Alpha_Loss : 0.8088729381561279
Agent1_Temperature : 0.09344887388935827
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 241 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 242 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 243 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 244 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 245 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 246 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 247 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 248 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 249 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 250 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -32.3735466003418
Agent0_Eval_StdReturn : 23.46923828125
Agent0_Eval_MaxReturn : -3.795340061187744
Agent0_Eval_MinReturn : -66.66313171386719
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -23.691837310791016
Agent0_Train_StdReturn : 21.325847625732422
Agent0_Train_MaxReturn : 0.9577248096466064
Agent0_Train_MinReturn : -76.80816650390625
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 376500
Agent0_TimeSinceStart : 572.7416260242462
Agent0_Critic_Loss : 0.2850643992424011
Agent0_Actor_Loss : -0.40922874212265015
Agent0_Alpha_Loss : 0.7994428873062134
Agent0_Temperature : 0.09323730557665216
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -18.46457862854004
Agent1_Eval_StdReturn : 17.27296257019043
Agent1_Eval_MaxReturn : 7.694613456726074
Agent1_Eval_MinReturn : -46.92676544189453
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -18.39484977722168
Agent1_Train_StdReturn : 15.374832153320312
Agent1_Train_MaxReturn : 11.0388822555542
Agent1_Train_MinReturn : -37.22166442871094
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 376500
Agent1_TimeSinceStart : 574.8169734477997
Agent1_Critic_Loss : 0.20400278270244598
Agent1_Actor_Loss : -0.5923650860786438
Agent1_Alpha_Loss : 0.8086287975311279
Agent1_Temperature : 0.09319086599320837
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 251 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 252 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 253 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 254 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 255 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 256 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 257 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 258 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 259 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 260 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -16.169286727905273
Agent0_Eval_StdReturn : 18.694875717163086
Agent0_Eval_MaxReturn : 17.32999610900879
Agent0_Eval_MinReturn : -39.41497039794922
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -27.217754364013672
Agent0_Train_StdReturn : 22.933446884155273
Agent0_Train_MaxReturn : 16.09127426147461
Agent0_Train_MinReturn : -65.10749816894531
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 391500
Agent0_TimeSinceStart : 595.6761384010315
Agent0_Critic_Loss : 0.26176387071609497
Agent0_Actor_Loss : -0.36986789107322693
Agent0_Alpha_Loss : 0.8022457957267761
Agent0_Temperature : 0.09298062918509852
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -28.7261962890625
Agent1_Eval_StdReturn : 14.294690132141113
Agent1_Eval_MaxReturn : -4.822025299072266
Agent1_Eval_MinReturn : -44.01750183105469
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -14.6421480178833
Agent1_Train_StdReturn : 18.195409774780273
Agent1_Train_MaxReturn : 12.734899520874023
Agent1_Train_MinReturn : -41.474700927734375
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 391500
Agent1_TimeSinceStart : 597.7392387390137
Agent1_Critic_Loss : 0.34178680181503296
Agent1_Actor_Loss : -0.5325272679328918
Agent1_Alpha_Loss : 0.7996779680252075
Agent1_Temperature : 0.09293297388760471
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 261 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 262 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 263 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 264 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 265 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 266 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 267 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 268 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 269 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 270 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -8.830592155456543
Agent0_Eval_StdReturn : 23.973060607910156
Agent0_Eval_MaxReturn : 37.04143524169922
Agent0_Eval_MinReturn : -38.170684814453125
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -17.002735137939453
Agent0_Train_StdReturn : 23.8173770904541
Agent0_Train_MaxReturn : 24.592941284179688
Agent0_Train_MinReturn : -72.58917999267578
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 406500
Agent0_TimeSinceStart : 618.4507205486298
Agent0_Critic_Loss : 0.2818711996078491
Agent0_Actor_Loss : -0.38809651136398315
Agent0_Alpha_Loss : 0.8022894263267517
Agent0_Temperature : 0.09272166702710759
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -14.469942092895508
Agent1_Eval_StdReturn : 15.369505882263184
Agent1_Eval_MaxReturn : 8.262344360351562
Agent1_Eval_MinReturn : -44.58076477050781
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -34.48859405517578
Agent1_Train_StdReturn : 10.63591480255127
Agent1_Train_MaxReturn : -19.773975372314453
Agent1_Train_MinReturn : -49.332862854003906
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 406500
Agent1_TimeSinceStart : 620.5075852870941
Agent1_Critic_Loss : 0.3110955059528351
Agent1_Actor_Loss : -0.5391139984130859
Agent1_Alpha_Loss : 0.7952686548233032
Agent1_Temperature : 0.09267566039814082
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 271 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 272 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 273 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 274 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 275 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 276 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 277 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 278 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 279 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 280 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -29.437118530273438
Agent0_Eval_StdReturn : 20.271406173706055
Agent0_Eval_MaxReturn : 10.233766555786133
Agent0_Eval_MinReturn : -58.559478759765625
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -31.374256134033203
Agent0_Train_StdReturn : 15.896149635314941
Agent0_Train_MaxReturn : -7.286345481872559
Agent0_Train_MinReturn : -59.03761672973633
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 421500
Agent0_TimeSinceStart : 641.2783060073853
Agent0_Critic_Loss : 0.28867489099502563
Agent0_Actor_Loss : -0.5071629285812378
Agent0_Alpha_Loss : 0.7861278057098389
Agent0_Temperature : 0.09246285321439318
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -10.922975540161133
Agent1_Eval_StdReturn : 14.061430931091309
Agent1_Eval_MaxReturn : 20.354406356811523
Agent1_Eval_MinReturn : -27.05632972717285
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -20.547046661376953
Agent1_Train_StdReturn : 12.871415138244629
Agent1_Train_MaxReturn : -2.233945846557617
Agent1_Train_MinReturn : -48.56040954589844
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 421500
Agent1_TimeSinceStart : 643.3490207195282
Agent1_Critic_Loss : 0.3357458710670471
Agent1_Actor_Loss : -0.5688297748565674
Agent1_Alpha_Loss : 0.8170811533927917
Agent1_Temperature : 0.09241842820853413
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 281 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 282 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 283 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 284 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 285 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 286 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 287 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 288 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 289 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 290 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -21.71173858642578
Agent0_Eval_StdReturn : 20.16192054748535
Agent0_Eval_MaxReturn : 8.067686080932617
Agent0_Eval_MinReturn : -60.01726531982422
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -12.716248512268066
Agent0_Train_StdReturn : 15.684078216552734
Agent0_Train_MaxReturn : 13.780726432800293
Agent0_Train_MinReturn : -39.08708572387695
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 436500
Agent0_TimeSinceStart : 664.0937314033508
Agent0_Critic_Loss : 0.36568909883499146
Agent0_Actor_Loss : -0.4024902582168579
Agent0_Alpha_Loss : 0.7912461757659912
Agent0_Temperature : 0.09220505289547207
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -18.578733444213867
Agent1_Eval_StdReturn : 20.833667755126953
Agent1_Eval_MaxReturn : 10.416316986083984
Agent1_Eval_MinReturn : -47.876953125
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -9.056354522705078
Agent1_Train_StdReturn : 20.778688430786133
Agent1_Train_MaxReturn : 30.503755569458008
Agent1_Train_MinReturn : -57.969764709472656
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 436500
Agent1_TimeSinceStart : 666.1542510986328
Agent1_Critic_Loss : 0.3315914273262024
Agent1_Actor_Loss : -0.5646544694900513
Agent1_Alpha_Loss : 0.8037965297698975
Agent1_Temperature : 0.09216186992626155
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 291 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 292 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 293 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 294 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 295 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 296 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 297 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 298 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 299 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 300 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -34.59016799926758
Agent0_Eval_StdReturn : 21.419849395751953
Agent0_Eval_MaxReturn : 6.754779815673828
Agent0_Eval_MinReturn : -64.0755844116211
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -33.80540084838867
Agent0_Train_StdReturn : 21.685056686401367
Agent0_Train_MaxReturn : 17.6574764251709
Agent0_Train_MinReturn : -59.10113525390625
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 451500
Agent0_TimeSinceStart : 686.926319360733
Agent0_Critic_Loss : 0.4129416346549988
Agent0_Actor_Loss : -0.49102622270584106
Agent0_Alpha_Loss : 0.796013355255127
Agent0_Temperature : 0.09194853124628809
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -10.005633354187012
Agent1_Eval_StdReturn : 12.078459739685059
Agent1_Eval_MaxReturn : 3.9682111740112305
Agent1_Eval_MinReturn : -35.50504684448242
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -20.95986557006836
Agent1_Train_StdReturn : 22.98246192932129
Agent1_Train_MaxReturn : 12.024311065673828
Agent1_Train_MinReturn : -64.5975570678711
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 451500
Agent1_TimeSinceStart : 688.9949560165405
Agent1_Critic_Loss : 0.34250202775001526
Agent1_Actor_Loss : -0.7133606672286987
Agent1_Alpha_Loss : 0.8033043146133423
Agent1_Temperature : 0.09190538604575317
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 301 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 302 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 303 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 304 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 305 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 306 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 307 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 308 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 309 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 310 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -23.66707420349121
Agent0_Eval_StdReturn : 27.774991989135742
Agent0_Eval_MaxReturn : 49.110782623291016
Agent0_Eval_MinReturn : -54.02532958984375
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -10.997737884521484
Agent0_Train_StdReturn : 14.079773902893066
Agent0_Train_MaxReturn : 12.485090255737305
Agent0_Train_MinReturn : -33.356773376464844
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 466500
Agent0_TimeSinceStart : 709.8150129318237
Agent0_Critic_Loss : 0.3596513867378235
Agent0_Actor_Loss : -0.44656991958618164
Agent0_Alpha_Loss : 0.7941880226135254
Agent0_Temperature : 0.09169201659203208
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -17.326358795166016
Agent1_Eval_StdReturn : 12.931768417358398
Agent1_Eval_MaxReturn : 7.1074981689453125
Agent1_Eval_MinReturn : -39.98247528076172
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -16.466020584106445
Agent1_Train_StdReturn : 15.030253410339355
Agent1_Train_MaxReturn : 1.9387803077697754
Agent1_Train_MinReturn : -52.482086181640625
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 466500
Agent1_TimeSinceStart : 711.8826172351837
Agent1_Critic_Loss : 0.3420843482017517
Agent1_Actor_Loss : -0.5461178421974182
Agent1_Alpha_Loss : 0.7913745641708374
Agent1_Temperature : 0.09164863405718413
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 311 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 312 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 313 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 314 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 315 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 316 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 317 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 318 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 319 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 320 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -31.417682647705078
Agent0_Eval_StdReturn : 28.419633865356445
Agent0_Eval_MaxReturn : 19.038705825805664
Agent0_Eval_MinReturn : -82.7593994140625
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -22.13536262512207
Agent0_Train_StdReturn : 20.31511116027832
Agent0_Train_MaxReturn : 13.119131088256836
Agent0_Train_MinReturn : -68.36769104003906
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 481500
Agent0_TimeSinceStart : 732.6683039665222
Agent0_Critic_Loss : 0.29098325967788696
Agent0_Actor_Loss : -0.5146277546882629
Agent0_Alpha_Loss : 0.8125776052474976
Agent0_Temperature : 0.09143475735888251
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -17.696311950683594
Agent1_Eval_StdReturn : 14.26098918914795
Agent1_Eval_MaxReturn : -2.1612377166748047
Agent1_Eval_MinReturn : -44.31068420410156
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -21.889663696289062
Agent1_Train_StdReturn : 17.780359268188477
Agent1_Train_MaxReturn : 14.946634292602539
Agent1_Train_MinReturn : -44.348960876464844
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 481500
Agent1_TimeSinceStart : 734.7372524738312
Agent1_Critic_Loss : 0.3347543478012085
Agent1_Actor_Loss : -0.530648946762085
Agent1_Alpha_Loss : 0.7899632453918457
Agent1_Temperature : 0.09139414588491951
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 321 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 322 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 323 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 324 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 325 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 326 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 327 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 328 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 329 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 330 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -13.853536605834961
Agent0_Eval_StdReturn : 10.978808403015137
Agent0_Eval_MaxReturn : 1.097726583480835
Agent0_Eval_MinReturn : -39.02105712890625
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -21.37209129333496
Agent0_Train_StdReturn : 12.435802459716797
Agent0_Train_MaxReturn : 2.9026975631713867
Agent0_Train_MinReturn : -37.473655700683594
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 496500
Agent0_TimeSinceStart : 755.5532555580139
Agent0_Critic_Loss : 0.364053338766098
Agent0_Actor_Loss : -0.43641215562820435
Agent0_Alpha_Loss : 0.7984566688537598
Agent0_Temperature : 0.09117750254860199
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -28.643169403076172
Agent1_Eval_StdReturn : 12.299561500549316
Agent1_Eval_MaxReturn : -0.6921176910400391
Agent1_Eval_MinReturn : -45.07029342651367
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -13.716038703918457
Agent1_Train_StdReturn : 13.222245216369629
Agent1_Train_MaxReturn : 13.246891021728516
Agent1_Train_MinReturn : -37.61188507080078
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 496500
Agent1_TimeSinceStart : 757.6247560977936
Agent1_Critic_Loss : 0.30364638566970825
Agent1_Actor_Loss : -0.5524756908416748
Agent1_Alpha_Loss : 0.7668384909629822
Agent1_Temperature : 0.0911413077359803
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 331 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 332 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 333 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 334 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 335 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 336 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 337 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 338 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 339 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 340 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -16.699501037597656
Agent0_Eval_StdReturn : 9.909378051757812
Agent0_Eval_MaxReturn : 1.2883856296539307
Agent0_Eval_MinReturn : -29.67685890197754
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -21.01651954650879
Agent0_Train_StdReturn : 19.729534149169922
Agent0_Train_MaxReturn : 17.028488159179688
Agent0_Train_MinReturn : -47.02600860595703
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 511500
Agent0_TimeSinceStart : 778.4515640735626
Agent0_Critic_Loss : 0.3548048734664917
Agent0_Actor_Loss : -0.4590376615524292
Agent0_Alpha_Loss : 0.7978923320770264
Agent0_Temperature : 0.09092027129809074
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -22.357769012451172
Agent1_Eval_StdReturn : 11.360347747802734
Agent1_Eval_MaxReturn : -4.440496444702148
Agent1_Eval_MinReturn : -38.65544891357422
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -21.732654571533203
Agent1_Train_StdReturn : 18.92816162109375
Agent1_Train_MaxReturn : -0.8032045364379883
Agent1_Train_MinReturn : -55.81163787841797
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 511500
Agent1_TimeSinceStart : 780.5207140445709
Agent1_Critic_Loss : 0.3377198576927185
Agent1_Actor_Loss : -0.6431119441986084
Agent1_Alpha_Loss : 0.7759073972702026
Agent1_Temperature : 0.0908904100462731
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 341 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 342 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 343 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 344 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 345 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 346 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 347 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 348 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 349 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 350 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -4.153913497924805
Agent0_Eval_StdReturn : 12.193614959716797
Agent0_Eval_MaxReturn : 21.66075325012207
Agent0_Eval_MinReturn : -21.997146606445312
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -14.222528457641602
Agent0_Train_StdReturn : 14.218676567077637
Agent0_Train_MaxReturn : 14.104767799377441
Agent0_Train_MinReturn : -39.28284454345703
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 526500
Agent0_TimeSinceStart : 801.3707449436188
Agent0_Critic_Loss : 0.34077340364456177
Agent0_Actor_Loss : -0.5019431114196777
Agent0_Alpha_Loss : 0.7869362831115723
Agent0_Temperature : 0.09066433068811589
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -13.386344909667969
Agent1_Eval_StdReturn : 19.744380950927734
Agent1_Eval_MaxReturn : 8.834539413452148
Agent1_Eval_MinReturn : -65.77220153808594
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -8.794768333435059
Agent1_Train_StdReturn : 18.36956787109375
Agent1_Train_MaxReturn : 23.716754913330078
Agent1_Train_MinReturn : -47.69325637817383
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 526500
Agent1_TimeSinceStart : 803.4482507705688
Agent1_Critic_Loss : 0.3689189553260803
Agent1_Actor_Loss : -0.6566136479377747
Agent1_Alpha_Loss : 0.7724124193191528
Agent1_Temperature : 0.09063995155955484
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 351 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 352 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 353 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 354 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 355 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 356 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 357 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 358 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 359 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 360 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -16.44986343383789
Agent0_Eval_StdReturn : 15.780421257019043
Agent0_Eval_MaxReturn : 9.349910736083984
Agent0_Eval_MinReturn : -41.21128463745117
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -17.655296325683594
Agent0_Train_StdReturn : 23.781408309936523
Agent0_Train_MaxReturn : 15.003175735473633
Agent0_Train_MinReturn : -72.5113754272461
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 541500
Agent0_TimeSinceStart : 824.288804769516
Agent0_Critic_Loss : 0.39002901315689087
Agent0_Actor_Loss : -0.4405617117881775
Agent0_Alpha_Loss : 0.7692112922668457
Agent0_Temperature : 0.09041051134873464
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -25.666629791259766
Agent1_Eval_StdReturn : 18.788358688354492
Agent1_Eval_MaxReturn : 0.9185059070587158
Agent1_Eval_MinReturn : -63.547035217285156
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -21.906633377075195
Agent1_Train_StdReturn : 17.64780616760254
Agent1_Train_MaxReturn : 3.2173635959625244
Agent1_Train_MinReturn : -57.8816032409668
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 541500
Agent1_TimeSinceStart : 826.356032371521
Agent1_Critic_Loss : 0.4044039249420166
Agent1_Actor_Loss : -0.6130666732788086
Agent1_Alpha_Loss : 0.7905219793319702
Agent1_Temperature : 0.09038983668668177
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 361 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 362 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 363 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 364 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 365 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 366 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 367 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 368 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 369 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 370 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -11.848169326782227
Agent0_Eval_StdReturn : 14.4962797164917
Agent0_Eval_MaxReturn : 19.852718353271484
Agent0_Eval_MinReturn : -33.47821044921875
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -18.74610710144043
Agent0_Train_StdReturn : 13.413089752197266
Agent0_Train_MaxReturn : -0.6261987686157227
Agent0_Train_MinReturn : -41.45829391479492
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 556500
Agent0_TimeSinceStart : 847.1708562374115
Agent0_Critic_Loss : 0.37975212931632996
Agent0_Actor_Loss : -0.48528385162353516
Agent0_Alpha_Loss : 0.7741063833236694
Agent0_Temperature : 0.09015817034974007
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -21.17336654663086
Agent1_Eval_StdReturn : 12.437556266784668
Agent1_Eval_MaxReturn : -4.257059097290039
Agent1_Eval_MinReturn : -46.392066955566406
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -24.025014877319336
Agent1_Train_StdReturn : 11.52939510345459
Agent1_Train_MaxReturn : 1.300985336303711
Agent1_Train_MinReturn : -42.473731994628906
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 556500
Agent1_TimeSinceStart : 849.2427036762238
Agent1_Critic_Loss : 0.3060595989227295
Agent1_Actor_Loss : -0.566693902015686
Agent1_Alpha_Loss : 0.7835659980773926
Agent1_Temperature : 0.09013892324698351
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 371 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 372 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 373 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 374 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 375 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 376 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 377 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 378 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 379 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 380 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -17.205615997314453
Agent0_Eval_StdReturn : 17.84322738647461
Agent0_Eval_MaxReturn : 10.081826210021973
Agent0_Eval_MinReturn : -45.98017883300781
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -21.011051177978516
Agent0_Train_StdReturn : 19.58672523498535
Agent0_Train_MaxReturn : 5.105833530426025
Agent0_Train_MinReturn : -70.44924926757812
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 571500
Agent0_TimeSinceStart : 870.0921292304993
Agent0_Critic_Loss : 0.3739166855812073
Agent0_Actor_Loss : -0.5036987662315369
Agent0_Alpha_Loss : 0.7726805806159973
Agent0_Temperature : 0.08990801559716165
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -18.540536880493164
Agent1_Eval_StdReturn : 15.035844802856445
Agent1_Eval_MaxReturn : 10.492572784423828
Agent1_Eval_MinReturn : -43.19024658203125
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -18.82219886779785
Agent1_Train_StdReturn : 11.81616497039795
Agent1_Train_MaxReturn : -1.5960254669189453
Agent1_Train_MinReturn : -47.12820053100586
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 571500
Agent1_TimeSinceStart : 872.1649696826935
Agent1_Critic_Loss : 0.3474060297012329
Agent1_Actor_Loss : -0.596429705619812
Agent1_Alpha_Loss : 0.7833575010299683
Agent1_Temperature : 0.08988793224384166
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 381 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 382 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 383 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 384 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 385 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 386 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 387 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 388 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 389 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 390 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -20.137584686279297
Agent0_Eval_StdReturn : 13.073507308959961
Agent0_Eval_MaxReturn : -0.683132529258728
Agent0_Eval_MinReturn : -50.57395935058594
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -11.995019912719727
Agent0_Train_StdReturn : 10.08627700805664
Agent0_Train_MaxReturn : 4.721505165100098
Agent0_Train_MinReturn : -28.57563591003418
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 586500
Agent0_TimeSinceStart : 893.0672333240509
Agent0_Critic_Loss : 0.3902644217014313
Agent0_Actor_Loss : -0.4018877148628235
Agent0_Alpha_Loss : 0.7900694012641907
Agent0_Temperature : 0.08965989056868252
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -17.409055709838867
Agent1_Eval_StdReturn : 13.260212898254395
Agent1_Eval_MaxReturn : 4.634934425354004
Agent1_Eval_MinReturn : -36.963802337646484
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -17.839876174926758
Agent1_Train_StdReturn : 10.526339530944824
Agent1_Train_MaxReturn : 7.396707534790039
Agent1_Train_MinReturn : -30.656475067138672
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 586500
Agent1_TimeSinceStart : 895.147675037384
Agent1_Critic_Loss : 0.43882375955581665
Agent1_Actor_Loss : -0.5723514556884766
Agent1_Alpha_Loss : 0.7577643990516663
Agent1_Temperature : 0.08963883002653408
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 391 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 392 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 393 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 394 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 395 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 396 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 397 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 398 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 399 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 400 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -17.62435531616211
Agent0_Eval_StdReturn : 18.412839889526367
Agent0_Eval_MaxReturn : 13.095370292663574
Agent0_Eval_MinReturn : -38.604087829589844
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -22.292800903320312
Agent0_Train_StdReturn : 18.095966339111328
Agent0_Train_MaxReturn : 2.425783157348633
Agent0_Train_MinReturn : -54.41737365722656
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 601500
Agent0_TimeSinceStart : 916.0066649913788
Agent0_Critic_Loss : 0.39566004276275635
Agent0_Actor_Loss : -0.3166046738624573
Agent0_Alpha_Loss : 0.769904375076294
Agent0_Temperature : 0.08941200655405554
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -16.353412628173828
Agent1_Eval_StdReturn : 11.514243125915527
Agent1_Eval_MaxReturn : 9.819938659667969
Agent1_Eval_MinReturn : -30.96038055419922
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -19.040437698364258
Agent1_Train_StdReturn : 12.022290229797363
Agent1_Train_MaxReturn : -1.4261598587036133
Agent1_Train_MinReturn : -46.15287399291992
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 601500
Agent1_TimeSinceStart : 918.0840871334076
Agent1_Critic_Loss : 0.3825071156024933
Agent1_Actor_Loss : -0.6050965189933777
Agent1_Alpha_Loss : 0.7576438188552856
Agent1_Temperature : 0.08939212123128376
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 401 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 402 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 403 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 404 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 405 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 406 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 407 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 408 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 409 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 410 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -19.976444244384766
Agent0_Eval_StdReturn : 21.967714309692383
Agent0_Eval_MaxReturn : 0.9853954315185547
Agent0_Eval_MinReturn : -76.84526062011719
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -16.282039642333984
Agent0_Train_StdReturn : 13.395174026489258
Agent0_Train_MaxReturn : -2.58232045173645
Agent0_Train_MinReturn : -45.96685028076172
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 616500
Agent0_TimeSinceStart : 938.9454321861267
Agent0_Critic_Loss : 0.3884899914264679
Agent0_Actor_Loss : -0.3891936242580414
Agent0_Alpha_Loss : 0.7911587953567505
Agent0_Temperature : 0.08916457549145464
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -19.632448196411133
Agent1_Eval_StdReturn : 16.680057525634766
Agent1_Eval_MaxReturn : -2.3615670204162598
Agent1_Eval_MinReturn : -66.13249969482422
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -14.008397102355957
Agent1_Train_StdReturn : 14.737716674804688
Agent1_Train_MaxReturn : 13.702550888061523
Agent1_Train_MinReturn : -35.670310974121094
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 616500
Agent1_TimeSinceStart : 941.0186543464661
Agent1_Critic_Loss : 0.39274489879608154
Agent1_Actor_Loss : -0.6214008331298828
Agent1_Alpha_Loss : 0.760277509689331
Agent1_Temperature : 0.08914685960371213
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 411 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 412 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 413 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 414 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 415 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 416 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 417 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 418 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 419 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 420 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -19.600772857666016
Agent0_Eval_StdReturn : 11.237957000732422
Agent0_Eval_MaxReturn : 0.44670701026916504
Agent0_Eval_MinReturn : -41.458648681640625
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -15.6837739944458
Agent0_Train_StdReturn : 15.869152069091797
Agent0_Train_MaxReturn : 18.90491485595703
Agent0_Train_MinReturn : -39.85868453979492
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 631500
Agent0_TimeSinceStart : 961.9464204311371
Agent0_Critic_Loss : 0.4036877751350403
Agent0_Actor_Loss : -0.49033477902412415
Agent0_Alpha_Loss : 0.7720290422439575
Agent0_Temperature : 0.0889152114329401
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -12.742067337036133
Agent1_Eval_StdReturn : 14.053691864013672
Agent1_Eval_MaxReturn : 20.04946517944336
Agent1_Eval_MinReturn : -27.94371223449707
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -19.853849411010742
Agent1_Train_StdReturn : 18.55593490600586
Agent1_Train_MaxReturn : 11.074519157409668
Agent1_Train_MinReturn : -55.2587890625
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 631500
Agent1_TimeSinceStart : 964.0160481929779
Agent1_Critic_Loss : 0.41961216926574707
Agent1_Actor_Loss : -0.525293231010437
Agent1_Alpha_Loss : 0.7829804420471191
Agent1_Temperature : 0.08890076673768592
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 421 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 422 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 423 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 424 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 425 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 426 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 427 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 428 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 429 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 430 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -18.859359741210938
Agent0_Eval_StdReturn : 16.78538703918457
Agent0_Eval_MaxReturn : -1.0152215957641602
Agent0_Eval_MinReturn : -52.45621871948242
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -14.761053085327148
Agent0_Train_StdReturn : 14.811735153198242
Agent0_Train_MaxReturn : 2.9678471088409424
Agent0_Train_MinReturn : -38.066322326660156
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 646500
Agent0_TimeSinceStart : 984.9425842761993
Agent0_Critic_Loss : 0.39037036895751953
Agent0_Actor_Loss : -0.6049894094467163
Agent0_Alpha_Loss : 0.779627799987793
Agent0_Temperature : 0.08866467462090748
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -14.896084785461426
Agent1_Eval_StdReturn : 16.43863296508789
Agent1_Eval_MaxReturn : 23.345733642578125
Agent1_Eval_MinReturn : -33.608543395996094
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -14.448293685913086
Agent1_Train_StdReturn : 13.875933647155762
Agent1_Train_MaxReturn : 8.857091903686523
Agent1_Train_MinReturn : -39.956787109375
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 646500
Agent1_TimeSinceStart : 987.0194234848022
Agent1_Critic_Loss : 0.45110681653022766
Agent1_Actor_Loss : -0.6109698414802551
Agent1_Alpha_Loss : 0.7768856287002563
Agent1_Temperature : 0.08865400535421578
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 431 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 432 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 433 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 434 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 435 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 436 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 437 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 438 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 439 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 440 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -13.227884292602539
Agent0_Eval_StdReturn : 15.364706993103027
Agent0_Eval_MaxReturn : 23.924396514892578
Agent0_Eval_MinReturn : -28.492385864257812
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -19.591472625732422
Agent0_Train_StdReturn : 20.840801239013672
Agent0_Train_MaxReturn : 14.157011985778809
Agent0_Train_MinReturn : -61.999847412109375
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 661500
Agent0_TimeSinceStart : 1007.9166598320007
Agent0_Critic_Loss : 0.46709296107292175
Agent0_Actor_Loss : -0.7017835974693298
Agent0_Alpha_Loss : 0.7942085862159729
Agent0_Temperature : 0.08841460475468842
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -13.075879096984863
Agent1_Eval_StdReturn : 20.52445411682129
Agent1_Eval_MaxReturn : 12.46137523651123
Agent1_Eval_MinReturn : -51.30586242675781
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -22.693880081176758
Agent1_Train_StdReturn : 22.451892852783203
Agent1_Train_MaxReturn : 10.459871292114258
Agent1_Train_MinReturn : -63.16377258300781
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 661500
Agent1_TimeSinceStart : 1009.9972720146179
Agent1_Critic_Loss : 0.38806796073913574
Agent1_Actor_Loss : -0.524726152420044
Agent1_Alpha_Loss : 0.7926880121231079
Agent1_Temperature : 0.08840570352979484
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 441 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 442 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 443 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 444 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 445 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 446 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 447 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 448 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 449 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 450 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -19.42804718017578
Agent0_Eval_StdReturn : 25.699687957763672
Agent0_Eval_MaxReturn : 22.035892486572266
Agent0_Eval_MinReturn : -56.99649429321289
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -15.820162773132324
Agent0_Train_StdReturn : 20.13653564453125
Agent0_Train_MaxReturn : 19.937034606933594
Agent0_Train_MinReturn : -45.627479553222656
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 676500
Agent0_TimeSinceStart : 1030.4813630580902
Agent0_Critic_Loss : 0.40684232115745544
Agent0_Actor_Loss : -0.48494261503219604
Agent0_Alpha_Loss : 0.7726725339889526
Agent0_Temperature : 0.08816531436393063
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -13.033653259277344
Agent1_Eval_StdReturn : 10.772171974182129
Agent1_Eval_MaxReturn : 8.231582641601562
Agent1_Eval_MinReturn : -28.726879119873047
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -13.276847839355469
Agent1_Train_StdReturn : 11.299575805664062
Agent1_Train_MaxReturn : 10.525200843811035
Agent1_Train_MinReturn : -25.208179473876953
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 676500
Agent1_TimeSinceStart : 1032.5239248275757
Agent1_Critic_Loss : 0.3484123945236206
Agent1_Actor_Loss : -0.6895925998687744
Agent1_Alpha_Loss : 0.7883237600326538
Agent1_Temperature : 0.0881571810036805
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 451 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 452 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 453 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 454 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 455 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 456 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 457 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 458 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 459 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 460 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -20.875125885009766
Agent0_Eval_StdReturn : 23.436134338378906
Agent0_Eval_MaxReturn : 14.034128189086914
Agent0_Eval_MinReturn : -71.99649047851562
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -19.717660903930664
Agent0_Train_StdReturn : 15.26095199584961
Agent0_Train_MaxReturn : 9.128549575805664
Agent0_Train_MinReturn : -35.50041198730469
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 691500
Agent0_TimeSinceStart : 1053.190968990326
Agent0_Critic_Loss : 0.3935311436653137
Agent0_Actor_Loss : -0.551895260810852
Agent0_Alpha_Loss : 0.7881442308425903
Agent0_Temperature : 0.08791563422130853
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -14.918339729309082
Agent1_Eval_StdReturn : 19.501955032348633
Agent1_Eval_MaxReturn : 21.53673553466797
Agent1_Eval_MinReturn : -43.60742950439453
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -9.23992919921875
Agent1_Train_StdReturn : 10.54200267791748
Agent1_Train_MaxReturn : 9.749228477478027
Agent1_Train_MinReturn : -22.846637725830078
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 691500
Agent1_TimeSinceStart : 1055.2790360450745
Agent1_Critic_Loss : 0.5095545649528503
Agent1_Actor_Loss : -0.6350686550140381
Agent1_Alpha_Loss : 0.7856808304786682
Agent1_Temperature : 0.08790930751343
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 461 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 462 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 463 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 464 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 465 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 466 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 467 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 468 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 469 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 470 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -14.931729316711426
Agent0_Eval_StdReturn : 17.193357467651367
Agent0_Eval_MaxReturn : 2.019618511199951
Agent0_Eval_MinReturn : -58.25473403930664
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -21.851428985595703
Agent0_Train_StdReturn : 19.9017276763916
Agent0_Train_MaxReturn : 15.214674949645996
Agent0_Train_MinReturn : -50.060157775878906
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 706500
Agent0_TimeSinceStart : 1076.1871778964996
Agent0_Critic_Loss : 0.39611005783081055
Agent0_Actor_Loss : -0.5248307585716248
Agent0_Alpha_Loss : 0.7838223576545715
Agent0_Temperature : 0.08766508926548162
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -18.742097854614258
Agent1_Eval_StdReturn : 17.17107391357422
Agent1_Eval_MaxReturn : 9.221521377563477
Agent1_Eval_MinReturn : -40.96721267700195
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -25.33680534362793
Agent1_Train_StdReturn : 12.94883918762207
Agent1_Train_MaxReturn : -6.701727867126465
Agent1_Train_MinReturn : -44.2752571105957
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 706500
Agent1_TimeSinceStart : 1078.2652134895325
Agent1_Critic_Loss : 0.3334636092185974
Agent1_Actor_Loss : -0.5242506861686707
Agent1_Alpha_Loss : 0.7774423360824585
Agent1_Temperature : 0.08766237886004485
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 471 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 472 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 473 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 474 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 475 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 476 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 477 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 478 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 479 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 480 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -23.78609275817871
Agent0_Eval_StdReturn : 18.49661636352539
Agent0_Eval_MaxReturn : 0.9484844207763672
Agent0_Eval_MinReturn : -51.99486541748047
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -12.40347671508789
Agent0_Train_StdReturn : 15.29958438873291
Agent0_Train_MaxReturn : 12.419658660888672
Agent0_Train_MinReturn : -39.66883850097656
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 721500
Agent0_TimeSinceStart : 1099.1686928272247
Agent0_Critic_Loss : 0.3393387794494629
Agent0_Actor_Loss : -0.5197559595108032
Agent0_Alpha_Loss : 0.7707560062408447
Agent0_Temperature : 0.08741485047024433
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -10.29857063293457
Agent1_Eval_StdReturn : 12.376964569091797
Agent1_Eval_MaxReturn : 7.8498663902282715
Agent1_Eval_MinReturn : -31.393306732177734
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -15.596531867980957
Agent1_Train_StdReturn : 21.202184677124023
Agent1_Train_MaxReturn : 8.717048645019531
Agent1_Train_MinReturn : -56.5689697265625
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 721500
Agent1_TimeSinceStart : 1101.248971939087
Agent1_Critic_Loss : 0.38059645891189575
Agent1_Actor_Loss : -0.6510242223739624
Agent1_Alpha_Loss : 0.7745919227600098
Agent1_Temperature : 0.08741458597638774
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 481 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 482 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 483 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 484 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 485 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 486 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 487 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 488 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 489 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 490 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -20.412885665893555
Agent0_Eval_StdReturn : 30.73226547241211
Agent0_Eval_MaxReturn : 14.237833023071289
Agent0_Eval_MinReturn : -80.90066528320312
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -16.785369873046875
Agent0_Train_StdReturn : 12.144124984741211
Agent0_Train_MaxReturn : 2.1561331748962402
Agent0_Train_MinReturn : -41.600547790527344
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 736500
Agent0_TimeSinceStart : 1122.130175113678
Agent0_Critic_Loss : 0.4278745651245117
Agent0_Actor_Loss : -0.5988946557044983
Agent0_Alpha_Loss : 0.7916018962860107
Agent0_Temperature : 0.08716571562196235
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -18.930660247802734
Agent1_Eval_StdReturn : 19.136878967285156
Agent1_Eval_MaxReturn : 7.560704231262207
Agent1_Eval_MinReturn : -54.6314697265625
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -22.34537124633789
Agent1_Train_StdReturn : 23.068138122558594
Agent1_Train_MaxReturn : 9.989339828491211
Agent1_Train_MinReturn : -73.86368560791016
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 736500
Agent1_TimeSinceStart : 1124.2047038078308
Agent1_Critic_Loss : 0.39950913190841675
Agent1_Actor_Loss : -0.631294846534729
Agent1_Alpha_Loss : 0.783039927482605
Agent1_Temperature : 0.08716657103035659
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 491 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 492 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 493 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 494 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 495 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 496 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 497 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 498 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 499 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 500 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -14.513646125793457
Agent0_Eval_StdReturn : 25.21091651916504
Agent0_Eval_MaxReturn : 34.1112174987793
Agent0_Eval_MinReturn : -53.276100158691406
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -7.904667854309082
Agent0_Train_StdReturn : 18.204347610473633
Agent0_Train_MaxReturn : 16.774856567382812
Agent0_Train_MinReturn : -36.465476989746094
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 751500
Agent0_TimeSinceStart : 1145.140056848526
Agent0_Critic_Loss : 0.4307962954044342
Agent0_Actor_Loss : -0.5263699293136597
Agent0_Alpha_Loss : 0.7721030712127686
Agent0_Temperature : 0.08691630177667954
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -3.890847682952881
Agent1_Eval_StdReturn : 6.658429145812988
Agent1_Eval_MaxReturn : 5.788137912750244
Agent1_Eval_MinReturn : -12.60276985168457
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -15.982345581054688
Agent1_Train_StdReturn : 17.49322509765625
Agent1_Train_MaxReturn : 24.030515670776367
Agent1_Train_MinReturn : -48.55230712890625
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 751500
Agent1_TimeSinceStart : 1147.225415945053
Agent1_Critic_Loss : 0.4685179591178894
Agent1_Actor_Loss : -0.6289372444152832
Agent1_Alpha_Loss : 0.7864287495613098
Agent1_Temperature : 0.08691976618126014
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 501 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 502 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 503 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 504 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 505 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 506 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 507 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 508 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 509 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 510 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -14.334981918334961
Agent0_Eval_StdReturn : 19.021223068237305
Agent0_Eval_MaxReturn : 9.262336730957031
Agent0_Eval_MinReturn : -47.81731414794922
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -15.389147758483887
Agent0_Train_StdReturn : 10.438002586364746
Agent0_Train_MaxReturn : 8.755430221557617
Agent0_Train_MinReturn : -30.389728546142578
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 766500
Agent0_TimeSinceStart : 1168.1333184242249
Agent0_Critic_Loss : 0.4994024634361267
Agent0_Actor_Loss : -0.5041120052337646
Agent0_Alpha_Loss : 0.7885651588439941
Agent0_Temperature : 0.08666821987739493
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -25.249629974365234
Agent1_Eval_StdReturn : 20.489383697509766
Agent1_Eval_MaxReturn : 9.976041793823242
Agent1_Eval_MinReturn : -56.2510986328125
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -7.796441078186035
Agent1_Train_StdReturn : 14.888113021850586
Agent1_Train_MaxReturn : 12.95469856262207
Agent1_Train_MinReturn : -37.818321228027344
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 766500
Agent1_TimeSinceStart : 1170.2048161029816
Agent1_Critic_Loss : 0.39899444580078125
Agent1_Actor_Loss : -0.7259325981140137
Agent1_Alpha_Loss : 0.781425952911377
Agent1_Temperature : 0.08667333761133296
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 511 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 512 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 513 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 514 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 515 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 516 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 517 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 518 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 519 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 520 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -16.776954650878906
Agent0_Eval_StdReturn : 16.08435821533203
Agent0_Eval_MaxReturn : 7.742480754852295
Agent0_Eval_MinReturn : -46.644287109375
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -11.837955474853516
Agent0_Train_StdReturn : 13.489106178283691
Agent0_Train_MaxReturn : 6.1932759284973145
Agent0_Train_MinReturn : -31.199195861816406
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 781500
Agent0_TimeSinceStart : 1191.1247861385345
Agent0_Critic_Loss : 0.4918518364429474
Agent0_Actor_Loss : -0.5338878631591797
Agent0_Alpha_Loss : 0.7863858342170715
Agent0_Temperature : 0.08641993590167112
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -30.010473251342773
Agent1_Eval_StdReturn : 17.753280639648438
Agent1_Eval_MaxReturn : 0.5066537857055664
Agent1_Eval_MinReturn : -53.64421081542969
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -25.949153900146484
Agent1_Train_StdReturn : 14.034697532653809
Agent1_Train_MaxReturn : -6.471985816955566
Agent1_Train_MinReturn : -49.16902160644531
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 781500
Agent1_TimeSinceStart : 1193.198917388916
Agent1_Critic_Loss : 0.5016757249832153
Agent1_Actor_Loss : -0.5902674794197083
Agent1_Alpha_Loss : 0.7863718271255493
Agent1_Temperature : 0.08642691138597193
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 521 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 522 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 523 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 524 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 525 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 526 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 527 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 528 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 529 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 530 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -21.7619686126709
Agent0_Eval_StdReturn : 17.25685691833496
Agent0_Eval_MaxReturn : 9.160436630249023
Agent0_Eval_MinReturn : -53.1319580078125
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -13.526644706726074
Agent0_Train_StdReturn : 15.382420539855957
Agent0_Train_MaxReturn : 6.0567626953125
Agent0_Train_MinReturn : -47.56563949584961
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 796500
Agent0_TimeSinceStart : 1214.0737709999084
Agent0_Critic_Loss : 0.5159310102462769
Agent0_Actor_Loss : -0.48805731534957886
Agent0_Alpha_Loss : 0.7825620770454407
Agent0_Temperature : 0.08617250518479455
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -19.598310470581055
Agent1_Eval_StdReturn : 21.38932228088379
Agent1_Eval_MaxReturn : 14.471403121948242
Agent1_Eval_MinReturn : -45.67906188964844
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -18.42459487915039
Agent1_Train_StdReturn : 15.237044334411621
Agent1_Train_MaxReturn : -0.2380084991455078
Agent1_Train_MinReturn : -49.20746994018555
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 796500
Agent1_TimeSinceStart : 1216.1456685066223
Agent1_Critic_Loss : 0.5236517190933228
Agent1_Actor_Loss : -0.7281553745269775
Agent1_Alpha_Loss : 0.7897605895996094
Agent1_Temperature : 0.0861799999507498
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 531 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 532 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 533 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 534 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 535 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 536 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 537 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 538 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 539 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 540 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -10.694601058959961
Agent0_Eval_StdReturn : 10.684357643127441
Agent0_Eval_MaxReturn : 2.824723243713379
Agent0_Eval_MinReturn : -37.37053298950195
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -10.751474380493164
Agent0_Train_StdReturn : 12.367990493774414
Agent0_Train_MaxReturn : 14.343315124511719
Agent0_Train_MinReturn : -31.819372177124023
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 811500
Agent0_TimeSinceStart : 1237.0267796516418
Agent0_Critic_Loss : 0.47882118821144104
Agent0_Actor_Loss : -0.4997652769088745
Agent0_Alpha_Loss : 0.7820830941200256
Agent0_Temperature : 0.08592631998750107
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -19.179283142089844
Agent1_Eval_StdReturn : 9.743865966796875
Agent1_Eval_MaxReturn : -9.907432556152344
Agent1_Eval_MinReturn : -41.66950225830078
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -17.465648651123047
Agent1_Train_StdReturn : 23.249792098999023
Agent1_Train_MaxReturn : 20.29754638671875
Agent1_Train_MinReturn : -62.98292541503906
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 811500
Agent1_TimeSinceStart : 1239.108122587204
Agent1_Critic_Loss : 0.7062333226203918
Agent1_Actor_Loss : -0.7197225093841553
Agent1_Alpha_Loss : 0.7853997349739075
Agent1_Temperature : 0.08593295091363501
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 541 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 542 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 543 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 544 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 545 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 546 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 547 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 548 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 549 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 550 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -27.10080909729004
Agent0_Eval_StdReturn : 18.79487419128418
Agent0_Eval_MaxReturn : -4.4282941818237305
Agent0_Eval_MinReturn : -69.01715850830078
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -20.214031219482422
Agent0_Train_StdReturn : 11.153538703918457
Agent0_Train_MaxReturn : 3.1899752616882324
Agent0_Train_MinReturn : -36.0400505065918
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 826500
Agent0_TimeSinceStart : 1259.9822661876678
Agent0_Critic_Loss : 0.5076723098754883
Agent0_Actor_Loss : -0.5924091339111328
Agent0_Alpha_Loss : 0.7901421785354614
Agent0_Temperature : 0.0856800047431566
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -20.468753814697266
Agent1_Eval_StdReturn : 23.431377410888672
Agent1_Eval_MaxReturn : 11.443513870239258
Agent1_Eval_MinReturn : -59.19902038574219
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -15.684804916381836
Agent1_Train_StdReturn : 17.643177032470703
Agent1_Train_MaxReturn : 7.252008438110352
Agent1_Train_MinReturn : -42.00849151611328
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 826500
Agent1_TimeSinceStart : 1262.0535414218903
Agent1_Critic_Loss : 0.5406312346458435
Agent1_Actor_Loss : -0.6626356840133667
Agent1_Alpha_Loss : 0.7771177887916565
Agent1_Temperature : 0.08568790003665867
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 551 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 552 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 553 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 554 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 555 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 556 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 557 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 558 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 559 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 560 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -10.856356620788574
Agent0_Eval_StdReturn : 21.13762855529785
Agent0_Eval_MaxReturn : 30.50897216796875
Agent0_Eval_MinReturn : -39.9981689453125
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -7.493853569030762
Agent0_Train_StdReturn : 15.713570594787598
Agent0_Train_MaxReturn : 16.650094985961914
Agent0_Train_MinReturn : -44.23994064331055
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 841500
Agent0_TimeSinceStart : 1282.9855012893677
Agent0_Critic_Loss : 0.5150788426399231
Agent0_Actor_Loss : -0.5479227900505066
Agent0_Alpha_Loss : 0.7794061303138733
Agent0_Temperature : 0.08543500076141688
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -17.081655502319336
Agent1_Eval_StdReturn : 10.340754508972168
Agent1_Eval_MaxReturn : 6.368247032165527
Agent1_Eval_MinReturn : -32.11155319213867
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -13.199785232543945
Agent1_Train_StdReturn : 20.65049171447754
Agent1_Train_MaxReturn : 12.870691299438477
Agent1_Train_MinReturn : -48.464866638183594
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 841500
Agent1_TimeSinceStart : 1285.061849117279
Agent1_Critic_Loss : 0.658190131187439
Agent1_Actor_Loss : -0.7022883296012878
Agent1_Alpha_Loss : 0.7833274006843567
Agent1_Temperature : 0.08544442366225824
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 561 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 562 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 563 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 564 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 565 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 566 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 567 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 568 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 569 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 570 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -7.917021751403809
Agent0_Eval_StdReturn : 15.537736892700195
Agent0_Eval_MaxReturn : 16.76669692993164
Agent0_Eval_MinReturn : -35.23849868774414
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -11.094697952270508
Agent0_Train_StdReturn : 14.59049129486084
Agent0_Train_MaxReturn : 13.929101943969727
Agent0_Train_MinReturn : -37.77021789550781
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 856500
Agent0_TimeSinceStart : 1305.9521305561066
Agent0_Critic_Loss : 0.4672778248786926
Agent0_Actor_Loss : -0.5096803307533264
Agent0_Alpha_Loss : 0.7793806791305542
Agent0_Temperature : 0.08519124642065495
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -20.33612060546875
Agent1_Eval_StdReturn : 7.0080976486206055
Agent1_Eval_MaxReturn : -8.762984275817871
Agent1_Eval_MinReturn : -33.9891357421875
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -15.303979873657227
Agent1_Train_StdReturn : 11.162581443786621
Agent1_Train_MaxReturn : 2.080373764038086
Agent1_Train_MinReturn : -32.36736297607422
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 856500
Agent1_TimeSinceStart : 1308.035441160202
Agent1_Critic_Loss : 0.5048006772994995
Agent1_Actor_Loss : -0.6152321100234985
Agent1_Alpha_Loss : 0.7570710182189941
Agent1_Temperature : 0.08520282047098336
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 571 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 572 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 573 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 574 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 575 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 576 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 577 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 578 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 579 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 580 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -17.965681076049805
Agent0_Eval_StdReturn : 15.070311546325684
Agent0_Eval_MaxReturn : 7.228653907775879
Agent0_Eval_MinReturn : -43.70570373535156
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -8.301798820495605
Agent0_Train_StdReturn : 9.400897026062012
Agent0_Train_MaxReturn : 11.03385066986084
Agent0_Train_MinReturn : -21.782691955566406
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 871500
Agent0_TimeSinceStart : 1329.055008172989
Agent0_Critic_Loss : 0.5708181858062744
Agent0_Actor_Loss : -0.5846831798553467
Agent0_Alpha_Loss : 0.7725229263305664
Agent0_Temperature : 0.0849478730720243
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -10.95566177368164
Agent1_Eval_StdReturn : 11.932312965393066
Agent1_Eval_MaxReturn : 5.020627975463867
Agent1_Eval_MinReturn : -30.77415657043457
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -8.346047401428223
Agent1_Train_StdReturn : 20.454267501831055
Agent1_Train_MaxReturn : 41.64658737182617
Agent1_Train_MinReturn : -37.19621276855469
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 871500
Agent1_TimeSinceStart : 1331.1377141475677
Agent1_Critic_Loss : 0.6191519498825073
Agent1_Actor_Loss : -0.763810932636261
Agent1_Alpha_Loss : 0.750056803226471
Agent1_Temperature : 0.08496363496660701
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 581 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 582 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 583 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 584 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 585 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 586 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 587 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 588 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 589 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 590 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -15.859667778015137
Agent0_Eval_StdReturn : 16.234914779663086
Agent0_Eval_MaxReturn : 5.07524299621582
Agent0_Eval_MinReturn : -52.09171676635742
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -10.689359664916992
Agent0_Train_StdReturn : 13.056059837341309
Agent0_Train_MaxReturn : 7.183826446533203
Agent0_Train_MinReturn : -28.092544555664062
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 886500
Agent0_TimeSinceStart : 1352.117285490036
Agent0_Critic_Loss : 0.46581071615219116
Agent0_Actor_Loss : -0.5632685422897339
Agent0_Alpha_Loss : 0.7796280384063721
Agent0_Temperature : 0.08470651120533126
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -15.803781509399414
Agent1_Eval_StdReturn : 15.620857238769531
Agent1_Eval_MaxReturn : 5.487699031829834
Agent1_Eval_MinReturn : -47.04423141479492
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -15.331230163574219
Agent1_Train_StdReturn : 6.211780071258545
Agent1_Train_MaxReturn : -3.1791248321533203
Agent1_Train_MinReturn : -23.196775436401367
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 886500
Agent1_TimeSinceStart : 1354.2047255039215
Agent1_Critic_Loss : 0.6237125396728516
Agent1_Actor_Loss : -0.6838277578353882
Agent1_Alpha_Loss : 0.7664633393287659
Agent1_Temperature : 0.08472570528116947
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 591 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 592 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 593 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 594 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 595 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 596 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 597 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 598 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 599 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 600 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -16.733299255371094
Agent0_Eval_StdReturn : 10.616755485534668
Agent0_Eval_MaxReturn : -1.8078007698059082
Agent0_Eval_MinReturn : -35.62833786010742
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -12.63737678527832
Agent0_Train_StdReturn : 15.41231632232666
Agent0_Train_MaxReturn : 12.143095016479492
Agent0_Train_MinReturn : -44.051937103271484
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 901500
Agent0_TimeSinceStart : 1375.1749970912933
Agent0_Critic_Loss : 0.5000241994857788
Agent0_Actor_Loss : -0.6112868785858154
Agent0_Alpha_Loss : 0.7701322436332703
Agent0_Temperature : 0.08446584815473109
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -10.733138084411621
Agent1_Eval_StdReturn : 13.201155662536621
Agent1_Eval_MaxReturn : 15.610371589660645
Agent1_Eval_MinReturn : -25.60657501220703
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -19.307592391967773
Agent1_Train_StdReturn : 17.359161376953125
Agent1_Train_MaxReturn : 23.729568481445312
Agent1_Train_MinReturn : -37.722564697265625
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 901500
Agent1_TimeSinceStart : 1377.2617943286896
Agent1_Critic_Loss : 0.6257579922676086
Agent1_Actor_Loss : -0.5934855937957764
Agent1_Alpha_Loss : 0.7593859434127808
Agent1_Temperature : 0.08448831464929608
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 601 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 602 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 603 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 604 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 605 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 606 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 607 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 608 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 609 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 610 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -12.94428539276123
Agent0_Eval_StdReturn : 17.783979415893555
Agent0_Eval_MaxReturn : 12.997884750366211
Agent0_Eval_MinReturn : -44.64665985107422
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -20.72538948059082
Agent0_Train_StdReturn : 13.627620697021484
Agent0_Train_MaxReturn : 1.5374469757080078
Agent0_Train_MinReturn : -46.435115814208984
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 916500
Agent0_TimeSinceStart : 1398.216055393219
Agent0_Critic_Loss : 0.6575592756271362
Agent0_Actor_Loss : -0.5874159336090088
Agent0_Alpha_Loss : 0.7834722995758057
Agent0_Temperature : 0.08422507229789687
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -16.058866500854492
Agent1_Eval_StdReturn : 12.41718864440918
Agent1_Eval_MaxReturn : 1.3622586727142334
Agent1_Eval_MinReturn : -43.48389434814453
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -9.422894477844238
Agent1_Train_StdReturn : 12.825884819030762
Agent1_Train_MaxReturn : 11.865260124206543
Agent1_Train_MinReturn : -36.00737762451172
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 916500
Agent1_TimeSinceStart : 1400.2922644615173
Agent1_Critic_Loss : 0.6760923862457275
Agent1_Actor_Loss : -0.8177477121353149
Agent1_Alpha_Loss : 0.7742232084274292
Agent1_Temperature : 0.08425151829380208
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 611 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 612 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 613 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 614 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 615 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 616 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 617 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 618 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 619 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 620 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -11.466951370239258
Agent0_Eval_StdReturn : 9.966744422912598
Agent0_Eval_MaxReturn : -0.5121870040893555
Agent0_Eval_MinReturn : -27.477420806884766
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -6.868640899658203
Agent0_Train_StdReturn : 13.170366287231445
Agent0_Train_MaxReturn : 9.545185089111328
Agent0_Train_MinReturn : -40.07073974609375
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 931500
Agent0_TimeSinceStart : 1421.2298481464386
Agent0_Critic_Loss : 0.5925977230072021
Agent0_Actor_Loss : -0.5455197095870972
Agent0_Alpha_Loss : 0.7596611976623535
Agent0_Temperature : 0.0839848360383313
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -17.4682674407959
Agent1_Eval_StdReturn : 14.346803665161133
Agent1_Eval_MaxReturn : -2.2940478324890137
Agent1_Eval_MinReturn : -46.041927337646484
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -11.329055786132812
Agent1_Train_StdReturn : 14.721920013427734
Agent1_Train_MaxReturn : 19.40625
Agent1_Train_MinReturn : -30.179302215576172
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 931500
Agent1_TimeSinceStart : 1423.3122732639313
Agent1_Critic_Loss : 0.6487200856208801
Agent1_Actor_Loss : -0.8339424133300781
Agent1_Alpha_Loss : 0.7622144222259521
Agent1_Temperature : 0.08401336852963377
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 621 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 622 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 623 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 624 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 625 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 626 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 627 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 628 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 629 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 630 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -12.695671081542969
Agent0_Eval_StdReturn : 12.081082344055176
Agent0_Eval_MaxReturn : 8.37240982055664
Agent0_Eval_MinReturn : -30.372386932373047
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -21.690088272094727
Agent0_Train_StdReturn : 17.96774673461914
Agent0_Train_MaxReturn : 0.5587887763977051
Agent0_Train_MinReturn : -54.8952751159668
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 946500
Agent0_TimeSinceStart : 1444.2742609977722
Agent0_Critic_Loss : 0.6336269974708557
Agent0_Actor_Loss : -0.7071835994720459
Agent0_Alpha_Loss : 0.7536292672157288
Agent0_Temperature : 0.0837456197936511
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -11.083611488342285
Agent1_Eval_StdReturn : 7.880646705627441
Agent1_Eval_MaxReturn : -1.5969960689544678
Agent1_Eval_MinReturn : -31.451139450073242
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -19.68031120300293
Agent1_Train_StdReturn : 12.355145454406738
Agent1_Train_MaxReturn : 6.7083353996276855
Agent1_Train_MinReturn : -42.10831832885742
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 946500
Agent1_TimeSinceStart : 1446.3571305274963
Agent1_Critic_Loss : 0.7437644600868225
Agent1_Actor_Loss : -0.6465713977813721
Agent1_Alpha_Loss : 0.7756650447845459
Agent1_Temperature : 0.08377469498504661
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 631 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 632 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 633 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 634 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 635 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 636 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 637 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 638 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 639 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 640 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -15.710803031921387
Agent0_Eval_StdReturn : 12.179352760314941
Agent0_Eval_MaxReturn : 10.616983413696289
Agent0_Eval_MinReturn : -33.75432586669922
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -16.879192352294922
Agent0_Train_StdReturn : 22.10559844970703
Agent0_Train_MaxReturn : 10.646232604980469
Agent0_Train_MinReturn : -66.3825454711914
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 961500
Agent0_TimeSinceStart : 1467.2830398082733
Agent0_Critic_Loss : 0.5394467711448669
Agent0_Actor_Loss : -0.7453135251998901
Agent0_Alpha_Loss : 0.7722079753875732
Agent0_Temperature : 0.0835073068019309
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -18.518808364868164
Agent1_Eval_StdReturn : 16.580453872680664
Agent1_Eval_MaxReturn : 2.5234851837158203
Agent1_Eval_MinReturn : -46.69172286987305
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -21.90793228149414
Agent1_Train_StdReturn : 13.55798625946045
Agent1_Train_MaxReturn : -6.078652858734131
Agent1_Train_MinReturn : -46.17750549316406
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 961500
Agent1_TimeSinceStart : 1469.3601529598236
Agent1_Critic_Loss : 0.6659697890281677
Agent1_Actor_Loss : -0.7374945878982544
Agent1_Alpha_Loss : 0.776980996131897
Agent1_Temperature : 0.08353563318019491
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 641 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 642 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 643 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 644 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 645 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 646 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 647 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 648 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 649 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 650 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -14.951184272766113
Agent0_Eval_StdReturn : 14.88510799407959
Agent0_Eval_MaxReturn : 7.307082176208496
Agent0_Eval_MinReturn : -39.766475677490234
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -20.00259017944336
Agent0_Train_StdReturn : 16.94331932067871
Agent0_Train_MaxReturn : -1.3454256057739258
Agent0_Train_MinReturn : -55.796634674072266
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 976500
Agent0_TimeSinceStart : 1490.2899956703186
Agent0_Critic_Loss : 0.6533994078636169
Agent0_Actor_Loss : -0.6331635117530823
Agent0_Alpha_Loss : 0.7644267082214355
Agent0_Temperature : 0.08326975923516707
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -11.478757858276367
Agent1_Eval_StdReturn : 11.765989303588867
Agent1_Eval_MaxReturn : 6.780707359313965
Agent1_Eval_MinReturn : -29.692138671875
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -10.948481559753418
Agent1_Train_StdReturn : 16.470792770385742
Agent1_Train_MaxReturn : 16.35126495361328
Agent1_Train_MinReturn : -37.7554817199707
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 976500
Agent1_TimeSinceStart : 1492.3652746677399
Agent1_Critic_Loss : 0.7075092792510986
Agent1_Actor_Loss : -0.6390426158905029
Agent1_Alpha_Loss : 0.7804238796234131
Agent1_Temperature : 0.08329651519023698
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 651 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 652 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 653 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 654 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 655 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 656 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 657 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 658 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 659 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 660 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -4.21898889541626
Agent0_Eval_StdReturn : 9.205902099609375
Agent0_Eval_MaxReturn : 11.458770751953125
Agent0_Eval_MinReturn : -21.818214416503906
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -4.197646617889404
Agent0_Train_StdReturn : 21.260560989379883
Agent0_Train_MaxReturn : 39.54447937011719
Agent0_Train_MinReturn : -50.188880920410156
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 991500
Agent0_TimeSinceStart : 1513.2947943210602
Agent0_Critic_Loss : 0.6298233866691589
Agent0_Actor_Loss : -0.5649089813232422
Agent0_Alpha_Loss : 0.7699682712554932
Agent0_Temperature : 0.08303253264869874
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -20.10640525817871
Agent1_Eval_StdReturn : 22.337379455566406
Agent1_Eval_MaxReturn : 13.590217590332031
Agent1_Eval_MinReturn : -62.59346008300781
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -29.101818084716797
Agent1_Train_StdReturn : 28.44843864440918
Agent1_Train_MaxReturn : 16.252092361450195
Agent1_Train_MinReturn : -89.87881469726562
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 991500
Agent1_TimeSinceStart : 1515.366290807724
Agent1_Critic_Loss : 0.6263264417648315
Agent1_Actor_Loss : -0.8233432173728943
Agent1_Alpha_Loss : 0.7748788595199585
Agent1_Temperature : 0.08305742423469886
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 661 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 662 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 663 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 664 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 665 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 666 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 667 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 668 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 669 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 670 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -6.939528465270996
Agent0_Eval_StdReturn : 9.068865776062012
Agent0_Eval_MaxReturn : 8.876797676086426
Agent0_Eval_MinReturn : -19.29499053955078
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -8.699640274047852
Agent0_Train_StdReturn : 17.250282287597656
Agent0_Train_MaxReturn : 30.227399826049805
Agent0_Train_MinReturn : -40.6070556640625
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1006500
Agent0_TimeSinceStart : 1536.284628868103
Agent0_Critic_Loss : 0.6438653469085693
Agent0_Actor_Loss : -0.585671067237854
Agent0_Alpha_Loss : 0.7696785926818848
Agent0_Temperature : 0.08279622519725664
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -9.687605857849121
Agent1_Eval_StdReturn : 14.46047306060791
Agent1_Eval_MaxReturn : 14.627235412597656
Agent1_Eval_MinReturn : -30.42053985595703
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -2.4290335178375244
Agent1_Train_StdReturn : 15.12467098236084
Agent1_Train_MaxReturn : 19.931781768798828
Agent1_Train_MinReturn : -28.422651290893555
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1006500
Agent1_TimeSinceStart : 1538.3624477386475
Agent1_Critic_Loss : 0.5879642963409424
Agent1_Actor_Loss : -0.7406772375106812
Agent1_Alpha_Loss : 0.7848378419876099
Agent1_Temperature : 0.08281868464545745
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 671 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 672 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 673 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 674 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 675 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 676 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 677 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 678 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 679 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 680 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -13.125452995300293
Agent0_Eval_StdReturn : 21.152812957763672
Agent0_Eval_MaxReturn : 16.30868148803711
Agent0_Eval_MinReturn : -69.11656951904297
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -15.412384033203125
Agent0_Train_StdReturn : 12.49785041809082
Agent0_Train_MaxReturn : 0.16976022720336914
Agent0_Train_MinReturn : -42.57850646972656
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1021500
Agent0_TimeSinceStart : 1559.256843805313
Agent0_Critic_Loss : 0.5335162878036499
Agent0_Actor_Loss : -0.6882231831550598
Agent0_Alpha_Loss : 0.7640416622161865
Agent0_Temperature : 0.08256061457359491
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -17.856021881103516
Agent1_Eval_StdReturn : 11.267338752746582
Agent1_Eval_MaxReturn : 0.33519434928894043
Agent1_Eval_MinReturn : -34.28894805908203
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -7.964243412017822
Agent1_Train_StdReturn : 9.269270896911621
Agent1_Train_MaxReturn : 10.134136199951172
Agent1_Train_MinReturn : -20.013748168945312
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1021500
Agent1_TimeSinceStart : 1561.3352673053741
Agent1_Critic_Loss : 0.7080850601196289
Agent1_Actor_Loss : -0.6334947347640991
Agent1_Alpha_Loss : 0.7819128036499023
Agent1_Temperature : 0.08258036638068589
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 681 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 682 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 683 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 684 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 685 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 686 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 687 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 688 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 689 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 690 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -10.314730644226074
Agent0_Eval_StdReturn : 19.50446128845215
Agent0_Eval_MaxReturn : 22.19564437866211
Agent0_Eval_MinReturn : -44.842681884765625
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -5.123166084289551
Agent0_Train_StdReturn : 17.81913948059082
Agent0_Train_MaxReturn : 16.757291793823242
Agent0_Train_MinReturn : -42.884681701660156
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1036500
Agent0_TimeSinceStart : 1582.2360877990723
Agent0_Critic_Loss : 0.557409405708313
Agent0_Actor_Loss : -0.7094197273254395
Agent0_Alpha_Loss : 0.7691879868507385
Agent0_Temperature : 0.0823250009063405
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -7.825743675231934
Agent1_Eval_StdReturn : 13.625067710876465
Agent1_Eval_MaxReturn : 17.58975601196289
Agent1_Eval_MinReturn : -34.74309158325195
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -19.083805084228516
Agent1_Train_StdReturn : 16.78592300415039
Agent1_Train_MaxReturn : 6.286169052124023
Agent1_Train_MinReturn : -47.89531326293945
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1036500
Agent1_TimeSinceStart : 1584.3167703151703
Agent1_Critic_Loss : 0.6250892281532288
Agent1_Actor_Loss : -0.6626651287078857
Agent1_Alpha_Loss : 0.7762489318847656
Agent1_Temperature : 0.0823438138265931
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 691 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 692 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 693 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 694 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 695 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 696 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 697 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 698 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 699 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 700 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -12.581324577331543
Agent0_Eval_StdReturn : 15.422002792358398
Agent0_Eval_MaxReturn : 14.93863582611084
Agent0_Eval_MinReturn : -36.196632385253906
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -13.920916557312012
Agent0_Train_StdReturn : 10.321903228759766
Agent0_Train_MaxReturn : 6.82619047164917
Agent0_Train_MinReturn : -26.218923568725586
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1051500
Agent0_TimeSinceStart : 1605.21324300766
Agent0_Critic_Loss : 0.5918079614639282
Agent0_Actor_Loss : -0.6278588771820068
Agent0_Alpha_Loss : 0.77642822265625
Agent0_Temperature : 0.0820892330964672
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -17.564056396484375
Agent1_Eval_StdReturn : 16.777273178100586
Agent1_Eval_MaxReturn : 1.0375196933746338
Agent1_Eval_MinReturn : -58.475364685058594
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -15.982874870300293
Agent1_Train_StdReturn : 16.631526947021484
Agent1_Train_MaxReturn : 5.012343406677246
Agent1_Train_MinReturn : -50.700321197509766
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1051500
Agent1_TimeSinceStart : 1607.2975742816925
Agent1_Critic_Loss : 0.6420948505401611
Agent1_Actor_Loss : -0.7872040271759033
Agent1_Alpha_Loss : 0.7718448638916016
Agent1_Temperature : 0.08210864254596081
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 701 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 702 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 703 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 704 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 705 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 706 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 707 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 708 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 709 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 710 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -23.610477447509766
Agent0_Eval_StdReturn : 22.871400833129883
Agent0_Eval_MaxReturn : 12.559700012207031
Agent0_Eval_MinReturn : -70.50496673583984
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -6.400660514831543
Agent0_Train_StdReturn : 22.502912521362305
Agent0_Train_MaxReturn : 30.804946899414062
Agent0_Train_MinReturn : -41.520198822021484
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1066500
Agent0_TimeSinceStart : 1628.17946767807
Agent0_Critic_Loss : 0.7137014865875244
Agent0_Actor_Loss : -0.639297604560852
Agent0_Alpha_Loss : 0.7619972229003906
Agent0_Temperature : 0.0818522988496331
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -12.579885482788086
Agent1_Eval_StdReturn : 16.892732620239258
Agent1_Eval_MaxReturn : 17.123077392578125
Agent1_Eval_MinReturn : -48.05352020263672
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -16.279943466186523
Agent1_Train_StdReturn : 16.080446243286133
Agent1_Train_MaxReturn : 13.693243980407715
Agent1_Train_MinReturn : -30.92578887939453
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1066500
Agent1_TimeSinceStart : 1630.2755386829376
Agent1_Critic_Loss : 0.7015179395675659
Agent1_Actor_Loss : -0.8198579549789429
Agent1_Alpha_Loss : 0.7583490610122681
Agent1_Temperature : 0.08187382731971067
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 711 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 712 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 713 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 714 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 715 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 716 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 717 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 718 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 719 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 720 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -35.374656677246094
Agent0_Eval_StdReturn : 23.266536712646484
Agent0_Eval_MaxReturn : -2.1989760398864746
Agent0_Eval_MinReturn : -75.24349975585938
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -18.301959991455078
Agent0_Train_StdReturn : 21.15044593811035
Agent0_Train_MaxReturn : 7.86512565612793
Agent0_Train_MinReturn : -51.8487548828125
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1081500
Agent0_TimeSinceStart : 1651.1636312007904
Agent0_Critic_Loss : 0.5985660552978516
Agent0_Actor_Loss : -0.7762481570243835
Agent0_Alpha_Loss : 0.7764366269111633
Agent0_Temperature : 0.0816150911741947
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -16.22689437866211
Agent1_Eval_StdReturn : 14.902009010314941
Agent1_Eval_MaxReturn : 0.699864387512207
Agent1_Eval_MinReturn : -46.976104736328125
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -11.074004173278809
Agent1_Train_StdReturn : 15.660433769226074
Agent1_Train_MaxReturn : 11.204364776611328
Agent1_Train_MinReturn : -36.55290222167969
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1081500
Agent1_TimeSinceStart : 1653.2468481063843
Agent1_Critic_Loss : 0.6438397169113159
Agent1_Actor_Loss : -0.9880567789077759
Agent1_Alpha_Loss : 0.7510092258453369
Agent1_Temperature : 0.08163966682405703
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 721 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 722 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 723 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 724 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 725 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 726 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 727 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 728 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 729 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 730 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -29.152393341064453
Agent0_Eval_StdReturn : 29.57630729675293
Agent0_Eval_MaxReturn : 12.16895866394043
Agent0_Eval_MinReturn : -78.8507308959961
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -12.450254440307617
Agent0_Train_StdReturn : 24.70742416381836
Agent0_Train_MaxReturn : 25.329639434814453
Agent0_Train_MinReturn : -45.44435119628906
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1096500
Agent0_TimeSinceStart : 1674.1065542697906
Agent0_Critic_Loss : 0.8106931447982788
Agent0_Actor_Loss : -0.7732675075531006
Agent0_Alpha_Loss : 0.7712045907974243
Agent0_Temperature : 0.081377602306695
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -14.292379379272461
Agent1_Eval_StdReturn : 12.40388298034668
Agent1_Eval_MaxReturn : 8.501640319824219
Agent1_Eval_MinReturn : -40.072792053222656
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -11.910776138305664
Agent1_Train_StdReturn : 17.22313690185547
Agent1_Train_MaxReturn : 8.945563316345215
Agent1_Train_MinReturn : -39.588958740234375
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1096500
Agent1_TimeSinceStart : 1676.1897053718567
Agent1_Critic_Loss : 0.7613534927368164
Agent1_Actor_Loss : -0.821627140045166
Agent1_Alpha_Loss : 0.7591258883476257
Agent1_Temperature : 0.08140655131957643
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 731 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 732 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 733 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 734 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 735 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 736 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 737 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 738 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 739 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 740 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -19.621984481811523
Agent0_Eval_StdReturn : 22.610414505004883
Agent0_Eval_MaxReturn : 7.658884048461914
Agent0_Eval_MinReturn : -60.43291473388672
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -17.111248016357422
Agent0_Train_StdReturn : 17.999711990356445
Agent0_Train_MaxReturn : 18.12259864807129
Agent0_Train_MinReturn : -48.72380828857422
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1111500
Agent0_TimeSinceStart : 1697.0436220169067
Agent0_Critic_Loss : 0.679745078086853
Agent0_Actor_Loss : -0.7016181945800781
Agent0_Alpha_Loss : 0.7789795994758606
Agent0_Temperature : 0.08114096202455216
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -18.6118221282959
Agent1_Eval_StdReturn : 14.144076347351074
Agent1_Eval_MaxReturn : 3.0453648567199707
Agent1_Eval_MinReturn : -38.046607971191406
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -6.806725978851318
Agent1_Train_StdReturn : 14.410191535949707
Agent1_Train_MaxReturn : 24.5355224609375
Agent1_Train_MinReturn : -27.11695098876953
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1111500
Agent1_TimeSinceStart : 1699.1226296424866
Agent1_Critic_Loss : 0.6334279775619507
Agent1_Actor_Loss : -0.7731486558914185
Agent1_Alpha_Loss : 0.7673468589782715
Agent1_Temperature : 0.08117355388496197
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 741 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 742 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 743 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 744 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 745 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 746 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 747 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 748 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 749 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 750 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -31.195642471313477
Agent0_Eval_StdReturn : 28.91629981994629
Agent0_Eval_MaxReturn : 0.5760641098022461
Agent0_Eval_MinReturn : -88.50198364257812
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -17.97779083251953
Agent0_Train_StdReturn : 21.993608474731445
Agent0_Train_MaxReturn : 8.503923416137695
Agent0_Train_MinReturn : -77.40342712402344
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1126500
Agent0_TimeSinceStart : 1719.9675123691559
Agent0_Critic_Loss : 0.7528769373893738
Agent0_Actor_Loss : -0.7085973024368286
Agent0_Alpha_Loss : 0.7645021080970764
Agent0_Temperature : 0.08090578876337678
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -7.177611351013184
Agent1_Eval_StdReturn : 13.773558616638184
Agent1_Eval_MaxReturn : 22.332048416137695
Agent1_Eval_MinReturn : -28.00418472290039
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -5.504899024963379
Agent1_Train_StdReturn : 17.488739013671875
Agent1_Train_MaxReturn : 28.423873901367188
Agent1_Train_MinReturn : -30.508140563964844
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1126500
Agent1_TimeSinceStart : 1722.0510115623474
Agent1_Critic_Loss : 1.2266618013381958
Agent1_Actor_Loss : -0.7881240248680115
Agent1_Alpha_Loss : 0.7693197131156921
Agent1_Temperature : 0.08094121782592023
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 751 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 752 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 753 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 754 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 755 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 756 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 757 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 758 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 759 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 760 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -20.46597671508789
Agent0_Eval_StdReturn : 15.01645565032959
Agent0_Eval_MaxReturn : -1.2619876861572266
Agent0_Eval_MinReturn : -57.254913330078125
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -10.88150691986084
Agent0_Train_StdReturn : 16.992074966430664
Agent0_Train_MaxReturn : 18.176620483398438
Agent0_Train_MinReturn : -31.991024017333984
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1141500
Agent0_TimeSinceStart : 1742.9348878860474
Agent0_Critic_Loss : 0.7784530520439148
Agent0_Actor_Loss : -0.616187572479248
Agent0_Alpha_Loss : 0.7686223983764648
Agent0_Temperature : 0.08067332877751585
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -9.932123184204102
Agent1_Eval_StdReturn : 12.857192993164062
Agent1_Eval_MaxReturn : 4.000186920166016
Agent1_Eval_MinReturn : -35.008392333984375
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -25.755294799804688
Agent1_Train_StdReturn : 23.525123596191406
Agent1_Train_MaxReturn : 2.7319231033325195
Agent1_Train_MinReturn : -75.97659301757812
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1141500
Agent1_TimeSinceStart : 1745.004781961441
Agent1_Critic_Loss : 0.9130638241767883
Agent1_Actor_Loss : -0.8334023952484131
Agent1_Alpha_Loss : 0.7594473361968994
Agent1_Temperature : 0.08070982853121195
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 761 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 762 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 763 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 764 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 765 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 766 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 767 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 768 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 769 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 770 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -13.426406860351562
Agent0_Eval_StdReturn : 11.146951675415039
Agent0_Eval_MaxReturn : -0.08875703811645508
Agent0_Eval_MinReturn : -34.47095489501953
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -18.883892059326172
Agent0_Train_StdReturn : 13.414751052856445
Agent0_Train_MaxReturn : 2.636075973510742
Agent0_Train_MinReturn : -43.00537109375
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1156500
Agent0_TimeSinceStart : 1765.933970451355
Agent0_Critic_Loss : 0.9878892302513123
Agent0_Actor_Loss : -0.7482775449752808
Agent0_Alpha_Loss : 0.7527958154678345
Agent0_Temperature : 0.08044377891753295
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -7.957898139953613
Agent1_Eval_StdReturn : 19.940387725830078
Agent1_Eval_MaxReturn : 32.01667022705078
Agent1_Eval_MinReturn : -40.08042526245117
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -13.176191329956055
Agent1_Train_StdReturn : 14.435381889343262
Agent1_Train_MaxReturn : 5.393584251403809
Agent1_Train_MinReturn : -52.45796585083008
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1156500
Agent1_TimeSinceStart : 1768.0180840492249
Agent1_Critic_Loss : 0.9655924439430237
Agent1_Actor_Loss : -0.9341767430305481
Agent1_Alpha_Loss : 0.7589448094367981
Agent1_Temperature : 0.08047979544835851
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 771 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 772 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 773 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 774 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 775 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 776 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 777 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 778 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 779 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 780 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -3.795236587524414
Agent0_Eval_StdReturn : 9.890043258666992
Agent0_Eval_MaxReturn : 17.659320831298828
Agent0_Eval_MinReturn : -17.79446029663086
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -13.608589172363281
Agent0_Train_StdReturn : 6.479608535766602
Agent0_Train_MaxReturn : -0.28619933128356934
Agent0_Train_MinReturn : -23.07335662841797
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1171500
Agent0_TimeSinceStart : 1788.9872946739197
Agent0_Critic_Loss : 0.7849146127700806
Agent0_Actor_Loss : -0.5583111047744751
Agent0_Alpha_Loss : 0.7355921268463135
Agent0_Temperature : 0.08021744800537309
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -18.366792678833008
Agent1_Eval_StdReturn : 23.644514083862305
Agent1_Eval_MaxReturn : 14.989288330078125
Agent1_Eval_MinReturn : -53.41913604736328
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -9.110135078430176
Agent1_Train_StdReturn : 11.900182723999023
Agent1_Train_MaxReturn : 16.836044311523438
Agent1_Train_MinReturn : -25.639633178710938
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1171500
Agent1_TimeSinceStart : 1791.069578409195
Agent1_Critic_Loss : 0.7650361061096191
Agent1_Actor_Loss : -0.8591817021369934
Agent1_Alpha_Loss : 0.7533645629882812
Agent1_Temperature : 0.08025133390574081
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 781 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 782 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 783 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 784 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 785 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 786 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 787 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 788 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 789 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 790 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -2.727992534637451
Agent0_Eval_StdReturn : 15.325855255126953
Agent0_Eval_MaxReturn : 21.567888259887695
Agent0_Eval_MinReturn : -34.44384002685547
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -10.78449821472168
Agent0_Train_StdReturn : 14.991409301757812
Agent0_Train_MaxReturn : 13.080888748168945
Agent0_Train_MinReturn : -40.936134338378906
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1186500
Agent0_TimeSinceStart : 1812.03639960289
Agent0_Critic_Loss : 0.943146824836731
Agent0_Actor_Loss : -0.6340826749801636
Agent0_Alpha_Loss : 0.7424752712249756
Agent0_Temperature : 0.07999368199400711
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -9.010022163391113
Agent1_Eval_StdReturn : 17.471895217895508
Agent1_Eval_MaxReturn : 18.780353546142578
Agent1_Eval_MinReturn : -32.54744338989258
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -13.855552673339844
Agent1_Train_StdReturn : 19.98378562927246
Agent1_Train_MaxReturn : 22.72886848449707
Agent1_Train_MinReturn : -47.65247344970703
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1186500
Agent1_TimeSinceStart : 1814.1236300468445
Agent1_Critic_Loss : 0.8927640914916992
Agent1_Actor_Loss : -0.8683830499649048
Agent1_Alpha_Loss : 0.7436788082122803
Agent1_Temperature : 0.08002463062281048
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 791 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 792 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 793 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 794 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 795 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 796 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 797 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 798 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 799 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 800 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -12.008943557739258
Agent0_Eval_StdReturn : 13.940594673156738
Agent0_Eval_MaxReturn : 8.39854621887207
Agent0_Eval_MinReturn : -36.500457763671875
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -16.77198600769043
Agent0_Train_StdReturn : 15.071233749389648
Agent0_Train_MaxReturn : -0.3060340881347656
Agent0_Train_MinReturn : -44.50452423095703
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1201500
Agent0_TimeSinceStart : 1835.1216325759888
Agent0_Critic_Loss : 0.6861767768859863
Agent0_Actor_Loss : -0.8502951860427856
Agent0_Alpha_Loss : 0.7408121824264526
Agent0_Temperature : 0.07976996682641249
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -9.003747940063477
Agent1_Eval_StdReturn : 19.19068145751953
Agent1_Eval_MaxReturn : 23.268104553222656
Agent1_Eval_MinReturn : -49.91004180908203
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -12.704530715942383
Agent1_Train_StdReturn : 14.743815422058105
Agent1_Train_MaxReturn : 4.154818534851074
Agent1_Train_MinReturn : -48.63246154785156
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1201500
Agent1_TimeSinceStart : 1837.2042489051819
Agent1_Critic_Loss : 0.962290346622467
Agent1_Actor_Loss : -0.9304301738739014
Agent1_Alpha_Loss : 0.741479754447937
Agent1_Temperature : 0.07980052554030985
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 801 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 802 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 803 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 804 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 805 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 806 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 807 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 808 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 809 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 810 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -16.838329315185547
Agent0_Eval_StdReturn : 14.921545028686523
Agent0_Eval_MaxReturn : 5.23796272277832
Agent0_Eval_MinReturn : -35.97307586669922
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -14.127062797546387
Agent0_Train_StdReturn : 18.08334732055664
Agent0_Train_MaxReturn : 18.460926055908203
Agent0_Train_MinReturn : -48.96293640136719
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1216500
Agent0_TimeSinceStart : 1858.146240234375
Agent0_Critic_Loss : 0.7774394750595093
Agent0_Actor_Loss : -0.8605591058731079
Agent0_Alpha_Loss : 0.7427137494087219
Agent0_Temperature : 0.07954754837028524
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -8.330997467041016
Agent1_Eval_StdReturn : 9.435765266418457
Agent1_Eval_MaxReturn : 12.959741592407227
Agent1_Eval_MinReturn : -23.741195678710938
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -3.64776349067688
Agent1_Train_StdReturn : 9.676138877868652
Agent1_Train_MaxReturn : 13.747069358825684
Agent1_Train_MinReturn : -18.714935302734375
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1216500
Agent1_TimeSinceStart : 1860.2263207435608
Agent1_Critic_Loss : 0.8450015783309937
Agent1_Actor_Loss : -0.8366804718971252
Agent1_Alpha_Loss : 0.7369234561920166
Agent1_Temperature : 0.07957756634362902
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 811 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 812 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 813 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 814 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 815 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 816 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 817 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 818 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 819 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 820 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -26.49686622619629
Agent0_Eval_StdReturn : 20.812931060791016
Agent0_Eval_MaxReturn : 0.5930824279785156
Agent0_Eval_MinReturn : -64.4088134765625
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -7.611119747161865
Agent0_Train_StdReturn : 17.24712562561035
Agent0_Train_MaxReturn : 25.295473098754883
Agent0_Train_MinReturn : -47.31867599487305
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1231500
Agent0_TimeSinceStart : 1881.1417171955109
Agent0_Critic_Loss : 0.8808774948120117
Agent0_Actor_Loss : -0.787966787815094
Agent0_Alpha_Loss : 0.7294992804527283
Agent0_Temperature : 0.07932676676254627
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -18.183032989501953
Agent1_Eval_StdReturn : 18.003950119018555
Agent1_Eval_MaxReturn : 6.750616550445557
Agent1_Eval_MinReturn : -56.559566497802734
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : 0.05693311616778374
Agent1_Train_StdReturn : 9.743096351623535
Agent1_Train_MaxReturn : 12.602914810180664
Agent1_Train_MinReturn : -18.789756774902344
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1231500
Agent1_TimeSinceStart : 1883.2171149253845
Agent1_Critic_Loss : 0.7218862175941467
Agent1_Actor_Loss : -1.0289109945297241
Agent1_Alpha_Loss : 0.7442799806594849
Agent1_Temperature : 0.0793552751448918
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 821 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 822 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 823 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 824 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 825 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 826 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 827 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 828 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 829 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 830 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -11.632295608520508
Agent0_Eval_StdReturn : 12.078277587890625
Agent0_Eval_MaxReturn : 12.59589672088623
Agent0_Eval_MinReturn : -25.93134880065918
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -14.622610092163086
Agent0_Train_StdReturn : 10.94298267364502
Agent0_Train_MaxReturn : 4.174557685852051
Agent0_Train_MinReturn : -33.39490509033203
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1246500
Agent0_TimeSinceStart : 1904.1489040851593
Agent0_Critic_Loss : 0.6740458011627197
Agent0_Actor_Loss : -0.7697207927703857
Agent0_Alpha_Loss : 0.7295504212379456
Agent0_Temperature : 0.07910714876843747
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -8.886743545532227
Agent1_Eval_StdReturn : 16.734312057495117
Agent1_Eval_MaxReturn : 16.070175170898438
Agent1_Eval_MinReturn : -41.2557373046875
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -14.969537734985352
Agent1_Train_StdReturn : 15.999038696289062
Agent1_Train_MaxReturn : 6.873287200927734
Agent1_Train_MinReturn : -43.53984069824219
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1246500
Agent1_TimeSinceStart : 1906.2290225028992
Agent1_Critic_Loss : 0.937712550163269
Agent1_Actor_Loss : -1.0814460515975952
Agent1_Alpha_Loss : 0.7531269192695618
Agent1_Temperature : 0.07913300672936256
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 831 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 832 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 833 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 834 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 835 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 836 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 837 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 838 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 839 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 840 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -9.161808013916016
Agent0_Eval_StdReturn : 9.867920875549316
Agent0_Eval_MaxReturn : 15.527299880981445
Agent0_Eval_MinReturn : -18.098615646362305
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -6.922369956970215
Agent0_Train_StdReturn : 17.237655639648438
Agent0_Train_MaxReturn : 20.854509353637695
Agent0_Train_MinReturn : -47.75648498535156
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1261500
Agent0_TimeSinceStart : 1927.1861100196838
Agent0_Critic_Loss : 0.7612685561180115
Agent0_Actor_Loss : -0.6755419969558716
Agent0_Alpha_Loss : 0.7309253215789795
Agent0_Temperature : 0.07888733401936693
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -9.42836856842041
Agent1_Eval_StdReturn : 11.689385414123535
Agent1_Eval_MaxReturn : 11.585412979125977
Agent1_Eval_MinReturn : -25.70182228088379
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -18.78097152709961
Agent1_Train_StdReturn : 15.762837409973145
Agent1_Train_MaxReturn : 1.4339799880981445
Agent1_Train_MinReturn : -39.010528564453125
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1261500
Agent1_TimeSinceStart : 1929.267685174942
Agent1_Critic_Loss : 0.6899999380111694
Agent1_Actor_Loss : -0.9723137617111206
Agent1_Alpha_Loss : 0.757503867149353
Agent1_Temperature : 0.0789098843529464
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 841 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 842 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 843 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 844 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 845 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 846 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 847 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 848 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 849 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 850 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -1.9235572814941406
Agent0_Eval_StdReturn : 9.63398551940918
Agent0_Eval_MaxReturn : 14.252154350280762
Agent0_Eval_MinReturn : -15.715551376342773
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -1.6402511596679688
Agent0_Train_StdReturn : 15.556614875793457
Agent0_Train_MaxReturn : 24.906478881835938
Agent0_Train_MinReturn : -31.161060333251953
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1276500
Agent0_TimeSinceStart : 1950.286090373993
Agent0_Critic_Loss : 0.8121520280838013
Agent0_Actor_Loss : -0.7493395209312439
Agent0_Alpha_Loss : 0.7304858565330505
Agent0_Temperature : 0.07866746085359266
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -10.431772232055664
Agent1_Eval_StdReturn : 15.051170349121094
Agent1_Eval_MaxReturn : 10.733263969421387
Agent1_Eval_MinReturn : -43.013389587402344
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -19.829116821289062
Agent1_Train_StdReturn : 25.746707916259766
Agent1_Train_MaxReturn : 9.740511894226074
Agent1_Train_MinReturn : -70.34642028808594
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1276500
Agent1_TimeSinceStart : 1952.3650560379028
Agent1_Critic_Loss : 1.0024523735046387
Agent1_Actor_Loss : -0.9855443239212036
Agent1_Alpha_Loss : 0.7408530712127686
Agent1_Temperature : 0.07868736280743246
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 851 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 852 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 853 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 854 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 855 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 856 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 857 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 858 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 859 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 860 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -4.959744453430176
Agent0_Eval_StdReturn : 13.277884483337402
Agent0_Eval_MaxReturn : 16.464609146118164
Agent0_Eval_MinReturn : -26.0407772064209
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -4.753462791442871
Agent0_Train_StdReturn : 17.423133850097656
Agent0_Train_MaxReturn : 22.450990676879883
Agent0_Train_MinReturn : -35.96463394165039
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1291500
Agent0_TimeSinceStart : 1973.3299622535706
Agent0_Critic_Loss : 0.9873168468475342
Agent0_Actor_Loss : -0.8183072805404663
Agent0_Alpha_Loss : 0.7324491739273071
Agent0_Temperature : 0.07844790380828404
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -1.4734351634979248
Agent1_Eval_StdReturn : 14.993071556091309
Agent1_Eval_MaxReturn : 13.594819068908691
Agent1_Eval_MinReturn : -25.114669799804688
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -19.458932876586914
Agent1_Train_StdReturn : 17.58684539794922
Agent1_Train_MaxReturn : 10.478435516357422
Agent1_Train_MinReturn : -51.752906799316406
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1291500
Agent1_TimeSinceStart : 1975.41752243042
Agent1_Critic_Loss : 0.6789230108261108
Agent1_Actor_Loss : -1.0317678451538086
Agent1_Alpha_Loss : 0.7471731305122375
Agent1_Temperature : 0.0784660537820051
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 861 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 862 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 863 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 864 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 865 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 866 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 867 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 868 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 869 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 870 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -14.081216812133789
Agent0_Eval_StdReturn : 7.301386833190918
Agent0_Eval_MaxReturn : -3.615449905395508
Agent0_Eval_MinReturn : -26.7843017578125
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -11.020401000976562
Agent0_Train_StdReturn : 16.977617263793945
Agent0_Train_MaxReturn : 8.31516170501709
Agent0_Train_MinReturn : -43.211647033691406
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1306500
Agent0_TimeSinceStart : 1996.4129910469055
Agent0_Critic_Loss : 0.9097304344177246
Agent0_Actor_Loss : -0.9445905089378357
Agent0_Alpha_Loss : 0.7314879894256592
Agent0_Temperature : 0.0782287051690446
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -24.589794158935547
Agent1_Eval_StdReturn : 15.303278923034668
Agent1_Eval_MaxReturn : -6.66609001159668
Agent1_Eval_MinReturn : -51.108619689941406
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -4.635954856872559
Agent1_Train_StdReturn : 6.849098205566406
Agent1_Train_MaxReturn : 2.3691296577453613
Agent1_Train_MinReturn : -21.102081298828125
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1306500
Agent1_TimeSinceStart : 1998.4962706565857
Agent1_Critic_Loss : 0.7831120491027832
Agent1_Actor_Loss : -0.9531000852584839
Agent1_Alpha_Loss : 0.7458714246749878
Agent1_Temperature : 0.0782453681576405
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 871 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 872 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 873 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 874 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 875 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 876 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 877 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 878 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 879 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 880 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -6.9841156005859375
Agent0_Eval_StdReturn : 9.872000694274902
Agent0_Eval_MaxReturn : 6.607314109802246
Agent0_Eval_MinReturn : -33.81673812866211
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -10.456318855285645
Agent0_Train_StdReturn : 8.832435607910156
Agent0_Train_MaxReturn : 1.8804212808609009
Agent0_Train_MinReturn : -23.183286666870117
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1321500
Agent0_TimeSinceStart : 2019.463139295578
Agent0_Critic_Loss : 0.7803401350975037
Agent0_Actor_Loss : -0.8805267810821533
Agent0_Alpha_Loss : 0.7354398965835571
Agent0_Temperature : 0.07801008994524344
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -15.960453987121582
Agent1_Eval_StdReturn : 16.832469940185547
Agent1_Eval_MaxReturn : 8.871285438537598
Agent1_Eval_MinReturn : -40.77473068237305
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -10.1568021774292
Agent1_Train_StdReturn : 15.67337703704834
Agent1_Train_MaxReturn : 6.26672887802124
Agent1_Train_MinReturn : -50.768951416015625
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1321500
Agent1_TimeSinceStart : 2021.5414679050446
Agent1_Critic_Loss : 1.148870825767517
Agent1_Actor_Loss : -1.0026233196258545
Agent1_Alpha_Loss : 0.7391926646232605
Agent1_Temperature : 0.07802619781114986
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 881 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 882 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 883 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 884 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 885 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 886 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 887 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 888 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 889 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 890 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -7.762010097503662
Agent0_Eval_StdReturn : 7.660887241363525
Agent0_Eval_MaxReturn : 11.572547912597656
Agent0_Eval_MinReturn : -19.006078720092773
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -1.699806571006775
Agent0_Train_StdReturn : 13.729389190673828
Agent0_Train_MaxReturn : 19.624309539794922
Agent0_Train_MinReturn : -33.352294921875
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1336500
Agent0_TimeSinceStart : 2042.5488352775574
Agent0_Critic_Loss : 0.5945420861244202
Agent0_Actor_Loss : -0.7552732229232788
Agent0_Alpha_Loss : 0.7332068681716919
Agent0_Temperature : 0.07779197847540817
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -17.908512115478516
Agent1_Eval_StdReturn : 13.552848815917969
Agent1_Eval_MaxReturn : 0.563471794128418
Agent1_Eval_MinReturn : -43.10826873779297
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -28.277151107788086
Agent1_Train_StdReturn : 30.515222549438477
Agent1_Train_MaxReturn : 15.575252532958984
Agent1_Train_MinReturn : -81.1595458984375
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1336500
Agent1_TimeSinceStart : 2044.6273393630981
Agent1_Critic_Loss : 1.0312089920043945
Agent1_Actor_Loss : -0.7864325046539307
Agent1_Alpha_Loss : 0.7392966151237488
Agent1_Temperature : 0.07780758058342047
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 891 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 892 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 893 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 894 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 895 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 896 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 897 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 898 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 899 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 900 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -15.713276863098145
Agent0_Eval_StdReturn : 20.874847412109375
Agent0_Eval_MaxReturn : 14.335335731506348
Agent0_Eval_MinReturn : -59.23120880126953
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -10.012346267700195
Agent0_Train_StdReturn : 19.300579071044922
Agent0_Train_MaxReturn : 12.856512069702148
Agent0_Train_MinReturn : -50.36187744140625
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1351500
Agent0_TimeSinceStart : 2065.530793428421
Agent0_Critic_Loss : 0.9723014831542969
Agent0_Actor_Loss : -0.8230780363082886
Agent0_Alpha_Loss : 0.7506700754165649
Agent0_Temperature : 0.07757366796884985
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -19.869760513305664
Agent1_Eval_StdReturn : 24.400630950927734
Agent1_Eval_MaxReturn : 13.072311401367188
Agent1_Eval_MinReturn : -70.82682800292969
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -20.239213943481445
Agent1_Train_StdReturn : 27.129215240478516
Agent1_Train_MaxReturn : 28.128034591674805
Agent1_Train_MinReturn : -74.76495361328125
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1351500
Agent1_TimeSinceStart : 2067.606563091278
Agent1_Critic_Loss : 0.8510634899139404
Agent1_Actor_Loss : -1.0983489751815796
Agent1_Alpha_Loss : 0.751544713973999
Agent1_Temperature : 0.07758978626202978
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 901 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 902 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 903 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 904 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 905 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 906 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 907 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 908 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 909 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 910 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -21.6943416595459
Agent0_Eval_StdReturn : 25.330364227294922
Agent0_Eval_MaxReturn : 11.80364990234375
Agent0_Eval_MinReturn : -66.07615661621094
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -14.863632202148438
Agent0_Train_StdReturn : 30.864055633544922
Agent0_Train_MaxReturn : 63.012962341308594
Agent0_Train_MinReturn : -51.99676513671875
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1366500
Agent0_TimeSinceStart : 2088.488995552063
Agent0_Critic_Loss : 0.9027328491210938
Agent0_Actor_Loss : -0.9740374088287354
Agent0_Alpha_Loss : 0.75672447681427
Agent0_Temperature : 0.07735472911395119
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -21.793201446533203
Agent1_Eval_StdReturn : 21.341461181640625
Agent1_Eval_MaxReturn : 6.234418869018555
Agent1_Eval_MinReturn : -57.806610107421875
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -22.058635711669922
Agent1_Train_StdReturn : 16.415491104125977
Agent1_Train_MaxReturn : 3.003878116607666
Agent1_Train_MinReturn : -52.69645309448242
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1366500
Agent1_TimeSinceStart : 2090.5495970249176
Agent1_Critic_Loss : 0.9578192234039307
Agent1_Actor_Loss : -1.0074357986450195
Agent1_Alpha_Loss : 0.7352396249771118
Agent1_Temperature : 0.07737166707891222
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 911 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 912 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 913 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 914 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 915 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 916 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 917 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 918 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 919 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 920 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -29.83944320678711
Agent0_Eval_StdReturn : 18.24435043334961
Agent0_Eval_MaxReturn : 2.5212016105651855
Agent0_Eval_MinReturn : -70.68692016601562
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -14.577234268188477
Agent0_Train_StdReturn : 20.75189781188965
Agent0_Train_MaxReturn : 23.314449310302734
Agent0_Train_MinReturn : -51.94148254394531
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1381500
Agent0_TimeSinceStart : 2111.383856534958
Agent0_Critic_Loss : 0.9853072166442871
Agent0_Actor_Loss : -1.0118634700775146
Agent0_Alpha_Loss : 0.7444819211959839
Agent0_Temperature : 0.0771358050497222
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -29.724227905273438
Agent1_Eval_StdReturn : 19.41074562072754
Agent1_Eval_MaxReturn : 3.279153823852539
Agent1_Eval_MinReturn : -64.843505859375
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -20.850765228271484
Agent1_Train_StdReturn : 15.911526679992676
Agent1_Train_MaxReturn : 5.636395454406738
Agent1_Train_MinReturn : -46.41920852661133
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1381500
Agent1_TimeSinceStart : 2113.4573168754578
Agent1_Critic_Loss : 1.2232565879821777
Agent1_Actor_Loss : -1.011035680770874
Agent1_Alpha_Loss : 0.7395861148834229
Agent1_Temperature : 0.07715385871766753
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 921 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 922 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 923 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 924 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 925 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 926 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 927 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 928 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 929 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 930 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -36.75139236450195
Agent0_Eval_StdReturn : 22.945785522460938
Agent0_Eval_MaxReturn : 6.061384677886963
Agent0_Eval_MinReturn : -82.98402404785156
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -29.355182647705078
Agent0_Train_StdReturn : 19.73727798461914
Agent0_Train_MaxReturn : 7.9190497398376465
Agent0_Train_MinReturn : -61.254600524902344
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1396500
Agent0_TimeSinceStart : 2134.3019795417786
Agent0_Critic_Loss : 0.8539975881576538
Agent0_Actor_Loss : -0.8555874824523926
Agent0_Alpha_Loss : 0.7399411201477051
Agent0_Temperature : 0.0769177590675172
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -23.71405029296875
Agent1_Eval_StdReturn : 19.945758819580078
Agent1_Eval_MaxReturn : 5.877020835876465
Agent1_Eval_MinReturn : -64.7071533203125
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -26.833383560180664
Agent1_Train_StdReturn : 27.67584228515625
Agent1_Train_MaxReturn : 4.663156509399414
Agent1_Train_MinReturn : -90.16543579101562
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1396500
Agent1_TimeSinceStart : 2136.381716966629
Agent1_Critic_Loss : 1.2396318912506104
Agent1_Actor_Loss : -1.1134761571884155
Agent1_Alpha_Loss : 0.7340062856674194
Agent1_Temperature : 0.0769375171107857
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 931 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 932 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 933 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 934 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 935 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 936 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 937 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 938 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 939 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 940 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -18.851848602294922
Agent0_Eval_StdReturn : 18.6751766204834
Agent0_Eval_MaxReturn : 1.076493263244629
Agent0_Eval_MinReturn : -69.6573486328125
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -26.656940460205078
Agent0_Train_StdReturn : 24.83890724182129
Agent0_Train_MaxReturn : 12.418512344360352
Agent0_Train_MinReturn : -78.63006591796875
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1411500
Agent0_TimeSinceStart : 2157.2148270606995
Agent0_Critic_Loss : 1.4165310859680176
Agent0_Actor_Loss : -0.982062041759491
Agent0_Alpha_Loss : 0.7399687767028809
Agent0_Temperature : 0.07670108497676029
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -11.653099060058594
Agent1_Eval_StdReturn : 21.548274993896484
Agent1_Eval_MaxReturn : 13.205820083618164
Agent1_Eval_MinReturn : -59.38897705078125
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -23.628610610961914
Agent1_Train_StdReturn : 17.82310676574707
Agent1_Train_MaxReturn : 3.91323184967041
Agent1_Train_MinReturn : -58.596866607666016
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1411500
Agent1_TimeSinceStart : 2159.294968366623
Agent1_Critic_Loss : 0.9898573160171509
Agent1_Actor_Loss : -1.0627719163894653
Agent1_Alpha_Loss : 0.7267397046089172
Agent1_Temperature : 0.07672204655387899
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 941 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 942 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 943 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 944 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 945 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 946 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 947 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 948 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 949 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 950 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -42.97074890136719
Agent0_Eval_StdReturn : 22.46388816833496
Agent0_Eval_MaxReturn : 0.028277873992919922
Agent0_Eval_MinReturn : -69.37860107421875
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -20.176794052124023
Agent0_Train_StdReturn : 28.645418167114258
Agent0_Train_MaxReturn : 25.177997589111328
Agent0_Train_MinReturn : -70.6672134399414
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1426500
Agent0_TimeSinceStart : 2180.1725034713745
Agent0_Critic_Loss : 1.454372763633728
Agent0_Actor_Loss : -0.9436842799186707
Agent0_Alpha_Loss : 0.7313710451126099
Agent0_Temperature : 0.07648566251642895
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -21.598651885986328
Agent1_Eval_StdReturn : 14.683320045471191
Agent1_Eval_MaxReturn : -1.7919787168502808
Agent1_Eval_MinReturn : -41.61299514770508
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -19.473567962646484
Agent1_Train_StdReturn : 22.677871704101562
Agent1_Train_MaxReturn : 9.14894962310791
Agent1_Train_MinReturn : -67.19966888427734
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1426500
Agent1_TimeSinceStart : 2182.2499809265137
Agent1_Critic_Loss : 1.233298897743225
Agent1_Actor_Loss : -1.0698161125183105
Agent1_Alpha_Loss : 0.7304216623306274
Agent1_Temperature : 0.07650775848092653
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 951 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 952 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 953 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 954 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 955 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 956 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 957 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 958 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 959 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 960 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -6.7694501876831055
Agent0_Eval_StdReturn : 20.622257232666016
Agent0_Eval_MaxReturn : 21.298940658569336
Agent0_Eval_MinReturn : -53.46172332763672
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -12.038111686706543
Agent0_Train_StdReturn : 17.289073944091797
Agent0_Train_MaxReturn : 24.48956871032715
Agent0_Train_MinReturn : -37.60933303833008
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1441500
Agent0_TimeSinceStart : 2203.1164603233337
Agent0_Critic_Loss : 1.0496305227279663
Agent0_Actor_Loss : -0.8428078889846802
Agent0_Alpha_Loss : 0.7342259883880615
Agent0_Temperature : 0.07627147902428252
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -11.182028770446777
Agent1_Eval_StdReturn : 13.026851654052734
Agent1_Eval_MaxReturn : 7.154577255249023
Agent1_Eval_MinReturn : -34.21156692504883
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -8.601944923400879
Agent1_Train_StdReturn : 21.370643615722656
Agent1_Train_MaxReturn : 10.8250093460083
Agent1_Train_MinReturn : -68.2270736694336
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1441500
Agent1_TimeSinceStart : 2205.1338760852814
Agent1_Critic_Loss : 1.322322130203247
Agent1_Actor_Loss : -0.9294431209564209
Agent1_Alpha_Loss : 0.7180795669555664
Agent1_Temperature : 0.07629468948670093
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 961 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 962 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 963 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 964 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 965 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 966 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 967 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 968 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 969 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 970 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -12.77966022491455
Agent0_Eval_StdReturn : 18.75456428527832
Agent0_Eval_MaxReturn : 28.461206436157227
Agent0_Eval_MinReturn : -38.1671257019043
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -35.59154510498047
Agent0_Train_StdReturn : 28.93619728088379
Agent0_Train_MaxReturn : 10.492059707641602
Agent0_Train_MinReturn : -72.55291748046875
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1456500
Agent0_TimeSinceStart : 2225.287085056305
Agent0_Critic_Loss : 1.5017735958099365
Agent0_Actor_Loss : -1.0140202045440674
Agent0_Alpha_Loss : 0.7396183013916016
Agent0_Temperature : 0.0760576140145004
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : 1.3491226434707642
Agent1_Eval_StdReturn : 7.602552890777588
Agent1_Eval_MaxReturn : 11.024698257446289
Agent1_Eval_MinReturn : -15.883914947509766
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -17.691741943359375
Agent1_Train_StdReturn : 8.832107543945312
Agent1_Train_MaxReturn : -1.6772785186767578
Agent1_Train_MinReturn : -29.615264892578125
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1456500
Agent1_TimeSinceStart : 2227.295923471451
Agent1_Critic_Loss : 1.454913854598999
Agent1_Actor_Loss : -1.0117971897125244
Agent1_Alpha_Loss : 0.7117824554443359
Agent1_Temperature : 0.076082814507535
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 971 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 972 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 973 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 974 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 975 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 976 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 977 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 978 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 979 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 980 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -14.850308418273926
Agent0_Eval_StdReturn : 22.639184951782227
Agent0_Eval_MaxReturn : 16.573945999145508
Agent0_Eval_MinReturn : -47.68504333496094
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -6.904338836669922
Agent0_Train_StdReturn : 15.613605499267578
Agent0_Train_MaxReturn : 22.342754364013672
Agent0_Train_MinReturn : -25.662487030029297
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1471500
Agent0_TimeSinceStart : 2248.089991569519
Agent0_Critic_Loss : 1.0893226861953735
Agent0_Actor_Loss : -0.9673972129821777
Agent0_Alpha_Loss : 0.7261925935745239
Agent0_Temperature : 0.07584439357644575
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -17.461626052856445
Agent1_Eval_StdReturn : 15.573498725891113
Agent1_Eval_MaxReturn : 10.259119033813477
Agent1_Eval_MinReturn : -47.37226867675781
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -10.176528930664062
Agent1_Train_StdReturn : 9.356266021728516
Agent1_Train_MaxReturn : 5.5391669273376465
Agent1_Train_MinReturn : -23.78585433959961
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1471500
Agent1_TimeSinceStart : 2250.187762737274
Agent1_Critic_Loss : 1.4235605001449585
Agent1_Actor_Loss : -0.9820315837860107
Agent1_Alpha_Loss : 0.7157513499259949
Agent1_Temperature : 0.07587316817305888
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 981 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 982 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 983 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 984 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 985 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 986 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 987 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 988 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 989 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 990 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -10.176345825195312
Agent0_Eval_StdReturn : 15.154152870178223
Agent0_Eval_MaxReturn : 10.959372520446777
Agent0_Eval_MinReturn : -36.69731521606445
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -22.76410675048828
Agent0_Train_StdReturn : 27.761825561523438
Agent0_Train_MaxReturn : 4.431607246398926
Agent0_Train_MinReturn : -87.8451156616211
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1486500
Agent0_TimeSinceStart : 2271.1794712543488
Agent0_Critic_Loss : 1.4769470691680908
Agent0_Actor_Loss : -1.1012787818908691
Agent0_Alpha_Loss : 0.7199384570121765
Agent0_Temperature : 0.07563241611155931
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -7.780575752258301
Agent1_Eval_StdReturn : 13.079330444335938
Agent1_Eval_MaxReturn : 25.394493103027344
Agent1_Eval_MinReturn : -22.819442749023438
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -9.256680488586426
Agent1_Train_StdReturn : 8.667986869812012
Agent1_Train_MaxReturn : 4.472594261169434
Agent1_Train_MinReturn : -23.936355590820312
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1486500
Agent1_TimeSinceStart : 2273.272565603256
Agent1_Critic_Loss : 0.9163000583648682
Agent1_Actor_Loss : -1.0974459648132324
Agent1_Alpha_Loss : 0.7001011371612549
Agent1_Temperature : 0.07566575673897234
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 991 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 992 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 993 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 994 ************/home/harvey/anaconda3/envs/285final/lib/python3.7/site-packages/gym/core.py:318: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  "Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future."
/home/harvey/anaconda3/envs/285final/lib/python3.7/site-packages/gym/wrappers/step_api_compatibility.py:40: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  "Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future."
/home/harvey/anaconda3/envs/285final/lib/python3.7/site-packages/gym/core.py:257: DeprecationWarning: [33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.[0m
  "Function `env.seed(seed)` is marked as deprecated and will be removed in the future. "


Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 995 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 996 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 997 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 998 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 999 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...
./peersacv2_2ndrun.sh: 18: --seed: not found



LOGGING TO:  /home/harvey/Documents/cs285/CS285-Project/cs285/scripts/../../data/peersac_v2_5agents_eps0.6_HalfCheetah-v4_12-12-2022_15-05-51 



########################
logging outputs to  /home/harvey/Documents/cs285/CS285-Project/cs285/scripts/../../data/peersac_v2_5agents_eps0.6_HalfCheetah-v4_12-12-2022_15-05-51
########################
Using GPU id 0


********** Iteration 0 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -32.58100509643555
Agent0_Eval_StdReturn : 38.008583068847656
Agent0_Eval_MaxReturn : 18.935745239257812
Agent0_Eval_MinReturn : -95.31880187988281
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -68.51490020751953
Agent0_Train_StdReturn : 35.8519172668457
Agent0_Train_MaxReturn : 10.17027473449707
Agent0_Train_MinReturn : -109.59283447265625
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1500
Agent0_TimeSinceStart : 2.190413236618042
Agent0_Critic_Loss : 1.7086536884307861
Agent0_Actor_Loss : -0.34447938203811646
Agent0_Alpha_Loss : 0.9863041639328003
Agent0_Temperature : 0.09997000449985415
Agent0_Initial_DataCollection_AverageReturn : -68.51490020751953
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -52.60877227783203
Agent1_Eval_StdReturn : 36.110774993896484
Agent1_Eval_MaxReturn : -6.442377090454102
Agent1_Eval_MinReturn : -109.24239349365234
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -41.37040710449219
Agent1_Train_StdReturn : 23.476428985595703
Agent1_Train_MaxReturn : -3.7883758544921875
Agent1_Train_MinReturn : -74.03202819824219
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1500
Agent1_TimeSinceStart : 4.2479307651519775
Agent1_Critic_Loss : 0.9887043237686157
Agent1_Actor_Loss : -0.48759517073631287
Agent1_Alpha_Loss : 0.9798400402069092
Agent1_Temperature : 0.09997000449985614
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 1 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 2 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 3 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 4 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 5 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 6 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 7 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 8 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 9 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 10 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -16.689105987548828
Agent0_Eval_StdReturn : 30.834503173828125
Agent0_Eval_MaxReturn : 41.04553985595703
Agent0_Eval_MinReturn : -65.38418579101562
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -31.46488380432129
Agent0_Train_StdReturn : 26.753488540649414
Agent0_Train_MaxReturn : 5.917475700378418
Agent0_Train_MinReturn : -66.07237243652344
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 16500
Agent0_TimeSinceStart : 24.973496913909912
Agent0_Critic_Loss : 0.9285090565681458
Agent0_Actor_Loss : -0.3657960593700409
Agent0_Alpha_Loss : 0.9829058647155762
Agent0_Temperature : 0.09967056271390533
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -35.15570068359375
Agent1_Eval_StdReturn : 32.02640914916992
Agent1_Eval_MaxReturn : 16.7863712310791
Agent1_Eval_MinReturn : -91.48548889160156
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -44.53758239746094
Agent1_Train_StdReturn : 29.685022354125977
Agent1_Train_MaxReturn : 3.7171268463134766
Agent1_Train_MinReturn : -86.65126037597656
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 16500
Agent1_TimeSinceStart : 27.048049926757812
Agent1_Critic_Loss : 0.9182092547416687
Agent1_Actor_Loss : -0.5095957517623901
Agent1_Alpha_Loss : 0.9861770272254944
Agent1_Temperature : 0.09967042435579129
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 11 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 12 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 13 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 14 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 15 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 16 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 17 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 18 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 19 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 20 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -43.38697052001953
Agent0_Eval_StdReturn : 43.672325134277344
Agent0_Eval_MaxReturn : 9.642265319824219
Agent0_Eval_MinReturn : -116.5941162109375
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -33.40008544921875
Agent0_Train_StdReturn : 29.175334930419922
Agent0_Train_MaxReturn : 5.264189720153809
Agent0_Train_MinReturn : -82.53800964355469
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 31500
Agent0_TimeSinceStart : 47.853683948516846
Agent0_Critic_Loss : 0.8994090557098389
Agent0_Actor_Loss : -0.4210008978843689
Agent0_Alpha_Loss : 0.9935859441757202
Agent0_Temperature : 0.09937206042805405
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -53.96504592895508
Agent1_Eval_StdReturn : 43.379947662353516
Agent1_Eval_MaxReturn : 35.547664642333984
Agent1_Eval_MinReturn : -129.4097137451172
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -43.527915954589844
Agent1_Train_StdReturn : 28.746292114257812
Agent1_Train_MaxReturn : -4.636443138122559
Agent1_Train_MinReturn : -84.09095764160156
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 31500
Agent1_TimeSinceStart : 49.92219877243042
Agent1_Critic_Loss : 0.6898341774940491
Agent1_Actor_Loss : -0.5222538709640503
Agent1_Alpha_Loss : 0.9894306063652039
Agent1_Temperature : 0.099371725422022
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 21 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 22 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 23 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 24 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 25 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 26 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 27 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 28 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 29 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 30 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -30.686840057373047
Agent0_Eval_StdReturn : 31.976219177246094
Agent0_Eval_MaxReturn : 15.554892539978027
Agent0_Eval_MinReturn : -95.71600341796875
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -21.32683753967285
Agent0_Train_StdReturn : 34.12836456298828
Agent0_Train_MaxReturn : 11.6461181640625
Agent0_Train_MinReturn : -90.47835540771484
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 46500
Agent0_TimeSinceStart : 70.73244166374207
Agent0_Critic_Loss : 0.9358377456665039
Agent0_Actor_Loss : -0.4118671715259552
Agent0_Alpha_Loss : 0.9876188039779663
Agent0_Temperature : 0.09907424650166567
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -44.66895294189453
Agent1_Eval_StdReturn : 20.377052307128906
Agent1_Eval_MaxReturn : -7.406425476074219
Agent1_Eval_MinReturn : -80.6243667602539
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -56.577049255371094
Agent1_Train_StdReturn : 40.68922805786133
Agent1_Train_MaxReturn : 34.70890426635742
Agent1_Train_MinReturn : -114.0631103515625
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 46500
Agent1_TimeSinceStart : 72.80363702774048
Agent1_Critic_Loss : 0.8305315971374512
Agent1_Actor_Loss : -0.6114243268966675
Agent1_Alpha_Loss : 0.9846721887588501
Agent1_Temperature : 0.09907396921446175
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 31 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 32 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 33 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 34 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 35 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 36 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 37 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 38 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 39 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 40 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -58.8385124206543
Agent0_Eval_StdReturn : 36.875389099121094
Agent0_Eval_MaxReturn : 18.561731338500977
Agent0_Eval_MinReturn : -121.34124755859375
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -39.41211700439453
Agent0_Train_StdReturn : 31.211196899414062
Agent0_Train_MaxReturn : -1.5024425983428955
Agent0_Train_MinReturn : -102.93386840820312
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 61500
Agent0_TimeSinceStart : 93.6290352344513
Agent0_Critic_Loss : 0.7919868230819702
Agent0_Actor_Loss : -0.5017924904823303
Agent0_Alpha_Loss : 0.9837807416915894
Agent0_Temperature : 0.09877775447740954
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -33.764705657958984
Agent1_Eval_StdReturn : 31.169116973876953
Agent1_Eval_MaxReturn : 19.466182708740234
Agent1_Eval_MinReturn : -88.51805877685547
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -40.04237747192383
Agent1_Train_StdReturn : 34.22526931762695
Agent1_Train_MaxReturn : 4.663270950317383
Agent1_Train_MinReturn : -94.31086730957031
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 61500
Agent1_TimeSinceStart : 95.70761728286743
Agent1_Critic_Loss : 0.6820058822631836
Agent1_Actor_Loss : -0.61720871925354
Agent1_Alpha_Loss : 0.9784646034240723
Agent1_Temperature : 0.09877766513343532
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 41 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 42 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 43 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 44 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 45 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 46 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 47 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 48 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 49 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 50 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -40.2404670715332
Agent0_Eval_StdReturn : 33.054996490478516
Agent0_Eval_MaxReturn : 16.798763275146484
Agent0_Eval_MinReturn : -94.64860534667969
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -30.507116317749023
Agent0_Train_StdReturn : 30.74982261657715
Agent0_Train_MaxReturn : 18.7569522857666
Agent0_Train_MinReturn : -62.976890563964844
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 76500
Agent0_TimeSinceStart : 116.55953335762024
Agent0_Critic_Loss : 0.6696636080741882
Agent0_Actor_Loss : -0.5484128594398499
Agent0_Alpha_Loss : 0.9705269932746887
Agent0_Temperature : 0.09848284407898429
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -53.2364387512207
Agent1_Eval_StdReturn : 24.130664825439453
Agent1_Eval_MaxReturn : -16.806747436523438
Agent1_Eval_MinReturn : -85.96865844726562
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -26.66131019592285
Agent1_Train_StdReturn : 29.699268341064453
Agent1_Train_MaxReturn : 14.08652114868164
Agent1_Train_MinReturn : -82.72666931152344
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 76500
Agent1_TimeSinceStart : 118.64359998703003
Agent1_Critic_Loss : 0.6656782627105713
Agent1_Actor_Loss : -0.5844562649726868
Agent1_Alpha_Loss : 0.9852499961853027
Agent1_Temperature : 0.09848294805177957
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 51 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 52 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 53 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 54 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 55 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 56 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 57 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 58 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 59 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 60 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -35.65120315551758
Agent0_Eval_StdReturn : 31.44137191772461
Agent0_Eval_MaxReturn : 23.047245025634766
Agent0_Eval_MinReturn : -85.97941589355469
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -38.31502151489258
Agent0_Train_StdReturn : 28.90235710144043
Agent0_Train_MaxReturn : 2.0544748306274414
Agent0_Train_MinReturn : -85.96635437011719
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 91500
Agent0_TimeSinceStart : 139.51425218582153
Agent0_Critic_Loss : 0.6167566180229187
Agent0_Actor_Loss : -0.47789350152015686
Agent0_Alpha_Loss : 0.9705895185470581
Agent0_Temperature : 0.098189541619117
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -41.05083084106445
Agent1_Eval_StdReturn : 27.44729995727539
Agent1_Eval_MaxReturn : 9.700028419494629
Agent1_Eval_MinReturn : -77.75328826904297
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -42.59264373779297
Agent1_Train_StdReturn : 38.720054626464844
Agent1_Train_MaxReturn : 16.075944900512695
Agent1_Train_MinReturn : -99.79830932617188
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 91500
Agent1_TimeSinceStart : 141.58380484580994
Agent1_Critic_Loss : 0.65437912940979
Agent1_Actor_Loss : -0.5650622844696045
Agent1_Alpha_Loss : 0.9698150753974915
Agent1_Temperature : 0.09818927610808836
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 61 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 62 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 63 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 64 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 65 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 66 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 67 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 68 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 69 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 70 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -42.301429748535156
Agent0_Eval_StdReturn : 29.974374771118164
Agent0_Eval_MaxReturn : 3.220546007156372
Agent0_Eval_MinReturn : -87.86973571777344
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -36.35492706298828
Agent0_Train_StdReturn : 33.5159797668457
Agent0_Train_MaxReturn : 16.33430290222168
Agent0_Train_MinReturn : -90.46331024169922
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 106500
Agent0_TimeSinceStart : 162.38097548484802
Agent0_Critic_Loss : 0.6099430322647095
Agent0_Actor_Loss : -0.44114047288894653
Agent0_Alpha_Loss : 0.9626094698905945
Agent0_Temperature : 0.09789790917272123
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -30.946880340576172
Agent1_Eval_StdReturn : 22.71921157836914
Agent1_Eval_MaxReturn : -9.417581558227539
Agent1_Eval_MinReturn : -77.97965240478516
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -45.5745849609375
Agent1_Train_StdReturn : 29.953134536743164
Agent1_Train_MaxReturn : 1.3580138683319092
Agent1_Train_MinReturn : -109.576171875
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 106500
Agent1_TimeSinceStart : 164.44331908226013
Agent1_Critic_Loss : 0.6073858737945557
Agent1_Actor_Loss : -0.6296950578689575
Agent1_Alpha_Loss : 0.9604669213294983
Agent1_Temperature : 0.09789768644588068
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 71 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 72 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 73 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 74 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 75 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 76 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 77 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 78 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 79 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 80 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -62.808631896972656
Agent0_Eval_StdReturn : 35.297332763671875
Agent0_Eval_MaxReturn : -15.811286926269531
Agent0_Eval_MinReturn : -143.87709045410156
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -43.05418014526367
Agent0_Train_StdReturn : 19.3426513671875
Agent0_Train_MaxReturn : -6.720730304718018
Agent0_Train_MinReturn : -81.23765563964844
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 121500
Agent0_TimeSinceStart : 185.2471477985382
Agent0_Critic_Loss : 0.5835055112838745
Agent0_Actor_Loss : -0.5252723693847656
Agent0_Alpha_Loss : 0.9503120183944702
Agent0_Temperature : 0.09760916401928038
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -24.958459854125977
Agent1_Eval_StdReturn : 27.208646774291992
Agent1_Eval_MaxReturn : 24.621746063232422
Agent1_Eval_MinReturn : -60.690956115722656
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -33.3482780456543
Agent1_Train_StdReturn : 36.72779083251953
Agent1_Train_MaxReturn : 21.165443420410156
Agent1_Train_MinReturn : -120.62956237792969
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 121500
Agent1_TimeSinceStart : 187.31918334960938
Agent1_Critic_Loss : 0.518913745880127
Agent1_Actor_Loss : -0.6498725414276123
Agent1_Alpha_Loss : 0.943537175655365
Agent1_Temperature : 0.09760873286741864
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 81 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 82 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 83 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 84 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 85 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 86 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 87 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 88 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 89 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 90 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -31.816173553466797
Agent0_Eval_StdReturn : 20.06867027282715
Agent0_Eval_MaxReturn : -2.968216896057129
Agent0_Eval_MinReturn : -70.93370056152344
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -36.282325744628906
Agent0_Train_StdReturn : 26.2726993560791
Agent0_Train_MaxReturn : 3.581322193145752
Agent0_Train_MinReturn : -90.8082504272461
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 136500
Agent0_TimeSinceStart : 208.17842841148376
Agent0_Critic_Loss : 0.642711877822876
Agent0_Actor_Loss : -0.513516902923584
Agent0_Alpha_Loss : 0.9266514778137207
Agent0_Temperature : 0.0973241800307909
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -29.841506958007812
Agent1_Eval_StdReturn : 22.054649353027344
Agent1_Eval_MaxReturn : 1.825150966644287
Agent1_Eval_MinReturn : -77.45494842529297
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -38.693397521972656
Agent1_Train_StdReturn : 21.353191375732422
Agent1_Train_MaxReturn : -12.157110214233398
Agent1_Train_MinReturn : -76.73856353759766
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 136500
Agent1_TimeSinceStart : 210.25189208984375
Agent1_Critic_Loss : 0.5489075183868408
Agent1_Actor_Loss : -0.6440353393554688
Agent1_Alpha_Loss : 0.9441635608673096
Agent1_Temperature : 0.09732333462396554
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 91 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 92 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 93 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 94 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 95 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 96 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 97 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 98 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 99 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 100 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -15.971872329711914
Agent0_Eval_StdReturn : 23.232730865478516
Agent0_Eval_MaxReturn : 36.32105255126953
Agent0_Eval_MinReturn : -51.40620803833008
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -14.955472946166992
Agent0_Train_StdReturn : 7.823017597198486
Agent0_Train_MaxReturn : -4.583125114440918
Agent0_Train_MinReturn : -33.780364990234375
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 151500
Agent0_TimeSinceStart : 231.17255663871765
Agent0_Critic_Loss : 0.4893245995044708
Agent0_Actor_Loss : -0.5655577182769775
Agent0_Alpha_Loss : 0.8904958367347717
Agent0_Temperature : 0.09704442372504056
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -34.597801208496094
Agent1_Eval_StdReturn : 25.833707809448242
Agent1_Eval_MaxReturn : 5.16425895690918
Agent1_Eval_MinReturn : -83.5369873046875
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -22.46956443786621
Agent1_Train_StdReturn : 18.913043975830078
Agent1_Train_MaxReturn : 11.918903350830078
Agent1_Train_MinReturn : -49.00717544555664
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 151500
Agent1_TimeSinceStart : 233.26951122283936
Agent1_Critic_Loss : 0.5424003601074219
Agent1_Actor_Loss : -0.7103419303894043
Agent1_Alpha_Loss : 0.8896846175193787
Agent1_Temperature : 0.09704238637090877
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 101 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 102 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 103 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 104 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 105 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 106 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 107 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 108 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 109 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 110 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -25.219778060913086
Agent0_Eval_StdReturn : 7.050567626953125
Agent0_Eval_MaxReturn : -14.076716423034668
Agent0_Eval_MinReturn : -38.16297149658203
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -25.479724884033203
Agent0_Train_StdReturn : 14.440329551696777
Agent0_Train_MaxReturn : -4.266221046447754
Agent0_Train_MinReturn : -48.500640869140625
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 166500
Agent0_TimeSinceStart : 254.2911775112152
Agent0_Critic_Loss : 0.42267897725105286
Agent0_Actor_Loss : -0.6505429744720459
Agent0_Alpha_Loss : 0.8280765414237976
Agent0_Temperature : 0.09677335163045972
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -27.1691951751709
Agent1_Eval_StdReturn : 18.080652236938477
Agent1_Eval_MaxReturn : 14.577960968017578
Agent1_Eval_MinReturn : -52.738792419433594
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -18.316091537475586
Agent1_Train_StdReturn : 10.535684585571289
Agent1_Train_MaxReturn : -2.3949880599975586
Agent1_Train_MinReturn : -39.09020233154297
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 166500
Agent1_TimeSinceStart : 256.42263102531433
Agent1_Critic_Loss : 0.4074627161026001
Agent1_Actor_Loss : -0.6965429186820984
Agent1_Alpha_Loss : 0.8484166860580444
Agent1_Temperature : 0.09676935401429941
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 111 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 112 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 113 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 114 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 115 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 116 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 117 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 118 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 119 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 120 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -26.1876220703125
Agent0_Eval_StdReturn : 9.185425758361816
Agent0_Eval_MaxReturn : -4.072622299194336
Agent0_Eval_MinReturn : -36.80658721923828
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -20.970348358154297
Agent0_Train_StdReturn : 7.33211088180542
Agent0_Train_MaxReturn : -9.294639587402344
Agent0_Train_MinReturn : -35.894351959228516
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 181500
Agent0_TimeSinceStart : 277.5019896030426
Agent0_Critic_Loss : 0.47973179817199707
Agent0_Actor_Loss : -0.5085757374763489
Agent0_Alpha_Loss : 0.7924610376358032
Agent0_Temperature : 0.09651302484826114
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -28.571578979492188
Agent1_Eval_StdReturn : 15.67301082611084
Agent1_Eval_MaxReturn : -6.633373260498047
Agent1_Eval_MinReturn : -49.0264892578125
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -22.619464874267578
Agent1_Train_StdReturn : 16.6622314453125
Agent1_Train_MaxReturn : 10.88422679901123
Agent1_Train_MinReturn : -49.32700729370117
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 181500
Agent1_TimeSinceStart : 279.5943365097046
Agent1_Critic_Loss : 0.3865857720375061
Agent1_Actor_Loss : -0.6094276309013367
Agent1_Alpha_Loss : 0.7905857563018799
Agent1_Temperature : 0.09650630689851261
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 121 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 122 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 123 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 124 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 125 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 126 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 127 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 128 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 129 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 130 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -29.115625381469727
Agent0_Eval_StdReturn : 8.576529502868652
Agent0_Eval_MaxReturn : -15.763483047485352
Agent0_Eval_MinReturn : -40.35884475708008
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -26.51810646057129
Agent0_Train_StdReturn : 11.818973541259766
Agent0_Train_MaxReturn : -9.958226203918457
Agent0_Train_MinReturn : -52.94584655761719
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 196500
Agent0_TimeSinceStart : 300.6562991142273
Agent0_Critic_Loss : 0.47612708806991577
Agent0_Actor_Loss : -0.44914478063583374
Agent0_Alpha_Loss : 0.7840332984924316
Agent0_Temperature : 0.09626406079707081
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -27.29128074645996
Agent1_Eval_StdReturn : 13.655793190002441
Agent1_Eval_MaxReturn : -4.681344985961914
Agent1_Eval_MinReturn : -42.6507568359375
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -23.106441497802734
Agent1_Train_StdReturn : 10.708494186401367
Agent1_Train_MaxReturn : -7.691933631896973
Agent1_Train_MinReturn : -44.8114013671875
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 196500
Agent1_TimeSinceStart : 302.74803924560547
Agent1_Critic_Loss : 0.43622690439224243
Agent1_Actor_Loss : -0.5283331274986267
Agent1_Alpha_Loss : 0.7868212461471558
Agent1_Temperature : 0.09625311512311743
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 131 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 132 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 133 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 134 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 135 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 136 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 137 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 138 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 139 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 140 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -29.546222686767578
Agent0_Eval_StdReturn : 18.41615867614746
Agent0_Eval_MaxReturn : 0.7386660575866699
Agent0_Eval_MinReturn : -57.929237365722656
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -35.402950286865234
Agent0_Train_StdReturn : 7.742053985595703
Agent0_Train_MaxReturn : -24.472274780273438
Agent0_Train_MinReturn : -49.71193313598633
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 211500
Agent0_TimeSinceStart : 323.85896372795105
Agent0_Critic_Loss : 0.4160386919975281
Agent0_Actor_Loss : -0.3890208601951599
Agent0_Alpha_Loss : 0.7785576581954956
Agent0_Temperature : 0.09601954992581022
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -18.591421127319336
Agent1_Eval_StdReturn : 7.362422943115234
Agent1_Eval_MaxReturn : -4.786919593811035
Agent1_Eval_MinReturn : -31.342670440673828
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -25.78216552734375
Agent1_Train_StdReturn : 12.29578971862793
Agent1_Train_MaxReturn : -14.406673431396484
Agent1_Train_MinReturn : -53.54553985595703
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 211500
Agent1_TimeSinceStart : 325.95965909957886
Agent1_Critic_Loss : 0.3540774881839752
Agent1_Actor_Loss : -0.5932399034500122
Agent1_Alpha_Loss : 0.8204249143600464
Agent1_Temperature : 0.0960039532199791
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 141 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 142 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 143 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 144 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 145 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 146 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 147 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 148 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 149 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 150 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -36.290489196777344
Agent0_Eval_StdReturn : 12.122954368591309
Agent0_Eval_MaxReturn : -17.19602394104004
Agent0_Eval_MinReturn : -58.9616813659668
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -30.171382904052734
Agent0_Train_StdReturn : 10.661962509155273
Agent0_Train_MaxReturn : -12.430803298950195
Agent0_Train_MinReturn : -46.9097900390625
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 226500
Agent0_TimeSinceStart : 347.06037068367004
Agent0_Critic_Loss : 0.3709831237792969
Agent0_Actor_Loss : -0.449302613735199
Agent0_Alpha_Loss : 0.80012047290802
Agent0_Temperature : 0.09577423490148626
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -23.413631439208984
Agent1_Eval_StdReturn : 13.766435623168945
Agent1_Eval_MaxReturn : 3.851543426513672
Agent1_Eval_MinReturn : -43.74663543701172
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -22.44600486755371
Agent1_Train_StdReturn : 10.01215648651123
Agent1_Train_MaxReturn : -3.7045631408691406
Agent1_Train_MinReturn : -35.42446517944336
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 226500
Agent1_TimeSinceStart : 349.1511571407318
Agent1_Critic_Loss : 0.343717098236084
Agent1_Actor_Loss : -0.6993119716644287
Agent1_Alpha_Loss : 0.8084455728530884
Agent1_Temperature : 0.09575292996005902
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 151 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 152 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 153 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 154 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 155 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 156 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 157 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 158 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 159 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 160 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -28.8646183013916
Agent0_Eval_StdReturn : 10.096835136413574
Agent0_Eval_MaxReturn : -19.3649959564209
Agent0_Eval_MinReturn : -56.64392852783203
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -22.04267692565918
Agent0_Train_StdReturn : 12.488983154296875
Agent0_Train_MaxReturn : -6.148839950561523
Agent0_Train_MinReturn : -52.58303451538086
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 241500
Agent0_TimeSinceStart : 370.2314794063568
Agent0_Critic_Loss : 0.4022432565689087
Agent0_Actor_Loss : -0.4916233420372009
Agent0_Alpha_Loss : 0.8159464001655579
Agent0_Temperature : 0.09552433609581007
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -26.6223087310791
Agent1_Eval_StdReturn : 10.387969970703125
Agent1_Eval_MaxReturn : -7.464611053466797
Agent1_Eval_MinReturn : -41.601898193359375
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -21.869455337524414
Agent1_Train_StdReturn : 10.593989372253418
Agent1_Train_MaxReturn : -0.659977912902832
Agent1_Train_MinReturn : -36.14313888549805
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 241500
Agent1_TimeSinceStart : 372.3304295539856
Agent1_Critic_Loss : 0.506170392036438
Agent1_Actor_Loss : -0.6434035301208496
Agent1_Alpha_Loss : 0.8449909687042236
Agent1_Temperature : 0.09549852897058167
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 161 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 162 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 163 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 164 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 165 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 166 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 167 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 168 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 169 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 170 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -28.3478946685791
Agent0_Eval_StdReturn : 12.097359657287598
Agent0_Eval_MaxReturn : -8.141843795776367
Agent0_Eval_MinReturn : -53.37613296508789
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -20.984989166259766
Agent0_Train_StdReturn : 7.032236576080322
Agent0_Train_MaxReturn : -11.254098892211914
Agent0_Train_MinReturn : -36.411277770996094
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 256500
Agent0_TimeSinceStart : 393.3751082420349
Agent0_Critic_Loss : 0.32909929752349854
Agent0_Actor_Loss : -0.2907380759716034
Agent0_Alpha_Loss : 0.805544376373291
Agent0_Temperature : 0.09527055262663903
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -26.716049194335938
Agent1_Eval_StdReturn : 18.02027702331543
Agent1_Eval_MaxReturn : -1.6649909019470215
Agent1_Eval_MinReturn : -53.732566833496094
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -21.871097564697266
Agent1_Train_StdReturn : 10.348637580871582
Agent1_Train_MaxReturn : -10.057432174682617
Agent1_Train_MinReturn : -46.746124267578125
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 256500
Agent1_TimeSinceStart : 395.4610619544983
Agent1_Critic_Loss : 0.3049764335155487
Agent1_Actor_Loss : -0.509197473526001
Agent1_Alpha_Loss : 0.8098715543746948
Agent1_Temperature : 0.09524205356263774
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 171 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 172 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 173 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 174 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 175 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 176 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 177 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 178 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 179 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 180 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -20.903034210205078
Agent0_Eval_StdReturn : 14.032318115234375
Agent0_Eval_MaxReturn : 3.3147029876708984
Agent0_Eval_MinReturn : -49.04443359375
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -20.160114288330078
Agent0_Train_StdReturn : 9.439260482788086
Agent0_Train_MaxReturn : -9.385672569274902
Agent0_Train_MinReturn : -35.05316162109375
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 271500
Agent0_TimeSinceStart : 416.48646116256714
Agent0_Critic_Loss : 0.3051438331604004
Agent0_Actor_Loss : -0.41357260942459106
Agent0_Alpha_Loss : 0.7938680052757263
Agent0_Temperature : 0.09501581242244875
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -10.24060344696045
Agent1_Eval_StdReturn : 14.10252857208252
Agent1_Eval_MaxReturn : 18.755321502685547
Agent1_Eval_MinReturn : -23.795623779296875
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -26.04498291015625
Agent1_Train_StdReturn : 7.652140140533447
Agent1_Train_MaxReturn : -12.314702987670898
Agent1_Train_MinReturn : -35.219146728515625
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 271500
Agent1_TimeSinceStart : 418.58131766319275
Agent1_Critic_Loss : 0.28917181491851807
Agent1_Actor_Loss : -0.5309678316116333
Agent1_Alpha_Loss : 0.8087109327316284
Agent1_Temperature : 0.09498527083960473
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 181 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 182 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 183 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 184 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 185 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 186 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 187 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 188 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 189 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 190 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -22.07309341430664
Agent0_Eval_StdReturn : 17.41485023498535
Agent0_Eval_MaxReturn : 16.022737503051758
Agent0_Eval_MinReturn : -53.82146453857422
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -20.78061866760254
Agent0_Train_StdReturn : 7.108293056488037
Agent0_Train_MaxReturn : -10.481598854064941
Agent0_Train_MinReturn : -34.160282135009766
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 286500
Agent0_TimeSinceStart : 439.64732551574707
Agent0_Critic_Loss : 0.3493771553039551
Agent0_Actor_Loss : -0.4460321068763733
Agent0_Alpha_Loss : 0.792611837387085
Agent0_Temperature : 0.09476177702826037
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -21.250818252563477
Agent1_Eval_StdReturn : 17.112085342407227
Agent1_Eval_MaxReturn : 2.936591148376465
Agent1_Eval_MinReturn : -57.40129470825195
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -23.527307510375977
Agent1_Train_StdReturn : 11.507820129394531
Agent1_Train_MaxReturn : -6.4306960105896
Agent1_Train_MinReturn : -44.05596923828125
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 286500
Agent1_TimeSinceStart : 441.7358908653259
Agent1_Critic_Loss : 0.2741531431674957
Agent1_Actor_Loss : -0.5251791477203369
Agent1_Alpha_Loss : 0.8031151294708252
Agent1_Temperature : 0.0947278543345802
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 191 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 192 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 193 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 194 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 195 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 196 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 197 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 198 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 199 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 200 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -22.63446044921875
Agent0_Eval_StdReturn : 18.28514289855957
Agent0_Eval_MaxReturn : 16.823040008544922
Agent0_Eval_MinReturn : -45.415611267089844
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -24.533475875854492
Agent0_Train_StdReturn : 13.873749732971191
Agent0_Train_MaxReturn : 1.956168293952942
Agent0_Train_MinReturn : -47.155662536621094
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 301500
Agent0_TimeSinceStart : 462.7264828681946
Agent0_Critic_Loss : 0.25342071056365967
Agent0_Actor_Loss : -0.3998657166957855
Agent0_Alpha_Loss : 0.8027217388153076
Agent0_Temperature : 0.0945089726878936
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -14.98442554473877
Agent1_Eval_StdReturn : 11.627592086791992
Agent1_Eval_MaxReturn : 5.136971473693848
Agent1_Eval_MinReturn : -35.057132720947266
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -30.824270248413086
Agent1_Train_StdReturn : 18.609464645385742
Agent1_Train_MaxReturn : -3.0300283432006836
Agent1_Train_MinReturn : -62.83955383300781
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 301500
Agent1_TimeSinceStart : 464.81493186950684
Agent1_Critic_Loss : 0.2948990762233734
Agent1_Actor_Loss : -0.5183458924293518
Agent1_Alpha_Loss : 0.8067147135734558
Agent1_Temperature : 0.09447066897513634
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 201 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 202 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 203 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 204 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 205 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 206 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 207 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 208 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 209 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 210 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -18.87903594970703
Agent0_Eval_StdReturn : 7.918452739715576
Agent0_Eval_MaxReturn : -9.302515029907227
Agent0_Eval_MinReturn : -32.12144470214844
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -17.578004837036133
Agent0_Train_StdReturn : 14.806057929992676
Agent0_Train_MaxReturn : 7.91201114654541
Agent0_Train_MinReturn : -40.94824981689453
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 316500
Agent0_TimeSinceStart : 485.8036048412323
Agent0_Critic_Loss : 0.2367618829011917
Agent0_Actor_Loss : -0.3572932481765747
Agent0_Alpha_Loss : 0.7698644399642944
Agent0_Temperature : 0.09425573323588293
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -15.902830123901367
Agent1_Eval_StdReturn : 11.921513557434082
Agent1_Eval_MaxReturn : 4.802982330322266
Agent1_Eval_MinReturn : -34.1939811706543
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -13.949444770812988
Agent1_Train_StdReturn : 13.60876750946045
Agent1_Train_MaxReturn : -0.8086349964141846
Agent1_Train_MinReturn : -39.97772216796875
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 316500
Agent1_TimeSinceStart : 487.8864381313324
Agent1_Critic_Loss : 0.24425888061523438
Agent1_Actor_Loss : -0.5100332498550415
Agent1_Alpha_Loss : 0.7880580425262451
Agent1_Temperature : 0.09421482217058028
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 211 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 212 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 213 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 214 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 215 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 216 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 217 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 218 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 219 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 220 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -19.852983474731445
Agent0_Eval_StdReturn : 13.062447547912598
Agent0_Eval_MaxReturn : 0.5471076965332031
Agent0_Eval_MinReturn : -44.43468475341797
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -10.51824951171875
Agent0_Train_StdReturn : 13.686287879943848
Agent0_Train_MaxReturn : 9.06671142578125
Agent0_Train_MinReturn : -43.84870529174805
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 331500
Agent0_TimeSinceStart : 508.8538417816162
Agent0_Critic_Loss : 0.22993463277816772
Agent0_Actor_Loss : -0.32326486706733704
Agent0_Alpha_Loss : 0.7727056741714478
Agent0_Temperature : 0.09400257219076734
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -13.518315315246582
Agent1_Eval_StdReturn : 8.753687858581543
Agent1_Eval_MaxReturn : -2.456515312194824
Agent1_Eval_MinReturn : -31.088951110839844
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -16.9912166595459
Agent1_Train_StdReturn : 17.14722442626953
Agent1_Train_MaxReturn : 13.464906692504883
Agent1_Train_MinReturn : -46.179771423339844
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 331500
Agent1_TimeSinceStart : 510.93901205062866
Agent1_Critic_Loss : 0.3080263137817383
Agent1_Actor_Loss : -0.49696362018585205
Agent1_Alpha_Loss : 0.7716308832168579
Agent1_Temperature : 0.09396000113583818
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 221 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 222 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 223 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 224 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 225 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 226 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 227 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 228 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 229 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 230 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -14.924173355102539
Agent0_Eval_StdReturn : 9.780835151672363
Agent0_Eval_MaxReturn : 2.5503711700439453
Agent0_Eval_MinReturn : -31.565834045410156
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -17.19369125366211
Agent0_Train_StdReturn : 12.975512504577637
Agent0_Train_MaxReturn : -0.8702702522277832
Agent0_Train_MinReturn : -43.016151428222656
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 346500
Agent0_TimeSinceStart : 531.892035484314
Agent0_Critic_Loss : 0.29223567247390747
Agent0_Actor_Loss : -0.3110634386539459
Agent0_Alpha_Loss : 0.7835279703140259
Agent0_Temperature : 0.0937491307583831
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -20.145458221435547
Agent1_Eval_StdReturn : 24.956756591796875
Agent1_Eval_MaxReturn : 20.042255401611328
Agent1_Eval_MinReturn : -59.37761688232422
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -12.942392349243164
Agent1_Train_StdReturn : 12.004321098327637
Agent1_Train_MaxReturn : 11.952781677246094
Agent1_Train_MinReturn : -28.743526458740234
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 346500
Agent1_TimeSinceStart : 533.9770097732544
Agent1_Critic_Loss : 0.2807984948158264
Agent1_Actor_Loss : -0.5160170793533325
Agent1_Alpha_Loss : 0.8086038827896118
Agent1_Temperature : 0.09370543584577096
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 231 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 232 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 233 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 234 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 235 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 236 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 237 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 238 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 239 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 240 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -25.90419578552246
Agent0_Eval_StdReturn : 25.319076538085938
Agent0_Eval_MaxReturn : 0.1861124038696289
Agent0_Eval_MinReturn : -75.75120544433594
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -27.240936279296875
Agent0_Train_StdReturn : 11.350386619567871
Agent0_Train_MaxReturn : -11.811573028564453
Agent0_Train_MinReturn : -46.82594299316406
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 361500
Agent0_TimeSinceStart : 554.9200320243835
Agent0_Critic_Loss : 0.23605187237262726
Agent0_Actor_Loss : -0.3597260117530823
Agent0_Alpha_Loss : 0.8051731586456299
Agent0_Temperature : 0.09349390746452166
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -26.179798126220703
Agent1_Eval_StdReturn : 14.059050559997559
Agent1_Eval_MaxReturn : -5.650448799133301
Agent1_Eval_MinReturn : -46.27350616455078
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -34.50747299194336
Agent1_Train_StdReturn : 15.769944190979004
Agent1_Train_MaxReturn : -10.437248229980469
Agent1_Train_MinReturn : -64.09263610839844
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 361500
Agent1_TimeSinceStart : 557.0097305774689
Agent1_Critic_Loss : 0.2416575849056244
Agent1_Actor_Loss : -0.5448768138885498
Agent1_Alpha_Loss : 0.8088729381561279
Agent1_Temperature : 0.09344887388935827
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 241 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 242 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 243 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 244 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 245 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 246 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 247 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 248 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 249 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 250 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -32.3735466003418
Agent0_Eval_StdReturn : 23.46923828125
Agent0_Eval_MaxReturn : -3.795340061187744
Agent0_Eval_MinReturn : -66.66313171386719
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -23.691837310791016
Agent0_Train_StdReturn : 21.325847625732422
Agent0_Train_MaxReturn : 0.9577248096466064
Agent0_Train_MinReturn : -76.80816650390625
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 376500
Agent0_TimeSinceStart : 578.0108640193939
Agent0_Critic_Loss : 0.2850643992424011
Agent0_Actor_Loss : -0.40922874212265015
Agent0_Alpha_Loss : 0.7994428873062134
Agent0_Temperature : 0.09323730557665216
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -18.46457862854004
Agent1_Eval_StdReturn : 17.27296257019043
Agent1_Eval_MaxReturn : 7.694613456726074
Agent1_Eval_MinReturn : -46.92676544189453
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -18.39484977722168
Agent1_Train_StdReturn : 15.374832153320312
Agent1_Train_MaxReturn : 11.0388822555542
Agent1_Train_MinReturn : -37.22166442871094
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 376500
Agent1_TimeSinceStart : 580.0875768661499
Agent1_Critic_Loss : 0.20400278270244598
Agent1_Actor_Loss : -0.5923650860786438
Agent1_Alpha_Loss : 0.8086287975311279
Agent1_Temperature : 0.09319086599320837
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 251 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 252 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 253 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 254 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 255 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 256 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 257 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 258 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 259 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 260 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -16.169286727905273
Agent0_Eval_StdReturn : 18.694875717163086
Agent0_Eval_MaxReturn : 17.32999610900879
Agent0_Eval_MinReturn : -39.41497039794922
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -27.217754364013672
Agent0_Train_StdReturn : 22.933446884155273
Agent0_Train_MaxReturn : 16.09127426147461
Agent0_Train_MinReturn : -65.10749816894531
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 391500
Agent0_TimeSinceStart : 601.0100727081299
Agent0_Critic_Loss : 0.26176387071609497
Agent0_Actor_Loss : -0.36986789107322693
Agent0_Alpha_Loss : 0.8022457957267761
Agent0_Temperature : 0.09298062918509852
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -28.7261962890625
Agent1_Eval_StdReturn : 14.294690132141113
Agent1_Eval_MaxReturn : -4.822025299072266
Agent1_Eval_MinReturn : -44.01750183105469
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -14.6421480178833
Agent1_Train_StdReturn : 18.195409774780273
Agent1_Train_MaxReturn : 12.734899520874023
Agent1_Train_MinReturn : -41.474700927734375
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 391500
Agent1_TimeSinceStart : 603.0877120494843
Agent1_Critic_Loss : 0.34178680181503296
Agent1_Actor_Loss : -0.5325272679328918
Agent1_Alpha_Loss : 0.7996779680252075
Agent1_Temperature : 0.09293297388760471
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 261 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 262 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 263 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 264 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 265 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 266 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 267 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 268 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 269 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 270 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -8.830592155456543
Agent0_Eval_StdReturn : 23.973060607910156
Agent0_Eval_MaxReturn : 37.04143524169922
Agent0_Eval_MinReturn : -38.170684814453125
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -17.002735137939453
Agent0_Train_StdReturn : 23.8173770904541
Agent0_Train_MaxReturn : 24.592941284179688
Agent0_Train_MinReturn : -72.58917999267578
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 406500
Agent0_TimeSinceStart : 623.9937534332275
Agent0_Critic_Loss : 0.2818711996078491
Agent0_Actor_Loss : -0.38809651136398315
Agent0_Alpha_Loss : 0.8022894263267517
Agent0_Temperature : 0.09272166702710759
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -14.469942092895508
Agent1_Eval_StdReturn : 15.369505882263184
Agent1_Eval_MaxReturn : 8.262344360351562
Agent1_Eval_MinReturn : -44.58076477050781
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -34.48859405517578
Agent1_Train_StdReturn : 10.63591480255127
Agent1_Train_MaxReturn : -19.773975372314453
Agent1_Train_MinReturn : -49.332862854003906
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 406500
Agent1_TimeSinceStart : 626.0729203224182
Agent1_Critic_Loss : 0.3110955059528351
Agent1_Actor_Loss : -0.5391139984130859
Agent1_Alpha_Loss : 0.7952686548233032
Agent1_Temperature : 0.09267566039814082
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 271 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 272 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 273 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 274 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 275 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 276 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 277 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 278 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 279 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 280 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -29.437118530273438
Agent0_Eval_StdReturn : 20.271406173706055
Agent0_Eval_MaxReturn : 10.233766555786133
Agent0_Eval_MinReturn : -58.559478759765625
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -31.374256134033203
Agent0_Train_StdReturn : 15.896149635314941
Agent0_Train_MaxReturn : -7.286345481872559
Agent0_Train_MinReturn : -59.03761672973633
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 421500
Agent0_TimeSinceStart : 647.0255336761475
Agent0_Critic_Loss : 0.28867489099502563
Agent0_Actor_Loss : -0.5071629285812378
Agent0_Alpha_Loss : 0.7861278057098389
Agent0_Temperature : 0.09246285321439318
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -10.922975540161133
Agent1_Eval_StdReturn : 14.061430931091309
Agent1_Eval_MaxReturn : 20.354406356811523
Agent1_Eval_MinReturn : -27.05632972717285
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -20.547046661376953
Agent1_Train_StdReturn : 12.871415138244629
Agent1_Train_MaxReturn : -2.233945846557617
Agent1_Train_MinReturn : -48.56040954589844
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 421500
Agent1_TimeSinceStart : 649.1126062870026
Agent1_Critic_Loss : 0.3357458710670471
Agent1_Actor_Loss : -0.5688297748565674
Agent1_Alpha_Loss : 0.8170811533927917
Agent1_Temperature : 0.09241842820853413
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 281 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 282 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 283 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 284 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 285 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 286 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 287 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 288 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 289 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 290 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -21.71173858642578
Agent0_Eval_StdReturn : 20.16192054748535
Agent0_Eval_MaxReturn : 8.067686080932617
Agent0_Eval_MinReturn : -60.01726531982422
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -12.716248512268066
Agent0_Train_StdReturn : 15.684078216552734
Agent0_Train_MaxReturn : 13.780726432800293
Agent0_Train_MinReturn : -39.08708572387695
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 436500
Agent0_TimeSinceStart : 670.0457463264465
Agent0_Critic_Loss : 0.36568909883499146
Agent0_Actor_Loss : -0.4024902582168579
Agent0_Alpha_Loss : 0.7912461757659912
Agent0_Temperature : 0.09220505289547207
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -18.578733444213867
Agent1_Eval_StdReturn : 20.833667755126953
Agent1_Eval_MaxReturn : 10.416316986083984
Agent1_Eval_MinReturn : -47.876953125
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -9.056354522705078
Agent1_Train_StdReturn : 20.778688430786133
Agent1_Train_MaxReturn : 30.503755569458008
Agent1_Train_MinReturn : -57.969764709472656
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 436500
Agent1_TimeSinceStart : 672.1300649642944
Agent1_Critic_Loss : 0.3315914273262024
Agent1_Actor_Loss : -0.5646544694900513
Agent1_Alpha_Loss : 0.8037965297698975
Agent1_Temperature : 0.09216186992626155
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 291 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 292 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 293 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 294 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 295 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 296 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 297 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 298 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 299 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 300 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -34.59016799926758
Agent0_Eval_StdReturn : 21.419849395751953
Agent0_Eval_MaxReturn : 6.754779815673828
Agent0_Eval_MinReturn : -64.0755844116211
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -33.80540084838867
Agent0_Train_StdReturn : 21.685056686401367
Agent0_Train_MaxReturn : 17.6574764251709
Agent0_Train_MinReturn : -59.10113525390625
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 451500
Agent0_TimeSinceStart : 693.11456823349
Agent0_Critic_Loss : 0.4129416346549988
Agent0_Actor_Loss : -0.49102622270584106
Agent0_Alpha_Loss : 0.796013355255127
Agent0_Temperature : 0.09194853124628809
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -10.005633354187012
Agent1_Eval_StdReturn : 12.078459739685059
Agent1_Eval_MaxReturn : 3.9682111740112305
Agent1_Eval_MinReturn : -35.50504684448242
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -20.95986557006836
Agent1_Train_StdReturn : 22.98246192932129
Agent1_Train_MaxReturn : 12.024311065673828
Agent1_Train_MinReturn : -64.5975570678711
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 451500
Agent1_TimeSinceStart : 695.2051122188568
Agent1_Critic_Loss : 0.34250202775001526
Agent1_Actor_Loss : -0.7133606672286987
Agent1_Alpha_Loss : 0.8033043146133423
Agent1_Temperature : 0.09190538604575317
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 301 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 302 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 303 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 304 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 305 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 306 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 307 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 308 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 309 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 310 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -23.66707420349121
Agent0_Eval_StdReturn : 27.774991989135742
Agent0_Eval_MaxReturn : 49.110782623291016
Agent0_Eval_MinReturn : -54.02532958984375
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -10.997737884521484
Agent0_Train_StdReturn : 14.079773902893066
Agent0_Train_MaxReturn : 12.485090255737305
Agent0_Train_MinReturn : -33.356773376464844
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 466500
Agent0_TimeSinceStart : 716.1312453746796
Agent0_Critic_Loss : 0.3596513867378235
Agent0_Actor_Loss : -0.44656991958618164
Agent0_Alpha_Loss : 0.7941880226135254
Agent0_Temperature : 0.09169201659203208
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -17.326358795166016
Agent1_Eval_StdReturn : 12.931768417358398
Agent1_Eval_MaxReturn : 7.1074981689453125
Agent1_Eval_MinReturn : -39.98247528076172
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -16.466020584106445
Agent1_Train_StdReturn : 15.030253410339355
Agent1_Train_MaxReturn : 1.9387803077697754
Agent1_Train_MinReturn : -52.482086181640625
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 466500
Agent1_TimeSinceStart : 718.2174801826477
Agent1_Critic_Loss : 0.3420843482017517
Agent1_Actor_Loss : -0.5461178421974182
Agent1_Alpha_Loss : 0.7913745641708374
Agent1_Temperature : 0.09164863405718413
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 311 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 312 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 313 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 314 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 315 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 316 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 317 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 318 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 319 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 320 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -31.417682647705078
Agent0_Eval_StdReturn : 28.419633865356445
Agent0_Eval_MaxReturn : 19.038705825805664
Agent0_Eval_MinReturn : -82.7593994140625
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -22.13536262512207
Agent0_Train_StdReturn : 20.31511116027832
Agent0_Train_MaxReturn : 13.119131088256836
Agent0_Train_MinReturn : -68.36769104003906
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 481500
Agent0_TimeSinceStart : 739.1650602817535
Agent0_Critic_Loss : 0.29098325967788696
Agent0_Actor_Loss : -0.5146277546882629
Agent0_Alpha_Loss : 0.8125776052474976
Agent0_Temperature : 0.09143475735888251
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -17.696311950683594
Agent1_Eval_StdReturn : 14.26098918914795
Agent1_Eval_MaxReturn : -2.1612377166748047
Agent1_Eval_MinReturn : -44.31068420410156
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -21.889663696289062
Agent1_Train_StdReturn : 17.780359268188477
Agent1_Train_MaxReturn : 14.946634292602539
Agent1_Train_MinReturn : -44.348960876464844
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 481500
Agent1_TimeSinceStart : 741.2502665519714
Agent1_Critic_Loss : 0.3347543478012085
Agent1_Actor_Loss : -0.530648946762085
Agent1_Alpha_Loss : 0.7899632453918457
Agent1_Temperature : 0.09139414588491951
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 321 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 322 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 323 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 324 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 325 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 326 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 327 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 328 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 329 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 330 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -13.853536605834961
Agent0_Eval_StdReturn : 10.978808403015137
Agent0_Eval_MaxReturn : 1.097726583480835
Agent0_Eval_MinReturn : -39.02105712890625
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -21.37209129333496
Agent0_Train_StdReturn : 12.435802459716797
Agent0_Train_MaxReturn : 2.9026975631713867
Agent0_Train_MinReturn : -37.473655700683594
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 496500
Agent0_TimeSinceStart : 762.2034132480621
Agent0_Critic_Loss : 0.364053338766098
Agent0_Actor_Loss : -0.43641215562820435
Agent0_Alpha_Loss : 0.7984566688537598
Agent0_Temperature : 0.09117750254860199
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -28.643169403076172
Agent1_Eval_StdReturn : 12.299561500549316
Agent1_Eval_MaxReturn : -0.6921176910400391
Agent1_Eval_MinReturn : -45.07029342651367
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -13.716038703918457
Agent1_Train_StdReturn : 13.222245216369629
Agent1_Train_MaxReturn : 13.246891021728516
Agent1_Train_MinReturn : -37.61188507080078
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 496500
Agent1_TimeSinceStart : 764.2957501411438
Agent1_Critic_Loss : 0.30364638566970825
Agent1_Actor_Loss : -0.5524756908416748
Agent1_Alpha_Loss : 0.7668384909629822
Agent1_Temperature : 0.0911413077359803
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 331 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 332 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 333 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 334 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 335 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 336 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 337 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 338 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 339 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 340 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -16.699501037597656
Agent0_Eval_StdReturn : 9.909378051757812
Agent0_Eval_MaxReturn : 1.2883856296539307
Agent0_Eval_MinReturn : -29.67685890197754
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -21.01651954650879
Agent0_Train_StdReturn : 19.729534149169922
Agent0_Train_MaxReturn : 17.028488159179688
Agent0_Train_MinReturn : -47.02600860595703
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 511500
Agent0_TimeSinceStart : 785.3402764797211
Agent0_Critic_Loss : 0.3548048734664917
Agent0_Actor_Loss : -0.4590376615524292
Agent0_Alpha_Loss : 0.7978923320770264
Agent0_Temperature : 0.09092027129809074
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -22.357769012451172
Agent1_Eval_StdReturn : 11.360347747802734
Agent1_Eval_MaxReturn : -4.440496444702148
Agent1_Eval_MinReturn : -38.65544891357422
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -21.732654571533203
Agent1_Train_StdReturn : 18.92816162109375
Agent1_Train_MaxReturn : -0.8032045364379883
Agent1_Train_MinReturn : -55.81163787841797
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 511500
Agent1_TimeSinceStart : 787.4304783344269
Agent1_Critic_Loss : 0.3377198576927185
Agent1_Actor_Loss : -0.6431119441986084
Agent1_Alpha_Loss : 0.7759073972702026
Agent1_Temperature : 0.0908904100462731
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 341 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 342 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 343 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 344 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 345 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 346 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 347 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 348 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 349 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 350 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -4.153913497924805
Agent0_Eval_StdReturn : 12.193614959716797
Agent0_Eval_MaxReturn : 21.66075325012207
Agent0_Eval_MinReturn : -21.997146606445312
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -14.222528457641602
Agent0_Train_StdReturn : 14.218676567077637
Agent0_Train_MaxReturn : 14.104767799377441
Agent0_Train_MinReturn : -39.28284454345703
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 526500
Agent0_TimeSinceStart : 808.4661991596222
Agent0_Critic_Loss : 0.34077340364456177
Agent0_Actor_Loss : -0.5019431114196777
Agent0_Alpha_Loss : 0.7869362831115723
Agent0_Temperature : 0.09066433068811589
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -13.386344909667969
Agent1_Eval_StdReturn : 19.744380950927734
Agent1_Eval_MaxReturn : 8.834539413452148
Agent1_Eval_MinReturn : -65.77220153808594
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -8.794768333435059
Agent1_Train_StdReturn : 18.36956787109375
Agent1_Train_MaxReturn : 23.716754913330078
Agent1_Train_MinReturn : -47.69325637817383
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 526500
Agent1_TimeSinceStart : 810.5569081306458
Agent1_Critic_Loss : 0.3689189553260803
Agent1_Actor_Loss : -0.6566136479377747
Agent1_Alpha_Loss : 0.7724124193191528
Agent1_Temperature : 0.09063995155955484
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 351 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 352 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 353 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 354 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 355 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 356 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 357 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 358 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 359 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 360 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -16.44986343383789
Agent0_Eval_StdReturn : 15.780421257019043
Agent0_Eval_MaxReturn : 9.349910736083984
Agent0_Eval_MinReturn : -41.21128463745117
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -17.655296325683594
Agent0_Train_StdReturn : 23.781408309936523
Agent0_Train_MaxReturn : 15.003175735473633
Agent0_Train_MinReturn : -72.5113754272461
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 541500
Agent0_TimeSinceStart : 831.5419907569885
Agent0_Critic_Loss : 0.39002901315689087
Agent0_Actor_Loss : -0.4405617117881775
Agent0_Alpha_Loss : 0.7692112922668457
Agent0_Temperature : 0.09041051134873464
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -25.666629791259766
Agent1_Eval_StdReturn : 18.788358688354492
Agent1_Eval_MaxReturn : 0.9185059070587158
Agent1_Eval_MinReturn : -63.547035217285156
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -21.906633377075195
Agent1_Train_StdReturn : 17.64780616760254
Agent1_Train_MaxReturn : 3.2173635959625244
Agent1_Train_MinReturn : -57.8816032409668
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 541500
Agent1_TimeSinceStart : 833.6294410228729
Agent1_Critic_Loss : 0.4044039249420166
Agent1_Actor_Loss : -0.6130666732788086
Agent1_Alpha_Loss : 0.7905219793319702
Agent1_Temperature : 0.09038983668668177
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 361 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 362 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 363 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 364 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 365 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 366 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 367 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 368 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 369 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 370 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -11.848169326782227
Agent0_Eval_StdReturn : 14.4962797164917
Agent0_Eval_MaxReturn : 19.852718353271484
Agent0_Eval_MinReturn : -33.47821044921875
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -18.74610710144043
Agent0_Train_StdReturn : 13.413089752197266
Agent0_Train_MaxReturn : -0.6261987686157227
Agent0_Train_MinReturn : -41.45829391479492
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 556500
Agent0_TimeSinceStart : 854.6384427547455
Agent0_Critic_Loss : 0.37975212931632996
Agent0_Actor_Loss : -0.48528385162353516
Agent0_Alpha_Loss : 0.7741063833236694
Agent0_Temperature : 0.09015817034974007
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -21.17336654663086
Agent1_Eval_StdReturn : 12.437556266784668
Agent1_Eval_MaxReturn : -4.257059097290039
Agent1_Eval_MinReturn : -46.392066955566406
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -24.025014877319336
Agent1_Train_StdReturn : 11.52939510345459
Agent1_Train_MaxReturn : 1.300985336303711
Agent1_Train_MinReturn : -42.473731994628906
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 556500
Agent1_TimeSinceStart : 856.7263658046722
Agent1_Critic_Loss : 0.3060595989227295
Agent1_Actor_Loss : -0.566693902015686
Agent1_Alpha_Loss : 0.7835659980773926
Agent1_Temperature : 0.09013892324698351
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 371 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 372 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 373 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 374 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 375 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 376 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 377 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 378 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 379 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 380 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -17.205615997314453
Agent0_Eval_StdReturn : 17.84322738647461
Agent0_Eval_MaxReturn : 10.081826210021973
Agent0_Eval_MinReturn : -45.98017883300781
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -21.011051177978516
Agent0_Train_StdReturn : 19.58672523498535
Agent0_Train_MaxReturn : 5.105833530426025
Agent0_Train_MinReturn : -70.44924926757812
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 571500
Agent0_TimeSinceStart : 877.8076658248901
Agent0_Critic_Loss : 0.3739166855812073
Agent0_Actor_Loss : -0.5036987662315369
Agent0_Alpha_Loss : 0.7726805806159973
Agent0_Temperature : 0.08990801559716165
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -18.540536880493164
Agent1_Eval_StdReturn : 15.035844802856445
Agent1_Eval_MaxReturn : 10.492572784423828
Agent1_Eval_MinReturn : -43.19024658203125
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -18.82219886779785
Agent1_Train_StdReturn : 11.81616497039795
Agent1_Train_MaxReturn : -1.5960254669189453
Agent1_Train_MinReturn : -47.12820053100586
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 571500
Agent1_TimeSinceStart : 879.9013142585754
Agent1_Critic_Loss : 0.3474060297012329
Agent1_Actor_Loss : -0.596429705619812
Agent1_Alpha_Loss : 0.7833575010299683
Agent1_Temperature : 0.08988793224384166
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 381 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 382 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 383 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 384 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 385 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 386 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 387 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 388 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 389 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 390 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -20.137584686279297
Agent0_Eval_StdReturn : 13.073507308959961
Agent0_Eval_MaxReturn : -0.683132529258728
Agent0_Eval_MinReturn : -50.57395935058594
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -11.995019912719727
Agent0_Train_StdReturn : 10.08627700805664
Agent0_Train_MaxReturn : 4.721505165100098
Agent0_Train_MinReturn : -28.57563591003418
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 586500
Agent0_TimeSinceStart : 900.9551229476929
Agent0_Critic_Loss : 0.3902644217014313
Agent0_Actor_Loss : -0.4018877148628235
Agent0_Alpha_Loss : 0.7900694012641907
Agent0_Temperature : 0.08965989056868252
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -17.409055709838867
Agent1_Eval_StdReturn : 13.260212898254395
Agent1_Eval_MaxReturn : 4.634934425354004
Agent1_Eval_MinReturn : -36.963802337646484
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -17.839876174926758
Agent1_Train_StdReturn : 10.526339530944824
Agent1_Train_MaxReturn : 7.396707534790039
Agent1_Train_MinReturn : -30.656475067138672
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 586500
Agent1_TimeSinceStart : 903.0596599578857
Agent1_Critic_Loss : 0.43882375955581665
Agent1_Actor_Loss : -0.5723514556884766
Agent1_Alpha_Loss : 0.7577643990516663
Agent1_Temperature : 0.08963883002653408
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 391 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 392 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 393 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 394 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 395 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 396 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 397 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 398 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 399 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 400 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -17.62435531616211
Agent0_Eval_StdReturn : 18.412839889526367
Agent0_Eval_MaxReturn : 13.095370292663574
Agent0_Eval_MinReturn : -38.604087829589844
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -22.292800903320312
Agent0_Train_StdReturn : 18.095966339111328
Agent0_Train_MaxReturn : 2.425783157348633
Agent0_Train_MinReturn : -54.41737365722656
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 601500
Agent0_TimeSinceStart : 924.1403939723969
Agent0_Critic_Loss : 0.39566004276275635
Agent0_Actor_Loss : -0.3166046738624573
Agent0_Alpha_Loss : 0.769904375076294
Agent0_Temperature : 0.08941200655405554
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -16.353412628173828
Agent1_Eval_StdReturn : 11.514243125915527
Agent1_Eval_MaxReturn : 9.819938659667969
Agent1_Eval_MinReturn : -30.96038055419922
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -19.040437698364258
Agent1_Train_StdReturn : 12.022290229797363
Agent1_Train_MaxReturn : -1.4261598587036133
Agent1_Train_MinReturn : -46.15287399291992
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 601500
Agent1_TimeSinceStart : 926.2391910552979
Agent1_Critic_Loss : 0.3825071156024933
Agent1_Actor_Loss : -0.6050965189933777
Agent1_Alpha_Loss : 0.7576438188552856
Agent1_Temperature : 0.08939212123128376
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 401 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 402 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 403 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 404 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 405 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 406 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 407 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 408 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 409 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 410 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -19.976444244384766
Agent0_Eval_StdReturn : 21.967714309692383
Agent0_Eval_MaxReturn : 0.9853954315185547
Agent0_Eval_MinReturn : -76.84526062011719
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -16.282039642333984
Agent0_Train_StdReturn : 13.395174026489258
Agent0_Train_MaxReturn : -2.58232045173645
Agent0_Train_MinReturn : -45.96685028076172
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 616500
Agent0_TimeSinceStart : 947.3376848697662
Agent0_Critic_Loss : 0.3884899914264679
Agent0_Actor_Loss : -0.3891936242580414
Agent0_Alpha_Loss : 0.7911587953567505
Agent0_Temperature : 0.08916457549145464
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -19.632448196411133
Agent1_Eval_StdReturn : 16.680057525634766
Agent1_Eval_MaxReturn : -2.3615670204162598
Agent1_Eval_MinReturn : -66.13249969482422
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -14.008397102355957
Agent1_Train_StdReturn : 14.737716674804688
Agent1_Train_MaxReturn : 13.702550888061523
Agent1_Train_MinReturn : -35.670310974121094
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 616500
Agent1_TimeSinceStart : 949.4369359016418
Agent1_Critic_Loss : 0.39274489879608154
Agent1_Actor_Loss : -0.6214008331298828
Agent1_Alpha_Loss : 0.760277509689331
Agent1_Temperature : 0.08914685960371213
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 411 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 412 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 413 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 414 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 415 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 416 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 417 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 418 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 419 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 420 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -19.600772857666016
Agent0_Eval_StdReturn : 11.237957000732422
Agent0_Eval_MaxReturn : 0.44670701026916504
Agent0_Eval_MinReturn : -41.458648681640625
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -15.6837739944458
Agent0_Train_StdReturn : 15.869152069091797
Agent0_Train_MaxReturn : 18.90491485595703
Agent0_Train_MinReturn : -39.85868453979492
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 631500
Agent0_TimeSinceStart : 970.5347454547882
Agent0_Critic_Loss : 0.4036877751350403
Agent0_Actor_Loss : -0.49033477902412415
Agent0_Alpha_Loss : 0.7720290422439575
Agent0_Temperature : 0.0889152114329401
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -12.742067337036133
Agent1_Eval_StdReturn : 14.053691864013672
Agent1_Eval_MaxReturn : 20.04946517944336
Agent1_Eval_MinReturn : -27.94371223449707
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -19.853849411010742
Agent1_Train_StdReturn : 18.55593490600586
Agent1_Train_MaxReturn : 11.074519157409668
Agent1_Train_MinReturn : -55.2587890625
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 631500
Agent1_TimeSinceStart : 972.6264052391052
Agent1_Critic_Loss : 0.41961216926574707
Agent1_Actor_Loss : -0.525293231010437
Agent1_Alpha_Loss : 0.7829804420471191
Agent1_Temperature : 0.08890076673768592
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 421 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 422 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 423 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 424 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 425 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 426 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 427 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 428 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 429 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 430 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -18.859359741210938
Agent0_Eval_StdReturn : 16.78538703918457
Agent0_Eval_MaxReturn : -1.0152215957641602
Agent0_Eval_MinReturn : -52.45621871948242
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -14.761053085327148
Agent0_Train_StdReturn : 14.811735153198242
Agent0_Train_MaxReturn : 2.9678471088409424
Agent0_Train_MinReturn : -38.066322326660156
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 646500
Agent0_TimeSinceStart : 993.6739301681519
Agent0_Critic_Loss : 0.39037036895751953
Agent0_Actor_Loss : -0.6049894094467163
Agent0_Alpha_Loss : 0.779627799987793
Agent0_Temperature : 0.08866467462090748
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -14.896084785461426
Agent1_Eval_StdReturn : 16.43863296508789
Agent1_Eval_MaxReturn : 23.345733642578125
Agent1_Eval_MinReturn : -33.608543395996094
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -14.448293685913086
Agent1_Train_StdReturn : 13.875933647155762
Agent1_Train_MaxReturn : 8.857091903686523
Agent1_Train_MinReturn : -39.956787109375
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 646500
Agent1_TimeSinceStart : 995.7714884281158
Agent1_Critic_Loss : 0.45110681653022766
Agent1_Actor_Loss : -0.6109698414802551
Agent1_Alpha_Loss : 0.7768856287002563
Agent1_Temperature : 0.08865400535421578
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 431 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 432 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 433 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 434 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 435 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 436 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 437 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 438 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 439 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 440 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -13.227884292602539
Agent0_Eval_StdReturn : 15.364706993103027
Agent0_Eval_MaxReturn : 23.924396514892578
Agent0_Eval_MinReturn : -28.492385864257812
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -19.591472625732422
Agent0_Train_StdReturn : 20.840801239013672
Agent0_Train_MaxReturn : 14.157011985778809
Agent0_Train_MinReturn : -61.999847412109375
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 661500
Agent0_TimeSinceStart : 1016.8998594284058
Agent0_Critic_Loss : 0.46709296107292175
Agent0_Actor_Loss : -0.7017835974693298
Agent0_Alpha_Loss : 0.7942085862159729
Agent0_Temperature : 0.08841460475468842
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -13.075879096984863
Agent1_Eval_StdReturn : 20.52445411682129
Agent1_Eval_MaxReturn : 12.46137523651123
Agent1_Eval_MinReturn : -51.30586242675781
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -22.693880081176758
Agent1_Train_StdReturn : 22.451892852783203
Agent1_Train_MaxReturn : 10.459871292114258
Agent1_Train_MinReturn : -63.16377258300781
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 661500
Agent1_TimeSinceStart : 1018.9914066791534
Agent1_Critic_Loss : 0.38806796073913574
Agent1_Actor_Loss : -0.524726152420044
Agent1_Alpha_Loss : 0.7926880121231079
Agent1_Temperature : 0.08840570352979484
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 441 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 442 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 443 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 444 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 445 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 446 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 447 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 448 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 449 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 450 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -19.42804718017578
Agent0_Eval_StdReturn : 25.699687957763672
Agent0_Eval_MaxReturn : 22.035892486572266
Agent0_Eval_MinReturn : -56.99649429321289
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -15.820162773132324
Agent0_Train_StdReturn : 20.13653564453125
Agent0_Train_MaxReturn : 19.937034606933594
Agent0_Train_MinReturn : -45.627479553222656
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 676500
Agent0_TimeSinceStart : 1040.058744430542
Agent0_Critic_Loss : 0.40684232115745544
Agent0_Actor_Loss : -0.48494261503219604
Agent0_Alpha_Loss : 0.7726725339889526
Agent0_Temperature : 0.08816531436393063
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -13.033653259277344
Agent1_Eval_StdReturn : 10.772171974182129
Agent1_Eval_MaxReturn : 8.231582641601562
Agent1_Eval_MinReturn : -28.726879119873047
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -13.276847839355469
Agent1_Train_StdReturn : 11.299575805664062
Agent1_Train_MaxReturn : 10.525200843811035
Agent1_Train_MinReturn : -25.208179473876953
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 676500
Agent1_TimeSinceStart : 1042.1623361110687
Agent1_Critic_Loss : 0.3484123945236206
Agent1_Actor_Loss : -0.6895925998687744
Agent1_Alpha_Loss : 0.7883237600326538
Agent1_Temperature : 0.0881571810036805
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 451 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 452 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 453 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 454 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 455 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 456 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 457 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 458 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 459 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 460 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -20.875125885009766
Agent0_Eval_StdReturn : 23.436134338378906
Agent0_Eval_MaxReturn : 14.034128189086914
Agent0_Eval_MinReturn : -71.99649047851562
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -19.717660903930664
Agent0_Train_StdReturn : 15.26095199584961
Agent0_Train_MaxReturn : 9.128549575805664
Agent0_Train_MinReturn : -35.50041198730469
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 691500
Agent0_TimeSinceStart : 1063.194001674652
Agent0_Critic_Loss : 0.3935311436653137
Agent0_Actor_Loss : -0.551895260810852
Agent0_Alpha_Loss : 0.7881442308425903
Agent0_Temperature : 0.08791563422130853
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -14.918339729309082
Agent1_Eval_StdReturn : 19.501955032348633
Agent1_Eval_MaxReturn : 21.53673553466797
Agent1_Eval_MinReturn : -43.60742950439453
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -9.23992919921875
Agent1_Train_StdReturn : 10.54200267791748
Agent1_Train_MaxReturn : 9.749228477478027
Agent1_Train_MinReturn : -22.846637725830078
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 691500
Agent1_TimeSinceStart : 1065.2797660827637
Agent1_Critic_Loss : 0.5095545649528503
Agent1_Actor_Loss : -0.6350686550140381
Agent1_Alpha_Loss : 0.7856808304786682
Agent1_Temperature : 0.08790930751343
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 461 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 462 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 463 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 464 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 465 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 466 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 467 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 468 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 469 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 470 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -14.931729316711426
Agent0_Eval_StdReturn : 17.193357467651367
Agent0_Eval_MaxReturn : 2.019618511199951
Agent0_Eval_MinReturn : -58.25473403930664
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -21.851428985595703
Agent0_Train_StdReturn : 19.9017276763916
Agent0_Train_MaxReturn : 15.214674949645996
Agent0_Train_MinReturn : -50.060157775878906
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 706500
Agent0_TimeSinceStart : 1086.3061182498932
Agent0_Critic_Loss : 0.39611005783081055
Agent0_Actor_Loss : -0.5248307585716248
Agent0_Alpha_Loss : 0.7838223576545715
Agent0_Temperature : 0.08766508926548162
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -18.742097854614258
Agent1_Eval_StdReturn : 17.17107391357422
Agent1_Eval_MaxReturn : 9.221521377563477
Agent1_Eval_MinReturn : -40.96721267700195
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -25.33680534362793
Agent1_Train_StdReturn : 12.94883918762207
Agent1_Train_MaxReturn : -6.701727867126465
Agent1_Train_MinReturn : -44.2752571105957
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 706500
Agent1_TimeSinceStart : 1088.395937204361
Agent1_Critic_Loss : 0.3334636092185974
Agent1_Actor_Loss : -0.5242506861686707
Agent1_Alpha_Loss : 0.7774423360824585
Agent1_Temperature : 0.08766237886004485
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 471 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 472 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 473 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 474 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 475 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 476 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 477 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 478 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 479 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 480 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -23.78609275817871
Agent0_Eval_StdReturn : 18.49661636352539
Agent0_Eval_MaxReturn : 0.9484844207763672
Agent0_Eval_MinReturn : -51.99486541748047
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -12.40347671508789
Agent0_Train_StdReturn : 15.29958438873291
Agent0_Train_MaxReturn : 12.419658660888672
Agent0_Train_MinReturn : -39.66883850097656
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 721500
Agent0_TimeSinceStart : 1109.371206521988
Agent0_Critic_Loss : 0.3393387794494629
Agent0_Actor_Loss : -0.5197559595108032
Agent0_Alpha_Loss : 0.7707560062408447
Agent0_Temperature : 0.08741485047024433
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -10.29857063293457
Agent1_Eval_StdReturn : 12.376964569091797
Agent1_Eval_MaxReturn : 7.8498663902282715
Agent1_Eval_MinReturn : -31.393306732177734
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -15.596531867980957
Agent1_Train_StdReturn : 21.202184677124023
Agent1_Train_MaxReturn : 8.717048645019531
Agent1_Train_MinReturn : -56.5689697265625
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 721500
Agent1_TimeSinceStart : 1111.4628314971924
Agent1_Critic_Loss : 0.38059645891189575
Agent1_Actor_Loss : -0.6510242223739624
Agent1_Alpha_Loss : 0.7745919227600098
Agent1_Temperature : 0.08741458597638774
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 481 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 482 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 483 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 484 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 485 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 486 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 487 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 488 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 489 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 490 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -20.412885665893555
Agent0_Eval_StdReturn : 30.73226547241211
Agent0_Eval_MaxReturn : 14.237833023071289
Agent0_Eval_MinReturn : -80.90066528320312
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -16.785369873046875
Agent0_Train_StdReturn : 12.144124984741211
Agent0_Train_MaxReturn : 2.1561331748962402
Agent0_Train_MinReturn : -41.600547790527344
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 736500
Agent0_TimeSinceStart : 1132.4648931026459
Agent0_Critic_Loss : 0.4278745651245117
Agent0_Actor_Loss : -0.5988946557044983
Agent0_Alpha_Loss : 0.7916018962860107
Agent0_Temperature : 0.08716571562196235
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -18.930660247802734
Agent1_Eval_StdReturn : 19.136878967285156
Agent1_Eval_MaxReturn : 7.560704231262207
Agent1_Eval_MinReturn : -54.6314697265625
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -22.34537124633789
Agent1_Train_StdReturn : 23.068138122558594
Agent1_Train_MaxReturn : 9.989339828491211
Agent1_Train_MinReturn : -73.86368560791016
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 736500
Agent1_TimeSinceStart : 1134.5469825267792
Agent1_Critic_Loss : 0.39950913190841675
Agent1_Actor_Loss : -0.631294846534729
Agent1_Alpha_Loss : 0.783039927482605
Agent1_Temperature : 0.08716657103035659
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 491 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 492 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 493 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 494 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 495 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 496 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 497 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 498 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 499 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 500 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -14.513646125793457
Agent0_Eval_StdReturn : 25.21091651916504
Agent0_Eval_MaxReturn : 34.1112174987793
Agent0_Eval_MinReturn : -53.276100158691406
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -7.904667854309082
Agent0_Train_StdReturn : 18.204347610473633
Agent0_Train_MaxReturn : 16.774856567382812
Agent0_Train_MinReturn : -36.465476989746094
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 751500
Agent0_TimeSinceStart : 1155.5953311920166
Agent0_Critic_Loss : 0.4307962954044342
Agent0_Actor_Loss : -0.5263699293136597
Agent0_Alpha_Loss : 0.7721030712127686
Agent0_Temperature : 0.08691630177667954
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -3.890847682952881
Agent1_Eval_StdReturn : 6.658429145812988
Agent1_Eval_MaxReturn : 5.788137912750244
Agent1_Eval_MinReturn : -12.60276985168457
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -15.982345581054688
Agent1_Train_StdReturn : 17.49322509765625
Agent1_Train_MaxReturn : 24.030515670776367
Agent1_Train_MinReturn : -48.55230712890625
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 751500
Agent1_TimeSinceStart : 1157.6922521591187
Agent1_Critic_Loss : 0.4685179591178894
Agent1_Actor_Loss : -0.6289372444152832
Agent1_Alpha_Loss : 0.7864287495613098
Agent1_Temperature : 0.08691976618126014
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 501 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 502 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 503 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 504 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 505 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 506 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 507 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 508 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 509 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 510 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -14.334981918334961
Agent0_Eval_StdReturn : 19.021223068237305
Agent0_Eval_MaxReturn : 9.262336730957031
Agent0_Eval_MinReturn : -47.81731414794922
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -15.389147758483887
Agent0_Train_StdReturn : 10.438002586364746
Agent0_Train_MaxReturn : 8.755430221557617
Agent0_Train_MinReturn : -30.389728546142578
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 766500
Agent0_TimeSinceStart : 1178.7946095466614
Agent0_Critic_Loss : 0.4994024634361267
Agent0_Actor_Loss : -0.5041120052337646
Agent0_Alpha_Loss : 0.7885651588439941
Agent0_Temperature : 0.08666821987739493
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -25.249629974365234
Agent1_Eval_StdReturn : 20.489383697509766
Agent1_Eval_MaxReturn : 9.976041793823242
Agent1_Eval_MinReturn : -56.2510986328125
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -7.796441078186035
Agent1_Train_StdReturn : 14.888113021850586
Agent1_Train_MaxReturn : 12.95469856262207
Agent1_Train_MinReturn : -37.818321228027344
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 766500
Agent1_TimeSinceStart : 1180.8869845867157
Agent1_Critic_Loss : 0.39899444580078125
Agent1_Actor_Loss : -0.7259325981140137
Agent1_Alpha_Loss : 0.781425952911377
Agent1_Temperature : 0.08667333761133296
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 511 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 512 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 513 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 514 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 515 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 516 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 517 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 518 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 519 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 520 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -16.776954650878906
Agent0_Eval_StdReturn : 16.08435821533203
Agent0_Eval_MaxReturn : 7.742480754852295
Agent0_Eval_MinReturn : -46.644287109375
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -11.837955474853516
Agent0_Train_StdReturn : 13.489106178283691
Agent0_Train_MaxReturn : 6.1932759284973145
Agent0_Train_MinReturn : -31.199195861816406
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 781500
Agent0_TimeSinceStart : 1201.9457604885101
Agent0_Critic_Loss : 0.4918518364429474
Agent0_Actor_Loss : -0.5338878631591797
Agent0_Alpha_Loss : 0.7863858342170715
Agent0_Temperature : 0.08641993590167112
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -30.010473251342773
Agent1_Eval_StdReturn : 17.753280639648438
Agent1_Eval_MaxReturn : 0.5066537857055664
Agent1_Eval_MinReturn : -53.64421081542969
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -25.949153900146484
Agent1_Train_StdReturn : 14.034697532653809
Agent1_Train_MaxReturn : -6.471985816955566
Agent1_Train_MinReturn : -49.16902160644531
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 781500
Agent1_TimeSinceStart : 1204.036423921585
Agent1_Critic_Loss : 0.5016757249832153
Agent1_Actor_Loss : -0.5902674794197083
Agent1_Alpha_Loss : 0.7863718271255493
Agent1_Temperature : 0.08642691138597193
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 521 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 522 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 523 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 524 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 525 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 526 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 527 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 528 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 529 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 530 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -21.7619686126709
Agent0_Eval_StdReturn : 17.25685691833496
Agent0_Eval_MaxReturn : 9.160436630249023
Agent0_Eval_MinReturn : -53.1319580078125
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -13.526644706726074
Agent0_Train_StdReturn : 15.382420539855957
Agent0_Train_MaxReturn : 6.0567626953125
Agent0_Train_MinReturn : -47.56563949584961
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 796500
Agent0_TimeSinceStart : 1225.0471591949463
Agent0_Critic_Loss : 0.5159310102462769
Agent0_Actor_Loss : -0.48805731534957886
Agent0_Alpha_Loss : 0.7825620770454407
Agent0_Temperature : 0.08617250518479455
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -19.598310470581055
Agent1_Eval_StdReturn : 21.38932228088379
Agent1_Eval_MaxReturn : 14.471403121948242
Agent1_Eval_MinReturn : -45.67906188964844
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -18.42459487915039
Agent1_Train_StdReturn : 15.237044334411621
Agent1_Train_MaxReturn : -0.2380084991455078
Agent1_Train_MinReturn : -49.20746994018555
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 796500
Agent1_TimeSinceStart : 1227.1413550376892
Agent1_Critic_Loss : 0.5236517190933228
Agent1_Actor_Loss : -0.7281553745269775
Agent1_Alpha_Loss : 0.7897605895996094
Agent1_Temperature : 0.0861799999507498
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 531 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 532 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 533 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 534 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 535 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 536 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 537 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 538 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 539 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 540 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -10.694601058959961
Agent0_Eval_StdReturn : 10.684357643127441
Agent0_Eval_MaxReturn : 2.824723243713379
Agent0_Eval_MinReturn : -37.37053298950195
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -10.751474380493164
Agent0_Train_StdReturn : 12.367990493774414
Agent0_Train_MaxReturn : 14.343315124511719
Agent0_Train_MinReturn : -31.819372177124023
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 811500
Agent0_TimeSinceStart : 1248.1596252918243
Agent0_Critic_Loss : 0.47882118821144104
Agent0_Actor_Loss : -0.4997652769088745
Agent0_Alpha_Loss : 0.7820830941200256
Agent0_Temperature : 0.08592631998750107
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -19.179283142089844
Agent1_Eval_StdReturn : 9.743865966796875
Agent1_Eval_MaxReturn : -9.907432556152344
Agent1_Eval_MinReturn : -41.66950225830078
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -17.465648651123047
Agent1_Train_StdReturn : 23.249792098999023
Agent1_Train_MaxReturn : 20.29754638671875
Agent1_Train_MinReturn : -62.98292541503906
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 811500
Agent1_TimeSinceStart : 1250.250631570816
Agent1_Critic_Loss : 0.7062333226203918
Agent1_Actor_Loss : -0.7197225093841553
Agent1_Alpha_Loss : 0.7853997349739075
Agent1_Temperature : 0.08593295091363501
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 541 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 542 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 543 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 544 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 545 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 546 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 547 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 548 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 549 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 550 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -27.10080909729004
Agent0_Eval_StdReturn : 18.79487419128418
Agent0_Eval_MaxReturn : -4.4282941818237305
Agent0_Eval_MinReturn : -69.01715850830078
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -20.214031219482422
Agent0_Train_StdReturn : 11.153538703918457
Agent0_Train_MaxReturn : 3.1899752616882324
Agent0_Train_MinReturn : -36.0400505065918
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 826500
Agent0_TimeSinceStart : 1271.3166370391846
Agent0_Critic_Loss : 0.5076723098754883
Agent0_Actor_Loss : -0.5924091339111328
Agent0_Alpha_Loss : 0.7901421785354614
Agent0_Temperature : 0.0856800047431566
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -20.468753814697266
Agent1_Eval_StdReturn : 23.431377410888672
Agent1_Eval_MaxReturn : 11.443513870239258
Agent1_Eval_MinReturn : -59.19902038574219
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -15.684804916381836
Agent1_Train_StdReturn : 17.643177032470703
Agent1_Train_MaxReturn : 7.252008438110352
Agent1_Train_MinReturn : -42.00849151611328
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 826500
Agent1_TimeSinceStart : 1273.4025523662567
Agent1_Critic_Loss : 0.5406312346458435
Agent1_Actor_Loss : -0.6626356840133667
Agent1_Alpha_Loss : 0.7771177887916565
Agent1_Temperature : 0.08568790003665867
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 551 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 552 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 553 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 554 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 555 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 556 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 557 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 558 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 559 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 560 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -10.856356620788574
Agent0_Eval_StdReturn : 21.13762855529785
Agent0_Eval_MaxReturn : 30.50897216796875
Agent0_Eval_MinReturn : -39.9981689453125
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -7.493853569030762
Agent0_Train_StdReturn : 15.713570594787598
Agent0_Train_MaxReturn : 16.650094985961914
Agent0_Train_MinReturn : -44.23994064331055
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 841500
Agent0_TimeSinceStart : 1294.4571180343628
Agent0_Critic_Loss : 0.5150788426399231
Agent0_Actor_Loss : -0.5479227900505066
Agent0_Alpha_Loss : 0.7794061303138733
Agent0_Temperature : 0.08543500076141688
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -17.081655502319336
Agent1_Eval_StdReturn : 10.340754508972168
Agent1_Eval_MaxReturn : 6.368247032165527
Agent1_Eval_MinReturn : -32.11155319213867
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -13.199785232543945
Agent1_Train_StdReturn : 20.65049171447754
Agent1_Train_MaxReturn : 12.870691299438477
Agent1_Train_MinReturn : -48.464866638183594
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 841500
Agent1_TimeSinceStart : 1296.5526745319366
Agent1_Critic_Loss : 0.658190131187439
Agent1_Actor_Loss : -0.7022883296012878
Agent1_Alpha_Loss : 0.7833274006843567
Agent1_Temperature : 0.08544442366225824
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 561 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 562 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 563 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 564 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 565 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 566 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 567 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 568 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 569 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 570 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -7.917021751403809
Agent0_Eval_StdReturn : 15.537736892700195
Agent0_Eval_MaxReturn : 16.76669692993164
Agent0_Eval_MinReturn : -35.23849868774414
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -11.094697952270508
Agent0_Train_StdReturn : 14.59049129486084
Agent0_Train_MaxReturn : 13.929101943969727
Agent0_Train_MinReturn : -37.77021789550781
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 856500
Agent0_TimeSinceStart : 1317.6037502288818
Agent0_Critic_Loss : 0.4672778248786926
Agent0_Actor_Loss : -0.5096803307533264
Agent0_Alpha_Loss : 0.7793806791305542
Agent0_Temperature : 0.08519124642065495
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -20.33612060546875
Agent1_Eval_StdReturn : 7.0080976486206055
Agent1_Eval_MaxReturn : -8.762984275817871
Agent1_Eval_MinReturn : -33.9891357421875
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -15.303979873657227
Agent1_Train_StdReturn : 11.162581443786621
Agent1_Train_MaxReturn : 2.080373764038086
Agent1_Train_MinReturn : -32.36736297607422
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 856500
Agent1_TimeSinceStart : 1319.696896314621
Agent1_Critic_Loss : 0.5048006772994995
Agent1_Actor_Loss : -0.6152321100234985
Agent1_Alpha_Loss : 0.7570710182189941
Agent1_Temperature : 0.08520282047098336
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 571 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 572 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 573 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 574 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 575 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 576 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 577 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 578 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 579 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 580 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -17.965681076049805
Agent0_Eval_StdReturn : 15.070311546325684
Agent0_Eval_MaxReturn : 7.228653907775879
Agent0_Eval_MinReturn : -43.70570373535156
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -8.301798820495605
Agent0_Train_StdReturn : 9.400897026062012
Agent0_Train_MaxReturn : 11.03385066986084
Agent0_Train_MinReturn : -21.782691955566406
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 871500
Agent0_TimeSinceStart : 1340.7986800670624
Agent0_Critic_Loss : 0.5708181858062744
Agent0_Actor_Loss : -0.5846831798553467
Agent0_Alpha_Loss : 0.7725229263305664
Agent0_Temperature : 0.0849478730720243
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -10.95566177368164
Agent1_Eval_StdReturn : 11.932312965393066
Agent1_Eval_MaxReturn : 5.020627975463867
Agent1_Eval_MinReturn : -30.77415657043457
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -8.346047401428223
Agent1_Train_StdReturn : 20.454267501831055
Agent1_Train_MaxReturn : 41.64658737182617
Agent1_Train_MinReturn : -37.19621276855469
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 871500
Agent1_TimeSinceStart : 1342.8936748504639
Agent1_Critic_Loss : 0.6191519498825073
Agent1_Actor_Loss : -0.763810932636261
Agent1_Alpha_Loss : 0.750056803226471
Agent1_Temperature : 0.08496363496660701
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 581 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 582 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 583 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 584 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 585 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 586 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 587 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 588 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 589 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 590 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -15.859667778015137
Agent0_Eval_StdReturn : 16.234914779663086
Agent0_Eval_MaxReturn : 5.07524299621582
Agent0_Eval_MinReturn : -52.09171676635742
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -10.689359664916992
Agent0_Train_StdReturn : 13.056059837341309
Agent0_Train_MaxReturn : 7.183826446533203
Agent0_Train_MinReturn : -28.092544555664062
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 886500
Agent0_TimeSinceStart : 1364.010074853897
Agent0_Critic_Loss : 0.46581071615219116
Agent0_Actor_Loss : -0.5632685422897339
Agent0_Alpha_Loss : 0.7796280384063721
Agent0_Temperature : 0.08470651120533126
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -15.803781509399414
Agent1_Eval_StdReturn : 15.620857238769531
Agent1_Eval_MaxReturn : 5.487699031829834
Agent1_Eval_MinReturn : -47.04423141479492
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -15.331230163574219
Agent1_Train_StdReturn : 6.211780071258545
Agent1_Train_MaxReturn : -3.1791248321533203
Agent1_Train_MinReturn : -23.196775436401367
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 886500
Agent1_TimeSinceStart : 1366.1197736263275
Agent1_Critic_Loss : 0.6237125396728516
Agent1_Actor_Loss : -0.6838277578353882
Agent1_Alpha_Loss : 0.7664633393287659
Agent1_Temperature : 0.08472570528116947
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 591 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 592 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 593 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 594 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 595 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 596 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 597 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 598 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 599 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 600 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -16.733299255371094
Agent0_Eval_StdReturn : 10.616755485534668
Agent0_Eval_MaxReturn : -1.8078007698059082
Agent0_Eval_MinReturn : -35.62833786010742
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -12.63737678527832
Agent0_Train_StdReturn : 15.41231632232666
Agent0_Train_MaxReturn : 12.143095016479492
Agent0_Train_MinReturn : -44.051937103271484
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 901500
Agent0_TimeSinceStart : 1387.2023701667786
Agent0_Critic_Loss : 0.5000241994857788
Agent0_Actor_Loss : -0.6112868785858154
Agent0_Alpha_Loss : 0.7701322436332703
Agent0_Temperature : 0.08446584815473109
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -10.733138084411621
Agent1_Eval_StdReturn : 13.201155662536621
Agent1_Eval_MaxReturn : 15.610371589660645
Agent1_Eval_MinReturn : -25.60657501220703
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -19.307592391967773
Agent1_Train_StdReturn : 17.359161376953125
Agent1_Train_MaxReturn : 23.729568481445312
Agent1_Train_MinReturn : -37.722564697265625
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 901500
Agent1_TimeSinceStart : 1389.298279285431
Agent1_Critic_Loss : 0.6257579922676086
Agent1_Actor_Loss : -0.5934855937957764
Agent1_Alpha_Loss : 0.7593859434127808
Agent1_Temperature : 0.08448831464929608
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 601 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 602 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 603 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 604 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 605 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 606 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 607 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 608 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 609 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 610 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -12.94428539276123
Agent0_Eval_StdReturn : 17.783979415893555
Agent0_Eval_MaxReturn : 12.997884750366211
Agent0_Eval_MinReturn : -44.64665985107422
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -20.72538948059082
Agent0_Train_StdReturn : 13.627620697021484
Agent0_Train_MaxReturn : 1.5374469757080078
Agent0_Train_MinReturn : -46.435115814208984
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 916500
Agent0_TimeSinceStart : 1410.3664302825928
Agent0_Critic_Loss : 0.6575592756271362
Agent0_Actor_Loss : -0.5874159336090088
Agent0_Alpha_Loss : 0.7834722995758057
Agent0_Temperature : 0.08422507229789687
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -16.058866500854492
Agent1_Eval_StdReturn : 12.41718864440918
Agent1_Eval_MaxReturn : 1.3622586727142334
Agent1_Eval_MinReturn : -43.48389434814453
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -9.422894477844238
Agent1_Train_StdReturn : 12.825884819030762
Agent1_Train_MaxReturn : 11.865260124206543
Agent1_Train_MinReturn : -36.00737762451172
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 916500
Agent1_TimeSinceStart : 1412.4729857444763
Agent1_Critic_Loss : 0.6760923862457275
Agent1_Actor_Loss : -0.8177477121353149
Agent1_Alpha_Loss : 0.7742232084274292
Agent1_Temperature : 0.08425151829380208
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 611 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 612 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 613 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 614 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 615 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 616 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 617 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 618 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 619 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 620 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -11.466951370239258
Agent0_Eval_StdReturn : 9.966744422912598
Agent0_Eval_MaxReturn : -0.5121870040893555
Agent0_Eval_MinReturn : -27.477420806884766
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -6.868640899658203
Agent0_Train_StdReturn : 13.170366287231445
Agent0_Train_MaxReturn : 9.545185089111328
Agent0_Train_MinReturn : -40.07073974609375
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 931500
Agent0_TimeSinceStart : 1433.5674893856049
Agent0_Critic_Loss : 0.5925977230072021
Agent0_Actor_Loss : -0.5455197095870972
Agent0_Alpha_Loss : 0.7596611976623535
Agent0_Temperature : 0.0839848360383313
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -17.4682674407959
Agent1_Eval_StdReturn : 14.346803665161133
Agent1_Eval_MaxReturn : -2.2940478324890137
Agent1_Eval_MinReturn : -46.041927337646484
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -11.329055786132812
Agent1_Train_StdReturn : 14.721920013427734
Agent1_Train_MaxReturn : 19.40625
Agent1_Train_MinReturn : -30.179302215576172
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 931500
Agent1_TimeSinceStart : 1435.6667273044586
Agent1_Critic_Loss : 0.6487200856208801
Agent1_Actor_Loss : -0.8339424133300781
Agent1_Alpha_Loss : 0.7622144222259521
Agent1_Temperature : 0.08401336852963377
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 621 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 622 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 623 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 624 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 625 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 626 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 627 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 628 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 629 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 630 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -12.695671081542969
Agent0_Eval_StdReturn : 12.081082344055176
Agent0_Eval_MaxReturn : 8.37240982055664
Agent0_Eval_MinReturn : -30.372386932373047
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -21.690088272094727
Agent0_Train_StdReturn : 17.96774673461914
Agent0_Train_MaxReturn : 0.5587887763977051
Agent0_Train_MinReturn : -54.8952751159668
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 946500
Agent0_TimeSinceStart : 1456.810099363327
Agent0_Critic_Loss : 0.6336269974708557
Agent0_Actor_Loss : -0.7071835994720459
Agent0_Alpha_Loss : 0.7536292672157288
Agent0_Temperature : 0.0837456197936511
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -11.083611488342285
Agent1_Eval_StdReturn : 7.880646705627441
Agent1_Eval_MaxReturn : -1.5969960689544678
Agent1_Eval_MinReturn : -31.451139450073242
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -19.68031120300293
Agent1_Train_StdReturn : 12.355145454406738
Agent1_Train_MaxReturn : 6.7083353996276855
Agent1_Train_MinReturn : -42.10831832885742
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 946500
Agent1_TimeSinceStart : 1458.9074840545654
Agent1_Critic_Loss : 0.7437644600868225
Agent1_Actor_Loss : -0.6465713977813721
Agent1_Alpha_Loss : 0.7756650447845459
Agent1_Temperature : 0.08377469498504661
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 631 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 632 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 633 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 634 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 635 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 636 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 637 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 638 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 639 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 640 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -15.710803031921387
Agent0_Eval_StdReturn : 12.179352760314941
Agent0_Eval_MaxReturn : 10.616983413696289
Agent0_Eval_MinReturn : -33.75432586669922
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -16.879192352294922
Agent0_Train_StdReturn : 22.10559844970703
Agent0_Train_MaxReturn : 10.646232604980469
Agent0_Train_MinReturn : -66.3825454711914
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 961500
Agent0_TimeSinceStart : 1479.9793400764465
Agent0_Critic_Loss : 0.5394467711448669
Agent0_Actor_Loss : -0.7453135251998901
Agent0_Alpha_Loss : 0.7722079753875732
Agent0_Temperature : 0.0835073068019309
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -18.518808364868164
Agent1_Eval_StdReturn : 16.580453872680664
Agent1_Eval_MaxReturn : 2.5234851837158203
Agent1_Eval_MinReturn : -46.69172286987305
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -21.90793228149414
Agent1_Train_StdReturn : 13.55798625946045
Agent1_Train_MaxReturn : -6.078652858734131
Agent1_Train_MinReturn : -46.17750549316406
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 961500
Agent1_TimeSinceStart : 1482.075835943222
Agent1_Critic_Loss : 0.6659697890281677
Agent1_Actor_Loss : -0.7374945878982544
Agent1_Alpha_Loss : 0.776980996131897
Agent1_Temperature : 0.08353563318019491
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 641 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 642 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 643 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 644 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 645 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 646 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 647 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 648 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 649 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 650 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -14.951184272766113
Agent0_Eval_StdReturn : 14.88510799407959
Agent0_Eval_MaxReturn : 7.307082176208496
Agent0_Eval_MinReturn : -39.766475677490234
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -20.00259017944336
Agent0_Train_StdReturn : 16.94331932067871
Agent0_Train_MaxReturn : -1.3454256057739258
Agent0_Train_MinReturn : -55.796634674072266
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 976500
Agent0_TimeSinceStart : 1503.2134306430817
Agent0_Critic_Loss : 0.6533994078636169
Agent0_Actor_Loss : -0.6331635117530823
Agent0_Alpha_Loss : 0.7644267082214355
Agent0_Temperature : 0.08326975923516707
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -11.478757858276367
Agent1_Eval_StdReturn : 11.765989303588867
Agent1_Eval_MaxReturn : 6.780707359313965
Agent1_Eval_MinReturn : -29.692138671875
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -10.948481559753418
Agent1_Train_StdReturn : 16.470792770385742
Agent1_Train_MaxReturn : 16.35126495361328
Agent1_Train_MinReturn : -37.7554817199707
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 976500
Agent1_TimeSinceStart : 1505.3027999401093
Agent1_Critic_Loss : 0.7075092792510986
Agent1_Actor_Loss : -0.6390426158905029
Agent1_Alpha_Loss : 0.7804238796234131
Agent1_Temperature : 0.08329651519023698
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 651 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 652 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 653 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 654 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 655 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 656 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 657 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 658 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 659 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 660 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -4.21898889541626
Agent0_Eval_StdReturn : 9.205902099609375
Agent0_Eval_MaxReturn : 11.458770751953125
Agent0_Eval_MinReturn : -21.818214416503906
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -4.197646617889404
Agent0_Train_StdReturn : 21.260560989379883
Agent0_Train_MaxReturn : 39.54447937011719
Agent0_Train_MinReturn : -50.188880920410156
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 991500
Agent0_TimeSinceStart : 1526.6494715213776
Agent0_Critic_Loss : 0.6298233866691589
Agent0_Actor_Loss : -0.5649089813232422
Agent0_Alpha_Loss : 0.7699682712554932
Agent0_Temperature : 0.08303253264869874
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -20.10640525817871
Agent1_Eval_StdReturn : 22.337379455566406
Agent1_Eval_MaxReturn : 13.590217590332031
Agent1_Eval_MinReturn : -62.59346008300781
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -29.101818084716797
Agent1_Train_StdReturn : 28.44843864440918
Agent1_Train_MaxReturn : 16.252092361450195
Agent1_Train_MinReturn : -89.87881469726562
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 991500
Agent1_TimeSinceStart : 1528.7814581394196
Agent1_Critic_Loss : 0.6263264417648315
Agent1_Actor_Loss : -0.8233432173728943
Agent1_Alpha_Loss : 0.7748788595199585
Agent1_Temperature : 0.08305742423469886
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 661 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 662 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 663 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 664 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 665 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 666 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 667 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 668 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 669 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 670 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -6.939528465270996
Agent0_Eval_StdReturn : 9.068865776062012
Agent0_Eval_MaxReturn : 8.876797676086426
Agent0_Eval_MinReturn : -19.29499053955078
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -8.699640274047852
Agent0_Train_StdReturn : 17.250282287597656
Agent0_Train_MaxReturn : 30.227399826049805
Agent0_Train_MinReturn : -40.6070556640625
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1006500
Agent0_TimeSinceStart : 1550.2173192501068
Agent0_Critic_Loss : 0.6438653469085693
Agent0_Actor_Loss : -0.585671067237854
Agent0_Alpha_Loss : 0.7696785926818848
Agent0_Temperature : 0.08279622519725664
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -9.687605857849121
Agent1_Eval_StdReturn : 14.46047306060791
Agent1_Eval_MaxReturn : 14.627235412597656
Agent1_Eval_MinReturn : -30.42053985595703
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -2.4290335178375244
Agent1_Train_StdReturn : 15.12467098236084
Agent1_Train_MaxReturn : 19.931781768798828
Agent1_Train_MinReturn : -28.422651290893555
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1006500
Agent1_TimeSinceStart : 1552.3451073169708
Agent1_Critic_Loss : 0.5879642963409424
Agent1_Actor_Loss : -0.7406772375106812
Agent1_Alpha_Loss : 0.7848378419876099
Agent1_Temperature : 0.08281868464545745
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 671 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 672 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 673 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 674 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 675 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 676 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 677 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 678 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 679 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 680 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -13.125452995300293
Agent0_Eval_StdReturn : 21.152812957763672
Agent0_Eval_MaxReturn : 16.30868148803711
Agent0_Eval_MinReturn : -69.11656951904297
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -15.412384033203125
Agent0_Train_StdReturn : 12.49785041809082
Agent0_Train_MaxReturn : 0.16976022720336914
Agent0_Train_MinReturn : -42.57850646972656
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1021500
Agent0_TimeSinceStart : 1573.7388257980347
Agent0_Critic_Loss : 0.5335162878036499
Agent0_Actor_Loss : -0.6882231831550598
Agent0_Alpha_Loss : 0.7640416622161865
Agent0_Temperature : 0.08256061457359491
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -17.856021881103516
Agent1_Eval_StdReturn : 11.267338752746582
Agent1_Eval_MaxReturn : 0.33519434928894043
Agent1_Eval_MinReturn : -34.28894805908203
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -7.964243412017822
Agent1_Train_StdReturn : 9.269270896911621
Agent1_Train_MaxReturn : 10.134136199951172
Agent1_Train_MinReturn : -20.013748168945312
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1021500
Agent1_TimeSinceStart : 1575.8658595085144
Agent1_Critic_Loss : 0.7080850601196289
Agent1_Actor_Loss : -0.6334947347640991
Agent1_Alpha_Loss : 0.7819128036499023
Agent1_Temperature : 0.08258036638068589
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 681 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 682 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 683 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 684 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 685 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 686 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 687 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 688 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 689 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 690 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -10.314730644226074
Agent0_Eval_StdReturn : 19.50446128845215
Agent0_Eval_MaxReturn : 22.19564437866211
Agent0_Eval_MinReturn : -44.842681884765625
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -5.123166084289551
Agent0_Train_StdReturn : 17.81913948059082
Agent0_Train_MaxReturn : 16.757291793823242
Agent0_Train_MinReturn : -42.884681701660156
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1036500
Agent0_TimeSinceStart : 1597.2714955806732
Agent0_Critic_Loss : 0.557409405708313
Agent0_Actor_Loss : -0.7094197273254395
Agent0_Alpha_Loss : 0.7691879868507385
Agent0_Temperature : 0.0823250009063405
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -7.825743675231934
Agent1_Eval_StdReturn : 13.625067710876465
Agent1_Eval_MaxReturn : 17.58975601196289
Agent1_Eval_MinReturn : -34.74309158325195
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -19.083805084228516
Agent1_Train_StdReturn : 16.78592300415039
Agent1_Train_MaxReturn : 6.286169052124023
Agent1_Train_MinReturn : -47.89531326293945
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1036500
Agent1_TimeSinceStart : 1599.3917453289032
Agent1_Critic_Loss : 0.6250892281532288
Agent1_Actor_Loss : -0.6626651287078857
Agent1_Alpha_Loss : 0.7762489318847656
Agent1_Temperature : 0.0823438138265931
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 691 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 692 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 693 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 694 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 695 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 696 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 697 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 698 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 699 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 700 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -12.581324577331543
Agent0_Eval_StdReturn : 15.422002792358398
Agent0_Eval_MaxReturn : 14.93863582611084
Agent0_Eval_MinReturn : -36.196632385253906
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -13.920916557312012
Agent0_Train_StdReturn : 10.321903228759766
Agent0_Train_MaxReturn : 6.82619047164917
Agent0_Train_MinReturn : -26.218923568725586
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1051500
Agent0_TimeSinceStart : 1619.9292178153992
Agent0_Critic_Loss : 0.5918079614639282
Agent0_Actor_Loss : -0.6278588771820068
Agent0_Alpha_Loss : 0.77642822265625
Agent0_Temperature : 0.0820892330964672
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -17.564056396484375
Agent1_Eval_StdReturn : 16.777273178100586
Agent1_Eval_MaxReturn : 1.0375196933746338
Agent1_Eval_MinReturn : -58.475364685058594
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -15.982874870300293
Agent1_Train_StdReturn : 16.631526947021484
Agent1_Train_MaxReturn : 5.012343406677246
Agent1_Train_MinReturn : -50.700321197509766
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1051500
Agent1_TimeSinceStart : 1621.9847295284271
Agent1_Critic_Loss : 0.6420948505401611
Agent1_Actor_Loss : -0.7872040271759033
Agent1_Alpha_Loss : 0.7718448638916016
Agent1_Temperature : 0.08210864254596081
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 701 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 702 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 703 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 704 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 705 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 706 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 707 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 708 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 709 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 710 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -23.610477447509766
Agent0_Eval_StdReturn : 22.871400833129883
Agent0_Eval_MaxReturn : 12.559700012207031
Agent0_Eval_MinReturn : -70.50496673583984
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -6.400660514831543
Agent0_Train_StdReturn : 22.502912521362305
Agent0_Train_MaxReturn : 30.804946899414062
Agent0_Train_MinReturn : -41.520198822021484
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1066500
Agent0_TimeSinceStart : 1642.7837362289429
Agent0_Critic_Loss : 0.7137014865875244
Agent0_Actor_Loss : -0.639297604560852
Agent0_Alpha_Loss : 0.7619972229003906
Agent0_Temperature : 0.0818522988496331
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -12.579885482788086
Agent1_Eval_StdReturn : 16.892732620239258
Agent1_Eval_MaxReturn : 17.123077392578125
Agent1_Eval_MinReturn : -48.05352020263672
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -16.279943466186523
Agent1_Train_StdReturn : 16.080446243286133
Agent1_Train_MaxReturn : 13.693243980407715
Agent1_Train_MinReturn : -30.92578887939453
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1066500
Agent1_TimeSinceStart : 1644.8564620018005
Agent1_Critic_Loss : 0.7015179395675659
Agent1_Actor_Loss : -0.8198579549789429
Agent1_Alpha_Loss : 0.7583490610122681
Agent1_Temperature : 0.08187382731971067
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 711 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 712 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 713 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 714 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 715 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 716 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 717 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 718 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 719 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 720 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -35.374656677246094
Agent0_Eval_StdReturn : 23.266536712646484
Agent0_Eval_MaxReturn : -2.1989760398864746
Agent0_Eval_MinReturn : -75.24349975585938
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -18.301959991455078
Agent0_Train_StdReturn : 21.15044593811035
Agent0_Train_MaxReturn : 7.86512565612793
Agent0_Train_MinReturn : -51.8487548828125
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1081500
Agent0_TimeSinceStart : 1665.7166185379028
Agent0_Critic_Loss : 0.5985660552978516
Agent0_Actor_Loss : -0.7762481570243835
Agent0_Alpha_Loss : 0.7764366269111633
Agent0_Temperature : 0.0816150911741947
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -16.22689437866211
Agent1_Eval_StdReturn : 14.902009010314941
Agent1_Eval_MaxReturn : 0.699864387512207
Agent1_Eval_MinReturn : -46.976104736328125
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -11.074004173278809
Agent1_Train_StdReturn : 15.660433769226074
Agent1_Train_MaxReturn : 11.204364776611328
Agent1_Train_MinReturn : -36.55290222167969
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1081500
Agent1_TimeSinceStart : 1667.7968130111694
Agent1_Critic_Loss : 0.6438397169113159
Agent1_Actor_Loss : -0.9880567789077759
Agent1_Alpha_Loss : 0.7510092258453369
Agent1_Temperature : 0.08163966682405703
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 721 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 722 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 723 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 724 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 725 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 726 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 727 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 728 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 729 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 730 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -29.152393341064453
Agent0_Eval_StdReturn : 29.57630729675293
Agent0_Eval_MaxReturn : 12.16895866394043
Agent0_Eval_MinReturn : -78.8507308959961
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -12.450254440307617
Agent0_Train_StdReturn : 24.70742416381836
Agent0_Train_MaxReturn : 25.329639434814453
Agent0_Train_MinReturn : -45.44435119628906
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1096500
Agent0_TimeSinceStart : 1688.6682572364807
Agent0_Critic_Loss : 0.8106931447982788
Agent0_Actor_Loss : -0.7732675075531006
Agent0_Alpha_Loss : 0.7712045907974243
Agent0_Temperature : 0.081377602306695
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -14.292379379272461
Agent1_Eval_StdReturn : 12.40388298034668
Agent1_Eval_MaxReturn : 8.501640319824219
Agent1_Eval_MinReturn : -40.072792053222656
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -11.910776138305664
Agent1_Train_StdReturn : 17.22313690185547
Agent1_Train_MaxReturn : 8.945563316345215
Agent1_Train_MinReturn : -39.588958740234375
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1096500
Agent1_TimeSinceStart : 1690.7495801448822
Agent1_Critic_Loss : 0.7613534927368164
Agent1_Actor_Loss : -0.821627140045166
Agent1_Alpha_Loss : 0.7591258883476257
Agent1_Temperature : 0.08140655131957643
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 731 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 732 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 733 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 734 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 735 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 736 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 737 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 738 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 739 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 740 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -19.621984481811523
Agent0_Eval_StdReturn : 22.610414505004883
Agent0_Eval_MaxReturn : 7.658884048461914
Agent0_Eval_MinReturn : -60.43291473388672
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -17.111248016357422
Agent0_Train_StdReturn : 17.999711990356445
Agent0_Train_MaxReturn : 18.12259864807129
Agent0_Train_MinReturn : -48.72380828857422
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1111500
Agent0_TimeSinceStart : 1711.6416907310486
Agent0_Critic_Loss : 0.679745078086853
Agent0_Actor_Loss : -0.7016181945800781
Agent0_Alpha_Loss : 0.7789795994758606
Agent0_Temperature : 0.08114096202455216
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -18.6118221282959
Agent1_Eval_StdReturn : 14.144076347351074
Agent1_Eval_MaxReturn : 3.0453648567199707
Agent1_Eval_MinReturn : -38.046607971191406
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -6.806725978851318
Agent1_Train_StdReturn : 14.410191535949707
Agent1_Train_MaxReturn : 24.5355224609375
Agent1_Train_MinReturn : -27.11695098876953
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1111500
Agent1_TimeSinceStart : 1713.724096775055
Agent1_Critic_Loss : 0.6334279775619507
Agent1_Actor_Loss : -0.7731486558914185
Agent1_Alpha_Loss : 0.7673468589782715
Agent1_Temperature : 0.08117355388496197
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 741 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 742 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 743 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 744 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 745 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 746 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 747 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 748 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 749 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 750 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -31.195642471313477
Agent0_Eval_StdReturn : 28.91629981994629
Agent0_Eval_MaxReturn : 0.5760641098022461
Agent0_Eval_MinReturn : -88.50198364257812
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -17.97779083251953
Agent0_Train_StdReturn : 21.993608474731445
Agent0_Train_MaxReturn : 8.503923416137695
Agent0_Train_MinReturn : -77.40342712402344
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1126500
Agent0_TimeSinceStart : 1734.7063915729523
Agent0_Critic_Loss : 0.7528769373893738
Agent0_Actor_Loss : -0.7085973024368286
Agent0_Alpha_Loss : 0.7645021080970764
Agent0_Temperature : 0.08090578876337678
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -7.177611351013184
Agent1_Eval_StdReturn : 13.773558616638184
Agent1_Eval_MaxReturn : 22.332048416137695
Agent1_Eval_MinReturn : -28.00418472290039
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -5.504899024963379
Agent1_Train_StdReturn : 17.488739013671875
Agent1_Train_MaxReturn : 28.423873901367188
Agent1_Train_MinReturn : -30.508140563964844
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1126500
Agent1_TimeSinceStart : 1736.8053398132324
Agent1_Critic_Loss : 1.2266618013381958
Agent1_Actor_Loss : -0.7881240248680115
Agent1_Alpha_Loss : 0.7693197131156921
Agent1_Temperature : 0.08094121782592023
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 751 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 752 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 753 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 754 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 755 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 756 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 757 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 758 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 759 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 760 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -20.46597671508789
Agent0_Eval_StdReturn : 15.01645565032959
Agent0_Eval_MaxReturn : -1.2619876861572266
Agent0_Eval_MinReturn : -57.254913330078125
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -10.88150691986084
Agent0_Train_StdReturn : 16.992074966430664
Agent0_Train_MaxReturn : 18.176620483398438
Agent0_Train_MinReturn : -31.991024017333984
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1141500
Agent0_TimeSinceStart : 1757.8073725700378
Agent0_Critic_Loss : 0.7784530520439148
Agent0_Actor_Loss : -0.616187572479248
Agent0_Alpha_Loss : 0.7686223983764648
Agent0_Temperature : 0.08067332877751585
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -9.932123184204102
Agent1_Eval_StdReturn : 12.857192993164062
Agent1_Eval_MaxReturn : 4.000186920166016
Agent1_Eval_MinReturn : -35.008392333984375
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -25.755294799804688
Agent1_Train_StdReturn : 23.525123596191406
Agent1_Train_MaxReturn : 2.7319231033325195
Agent1_Train_MinReturn : -75.97659301757812
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1141500
Agent1_TimeSinceStart : 1759.8998880386353
Agent1_Critic_Loss : 0.9130638241767883
Agent1_Actor_Loss : -0.8334023952484131
Agent1_Alpha_Loss : 0.7594473361968994
Agent1_Temperature : 0.08070982853121195
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 761 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 762 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 763 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 764 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 765 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 766 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 767 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 768 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 769 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 770 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -13.426406860351562
Agent0_Eval_StdReturn : 11.146951675415039
Agent0_Eval_MaxReturn : -0.08875703811645508
Agent0_Eval_MinReturn : -34.47095489501953
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -18.883892059326172
Agent0_Train_StdReturn : 13.414751052856445
Agent0_Train_MaxReturn : 2.636075973510742
Agent0_Train_MinReturn : -43.00537109375
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1156500
Agent0_TimeSinceStart : 1780.9264986515045
Agent0_Critic_Loss : 0.9878892302513123
Agent0_Actor_Loss : -0.7482775449752808
Agent0_Alpha_Loss : 0.7527958154678345
Agent0_Temperature : 0.08044377891753295
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -7.957898139953613
Agent1_Eval_StdReturn : 19.940387725830078
Agent1_Eval_MaxReturn : 32.01667022705078
Agent1_Eval_MinReturn : -40.08042526245117
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -13.176191329956055
Agent1_Train_StdReturn : 14.435381889343262
Agent1_Train_MaxReturn : 5.393584251403809
Agent1_Train_MinReturn : -52.45796585083008
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1156500
Agent1_TimeSinceStart : 1783.0187165737152
Agent1_Critic_Loss : 0.9655924439430237
Agent1_Actor_Loss : -0.9341767430305481
Agent1_Alpha_Loss : 0.7589448094367981
Agent1_Temperature : 0.08047979544835851
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 771 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 772 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 773 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 774 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 775 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 776 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 777 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 778 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 779 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 780 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -3.795236587524414
Agent0_Eval_StdReturn : 9.890043258666992
Agent0_Eval_MaxReturn : 17.659320831298828
Agent0_Eval_MinReturn : -17.79446029663086
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -13.608589172363281
Agent0_Train_StdReturn : 6.479608535766602
Agent0_Train_MaxReturn : -0.28619933128356934
Agent0_Train_MinReturn : -23.07335662841797
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1171500
Agent0_TimeSinceStart : 1804.1206669807434
Agent0_Critic_Loss : 0.7849146127700806
Agent0_Actor_Loss : -0.5583111047744751
Agent0_Alpha_Loss : 0.7355921268463135
Agent0_Temperature : 0.08021744800537309
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -18.366792678833008
Agent1_Eval_StdReturn : 23.644514083862305
Agent1_Eval_MaxReturn : 14.989288330078125
Agent1_Eval_MinReturn : -53.41913604736328
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -9.110135078430176
Agent1_Train_StdReturn : 11.900182723999023
Agent1_Train_MaxReturn : 16.836044311523438
Agent1_Train_MinReturn : -25.639633178710938
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1171500
Agent1_TimeSinceStart : 1806.2250859737396
Agent1_Critic_Loss : 0.7650361061096191
Agent1_Actor_Loss : -0.8591817021369934
Agent1_Alpha_Loss : 0.7533645629882812
Agent1_Temperature : 0.08025133390574081
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 781 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 782 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 783 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 784 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 785 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 786 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 787 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 788 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 789 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 790 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -2.727992534637451
Agent0_Eval_StdReturn : 15.325855255126953
Agent0_Eval_MaxReturn : 21.567888259887695
Agent0_Eval_MinReturn : -34.44384002685547
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -10.78449821472168
Agent0_Train_StdReturn : 14.991409301757812
Agent0_Train_MaxReturn : 13.080888748168945
Agent0_Train_MinReturn : -40.936134338378906
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1186500
Agent0_TimeSinceStart : 1827.3394603729248
Agent0_Critic_Loss : 0.943146824836731
Agent0_Actor_Loss : -0.6340826749801636
Agent0_Alpha_Loss : 0.7424752712249756
Agent0_Temperature : 0.07999368199400711
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -9.010022163391113
Agent1_Eval_StdReturn : 17.471895217895508
Agent1_Eval_MaxReturn : 18.780353546142578
Agent1_Eval_MinReturn : -32.54744338989258
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -13.855552673339844
Agent1_Train_StdReturn : 19.98378562927246
Agent1_Train_MaxReturn : 22.72886848449707
Agent1_Train_MinReturn : -47.65247344970703
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1186500
Agent1_TimeSinceStart : 1829.4392700195312
Agent1_Critic_Loss : 0.8927640914916992
Agent1_Actor_Loss : -0.8683830499649048
Agent1_Alpha_Loss : 0.7436788082122803
Agent1_Temperature : 0.08002463062281048
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 791 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 792 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 793 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 794 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 795 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 796 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 797 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 798 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 799 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 800 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -12.008943557739258
Agent0_Eval_StdReturn : 13.940594673156738
Agent0_Eval_MaxReturn : 8.39854621887207
Agent0_Eval_MinReturn : -36.500457763671875
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -16.77198600769043
Agent0_Train_StdReturn : 15.071233749389648
Agent0_Train_MaxReturn : -0.3060340881347656
Agent0_Train_MinReturn : -44.50452423095703
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1201500
Agent0_TimeSinceStart : 1850.553987979889
Agent0_Critic_Loss : 0.6861767768859863
Agent0_Actor_Loss : -0.8502951860427856
Agent0_Alpha_Loss : 0.7408121824264526
Agent0_Temperature : 0.07976996682641249
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -9.003747940063477
Agent1_Eval_StdReturn : 19.19068145751953
Agent1_Eval_MaxReturn : 23.268104553222656
Agent1_Eval_MinReturn : -49.91004180908203
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -12.704530715942383
Agent1_Train_StdReturn : 14.743815422058105
Agent1_Train_MaxReturn : 4.154818534851074
Agent1_Train_MinReturn : -48.63246154785156
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1201500
Agent1_TimeSinceStart : 1852.6564009189606
Agent1_Critic_Loss : 0.962290346622467
Agent1_Actor_Loss : -0.9304301738739014
Agent1_Alpha_Loss : 0.741479754447937
Agent1_Temperature : 0.07980052554030985
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 801 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 802 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 803 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 804 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 805 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 806 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 807 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 808 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 809 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 810 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -16.838329315185547
Agent0_Eval_StdReturn : 14.921545028686523
Agent0_Eval_MaxReturn : 5.23796272277832
Agent0_Eval_MinReturn : -35.97307586669922
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -14.127062797546387
Agent0_Train_StdReturn : 18.08334732055664
Agent0_Train_MaxReturn : 18.460926055908203
Agent0_Train_MinReturn : -48.96293640136719
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1216500
Agent0_TimeSinceStart : 1873.80113363266
Agent0_Critic_Loss : 0.7774394750595093
Agent0_Actor_Loss : -0.8605591058731079
Agent0_Alpha_Loss : 0.7427137494087219
Agent0_Temperature : 0.07954754837028524
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -8.330997467041016
Agent1_Eval_StdReturn : 9.435765266418457
Agent1_Eval_MaxReturn : 12.959741592407227
Agent1_Eval_MinReturn : -23.741195678710938
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -3.64776349067688
Agent1_Train_StdReturn : 9.676138877868652
Agent1_Train_MaxReturn : 13.747069358825684
Agent1_Train_MinReturn : -18.714935302734375
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1216500
Agent1_TimeSinceStart : 1875.89826130867
Agent1_Critic_Loss : 0.8450015783309937
Agent1_Actor_Loss : -0.8366804718971252
Agent1_Alpha_Loss : 0.7369234561920166
Agent1_Temperature : 0.07957756634362902
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 811 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 812 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 813 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 814 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 815 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 816 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 817 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 818 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 819 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 820 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -26.49686622619629
Agent0_Eval_StdReturn : 20.812931060791016
Agent0_Eval_MaxReturn : 0.5930824279785156
Agent0_Eval_MinReturn : -64.4088134765625
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -7.611119747161865
Agent0_Train_StdReturn : 17.24712562561035
Agent0_Train_MaxReturn : 25.295473098754883
Agent0_Train_MinReturn : -47.31867599487305
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1231500
Agent0_TimeSinceStart : 1897.020403623581
Agent0_Critic_Loss : 0.8808774948120117
Agent0_Actor_Loss : -0.787966787815094
Agent0_Alpha_Loss : 0.7294992804527283
Agent0_Temperature : 0.07932676676254627
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -18.183032989501953
Agent1_Eval_StdReturn : 18.003950119018555
Agent1_Eval_MaxReturn : 6.750616550445557
Agent1_Eval_MinReturn : -56.559566497802734
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : 0.05693311616778374
Agent1_Train_StdReturn : 9.743096351623535
Agent1_Train_MaxReturn : 12.602914810180664
Agent1_Train_MinReturn : -18.789756774902344
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1231500
Agent1_TimeSinceStart : 1899.1040012836456
Agent1_Critic_Loss : 0.7218862175941467
Agent1_Actor_Loss : -1.0289109945297241
Agent1_Alpha_Loss : 0.7442799806594849
Agent1_Temperature : 0.0793552751448918
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 821 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 822 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 823 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 824 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 825 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 826 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 827 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 828 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 829 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 830 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -11.632295608520508
Agent0_Eval_StdReturn : 12.078277587890625
Agent0_Eval_MaxReturn : 12.59589672088623
Agent0_Eval_MinReturn : -25.93134880065918
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -14.622610092163086
Agent0_Train_StdReturn : 10.94298267364502
Agent0_Train_MaxReturn : 4.174557685852051
Agent0_Train_MinReturn : -33.39490509033203
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1246500
Agent0_TimeSinceStart : 1920.1742503643036
Agent0_Critic_Loss : 0.6740458011627197
Agent0_Actor_Loss : -0.7697207927703857
Agent0_Alpha_Loss : 0.7295504212379456
Agent0_Temperature : 0.07910714876843747
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -8.886743545532227
Agent1_Eval_StdReturn : 16.734312057495117
Agent1_Eval_MaxReturn : 16.070175170898438
Agent1_Eval_MinReturn : -41.2557373046875
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -14.969537734985352
Agent1_Train_StdReturn : 15.999038696289062
Agent1_Train_MaxReturn : 6.873287200927734
Agent1_Train_MinReturn : -43.53984069824219
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1246500
Agent1_TimeSinceStart : 1922.2658760547638
Agent1_Critic_Loss : 0.937712550163269
Agent1_Actor_Loss : -1.0814460515975952
Agent1_Alpha_Loss : 0.7531269192695618
Agent1_Temperature : 0.07913300672936256
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 831 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 832 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 833 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 834 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 835 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 836 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 837 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 838 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 839 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 840 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -9.161808013916016
Agent0_Eval_StdReturn : 9.867920875549316
Agent0_Eval_MaxReturn : 15.527299880981445
Agent0_Eval_MinReturn : -18.098615646362305
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -6.922369956970215
Agent0_Train_StdReturn : 17.237655639648438
Agent0_Train_MaxReturn : 20.854509353637695
Agent0_Train_MinReturn : -47.75648498535156
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1261500
Agent0_TimeSinceStart : 1943.3204827308655
Agent0_Critic_Loss : 0.7612685561180115
Agent0_Actor_Loss : -0.6755419969558716
Agent0_Alpha_Loss : 0.7309253215789795
Agent0_Temperature : 0.07888733401936693
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -9.42836856842041
Agent1_Eval_StdReturn : 11.689385414123535
Agent1_Eval_MaxReturn : 11.585412979125977
Agent1_Eval_MinReturn : -25.70182228088379
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -18.78097152709961
Agent1_Train_StdReturn : 15.762837409973145
Agent1_Train_MaxReturn : 1.4339799880981445
Agent1_Train_MinReturn : -39.010528564453125
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1261500
Agent1_TimeSinceStart : 1945.420135974884
Agent1_Critic_Loss : 0.6899999380111694
Agent1_Actor_Loss : -0.9723137617111206
Agent1_Alpha_Loss : 0.757503867149353
Agent1_Temperature : 0.0789098843529464
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 841 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 842 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 843 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 844 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 845 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 846 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 847 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 848 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 849 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 850 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -1.9235572814941406
Agent0_Eval_StdReturn : 9.63398551940918
Agent0_Eval_MaxReturn : 14.252154350280762
Agent0_Eval_MinReturn : -15.715551376342773
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -1.6402511596679688
Agent0_Train_StdReturn : 15.556614875793457
Agent0_Train_MaxReturn : 24.906478881835938
Agent0_Train_MinReturn : -31.161060333251953
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1276500
Agent0_TimeSinceStart : 1966.530383348465
Agent0_Critic_Loss : 0.8121520280838013
Agent0_Actor_Loss : -0.7493395209312439
Agent0_Alpha_Loss : 0.7304858565330505
Agent0_Temperature : 0.07866746085359266
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -10.431772232055664
Agent1_Eval_StdReturn : 15.051170349121094
Agent1_Eval_MaxReturn : 10.733263969421387
Agent1_Eval_MinReturn : -43.013389587402344
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -19.829116821289062
Agent1_Train_StdReturn : 25.746707916259766
Agent1_Train_MaxReturn : 9.740511894226074
Agent1_Train_MinReturn : -70.34642028808594
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1276500
Agent1_TimeSinceStart : 1968.6268775463104
Agent1_Critic_Loss : 1.0024523735046387
Agent1_Actor_Loss : -0.9855443239212036
Agent1_Alpha_Loss : 0.7408530712127686
Agent1_Temperature : 0.07868736280743246
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 851 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 852 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 853 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 854 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 855 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 856 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 857 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 858 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 859 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 860 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -4.959744453430176
Agent0_Eval_StdReturn : 13.277884483337402
Agent0_Eval_MaxReturn : 16.464609146118164
Agent0_Eval_MinReturn : -26.0407772064209
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -4.753462791442871
Agent0_Train_StdReturn : 17.423133850097656
Agent0_Train_MaxReturn : 22.450990676879883
Agent0_Train_MinReturn : -35.96463394165039
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1291500
Agent0_TimeSinceStart : 1989.727174282074
Agent0_Critic_Loss : 0.9873168468475342
Agent0_Actor_Loss : -0.8183072805404663
Agent0_Alpha_Loss : 0.7324491739273071
Agent0_Temperature : 0.07844790380828404
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -1.4734351634979248
Agent1_Eval_StdReturn : 14.993071556091309
Agent1_Eval_MaxReturn : 13.594819068908691
Agent1_Eval_MinReturn : -25.114669799804688
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -19.458932876586914
Agent1_Train_StdReturn : 17.58684539794922
Agent1_Train_MaxReturn : 10.478435516357422
Agent1_Train_MinReturn : -51.752906799316406
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1291500
Agent1_TimeSinceStart : 1991.8248641490936
Agent1_Critic_Loss : 0.6789230108261108
Agent1_Actor_Loss : -1.0317678451538086
Agent1_Alpha_Loss : 0.7471731305122375
Agent1_Temperature : 0.0784660537820051
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 861 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 862 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 863 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 864 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 865 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 866 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 867 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 868 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 869 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 870 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -14.081216812133789
Agent0_Eval_StdReturn : 7.301386833190918
Agent0_Eval_MaxReturn : -3.615449905395508
Agent0_Eval_MinReturn : -26.7843017578125
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -11.020401000976562
Agent0_Train_StdReturn : 16.977617263793945
Agent0_Train_MaxReturn : 8.31516170501709
Agent0_Train_MinReturn : -43.211647033691406
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1306500
Agent0_TimeSinceStart : 2012.9763190746307
Agent0_Critic_Loss : 0.9097304344177246
Agent0_Actor_Loss : -0.9445905089378357
Agent0_Alpha_Loss : 0.7314879894256592
Agent0_Temperature : 0.0782287051690446
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -24.589794158935547
Agent1_Eval_StdReturn : 15.303278923034668
Agent1_Eval_MaxReturn : -6.66609001159668
Agent1_Eval_MinReturn : -51.108619689941406
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -4.635954856872559
Agent1_Train_StdReturn : 6.849098205566406
Agent1_Train_MaxReturn : 2.3691296577453613
Agent1_Train_MinReturn : -21.102081298828125
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1306500
Agent1_TimeSinceStart : 2015.0720326900482
Agent1_Critic_Loss : 0.7831120491027832
Agent1_Actor_Loss : -0.9531000852584839
Agent1_Alpha_Loss : 0.7458714246749878
Agent1_Temperature : 0.0782453681576405
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 871 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 872 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 873 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 874 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 875 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 876 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 877 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 878 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 879 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 880 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -6.9841156005859375
Agent0_Eval_StdReturn : 9.872000694274902
Agent0_Eval_MaxReturn : 6.607314109802246
Agent0_Eval_MinReturn : -33.81673812866211
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -10.456318855285645
Agent0_Train_StdReturn : 8.832435607910156
Agent0_Train_MaxReturn : 1.8804212808609009
Agent0_Train_MinReturn : -23.183286666870117
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1321500
Agent0_TimeSinceStart : 2036.2242965698242
Agent0_Critic_Loss : 0.7803401350975037
Agent0_Actor_Loss : -0.8805267810821533
Agent0_Alpha_Loss : 0.7354398965835571
Agent0_Temperature : 0.07801008994524344
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -15.960453987121582
Agent1_Eval_StdReturn : 16.832469940185547
Agent1_Eval_MaxReturn : 8.871285438537598
Agent1_Eval_MinReturn : -40.77473068237305
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -10.1568021774292
Agent1_Train_StdReturn : 15.67337703704834
Agent1_Train_MaxReturn : 6.26672887802124
Agent1_Train_MinReturn : -50.768951416015625
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1321500
Agent1_TimeSinceStart : 2038.3191924095154
Agent1_Critic_Loss : 1.148870825767517
Agent1_Actor_Loss : -1.0026233196258545
Agent1_Alpha_Loss : 0.7391926646232605
Agent1_Temperature : 0.07802619781114986
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 881 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 882 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 883 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 884 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 885 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 886 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 887 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 888 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 889 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 890 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -7.762010097503662
Agent0_Eval_StdReturn : 7.660887241363525
Agent0_Eval_MaxReturn : 11.572547912597656
Agent0_Eval_MinReturn : -19.006078720092773
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -1.699806571006775
Agent0_Train_StdReturn : 13.729389190673828
Agent0_Train_MaxReturn : 19.624309539794922
Agent0_Train_MinReturn : -33.352294921875
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1336500
Agent0_TimeSinceStart : 2059.4994406700134
Agent0_Critic_Loss : 0.5945420861244202
Agent0_Actor_Loss : -0.7552732229232788
Agent0_Alpha_Loss : 0.7332068681716919
Agent0_Temperature : 0.07779197847540817
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -17.908512115478516
Agent1_Eval_StdReturn : 13.552848815917969
Agent1_Eval_MaxReturn : 0.563471794128418
Agent1_Eval_MinReturn : -43.10826873779297
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -28.277151107788086
Agent1_Train_StdReturn : 30.515222549438477
Agent1_Train_MaxReturn : 15.575252532958984
Agent1_Train_MinReturn : -81.1595458984375
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1336500
Agent1_TimeSinceStart : 2061.5908386707306
Agent1_Critic_Loss : 1.0312089920043945
Agent1_Actor_Loss : -0.7864325046539307
Agent1_Alpha_Loss : 0.7392966151237488
Agent1_Temperature : 0.07780758058342047
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 891 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 892 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 893 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 894 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 895 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 896 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 897 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 898 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 899 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 900 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -15.713276863098145
Agent0_Eval_StdReturn : 20.874847412109375
Agent0_Eval_MaxReturn : 14.335335731506348
Agent0_Eval_MinReturn : -59.23120880126953
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -10.012346267700195
Agent0_Train_StdReturn : 19.300579071044922
Agent0_Train_MaxReturn : 12.856512069702148
Agent0_Train_MinReturn : -50.36187744140625
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1351500
Agent0_TimeSinceStart : 2082.6474843025208
Agent0_Critic_Loss : 0.9723014831542969
Agent0_Actor_Loss : -0.8230780363082886
Agent0_Alpha_Loss : 0.7506700754165649
Agent0_Temperature : 0.07757366796884985
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -19.869760513305664
Agent1_Eval_StdReturn : 24.400630950927734
Agent1_Eval_MaxReturn : 13.072311401367188
Agent1_Eval_MinReturn : -70.82682800292969
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -20.239213943481445
Agent1_Train_StdReturn : 27.129215240478516
Agent1_Train_MaxReturn : 28.128034591674805
Agent1_Train_MinReturn : -74.76495361328125
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1351500
Agent1_TimeSinceStart : 2084.736866235733
Agent1_Critic_Loss : 0.8510634899139404
Agent1_Actor_Loss : -1.0983489751815796
Agent1_Alpha_Loss : 0.751544713973999
Agent1_Temperature : 0.07758978626202978
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 901 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 902 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 903 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 904 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 905 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 906 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 907 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 908 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 909 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 910 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -21.6943416595459
Agent0_Eval_StdReturn : 25.330364227294922
Agent0_Eval_MaxReturn : 11.80364990234375
Agent0_Eval_MinReturn : -66.07615661621094
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -14.863632202148438
Agent0_Train_StdReturn : 30.864055633544922
Agent0_Train_MaxReturn : 63.012962341308594
Agent0_Train_MinReturn : -51.99676513671875
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1366500
Agent0_TimeSinceStart : 2105.852530479431
Agent0_Critic_Loss : 0.9027328491210938
Agent0_Actor_Loss : -0.9740374088287354
Agent0_Alpha_Loss : 0.75672447681427
Agent0_Temperature : 0.07735472911395119
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -21.793201446533203
Agent1_Eval_StdReturn : 21.341461181640625
Agent1_Eval_MaxReturn : 6.234418869018555
Agent1_Eval_MinReturn : -57.806610107421875
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -22.058635711669922
Agent1_Train_StdReturn : 16.415491104125977
Agent1_Train_MaxReturn : 3.003878116607666
Agent1_Train_MinReturn : -52.69645309448242
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1366500
Agent1_TimeSinceStart : 2107.9423365592957
Agent1_Critic_Loss : 0.9578192234039307
Agent1_Actor_Loss : -1.0074357986450195
Agent1_Alpha_Loss : 0.7352396249771118
Agent1_Temperature : 0.07737166707891222
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 911 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 912 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 913 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 914 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 915 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 916 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 917 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 918 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 919 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 920 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -29.83944320678711
Agent0_Eval_StdReturn : 18.24435043334961
Agent0_Eval_MaxReturn : 2.5212016105651855
Agent0_Eval_MinReturn : -70.68692016601562
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -14.577234268188477
Agent0_Train_StdReturn : 20.75189781188965
Agent0_Train_MaxReturn : 23.314449310302734
Agent0_Train_MinReturn : -51.94148254394531
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1381500
Agent0_TimeSinceStart : 2128.9571464061737
Agent0_Critic_Loss : 0.9853072166442871
Agent0_Actor_Loss : -1.0118634700775146
Agent0_Alpha_Loss : 0.7444819211959839
Agent0_Temperature : 0.0771358050497222
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -29.724227905273438
Agent1_Eval_StdReturn : 19.41074562072754
Agent1_Eval_MaxReturn : 3.279153823852539
Agent1_Eval_MinReturn : -64.843505859375
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -20.850765228271484
Agent1_Train_StdReturn : 15.911526679992676
Agent1_Train_MaxReturn : 5.636395454406738
Agent1_Train_MinReturn : -46.41920852661133
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1381500
Agent1_TimeSinceStart : 2131.0501449108124
Agent1_Critic_Loss : 1.2232565879821777
Agent1_Actor_Loss : -1.011035680770874
Agent1_Alpha_Loss : 0.7395861148834229
Agent1_Temperature : 0.07715385871766753
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 921 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 922 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 923 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 924 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 925 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 926 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 927 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 928 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 929 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 930 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -36.75139236450195
Agent0_Eval_StdReturn : 22.945785522460938
Agent0_Eval_MaxReturn : 6.061384677886963
Agent0_Eval_MinReturn : -82.98402404785156
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -29.355182647705078
Agent0_Train_StdReturn : 19.73727798461914
Agent0_Train_MaxReturn : 7.9190497398376465
Agent0_Train_MinReturn : -61.254600524902344
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1396500
Agent0_TimeSinceStart : 2152.0347583293915
Agent0_Critic_Loss : 0.8539975881576538
Agent0_Actor_Loss : -0.8555874824523926
Agent0_Alpha_Loss : 0.7399411201477051
Agent0_Temperature : 0.0769177590675172
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -23.71405029296875
Agent1_Eval_StdReturn : 19.945758819580078
Agent1_Eval_MaxReturn : 5.877020835876465
Agent1_Eval_MinReturn : -64.7071533203125
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -26.833383560180664
Agent1_Train_StdReturn : 27.67584228515625
Agent1_Train_MaxReturn : 4.663156509399414
Agent1_Train_MinReturn : -90.16543579101562
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1396500
Agent1_TimeSinceStart : 2154.1245486736298
Agent1_Critic_Loss : 1.2396318912506104
Agent1_Actor_Loss : -1.1134761571884155
Agent1_Alpha_Loss : 0.7340062856674194
Agent1_Temperature : 0.0769375171107857
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 931 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 932 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 933 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 934 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 935 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 936 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 937 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 938 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 939 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 940 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -18.851848602294922
Agent0_Eval_StdReturn : 18.6751766204834
Agent0_Eval_MaxReturn : 1.076493263244629
Agent0_Eval_MinReturn : -69.6573486328125
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -26.656940460205078
Agent0_Train_StdReturn : 24.83890724182129
Agent0_Train_MaxReturn : 12.418512344360352
Agent0_Train_MinReturn : -78.63006591796875
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1411500
Agent0_TimeSinceStart : 2175.0551702976227
Agent0_Critic_Loss : 1.4165310859680176
Agent0_Actor_Loss : -0.982062041759491
Agent0_Alpha_Loss : 0.7399687767028809
Agent0_Temperature : 0.07670108497676029
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -11.653099060058594
Agent1_Eval_StdReturn : 21.548274993896484
Agent1_Eval_MaxReturn : 13.205820083618164
Agent1_Eval_MinReturn : -59.38897705078125
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -23.628610610961914
Agent1_Train_StdReturn : 17.82310676574707
Agent1_Train_MaxReturn : 3.91323184967041
Agent1_Train_MinReturn : -58.596866607666016
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1411500
Agent1_TimeSinceStart : 2177.147763490677
Agent1_Critic_Loss : 0.9898573160171509
Agent1_Actor_Loss : -1.0627719163894653
Agent1_Alpha_Loss : 0.7267397046089172
Agent1_Temperature : 0.07672204655387899
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 941 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 942 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 943 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 944 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 945 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 946 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 947 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 948 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 949 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 950 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -42.97074890136719
Agent0_Eval_StdReturn : 22.46388816833496
Agent0_Eval_MaxReturn : 0.028277873992919922
Agent0_Eval_MinReturn : -69.37860107421875
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -20.176794052124023
Agent0_Train_StdReturn : 28.645418167114258
Agent0_Train_MaxReturn : 25.177997589111328
Agent0_Train_MinReturn : -70.6672134399414
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1426500
Agent0_TimeSinceStart : 2198.297746181488
Agent0_Critic_Loss : 1.454372763633728
Agent0_Actor_Loss : -0.9436842799186707
Agent0_Alpha_Loss : 0.7313710451126099
Agent0_Temperature : 0.07648566251642895
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -21.598651885986328
Agent1_Eval_StdReturn : 14.683320045471191
Agent1_Eval_MaxReturn : -1.7919787168502808
Agent1_Eval_MinReturn : -41.61299514770508
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -19.473567962646484
Agent1_Train_StdReturn : 22.677871704101562
Agent1_Train_MaxReturn : 9.14894962310791
Agent1_Train_MinReturn : -67.19966888427734
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1426500
Agent1_TimeSinceStart : 2200.4052913188934
Agent1_Critic_Loss : 1.233298897743225
Agent1_Actor_Loss : -1.0698161125183105
Agent1_Alpha_Loss : 0.7304216623306274
Agent1_Temperature : 0.07650775848092653
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 951 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 952 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 953 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 954 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 955 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 956 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 957 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 958 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 959 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 960 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -6.7694501876831055
Agent0_Eval_StdReturn : 20.622257232666016
Agent0_Eval_MaxReturn : 21.298940658569336
Agent0_Eval_MinReturn : -53.46172332763672
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -12.038111686706543
Agent0_Train_StdReturn : 17.289073944091797
Agent0_Train_MaxReturn : 24.48956871032715
Agent0_Train_MinReturn : -37.60933303833008
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1441500
Agent0_TimeSinceStart : 2223.3697209358215
Agent0_Critic_Loss : 1.0496305227279663
Agent0_Actor_Loss : -0.8428078889846802
Agent0_Alpha_Loss : 0.7342259883880615
Agent0_Temperature : 0.07627147902428252
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -11.182028770446777
Agent1_Eval_StdReturn : 13.026851654052734
Agent1_Eval_MaxReturn : 7.154577255249023
Agent1_Eval_MinReturn : -34.21156692504883
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -8.601944923400879
Agent1_Train_StdReturn : 21.370643615722656
Agent1_Train_MaxReturn : 10.8250093460083
Agent1_Train_MinReturn : -68.2270736694336
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1441500
Agent1_TimeSinceStart : 2227.8686323165894
Agent1_Critic_Loss : 1.322322130203247
Agent1_Actor_Loss : -0.9294431209564209
Agent1_Alpha_Loss : 0.7180795669555664
Agent1_Temperature : 0.07629468948670093
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 961 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 962 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 963 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 964 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 965 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 966 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 967 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 968 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 969 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 970 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -12.77966022491455
Agent0_Eval_StdReturn : 18.75456428527832
Agent0_Eval_MaxReturn : 28.461206436157227
Agent0_Eval_MinReturn : -38.1671257019043
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -35.59154510498047
Agent0_Train_StdReturn : 28.93619728088379
Agent0_Train_MaxReturn : 10.492059707641602
Agent0_Train_MinReturn : -72.55291748046875
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1456500
Agent0_TimeSinceStart : 2255.23215007782
Agent0_Critic_Loss : 1.5017735958099365
Agent0_Actor_Loss : -1.0140202045440674
Agent0_Alpha_Loss : 0.7396183013916016
Agent0_Temperature : 0.0760576140145004
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : 1.3491226434707642
Agent1_Eval_StdReturn : 7.602552890777588
Agent1_Eval_MaxReturn : 11.024698257446289
Agent1_Eval_MinReturn : -15.883914947509766
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -17.691741943359375
Agent1_Train_StdReturn : 8.832107543945312
Agent1_Train_MaxReturn : -1.6772785186767578
Agent1_Train_MinReturn : -29.615264892578125
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1456500
Agent1_TimeSinceStart : 2257.4397666454315
Agent1_Critic_Loss : 1.454913854598999
Agent1_Actor_Loss : -1.0117971897125244
Agent1_Alpha_Loss : 0.7117824554443359
Agent1_Temperature : 0.076082814507535
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 971 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 972 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 973 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 974 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 975 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 976 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 977 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 978 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 979 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 980 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -14.850308418273926
Agent0_Eval_StdReturn : 22.639184951782227
Agent0_Eval_MaxReturn : 16.573945999145508
Agent0_Eval_MinReturn : -47.68504333496094
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -6.904338836669922
Agent0_Train_StdReturn : 15.613605499267578
Agent0_Train_MaxReturn : 22.342754364013672
Agent0_Train_MinReturn : -25.662487030029297
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1471500
Agent0_TimeSinceStart : 2279.51935505867
Agent0_Critic_Loss : 1.0893226861953735
Agent0_Actor_Loss : -0.9673972129821777
Agent0_Alpha_Loss : 0.7261925935745239
Agent0_Temperature : 0.07584439357644575
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -17.461626052856445
Agent1_Eval_StdReturn : 15.573498725891113
Agent1_Eval_MaxReturn : 10.259119033813477
Agent1_Eval_MinReturn : -47.37226867675781
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -10.176528930664062
Agent1_Train_StdReturn : 9.356266021728516
Agent1_Train_MaxReturn : 5.5391669273376465
Agent1_Train_MinReturn : -23.78585433959961
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1471500
Agent1_TimeSinceStart : 2281.704407930374
Agent1_Critic_Loss : 1.4235605001449585
Agent1_Actor_Loss : -0.9820315837860107
Agent1_Alpha_Loss : 0.7157513499259949
Agent1_Temperature : 0.07587316817305888
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 981 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 982 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 983 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 984 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 985 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 986 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 987 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 988 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 989 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 990 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -10.176345825195312
Agent0_Eval_StdReturn : 15.154152870178223
Agent0_Eval_MaxReturn : 10.959372520446777
Agent0_Eval_MinReturn : -36.69731521606445
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -22.76410675048828
Agent0_Train_StdReturn : 27.761825561523438
Agent0_Train_MaxReturn : 4.431607246398926
Agent0_Train_MinReturn : -87.8451156616211
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1486500
Agent0_TimeSinceStart : 2302.9045960903168
Agent0_Critic_Loss : 1.4769470691680908
Agent0_Actor_Loss : -1.1012787818908691
Agent0_Alpha_Loss : 0.7199384570121765
Agent0_Temperature : 0.07563241611155931
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -7.780575752258301
Agent1_Eval_StdReturn : 13.079330444335938
Agent1_Eval_MaxReturn : 25.394493103027344
Agent1_Eval_MinReturn : -22.819442749023438
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -9.256680488586426
Agent1_Train_StdReturn : 8.667986869812012
Agent1_Train_MaxReturn : 4.472594261169434
Agent1_Train_MinReturn : -23.936355590820312
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1486500
Agent1_TimeSinceStart : 2304.9594626426697
Agent1_Critic_Loss : 0.9163000583648682
Agent1_Actor_Loss : -1.0974459648132324
Agent1_Alpha_Loss : 0.7001011371612549
Agent1_Temperature : 0.07566575673897234
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 991 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 992 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 993 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 994 ************/home/harvey/anaconda3/envs/285final/lib/python3.7/site-packages/gym/core.py:318: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  "Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future."
/home/harvey/anaconda3/envs/285final/lib/python3.7/site-packages/gym/wrappers/step_api_compatibility.py:40: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  "Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future."
/home/harvey/anaconda3/envs/285final/lib/python3.7/site-packages/gym/core.py:257: DeprecationWarning: [33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.[0m
  "Function `env.seed(seed)` is marked as deprecated and will be removed in the future. "


Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 995 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 996 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 997 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 998 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 999 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...
./peersacv2_2ndrun.sh: 28: --seed: not found



LOGGING TO:  /home/harvey/Documents/cs285/CS285-Project/cs285/scripts/../../data/peersac_v2_2agents_eps1_HalfCheetah-v4_12-12-2022_15-44-37 



########################
logging outputs to  /home/harvey/Documents/cs285/CS285-Project/cs285/scripts/../../data/peersac_v2_2agents_eps1_HalfCheetah-v4_12-12-2022_15-44-37
########################
Using GPU id 0


********** Iteration 0 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -37.402889251708984
Agent0_Eval_StdReturn : 29.959867477416992
Agent0_Eval_MaxReturn : 2.8824901580810547
Agent0_Eval_MinReturn : -88.16786193847656
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -68.51490020751953
Agent0_Train_StdReturn : 35.8519172668457
Agent0_Train_MaxReturn : 10.17027473449707
Agent0_Train_MinReturn : -109.59283447265625
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1500
Agent0_TimeSinceStart : 2.2440717220306396
Agent0_Critic_Loss : 1.715803623199463
Agent0_Actor_Loss : -0.3432028293609619
Agent0_Alpha_Loss : 0.9863041639328003
Agent0_Temperature : 0.09997000449985415
Agent0_Initial_DataCollection_AverageReturn : -68.51490020751953
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -54.462310791015625
Agent1_Eval_StdReturn : 37.87112045288086
Agent1_Eval_MaxReturn : 15.620088577270508
Agent1_Eval_MinReturn : -98.72659301757812
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -41.37040710449219
Agent1_Train_StdReturn : 23.476428985595703
Agent1_Train_MaxReturn : -3.7883758544921875
Agent1_Train_MinReturn : -74.03202819824219
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1500
Agent1_TimeSinceStart : 4.361971139907837
Agent1_Critic_Loss : 1.1657971143722534
Agent1_Actor_Loss : -0.489025354385376
Agent1_Alpha_Loss : 0.980064868927002
Agent1_Temperature : 0.09997000449985606
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 1 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 2 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 3 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 4 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 5 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 6 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 7 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 8 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 9 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 10 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -23.91555404663086
Agent0_Eval_StdReturn : 36.396690368652344
Agent0_Eval_MaxReturn : 19.48440170288086
Agent0_Eval_MinReturn : -96.45121765136719
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -50.23561096191406
Agent0_Train_StdReturn : 25.51015853881836
Agent0_Train_MaxReturn : 2.222367286682129
Agent0_Train_MinReturn : -80.17941284179688
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 16500
Agent0_TimeSinceStart : 25.56270670890808
Agent0_Critic_Loss : 0.859268069267273
Agent0_Actor_Loss : -0.4422001540660858
Agent0_Alpha_Loss : 0.984131932258606
Agent0_Temperature : 0.0996705193621572
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -41.76715850830078
Agent1_Eval_StdReturn : 32.45429229736328
Agent1_Eval_MaxReturn : 17.20775604248047
Agent1_Eval_MinReturn : -96.88452911376953
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -50.48727798461914
Agent1_Train_StdReturn : 31.446962356567383
Agent1_Train_MaxReturn : -2.3715856075286865
Agent1_Train_MinReturn : -110.19876098632812
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 16500
Agent1_TimeSinceStart : 27.675464630126953
Agent1_Critic_Loss : 0.8242071270942688
Agent1_Actor_Loss : -0.5978373289108276
Agent1_Alpha_Loss : 0.9913411140441895
Agent1_Temperature : 0.09967041864865771
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 11 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 12 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 13 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 14 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 15 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 16 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 17 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 18 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 19 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 20 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -54.4146728515625
Agent0_Eval_StdReturn : 29.299518585205078
Agent0_Eval_MaxReturn : -3.030252456665039
Agent0_Eval_MinReturn : -112.00616455078125
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -42.122962951660156
Agent0_Train_StdReturn : 33.38285446166992
Agent0_Train_MaxReturn : 8.322027206420898
Agent0_Train_MinReturn : -115.837646484375
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 31500
Agent0_TimeSinceStart : 48.90228486061096
Agent0_Critic_Loss : 0.9875594973564148
Agent0_Actor_Loss : -0.4603153169155121
Agent0_Alpha_Loss : 0.9934805035591125
Agent0_Temperature : 0.09937189903597349
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -44.39208221435547
Agent1_Eval_StdReturn : 37.74639129638672
Agent1_Eval_MaxReturn : 16.940141677856445
Agent1_Eval_MinReturn : -112.73168182373047
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -29.703868865966797
Agent1_Train_StdReturn : 25.628751754760742
Agent1_Train_MaxReturn : 0.7001132965087891
Agent1_Train_MinReturn : -66.21515655517578
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 31500
Agent1_TimeSinceStart : 51.03096270561218
Agent1_Critic_Loss : 0.8050893545150757
Agent1_Actor_Loss : -0.49642840027809143
Agent1_Alpha_Loss : 0.9909679889678955
Agent1_Temperature : 0.09937173779425999
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 21 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 22 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 23 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 24 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 25 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 26 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 27 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 28 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 29 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 30 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -33.71171188354492
Agent0_Eval_StdReturn : 22.554655075073242
Agent0_Eval_MaxReturn : -2.0345535278320312
Agent0_Eval_MinReturn : -73.42320251464844
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -46.329307556152344
Agent0_Train_StdReturn : 18.40324592590332
Agent0_Train_MaxReturn : -5.066147327423096
Agent0_Train_MinReturn : -66.70167541503906
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 46500
Agent0_TimeSinceStart : 72.23276877403259
Agent0_Critic_Loss : 0.7971794605255127
Agent0_Actor_Loss : -0.3955150246620178
Agent0_Alpha_Loss : 0.989852786064148
Agent0_Temperature : 0.09907409799761885
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -36.81714630126953
Agent1_Eval_StdReturn : 23.335851669311523
Agent1_Eval_MaxReturn : -4.7169389724731445
Agent1_Eval_MinReturn : -85.56881713867188
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -53.330711364746094
Agent1_Train_StdReturn : 33.35007858276367
Agent1_Train_MaxReturn : 7.588226318359375
Agent1_Train_MinReturn : -85.77046203613281
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 46500
Agent1_TimeSinceStart : 74.34909200668335
Agent1_Critic_Loss : 0.8441203832626343
Agent1_Actor_Loss : -0.621477484703064
Agent1_Alpha_Loss : 0.9834251403808594
Agent1_Temperature : 0.09907406018154105
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 31 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 32 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 33 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 34 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 35 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 36 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 37 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 38 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 39 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 40 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -43.04814910888672
Agent0_Eval_StdReturn : 32.17839431762695
Agent0_Eval_MaxReturn : 0.7364044189453125
Agent0_Eval_MinReturn : -100.2462158203125
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -38.61564254760742
Agent0_Train_StdReturn : 38.854156494140625
Agent0_Train_MaxReturn : 20.940956115722656
Agent0_Train_MinReturn : -116.27200317382812
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 61500
Agent0_TimeSinceStart : 95.64056634902954
Agent0_Critic_Loss : 0.7907739877700806
Agent0_Actor_Loss : -0.5221840143203735
Agent0_Alpha_Loss : 0.9822091460227966
Agent0_Temperature : 0.09877769418986988
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -34.73299789428711
Agent1_Eval_StdReturn : 41.12437438964844
Agent1_Eval_MaxReturn : 26.9316463470459
Agent1_Eval_MinReturn : -92.31023406982422
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -37.83911895751953
Agent1_Train_StdReturn : 32.18024826049805
Agent1_Train_MaxReturn : 11.516632080078125
Agent1_Train_MinReturn : -101.08418273925781
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 61500
Agent1_TimeSinceStart : 97.75866723060608
Agent1_Critic_Loss : 0.6978700757026672
Agent1_Actor_Loss : -0.5253624320030212
Agent1_Alpha_Loss : 0.9788335561752319
Agent1_Temperature : 0.09877756782259886
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 41 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 42 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 43 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 44 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 45 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 46 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 47 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 48 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 49 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 50 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -46.934967041015625
Agent0_Eval_StdReturn : 31.348405838012695
Agent0_Eval_MaxReturn : -16.98957633972168
Agent0_Eval_MinReturn : -118.02684020996094
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -15.140853881835938
Agent0_Train_StdReturn : 24.39678955078125
Agent0_Train_MaxReturn : 40.97198486328125
Agent0_Train_MinReturn : -53.86602020263672
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 76500
Agent0_TimeSinceStart : 118.99281120300293
Agent0_Critic_Loss : 0.6611195802688599
Agent0_Actor_Loss : -0.5105288028717041
Agent0_Alpha_Loss : 0.9739531874656677
Agent0_Temperature : 0.09848289963040038
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -36.336097717285156
Agent1_Eval_StdReturn : 32.79088592529297
Agent1_Eval_MaxReturn : 24.158000946044922
Agent1_Eval_MinReturn : -70.31455993652344
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -29.5858154296875
Agent1_Train_StdReturn : 35.8078727722168
Agent1_Train_MaxReturn : 44.278663635253906
Agent1_Train_MinReturn : -76.22896575927734
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 76500
Agent1_TimeSinceStart : 121.1129081249237
Agent1_Critic_Loss : 0.6772318482398987
Agent1_Actor_Loss : -0.5262969732284546
Agent1_Alpha_Loss : 0.982785701751709
Agent1_Temperature : 0.09848275821373755
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 51 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 52 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 53 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 54 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 55 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 56 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 57 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 58 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 59 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 60 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -43.72178268432617
Agent0_Eval_StdReturn : 38.8220100402832
Agent0_Eval_MaxReturn : 35.61690902709961
Agent0_Eval_MinReturn : -104.31648254394531
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -52.030113220214844
Agent0_Train_StdReturn : 38.087100982666016
Agent0_Train_MaxReturn : 39.558963775634766
Agent0_Train_MinReturn : -98.00469207763672
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 91500
Agent0_TimeSinceStart : 142.35995626449585
Agent0_Critic_Loss : 0.6245212554931641
Agent0_Actor_Loss : -0.4247426986694336
Agent0_Alpha_Loss : 0.9661376476287842
Agent0_Temperature : 0.09818970216975532
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -30.328983306884766
Agent1_Eval_StdReturn : 15.20173454284668
Agent1_Eval_MaxReturn : -2.770376205444336
Agent1_Eval_MinReturn : -60.83476257324219
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -38.50912094116211
Agent1_Train_StdReturn : 39.56721878051758
Agent1_Train_MaxReturn : 16.756465911865234
Agent1_Train_MinReturn : -130.3779754638672
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 91500
Agent1_TimeSinceStart : 144.47949361801147
Agent1_Critic_Loss : 0.6105620265007019
Agent1_Actor_Loss : -0.5564115047454834
Agent1_Alpha_Loss : 0.9703361988067627
Agent1_Temperature : 0.09818930405035234
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 61 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 62 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 63 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 64 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 65 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 66 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 67 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 68 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 69 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 70 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -52.762855529785156
Agent0_Eval_StdReturn : 44.205299377441406
Agent0_Eval_MaxReturn : 15.64101791381836
Agent0_Eval_MinReturn : -142.34568786621094
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -49.44839859008789
Agent0_Train_StdReturn : 22.104602813720703
Agent0_Train_MaxReturn : -10.296367645263672
Agent0_Train_MinReturn : -82.19908142089844
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 106500
Agent0_TimeSinceStart : 165.72861862182617
Agent0_Critic_Loss : 0.6689488887786865
Agent0_Actor_Loss : -0.30811411142349243
Agent0_Alpha_Loss : 0.9603499174118042
Agent0_Temperature : 0.09789804591066706
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -11.847929954528809
Agent1_Eval_StdReturn : 23.670469284057617
Agent1_Eval_MaxReturn : 20.192594528198242
Agent1_Eval_MinReturn : -53.48154830932617
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -38.02881622314453
Agent1_Train_StdReturn : 31.219186782836914
Agent1_Train_MaxReturn : 3.945117950439453
Agent1_Train_MinReturn : -104.6073989868164
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 106500
Agent1_TimeSinceStart : 167.8392632007599
Agent1_Critic_Loss : 0.6293494701385498
Agent1_Actor_Loss : -0.5705143213272095
Agent1_Alpha_Loss : 0.9569061994552612
Agent1_Temperature : 0.09789783515036317
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 71 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 72 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 73 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 74 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 75 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 76 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 77 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 78 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 79 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 80 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -56.94144821166992
Agent0_Eval_StdReturn : 36.218387603759766
Agent0_Eval_MaxReturn : 5.019533157348633
Agent0_Eval_MinReturn : -114.47781372070312
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -39.97748565673828
Agent0_Train_StdReturn : 35.48146438598633
Agent0_Train_MaxReturn : 11.034629821777344
Agent0_Train_MinReturn : -89.38318634033203
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 121500
Agent0_TimeSinceStart : 189.02729511260986
Agent0_Critic_Loss : 0.5700304508209229
Agent0_Actor_Loss : -0.47591161727905273
Agent0_Alpha_Loss : 0.9490940570831299
Agent0_Temperature : 0.09760947079952008
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -33.63285446166992
Agent1_Eval_StdReturn : 20.059892654418945
Agent1_Eval_MaxReturn : 8.663753509521484
Agent1_Eval_MinReturn : -60.487937927246094
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -22.63499641418457
Agent1_Train_StdReturn : 26.519304275512695
Agent1_Train_MaxReturn : 10.277416229248047
Agent1_Train_MinReturn : -87.01278686523438
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 121500
Agent1_TimeSinceStart : 191.13105297088623
Agent1_Critic_Loss : 0.5817664861679077
Agent1_Actor_Loss : -0.49270516633987427
Agent1_Alpha_Loss : 0.9461566209793091
Agent1_Temperature : 0.09760911461694488
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 81 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 82 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 83 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 84 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 85 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 86 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 87 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 88 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 89 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 90 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -18.83267593383789
Agent0_Eval_StdReturn : 15.16438102722168
Agent0_Eval_MaxReturn : 5.713106632232666
Agent0_Eval_MinReturn : -44.82973098754883
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -24.416912078857422
Agent0_Train_StdReturn : 17.775209426879883
Agent0_Train_MaxReturn : 0.8707981109619141
Agent0_Train_MinReturn : -58.05852127075195
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 136500
Agent0_TimeSinceStart : 212.28702545166016
Agent0_Critic_Loss : 0.5475753545761108
Agent0_Actor_Loss : -0.6363674402236938
Agent0_Alpha_Loss : 0.9323199987411499
Agent0_Temperature : 0.09732457112416312
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -26.827835083007812
Agent1_Eval_StdReturn : 24.32474708557129
Agent1_Eval_MaxReturn : 37.67233657836914
Agent1_Eval_MinReturn : -58.71758270263672
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -29.234508514404297
Agent1_Train_StdReturn : 24.624916076660156
Agent1_Train_MaxReturn : -1.5855069160461426
Agent1_Train_MinReturn : -82.74052429199219
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 136500
Agent1_TimeSinceStart : 214.40085339546204
Agent1_Critic_Loss : 0.5042410492897034
Agent1_Actor_Loss : -0.5955747961997986
Agent1_Alpha_Loss : 0.9367141127586365
Agent1_Temperature : 0.09732402408973201
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 91 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 92 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 93 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 94 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 95 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 96 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 97 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 98 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 99 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 100 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -29.444652557373047
Agent0_Eval_StdReturn : 22.099498748779297
Agent0_Eval_MaxReturn : 7.326150894165039
Agent0_Eval_MinReturn : -58.50382995605469
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -14.757555961608887
Agent0_Train_StdReturn : 11.024503707885742
Agent0_Train_MaxReturn : -0.12058496475219727
Agent0_Train_MinReturn : -41.136993408203125
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 151500
Agent0_TimeSinceStart : 235.63234090805054
Agent0_Critic_Loss : 0.4772423505783081
Agent0_Actor_Loss : -0.5221172571182251
Agent0_Alpha_Loss : 0.8880226612091064
Agent0_Temperature : 0.09704510045243908
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -19.904706954956055
Agent1_Eval_StdReturn : 26.724220275878906
Agent1_Eval_MaxReturn : 10.418119430541992
Agent1_Eval_MinReturn : -87.53263854980469
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -23.447458267211914
Agent1_Train_StdReturn : 19.089914321899414
Agent1_Train_MaxReturn : 1.8365697860717773
Agent1_Train_MinReturn : -56.6861572265625
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 151500
Agent1_TimeSinceStart : 237.7504279613495
Agent1_Critic_Loss : 0.4125604033470154
Agent1_Actor_Loss : -0.707768440246582
Agent1_Alpha_Loss : 0.8971108198165894
Agent1_Temperature : 0.0970436132970357
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 101 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 102 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 103 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 104 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 105 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 106 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 107 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 108 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 109 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 110 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -30.767642974853516
Agent0_Eval_StdReturn : 17.50433921813965
Agent0_Eval_MaxReturn : -0.7569875717163086
Agent0_Eval_MinReturn : -62.048851013183594
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -23.379776000976562
Agent0_Train_StdReturn : 8.86280632019043
Agent0_Train_MaxReturn : -13.470674514770508
Agent0_Train_MinReturn : -38.76492691040039
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 166500
Agent0_TimeSinceStart : 258.9708514213562
Agent0_Critic_Loss : 0.5106647610664368
Agent0_Actor_Loss : -0.45430633425712585
Agent0_Alpha_Loss : 0.8220301866531372
Agent0_Temperature : 0.09677501457882966
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -31.079681396484375
Agent1_Eval_StdReturn : 7.5414934158325195
Agent1_Eval_MaxReturn : -18.115276336669922
Agent1_Eval_MinReturn : -42.8000373840332
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -16.983463287353516
Agent1_Train_StdReturn : 15.189926147460938
Agent1_Train_MaxReturn : -1.2720222473144531
Agent1_Train_MinReturn : -53.7143440246582
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 166500
Agent1_TimeSinceStart : 261.0896315574646
Agent1_Critic_Loss : 0.4368811845779419
Agent1_Actor_Loss : -0.7464069128036499
Agent1_Alpha_Loss : 0.8406094312667847
Agent1_Temperature : 0.09677101011721238
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 111 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 112 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 113 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 114 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 115 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 116 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 117 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 118 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 119 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 120 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -20.88374137878418
Agent0_Eval_StdReturn : 14.174619674682617
Agent0_Eval_MaxReturn : 4.246062755584717
Agent0_Eval_MinReturn : -40.55828094482422
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -20.741641998291016
Agent0_Train_StdReturn : 10.192222595214844
Agent0_Train_MaxReturn : 1.752439022064209
Agent0_Train_MinReturn : -36.037391662597656
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 181500
Agent0_TimeSinceStart : 282.42147946357727
Agent0_Critic_Loss : 0.5201339721679688
Agent0_Actor_Loss : -0.422872394323349
Agent0_Alpha_Loss : 0.7886238098144531
Agent0_Temperature : 0.09651591844458478
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -31.238265991210938
Agent1_Eval_StdReturn : 16.09378433227539
Agent1_Eval_MaxReturn : -7.596423625946045
Agent1_Eval_MinReturn : -56.38445281982422
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -23.652019500732422
Agent1_Train_StdReturn : 14.572884559631348
Agent1_Train_MaxReturn : 7.34368371963501
Agent1_Train_MinReturn : -53.63733673095703
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 181500
Agent1_TimeSinceStart : 284.5424554347992
Agent1_Critic_Loss : 0.44199109077453613
Agent1_Actor_Loss : -0.6862270832061768
Agent1_Alpha_Loss : 0.791344165802002
Agent1_Temperature : 0.09650866215102405
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 121 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 122 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 123 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 124 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 125 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 126 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 127 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 128 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 129 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 130 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -27.926334381103516
Agent0_Eval_StdReturn : 9.467351913452148
Agent0_Eval_MaxReturn : -8.975711822509766
Agent0_Eval_MinReturn : -39.29246520996094
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -27.27530288696289
Agent0_Train_StdReturn : 10.95773983001709
Agent0_Train_MaxReturn : -10.473200798034668
Agent0_Train_MinReturn : -47.45228576660156
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 196500
Agent0_TimeSinceStart : 305.96012234687805
Agent0_Critic_Loss : 0.45977354049682617
Agent0_Actor_Loss : -0.4179542362689972
Agent0_Alpha_Loss : 0.7858771085739136
Agent0_Temperature : 0.0962665421815333
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -33.37521743774414
Agent1_Eval_StdReturn : 11.096887588500977
Agent1_Eval_MaxReturn : -13.519022941589355
Agent1_Eval_MinReturn : -52.051910400390625
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -25.00204849243164
Agent1_Train_StdReturn : 6.33139181137085
Agent1_Train_MaxReturn : -15.062255859375
Agent1_Train_MinReturn : -35.988521575927734
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 196500
Agent1_TimeSinceStart : 308.0875144004822
Agent1_Critic_Loss : 0.46405088901519775
Agent1_Actor_Loss : -0.6285388469696045
Agent1_Alpha_Loss : 0.7820494174957275
Agent1_Temperature : 0.09625616381430681
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 131 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 132 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 133 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 134 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 135 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 136 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 137 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 138 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 139 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 140 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -23.519750595092773
Agent0_Eval_StdReturn : 15.197402000427246
Agent0_Eval_MaxReturn : 4.695085525512695
Agent0_Eval_MinReturn : -45.464698791503906
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -32.95502471923828
Agent0_Train_StdReturn : 9.782207489013672
Agent0_Train_MaxReturn : -15.930069923400879
Agent0_Train_MinReturn : -46.802696228027344
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 211500
Agent0_TimeSinceStart : 329.5284490585327
Agent0_Critic_Loss : 0.4417003393173218
Agent0_Actor_Loss : -0.41691136360168457
Agent0_Alpha_Loss : 0.780207633972168
Agent0_Temperature : 0.09602078137677841
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -21.26649284362793
Agent1_Eval_StdReturn : 15.819012641906738
Agent1_Eval_MaxReturn : -0.38559412956237793
Agent1_Eval_MinReturn : -54.704959869384766
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -28.739843368530273
Agent1_Train_StdReturn : 15.642762184143066
Agent1_Train_MaxReturn : -12.895857810974121
Agent1_Train_MinReturn : -65.59808349609375
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 211500
Agent1_TimeSinceStart : 331.6599714756012
Agent1_Critic_Loss : 0.3858966827392578
Agent1_Actor_Loss : -0.5920645594596863
Agent1_Alpha_Loss : 0.8160032629966736
Agent1_Temperature : 0.09600694172873044
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 141 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 142 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 143 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 144 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 145 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 146 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 147 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 148 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 149 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 150 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -28.1939697265625
Agent0_Eval_StdReturn : 13.960450172424316
Agent0_Eval_MaxReturn : -10.298070907592773
Agent0_Eval_MinReturn : -53.43170928955078
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -28.597814559936523
Agent0_Train_StdReturn : 9.148052215576172
Agent0_Train_MaxReturn : -13.346701622009277
Agent0_Train_MinReturn : -46.98386764526367
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 226500
Agent0_TimeSinceStart : 353.0515263080597
Agent0_Critic_Loss : 0.3562975823879242
Agent0_Actor_Loss : -0.5277118682861328
Agent0_Alpha_Loss : 0.7915433049201965
Agent0_Temperature : 0.0957752553508145
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -24.112308502197266
Agent1_Eval_StdReturn : 15.152573585510254
Agent1_Eval_MaxReturn : 6.5834245681762695
Agent1_Eval_MinReturn : -43.852516174316406
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -20.190866470336914
Agent1_Train_StdReturn : 9.12331771850586
Agent1_Train_MaxReturn : 0.14342880249023438
Agent1_Train_MinReturn : -30.758987426757812
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 226500
Agent1_TimeSinceStart : 355.18541717529297
Agent1_Critic_Loss : 0.3734341263771057
Agent1_Actor_Loss : -0.5671097040176392
Agent1_Alpha_Loss : 0.8059293031692505
Agent1_Temperature : 0.09575606524920333
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 151 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 152 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 153 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 154 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 155 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 156 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 157 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 158 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 159 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 160 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -25.204833984375
Agent0_Eval_StdReturn : 11.708731651306152
Agent0_Eval_MaxReturn : -4.343748569488525
Agent0_Eval_MinReturn : -47.12419128417969
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -19.054582595825195
Agent0_Train_StdReturn : 15.484556198120117
Agent0_Train_MaxReturn : 18.519432067871094
Agent0_Train_MinReturn : -38.156734466552734
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 241500
Agent0_TimeSinceStart : 376.5010209083557
Agent0_Critic_Loss : 0.4418940544128418
Agent0_Actor_Loss : -0.49285465478897095
Agent0_Alpha_Loss : 0.800083577632904
Agent0_Temperature : 0.09552755966466112
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -27.416723251342773
Agent1_Eval_StdReturn : 11.337067604064941
Agent1_Eval_MaxReturn : -10.333407402038574
Agent1_Eval_MinReturn : -47.17497253417969
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -23.22572898864746
Agent1_Train_StdReturn : 11.740751266479492
Agent1_Train_MaxReturn : -4.436774730682373
Agent1_Train_MinReturn : -46.06743621826172
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 241500
Agent1_TimeSinceStart : 378.63006496429443
Agent1_Critic_Loss : 0.5150948762893677
Agent1_Actor_Loss : -0.6063558459281921
Agent1_Alpha_Loss : 0.8357057571411133
Agent1_Temperature : 0.09550216267422923
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 161 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 162 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 163 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 164 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 165 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 166 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 167 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 168 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 169 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 170 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -22.155757904052734
Agent0_Eval_StdReturn : 16.179601669311523
Agent0_Eval_MaxReturn : 12.295085906982422
Agent0_Eval_MinReturn : -43.36664581298828
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -23.729684829711914
Agent0_Train_StdReturn : 11.769902229309082
Agent0_Train_MaxReturn : -9.187591552734375
Agent0_Train_MinReturn : -53.92979431152344
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 256500
Agent0_TimeSinceStart : 399.992639541626
Agent0_Critic_Loss : 0.32645654678344727
Agent0_Actor_Loss : -0.34486010670661926
Agent0_Alpha_Loss : 0.7950134873390198
Agent0_Temperature : 0.09527660947134277
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -18.02213478088379
Agent1_Eval_StdReturn : 11.25052261352539
Agent1_Eval_MaxReturn : -3.393223285675049
Agent1_Eval_MinReturn : -41.452423095703125
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -21.535785675048828
Agent1_Train_StdReturn : 12.459490776062012
Agent1_Train_MaxReturn : -0.09596538543701172
Agent1_Train_MinReturn : -37.55775451660156
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 256500
Agent1_TimeSinceStart : 402.11479139328003
Agent1_Critic_Loss : 0.302630752325058
Agent1_Actor_Loss : -0.4640001654624939
Agent1_Alpha_Loss : 0.8033294677734375
Agent1_Temperature : 0.09524684318721896
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 171 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 172 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 173 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 174 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 175 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 176 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 177 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 178 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 179 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 180 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -25.514184951782227
Agent0_Eval_StdReturn : 15.488993644714355
Agent0_Eval_MaxReturn : 2.4832701683044434
Agent0_Eval_MinReturn : -51.94955825805664
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -22.428421020507812
Agent0_Train_StdReturn : 5.748612403869629
Agent0_Train_MaxReturn : -12.550745964050293
Agent0_Train_MinReturn : -32.879493713378906
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 271500
Agent0_TimeSinceStart : 423.4488294124603
Agent0_Critic_Loss : 0.4610532522201538
Agent0_Actor_Loss : -0.4308801293373108
Agent0_Alpha_Loss : 0.7677969932556152
Agent0_Temperature : 0.09502497041679314
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -12.967350959777832
Agent1_Eval_StdReturn : 7.969706058502197
Agent1_Eval_MaxReturn : -3.8396964073181152
Agent1_Eval_MinReturn : -27.958669662475586
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -24.472042083740234
Agent1_Train_StdReturn : 21.196258544921875
Agent1_Train_MaxReturn : 16.082571029663086
Agent1_Train_MinReturn : -62.66522216796875
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 271500
Agent1_TimeSinceStart : 425.5758054256439
Agent1_Critic_Loss : 0.359713613986969
Agent1_Actor_Loss : -0.617526650428772
Agent1_Alpha_Loss : 0.8059419393539429
Agent1_Temperature : 0.09499105460929712
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 181 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 182 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 183 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 184 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 185 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 186 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 187 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 188 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 189 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 190 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -16.642990112304688
Agent0_Eval_StdReturn : 18.252405166625977
Agent0_Eval_MaxReturn : 12.778963088989258
Agent0_Eval_MinReturn : -53.057518005371094
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -16.450563430786133
Agent0_Train_StdReturn : 10.989173889160156
Agent0_Train_MaxReturn : -1.6186285018920898
Agent0_Train_MinReturn : -35.02390670776367
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 286500
Agent0_TimeSinceStart : 446.94743275642395
Agent0_Critic_Loss : 0.35467466711997986
Agent0_Actor_Loss : -0.3836682438850403
Agent0_Alpha_Loss : 0.7777705788612366
Agent0_Temperature : 0.09477488891768783
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -24.005855560302734
Agent1_Eval_StdReturn : 9.256022453308105
Agent1_Eval_MaxReturn : -8.834857940673828
Agent1_Eval_MinReturn : -37.57427215576172
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -22.10171127319336
Agent1_Train_StdReturn : 11.252330780029297
Agent1_Train_MaxReturn : -8.962278366088867
Agent1_Train_MinReturn : -38.74756622314453
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 286500
Agent1_TimeSinceStart : 449.0670530796051
Agent1_Critic_Loss : 0.3140887916088104
Agent1_Actor_Loss : -0.5815757513046265
Agent1_Alpha_Loss : 0.798014223575592
Agent1_Temperature : 0.09473492419390815
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 191 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 192 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 193 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 194 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 195 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 196 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 197 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 198 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 199 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 200 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -23.182857513427734
Agent0_Eval_StdReturn : 19.7374324798584
Agent0_Eval_MaxReturn : 5.638155937194824
Agent0_Eval_MinReturn : -61.58277893066406
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -17.979690551757812
Agent0_Train_StdReturn : 11.477479934692383
Agent0_Train_MaxReturn : -0.46777820587158203
Agent0_Train_MinReturn : -41.137046813964844
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 301500
Agent0_TimeSinceStart : 470.4138205051422
Agent0_Critic_Loss : 0.29808151721954346
Agent0_Actor_Loss : -0.41844767332077026
Agent0_Alpha_Loss : 0.7884504795074463
Agent0_Temperature : 0.09452629468104648
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -19.60263442993164
Agent1_Eval_StdReturn : 9.430371284484863
Agent1_Eval_MaxReturn : -9.52389907836914
Agent1_Eval_MinReturn : -41.741912841796875
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -22.64647674560547
Agent1_Train_StdReturn : 20.30595588684082
Agent1_Train_MaxReturn : 0.556675910949707
Agent1_Train_MinReturn : -65.47058868408203
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 301500
Agent1_TimeSinceStart : 472.5407660007477
Agent1_Critic_Loss : 0.26779142022132874
Agent1_Actor_Loss : -0.5618029832839966
Agent1_Alpha_Loss : 0.8041840195655823
Agent1_Temperature : 0.09447905397417984
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 201 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 202 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 203 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 204 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 205 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 206 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 207 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 208 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 209 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 210 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -16.834436416625977
Agent0_Eval_StdReturn : 5.489479064941406
Agent0_Eval_MaxReturn : -8.895668029785156
Agent0_Eval_MinReturn : -24.466964721679688
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -15.260477066040039
Agent0_Train_StdReturn : 11.939260482788086
Agent0_Train_MaxReturn : 8.224030494689941
Agent0_Train_MinReturn : -32.36702346801758
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 316500
Agent0_TimeSinceStart : 493.8822298049927
Agent0_Critic_Loss : 0.2859153151512146
Agent0_Actor_Loss : -0.3250885307788849
Agent0_Alpha_Loss : 0.7727420330047607
Agent0_Temperature : 0.09427620928925301
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -15.209630966186523
Agent1_Eval_StdReturn : 9.738685607910156
Agent1_Eval_MaxReturn : -2.1514415740966797
Agent1_Eval_MinReturn : -34.27082061767578
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -15.098068237304688
Agent1_Train_StdReturn : 14.361947059631348
Agent1_Train_MaxReturn : 5.692083358764648
Agent1_Train_MinReturn : -41.763580322265625
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 316500
Agent1_TimeSinceStart : 496.0005941390991
Agent1_Critic_Loss : 0.24216662347316742
Agent1_Actor_Loss : -0.5256650447845459
Agent1_Alpha_Loss : 0.7859071493148804
Agent1_Temperature : 0.0942237852170736
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 211 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 212 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 213 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 214 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 215 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 216 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 217 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 218 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 219 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 220 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -24.440153121948242
Agent0_Eval_StdReturn : 10.320208549499512
Agent0_Eval_MaxReturn : -11.086820602416992
Agent0_Eval_MinReturn : -41.61936950683594
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -16.37552261352539
Agent0_Train_StdReturn : 8.917698860168457
Agent0_Train_MaxReturn : -2.2386178970336914
Agent0_Train_MinReturn : -35.08063507080078
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 331500
Agent0_TimeSinceStart : 517.3043587207794
Agent0_Critic_Loss : 0.27453064918518066
Agent0_Actor_Loss : -0.2726828455924988
Agent0_Alpha_Loss : 0.7738845944404602
Agent0_Temperature : 0.09402493249027753
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -13.533790588378906
Agent1_Eval_StdReturn : 16.100234985351562
Agent1_Eval_MaxReturn : 14.346391677856445
Agent1_Eval_MinReturn : -44.485015869140625
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -19.28213119506836
Agent1_Train_StdReturn : 16.66891860961914
Agent1_Train_MaxReturn : 7.489724159240723
Agent1_Train_MinReturn : -53.477020263671875
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 331500
Agent1_TimeSinceStart : 519.4294567108154
Agent1_Critic_Loss : 0.22121810913085938
Agent1_Actor_Loss : -0.5803021788597107
Agent1_Alpha_Loss : 0.7763712406158447
Agent1_Temperature : 0.09396939435605729
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 221 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 222 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 223 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 224 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 225 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 226 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 227 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 228 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 229 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 230 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -23.29505729675293
Agent0_Eval_StdReturn : 9.816821098327637
Agent0_Eval_MaxReturn : -8.378107070922852
Agent0_Eval_MinReturn : -39.772056579589844
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -24.711734771728516
Agent0_Train_StdReturn : 11.530563354492188
Agent0_Train_MaxReturn : -5.971344947814941
Agent0_Train_MinReturn : -44.714805603027344
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 346500
Agent0_TimeSinceStart : 540.7399513721466
Agent0_Critic_Loss : 0.24280433356761932
Agent0_Actor_Loss : -0.38147494196891785
Agent0_Alpha_Loss : 0.7693901658058167
Agent0_Temperature : 0.09377368595503001
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -22.141942977905273
Agent1_Eval_StdReturn : 23.49115562438965
Agent1_Eval_MaxReturn : 13.136165618896484
Agent1_Eval_MinReturn : -54.332908630371094
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -15.963635444641113
Agent1_Train_StdReturn : 12.240062713623047
Agent1_Train_MaxReturn : 2.281604290008545
Agent1_Train_MinReturn : -38.98141098022461
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 346500
Agent1_TimeSinceStart : 542.857474565506
Agent1_Critic_Loss : 0.2722749710083008
Agent1_Actor_Loss : -0.5057464241981506
Agent1_Alpha_Loss : 0.7964900732040405
Agent1_Temperature : 0.09371546117565607
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 231 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 232 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 233 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 234 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 235 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 236 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 237 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 238 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 239 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 240 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -11.281886100769043
Agent0_Eval_StdReturn : 14.613313674926758
Agent0_Eval_MaxReturn : 12.651994705200195
Agent0_Eval_MinReturn : -31.262256622314453
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -17.237852096557617
Agent0_Train_StdReturn : 11.36341667175293
Agent0_Train_MaxReturn : 9.542861938476562
Agent0_Train_MinReturn : -29.696273803710938
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 361500
Agent0_TimeSinceStart : 564.1720721721649
Agent0_Critic_Loss : 0.24154458940029144
Agent0_Actor_Loss : -0.40000420808792114
Agent0_Alpha_Loss : 0.7888218760490417
Agent0_Temperature : 0.0935213291305389
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -14.188435554504395
Agent1_Eval_StdReturn : 22.246265411376953
Agent1_Eval_MaxReturn : 20.72504997253418
Agent1_Eval_MinReturn : -46.26112365722656
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -27.403432846069336
Agent1_Train_StdReturn : 10.972180366516113
Agent1_Train_MaxReturn : -12.427263259887695
Agent1_Train_MinReturn : -47.70875549316406
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 361500
Agent1_TimeSinceStart : 566.286895275116
Agent1_Critic_Loss : 0.3092811703681946
Agent1_Actor_Loss : -0.5406836271286011
Agent1_Alpha_Loss : 0.7957779169082642
Agent1_Temperature : 0.09346076573438206
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 241 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 242 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 243 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 244 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 245 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 246 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 247 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 248 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 249 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 250 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -25.413028717041016
Agent0_Eval_StdReturn : 22.131824493408203
Agent0_Eval_MaxReturn : 5.747021675109863
Agent0_Eval_MinReturn : -81.7874755859375
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -16.812053680419922
Agent0_Train_StdReturn : 21.83034324645996
Agent0_Train_MaxReturn : 2.614469051361084
Agent0_Train_MinReturn : -76.43199157714844
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 376500
Agent0_TimeSinceStart : 587.5377867221832
Agent0_Critic_Loss : 0.22156287729740143
Agent0_Actor_Loss : -0.3588688373565674
Agent0_Alpha_Loss : 0.7785330414772034
Agent0_Temperature : 0.09326861589151432
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -25.069589614868164
Agent1_Eval_StdReturn : 12.658096313476562
Agent1_Eval_MaxReturn : -9.556476593017578
Agent1_Eval_MinReturn : -54.11137390136719
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -15.532852172851562
Agent1_Train_StdReturn : 16.342899322509766
Agent1_Train_MaxReturn : 19.179737091064453
Agent1_Train_MinReturn : -35.47442626953125
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 376500
Agent1_TimeSinceStart : 589.6478235721588
Agent1_Critic_Loss : 0.23057740926742554
Agent1_Actor_Loss : -0.5553212761878967
Agent1_Alpha_Loss : 0.8062822818756104
Agent1_Temperature : 0.09320439294076945
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 251 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 252 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 253 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 254 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 255 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 256 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 257 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 258 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 259 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 260 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -22.067852020263672
Agent0_Eval_StdReturn : 19.949623107910156
Agent0_Eval_MaxReturn : 14.280997276306152
Agent0_Eval_MinReturn : -56.17497253417969
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : 0.9741851091384888
Agent0_Train_StdReturn : 12.435647010803223
Agent0_Train_MaxReturn : 25.781818389892578
Agent0_Train_MinReturn : -20.203397750854492
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 391500
Agent0_TimeSinceStart : 610.8739292621613
Agent0_Critic_Loss : 0.2918989062309265
Agent0_Actor_Loss : -0.4057426154613495
Agent0_Alpha_Loss : 0.7847590446472168
Agent0_Temperature : 0.09301579903860381
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -25.279991149902344
Agent1_Eval_StdReturn : 23.872486114501953
Agent1_Eval_MaxReturn : 6.143393516540527
Agent1_Eval_MinReturn : -81.24803161621094
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -21.101408004760742
Agent1_Train_StdReturn : 23.282503128051758
Agent1_Train_MaxReturn : 17.1980037689209
Agent1_Train_MinReturn : -60.66034698486328
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 391500
Agent1_TimeSinceStart : 612.9775867462158
Agent1_Critic_Loss : 0.35103023052215576
Agent1_Actor_Loss : -0.45326465368270874
Agent1_Alpha_Loss : 0.8069970607757568
Agent1_Temperature : 0.09294715321576939
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 261 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 262 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 263 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 264 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 265 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 266 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 267 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 268 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 269 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 270 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -22.86374282836914
Agent0_Eval_StdReturn : 22.648298263549805
Agent0_Eval_MaxReturn : 12.71311092376709
Agent0_Eval_MinReturn : -55.66093444824219
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -6.475412845611572
Agent0_Train_StdReturn : 31.328170776367188
Agent0_Train_MaxReturn : 41.81034469604492
Agent0_Train_MinReturn : -53.318626403808594
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 406500
Agent0_TimeSinceStart : 634.2120282649994
Agent0_Critic_Loss : 0.2768988609313965
Agent0_Actor_Loss : -0.34961432218551636
Agent0_Alpha_Loss : 0.7861909866333008
Agent0_Temperature : 0.09275960842400781
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -13.672192573547363
Agent1_Eval_StdReturn : 14.852211952209473
Agent1_Eval_MaxReturn : 4.951673984527588
Agent1_Eval_MinReturn : -42.61935043334961
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -31.37396812438965
Agent1_Train_StdReturn : 17.7661190032959
Agent1_Train_MaxReturn : 2.020401954650879
Agent1_Train_MinReturn : -61.086387634277344
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 406500
Agent1_TimeSinceStart : 636.322372674942
Agent1_Critic_Loss : 0.30948084592819214
Agent1_Actor_Loss : -0.6339108943939209
Agent1_Alpha_Loss : 0.7954014539718628
Agent1_Temperature : 0.09268933049967681
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 271 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 272 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 273 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 274 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 275 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 276 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 277 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 278 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 279 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 280 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -24.263530731201172
Agent0_Eval_StdReturn : 16.103404998779297
Agent0_Eval_MaxReturn : -0.28548717498779297
Agent0_Eval_MinReturn : -57.235443115234375
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -31.921184539794922
Agent0_Train_StdReturn : 21.66221046447754
Agent0_Train_MaxReturn : 0.5751638412475586
Agent0_Train_MinReturn : -67.64543151855469
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 421500
Agent0_TimeSinceStart : 657.6044504642487
Agent0_Critic_Loss : 0.26769882440567017
Agent0_Actor_Loss : -0.48555663228034973
Agent0_Alpha_Loss : 0.7681726813316345
Agent0_Temperature : 0.09250348509085103
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -18.675392150878906
Agent1_Eval_StdReturn : 18.813934326171875
Agent1_Eval_MaxReturn : 29.488367080688477
Agent1_Eval_MinReturn : -40.71168518066406
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -19.3332576751709
Agent1_Train_StdReturn : 18.772783279418945
Agent1_Train_MaxReturn : 14.11131477355957
Agent1_Train_MinReturn : -44.97947692871094
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 421500
Agent1_TimeSinceStart : 659.7105648517609
Agent1_Critic_Loss : 0.26722121238708496
Agent1_Actor_Loss : -0.5769151449203491
Agent1_Alpha_Loss : 0.8111541271209717
Agent1_Temperature : 0.0924317086128364
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 281 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 282 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 283 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 284 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 285 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 286 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 287 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 288 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 289 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 290 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -25.209232330322266
Agent0_Eval_StdReturn : 21.18598747253418
Agent0_Eval_MaxReturn : 7.603050231933594
Agent0_Eval_MinReturn : -56.278160095214844
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -20.7010440826416
Agent0_Train_StdReturn : 15.803474426269531
Agent0_Train_MaxReturn : 7.370441436767578
Agent0_Train_MinReturn : -47.5135383605957
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 436500
Agent0_TimeSinceStart : 680.91339802742
Agent0_Critic_Loss : 0.3377474248409271
Agent0_Actor_Loss : -0.4439707398414612
Agent0_Alpha_Loss : 0.7806147336959839
Agent0_Temperature : 0.09224866946727557
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -16.544105529785156
Agent1_Eval_StdReturn : 24.70606231689453
Agent1_Eval_MaxReturn : 17.474958419799805
Agent1_Eval_MinReturn : -71.1980209350586
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -19.186769485473633
Agent1_Train_StdReturn : 19.92337989807129
Agent1_Train_MaxReturn : 4.1470208168029785
Agent1_Train_MinReturn : -72.58134460449219
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 436500
Agent1_TimeSinceStart : 683.0252432823181
Agent1_Critic_Loss : 0.3275989890098572
Agent1_Actor_Loss : -0.5675286650657654
Agent1_Alpha_Loss : 0.7977250814437866
Agent1_Temperature : 0.09217512644443648
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 291 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 292 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 293 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 294 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 295 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 296 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 297 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 298 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 299 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 300 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -20.810169219970703
Agent0_Eval_StdReturn : 19.753664016723633
Agent0_Eval_MaxReturn : 19.3043155670166
Agent0_Eval_MinReturn : -46.19401931762695
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -25.004430770874023
Agent0_Train_StdReturn : 21.718950271606445
Agent0_Train_MaxReturn : 3.190286159515381
Agent0_Train_MinReturn : -64.66511535644531
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 451500
Agent0_TimeSinceStart : 704.3107867240906
Agent0_Critic_Loss : 0.32145002484321594
Agent0_Actor_Loss : -0.4336237609386444
Agent0_Alpha_Loss : 0.7983766794204712
Agent0_Temperature : 0.09199441816617436
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -13.7927885055542
Agent1_Eval_StdReturn : 22.00375747680664
Agent1_Eval_MaxReturn : 11.394819259643555
Agent1_Eval_MinReturn : -64.40591430664062
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -15.238960266113281
Agent1_Train_StdReturn : 20.620824813842773
Agent1_Train_MaxReturn : 14.537681579589844
Agent1_Train_MinReturn : -45.85527801513672
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 451500
Agent1_TimeSinceStart : 706.4327056407928
Agent1_Critic_Loss : 0.32500720024108887
Agent1_Actor_Loss : -0.58185213804245
Agent1_Alpha_Loss : 0.7930086255073547
Agent1_Temperature : 0.09191891347763123
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 301 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 302 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 303 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 304 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 305 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 306 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 307 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 308 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 309 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 310 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -19.438772201538086
Agent0_Eval_StdReturn : 22.85051918029785
Agent0_Eval_MaxReturn : 40.415618896484375
Agent0_Eval_MinReturn : -40.983299255371094
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -12.88322639465332
Agent0_Train_StdReturn : 27.251541137695312
Agent0_Train_MaxReturn : 44.63874435424805
Agent0_Train_MinReturn : -69.44587707519531
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 466500
Agent0_TimeSinceStart : 727.7182593345642
Agent0_Critic_Loss : 0.35300883650779724
Agent0_Actor_Loss : -0.4780850410461426
Agent0_Alpha_Loss : 0.7913732528686523
Agent0_Temperature : 0.09173880140103956
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -24.722148895263672
Agent1_Eval_StdReturn : 16.873397827148438
Agent1_Eval_MaxReturn : -1.6646194458007812
Agent1_Eval_MinReturn : -60.575443267822266
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -16.8466854095459
Agent1_Train_StdReturn : 16.341018676757812
Agent1_Train_MaxReturn : 4.055912017822266
Agent1_Train_MinReturn : -52.70538330078125
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 466500
Agent1_TimeSinceStart : 729.8461201190948
Agent1_Critic_Loss : 0.3651657700538635
Agent1_Actor_Loss : -0.5078121423721313
Agent1_Alpha_Loss : 0.7837432026863098
Agent1_Temperature : 0.09166337168990596
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 311 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 312 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 313 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 314 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 315 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 316 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 317 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 318 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 319 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 320 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -16.693052291870117
Agent0_Eval_StdReturn : 18.080591201782227
Agent0_Eval_MaxReturn : 8.324410438537598
Agent0_Eval_MinReturn : -46.566131591796875
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -17.251731872558594
Agent0_Train_StdReturn : 10.113831520080566
Agent0_Train_MaxReturn : 2.060420036315918
Agent0_Train_MinReturn : -33.10677719116211
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 481500
Agent0_TimeSinceStart : 751.1757431030273
Agent0_Critic_Loss : 0.3338434398174286
Agent0_Actor_Loss : -0.5211151242256165
Agent0_Alpha_Loss : 0.7938306331634521
Agent0_Temperature : 0.09148211776484526
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -13.722424507141113
Agent1_Eval_StdReturn : 12.981816291809082
Agent1_Eval_MaxReturn : 3.1821160316467285
Agent1_Eval_MinReturn : -36.329017639160156
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -24.52604103088379
Agent1_Train_StdReturn : 13.167064666748047
Agent1_Train_MaxReturn : -0.6586706638336182
Agent1_Train_MinReturn : -43.49568176269531
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 481500
Agent1_TimeSinceStart : 753.2863805294037
Agent1_Critic_Loss : 0.3973739445209503
Agent1_Actor_Loss : -0.6562386751174927
Agent1_Alpha_Loss : 0.7919934988021851
Agent1_Temperature : 0.09140932746725346
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 321 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 322 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 323 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 324 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 325 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 326 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 327 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 328 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 329 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 330 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -23.442127227783203
Agent0_Eval_StdReturn : 12.401371002197266
Agent0_Eval_MaxReturn : -14.896387100219727
Agent0_Eval_MinReturn : -56.32659912109375
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -14.619461059570312
Agent0_Train_StdReturn : 12.37103271484375
Agent0_Train_MaxReturn : 4.220873832702637
Agent0_Train_MinReturn : -42.821449279785156
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 496500
Agent0_TimeSinceStart : 774.5920791625977
Agent0_Critic_Loss : 0.34227651357650757
Agent0_Actor_Loss : -0.49015194177627563
Agent0_Alpha_Loss : 0.7843832969665527
Agent0_Temperature : 0.09122597480362415
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -22.32973289489746
Agent1_Eval_StdReturn : 7.552016258239746
Agent1_Eval_MaxReturn : -7.809701919555664
Agent1_Eval_MinReturn : -33.30739974975586
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -27.224822998046875
Agent1_Train_StdReturn : 18.263124465942383
Agent1_Train_MaxReturn : 1.5657994747161865
Agent1_Train_MinReturn : -61.164878845214844
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 496500
Agent1_TimeSinceStart : 776.7262513637543
Agent1_Critic_Loss : 0.3484386205673218
Agent1_Actor_Loss : -0.6473129987716675
Agent1_Alpha_Loss : 0.7777743339538574
Agent1_Temperature : 0.0911557716470665
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 331 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 332 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 333 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 334 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 335 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 336 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 337 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 338 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 339 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 340 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -16.581073760986328
Agent0_Eval_StdReturn : 8.70246696472168
Agent0_Eval_MaxReturn : -6.4341630935668945
Agent0_Eval_MinReturn : -31.619304656982422
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -14.996225357055664
Agent0_Train_StdReturn : 16.568002700805664
Agent0_Train_MaxReturn : 16.837413787841797
Agent0_Train_MinReturn : -39.869422912597656
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 511500
Agent0_TimeSinceStart : 797.9609277248383
Agent0_Critic_Loss : 0.30954450368881226
Agent0_Actor_Loss : -0.3898780941963196
Agent0_Alpha_Loss : 0.7854546904563904
Agent0_Temperature : 0.09097056333923276
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -21.8474063873291
Agent1_Eval_StdReturn : 14.524008750915527
Agent1_Eval_MaxReturn : 4.271660804748535
Agent1_Eval_MinReturn : -45.8021125793457
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -27.691631317138672
Agent1_Train_StdReturn : 20.68902587890625
Agent1_Train_MaxReturn : -2.3704681396484375
Agent1_Train_MinReturn : -65.98509216308594
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 511500
Agent1_TimeSinceStart : 800.0753631591797
Agent1_Critic_Loss : 0.36609381437301636
Agent1_Actor_Loss : -0.47877973318099976
Agent1_Alpha_Loss : 0.7798566818237305
Agent1_Temperature : 0.09090340606826992
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 341 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 342 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 343 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 344 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 345 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 346 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 347 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 348 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 349 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 350 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -14.07818603515625
Agent0_Eval_StdReturn : 10.909381866455078
Agent0_Eval_MaxReturn : 2.7400918006896973
Agent0_Eval_MinReturn : -32.11608123779297
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -18.106605529785156
Agent0_Train_StdReturn : 10.93648910522461
Agent0_Train_MaxReturn : -0.5720691680908203
Agent0_Train_MinReturn : -39.17164611816406
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 526500
Agent0_TimeSinceStart : 821.3352162837982
Agent0_Critic_Loss : 0.3923066258430481
Agent0_Actor_Loss : -0.5253956317901611
Agent0_Alpha_Loss : 0.7750826478004456
Agent0_Temperature : 0.09071655842535688
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -20.130168914794922
Agent1_Eval_StdReturn : 17.874229431152344
Agent1_Eval_MaxReturn : 5.395743370056152
Agent1_Eval_MinReturn : -58.215084075927734
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -12.712677001953125
Agent1_Train_StdReturn : 6.229047775268555
Agent1_Train_MaxReturn : -4.986265659332275
Agent1_Train_MinReturn : -23.117769241333008
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 526500
Agent1_TimeSinceStart : 823.4565570354462
Agent1_Critic_Loss : 0.4059273898601532
Agent1_Actor_Loss : -0.6257137060165405
Agent1_Alpha_Loss : 0.7796672582626343
Agent1_Temperature : 0.09065143796303281
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 351 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 352 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 353 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 354 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 355 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 356 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 357 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 358 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 359 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 360 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -21.30446434020996
Agent0_Eval_StdReturn : 24.995744705200195
Agent0_Eval_MaxReturn : 30.533470153808594
Agent0_Eval_MinReturn : -58.730831146240234
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -12.3490571975708
Agent0_Train_StdReturn : 15.812942504882812
Agent0_Train_MaxReturn : 19.706954956054688
Agent0_Train_MinReturn : -42.52070617675781
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 541500
Agent0_TimeSinceStart : 844.8048322200775
Agent0_Critic_Loss : 0.353329598903656
Agent0_Actor_Loss : -0.5314981937408447
Agent0_Alpha_Loss : 0.7704370021820068
Agent0_Temperature : 0.09046309404630544
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -27.320510864257812
Agent1_Eval_StdReturn : 12.575575828552246
Agent1_Eval_MaxReturn : -11.832725524902344
Agent1_Eval_MinReturn : -53.462276458740234
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -22.19598388671875
Agent1_Train_StdReturn : 15.032611846923828
Agent1_Train_MaxReturn : -1.3937023878097534
Agent1_Train_MinReturn : -56.22062301635742
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 541500
Agent1_TimeSinceStart : 846.9201474189758
Agent1_Critic_Loss : 0.3880499303340912
Agent1_Actor_Loss : -0.6676984429359436
Agent1_Alpha_Loss : 0.7915647029876709
Agent1_Temperature : 0.09039976981256632
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 361 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 362 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 363 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 364 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 365 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 366 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 367 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 368 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 369 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 370 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -11.054123878479004
Agent0_Eval_StdReturn : 13.579546928405762
Agent0_Eval_MaxReturn : 11.95913028717041
Agent0_Eval_MinReturn : -34.96487045288086
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -14.609376907348633
Agent0_Train_StdReturn : 16.792207717895508
Agent0_Train_MaxReturn : 17.357681274414062
Agent0_Train_MinReturn : -47.03812789916992
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 556500
Agent0_TimeSinceStart : 868.2176780700684
Agent0_Critic_Loss : 0.4483591914176941
Agent0_Actor_Loss : -0.507468581199646
Agent0_Alpha_Loss : 0.777197539806366
Agent0_Temperature : 0.09020923384100507
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -23.706348419189453
Agent1_Eval_StdReturn : 13.375577926635742
Agent1_Eval_MaxReturn : 2.978182077407837
Agent1_Eval_MinReturn : -44.25049591064453
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -17.34799575805664
Agent1_Train_StdReturn : 13.994400024414062
Agent1_Train_MaxReturn : 8.299437522888184
Agent1_Train_MinReturn : -34.95197296142578
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 556500
Agent1_TimeSinceStart : 870.3404757976532
Agent1_Critic_Loss : 0.4095737338066101
Agent1_Actor_Loss : -0.5987250804901123
Agent1_Alpha_Loss : 0.7762559652328491
Agent1_Temperature : 0.09014843909640356
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 371 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 372 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 373 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 374 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 375 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 376 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 377 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 378 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 379 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 380 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -24.579992294311523
Agent0_Eval_StdReturn : 14.21782112121582
Agent0_Eval_MaxReturn : -1.2908400297164917
Agent0_Eval_MinReturn : -47.359840393066406
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -16.921741485595703
Agent0_Train_StdReturn : 12.384235382080078
Agent0_Train_MaxReturn : 7.604168891906738
Agent0_Train_MinReturn : -41.77024841308594
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 571500
Agent0_TimeSinceStart : 891.6026654243469
Agent0_Critic_Loss : 0.4132230281829834
Agent0_Actor_Loss : -0.4720035791397095
Agent0_Alpha_Loss : 0.7683382034301758
Agent0_Temperature : 0.08995699558147861
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -15.715370178222656
Agent1_Eval_StdReturn : 12.728795051574707
Agent1_Eval_MaxReturn : 8.217905044555664
Agent1_Eval_MinReturn : -37.874542236328125
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -19.479143142700195
Agent1_Train_StdReturn : 13.287662506103516
Agent1_Train_MaxReturn : 3.0131590366363525
Agent1_Train_MinReturn : -38.823081970214844
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 571500
Agent1_TimeSinceStart : 893.7244002819061
Agent1_Critic_Loss : 0.3452942669391632
Agent1_Actor_Loss : -0.6767685413360596
Agent1_Alpha_Loss : 0.77814120054245
Agent1_Temperature : 0.08989788822832008
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 381 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 382 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 383 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 384 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 385 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 386 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 387 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 388 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 389 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 390 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -21.56639862060547
Agent0_Eval_StdReturn : 12.57038688659668
Agent0_Eval_MaxReturn : -7.579676628112793
Agent0_Eval_MinReturn : -44.25579071044922
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -12.462485313415527
Agent0_Train_StdReturn : 6.726092338562012
Agent0_Train_MaxReturn : 1.477391242980957
Agent0_Train_MinReturn : -22.951141357421875
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 586500
Agent0_TimeSinceStart : 915.110552072525
Agent0_Critic_Loss : 0.3417307734489441
Agent0_Actor_Loss : -0.5329445600509644
Agent0_Alpha_Loss : 0.7842623591423035
Agent0_Temperature : 0.08970722158038294
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -19.374677658081055
Agent1_Eval_StdReturn : 14.141448020935059
Agent1_Eval_MaxReturn : -1.4208316802978516
Agent1_Eval_MinReturn : -44.54280471801758
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -23.079906463623047
Agent1_Train_StdReturn : 14.043539047241211
Agent1_Train_MaxReturn : -2.8329505920410156
Agent1_Train_MinReturn : -49.422096252441406
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 586500
Agent1_TimeSinceStart : 917.2507407665253
Agent1_Critic_Loss : 0.40343567728996277
Agent1_Actor_Loss : -0.6550102233886719
Agent1_Alpha_Loss : 0.7581074237823486
Agent1_Temperature : 0.08964927886648394
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 391 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 392 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 393 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 394 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 395 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 396 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 397 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 398 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 399 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 400 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -19.115259170532227
Agent0_Eval_StdReturn : 12.327378273010254
Agent0_Eval_MaxReturn : -5.303356170654297
Agent0_Eval_MinReturn : -46.81766891479492
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -20.7404842376709
Agent0_Train_StdReturn : 22.054216384887695
Agent0_Train_MaxReturn : 21.63334083557129
Agent0_Train_MinReturn : -60.045387268066406
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 601500
Agent0_TimeSinceStart : 938.6255924701691
Agent0_Critic_Loss : 0.3775748312473297
Agent0_Actor_Loss : -0.46556198596954346
Agent0_Alpha_Loss : 0.7683945894241333
Agent0_Temperature : 0.08945790106558134
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -20.37146759033203
Agent1_Eval_StdReturn : 6.914867401123047
Agent1_Eval_MaxReturn : -7.70777702331543
Agent1_Eval_MinReturn : -31.99854278564453
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -19.321147918701172
Agent1_Train_StdReturn : 10.182555198669434
Agent1_Train_MaxReturn : 3.503124952316284
Agent1_Train_MinReturn : -33.83456039428711
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 601500
Agent1_TimeSinceStart : 940.743992805481
Agent1_Critic_Loss : 0.47056689858436584
Agent1_Actor_Loss : -0.5597981810569763
Agent1_Alpha_Loss : 0.7515952587127686
Agent1_Temperature : 0.08940287433933918
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 401 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 402 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 403 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 404 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 405 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 406 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 407 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 408 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 409 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 410 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -14.543493270874023
Agent0_Eval_StdReturn : 12.776885032653809
Agent0_Eval_MaxReturn : 7.924971580505371
Agent0_Eval_MinReturn : -34.679359436035156
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -13.116701126098633
Agent0_Train_StdReturn : 6.936010837554932
Agent0_Train_MaxReturn : -3.6207213401794434
Agent0_Train_MinReturn : -26.188751220703125
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 616500
Agent0_TimeSinceStart : 962.1233541965485
Agent0_Critic_Loss : 0.42409276962280273
Agent0_Actor_Loss : -0.4388878047466278
Agent0_Alpha_Loss : 0.7871904373168945
Agent0_Temperature : 0.0892089356927311
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -19.336782455444336
Agent1_Eval_StdReturn : 10.311163902282715
Agent1_Eval_MaxReturn : 1.9575157165527344
Agent1_Eval_MinReturn : -36.83098220825195
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -17.968019485473633
Agent1_Train_StdReturn : 13.190056800842285
Agent1_Train_MaxReturn : -0.1585240364074707
Agent1_Train_MinReturn : -50.516456604003906
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 616500
Agent1_TimeSinceStart : 964.2504391670227
Agent1_Critic_Loss : 0.4132380187511444
Agent1_Actor_Loss : -0.6205552816390991
Agent1_Alpha_Loss : 0.7551363706588745
Agent1_Temperature : 0.0891579039644749
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 411 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 412 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 413 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 414 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 415 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 416 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 417 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 418 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 419 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 420 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -24.739521026611328
Agent0_Eval_StdReturn : 17.69223403930664
Agent0_Eval_MaxReturn : 11.377243995666504
Agent0_Eval_MinReturn : -55.88905334472656
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -11.430936813354492
Agent0_Train_StdReturn : 16.38728904724121
Agent0_Train_MaxReturn : 23.427337646484375
Agent0_Train_MinReturn : -29.135406494140625
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 631500
Agent0_TimeSinceStart : 985.582603931427
Agent0_Critic_Loss : 0.43879687786102295
Agent0_Actor_Loss : -0.5059113502502441
Agent0_Alpha_Loss : 0.7675846815109253
Agent0_Temperature : 0.08895819685767006
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -13.182065963745117
Agent1_Eval_StdReturn : 9.990313529968262
Agent1_Eval_MaxReturn : 14.311903953552246
Agent1_Eval_MinReturn : -23.07171630859375
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -18.75420379638672
Agent1_Train_StdReturn : 11.378400802612305
Agent1_Train_MaxReturn : 5.158900260925293
Agent1_Train_MinReturn : -39.781471252441406
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 631500
Agent1_TimeSinceStart : 987.7035536766052
Agent1_Critic_Loss : 0.34421417117118835
Agent1_Actor_Loss : -0.7152687311172485
Agent1_Alpha_Loss : 0.7717792391777039
Agent1_Temperature : 0.08891325016801646
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 421 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 422 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 423 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 424 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 425 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 426 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 427 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 428 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 429 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 430 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -17.3409481048584
Agent0_Eval_StdReturn : 21.05257797241211
Agent0_Eval_MaxReturn : 8.369288444519043
Agent0_Eval_MinReturn : -51.1655158996582
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -17.846616744995117
Agent0_Train_StdReturn : 14.23659896850586
Agent0_Train_MaxReturn : 3.797335624694824
Agent0_Train_MinReturn : -40.024436950683594
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 646500
Agent0_TimeSinceStart : 1009.104551076889
Agent0_Critic_Loss : 0.4214019179344177
Agent0_Actor_Loss : -0.4971740245819092
Agent0_Alpha_Loss : 0.7776720523834229
Agent0_Temperature : 0.08870639334438642
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -20.07147979736328
Agent1_Eval_StdReturn : 14.886123657226562
Agent1_Eval_MaxReturn : 12.131964683532715
Agent1_Eval_MinReturn : -42.36559295654297
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -7.143959045410156
Agent1_Train_StdReturn : 12.218351364135742
Agent1_Train_MaxReturn : 10.142400741577148
Agent1_Train_MinReturn : -28.24764633178711
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 646500
Agent1_TimeSinceStart : 1011.2300705909729
Agent1_Critic_Loss : 0.3664857745170593
Agent1_Actor_Loss : -0.554129958152771
Agent1_Alpha_Loss : 0.7729469537734985
Agent1_Temperature : 0.08866776681957375
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 431 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 432 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 433 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 434 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 435 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 436 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 437 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 438 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 439 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 440 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -13.895833015441895
Agent0_Eval_StdReturn : 18.00188446044922
Agent0_Eval_MaxReturn : 11.246768951416016
Agent0_Eval_MinReturn : -45.88405227661133
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -21.802764892578125
Agent0_Train_StdReturn : 11.137162208557129
Agent0_Train_MaxReturn : -7.668822765350342
Agent0_Train_MinReturn : -44.99763488769531
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 661500
Agent0_TimeSinceStart : 1032.5698063373566
Agent0_Critic_Loss : 0.42966312170028687
Agent0_Actor_Loss : -0.38965776562690735
Agent0_Alpha_Loss : 0.7962244749069214
Agent0_Temperature : 0.08845499964931633
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -25.40813636779785
Agent1_Eval_StdReturn : 13.994773864746094
Agent1_Eval_MaxReturn : -3.6241343021392822
Agent1_Eval_MinReturn : -48.03012466430664
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -15.349291801452637
Agent1_Train_StdReturn : 19.365102767944336
Agent1_Train_MaxReturn : 23.495887756347656
Agent1_Train_MinReturn : -46.371002197265625
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 661500
Agent1_TimeSinceStart : 1034.6930520534515
Agent1_Critic_Loss : 0.3168865442276001
Agent1_Actor_Loss : -0.6022745370864868
Agent1_Alpha_Loss : 0.7914738655090332
Agent1_Temperature : 0.08842025115126144
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 441 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 442 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 443 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 444 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 445 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 446 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 447 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 448 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 449 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 450 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -13.786158561706543
Agent0_Eval_StdReturn : 11.450437545776367
Agent0_Eval_MaxReturn : 12.633161544799805
Agent0_Eval_MinReturn : -28.356826782226562
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -15.307952880859375
Agent0_Train_StdReturn : 12.567571640014648
Agent0_Train_MaxReturn : 5.17082405090332
Agent0_Train_MinReturn : -39.96877670288086
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 676500
Agent0_TimeSinceStart : 1055.9784281253815
Agent0_Critic_Loss : 0.4448821246623993
Agent0_Actor_Loss : -0.4277225732803345
Agent0_Alpha_Loss : 0.7700904607772827
Agent0_Temperature : 0.08820391026932957
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -12.066048622131348
Agent1_Eval_StdReturn : 10.13454818725586
Agent1_Eval_MaxReturn : -0.692851185798645
Agent1_Eval_MinReturn : -34.40960693359375
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -18.769927978515625
Agent1_Train_StdReturn : 14.488950729370117
Agent1_Train_MaxReturn : 0.6472107172012329
Agent1_Train_MinReturn : -49.95293426513672
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 676500
Agent1_TimeSinceStart : 1058.099619626999
Agent1_Critic_Loss : 0.33078983426094055
Agent1_Actor_Loss : -0.6683016419410706
Agent1_Alpha_Loss : 0.7840918302536011
Agent1_Temperature : 0.08817169886163385
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 451 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 452 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 453 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 454 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 455 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 456 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 457 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 458 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 459 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 460 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -17.88398551940918
Agent0_Eval_StdReturn : 20.08487892150879
Agent0_Eval_MaxReturn : 9.94140338897705
Agent0_Eval_MinReturn : -61.09196472167969
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -19.56681251525879
Agent0_Train_StdReturn : 15.398813247680664
Agent0_Train_MaxReturn : -1.2075632810592651
Agent0_Train_MinReturn : -52.77657699584961
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 691500
Agent0_TimeSinceStart : 1079.3341760635376
Agent0_Critic_Loss : 0.4113115072250366
Agent0_Actor_Loss : -0.5976359248161316
Agent0_Alpha_Loss : 0.7812236547470093
Agent0_Temperature : 0.0879528330811661
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -20.491405487060547
Agent1_Eval_StdReturn : 16.883386611938477
Agent1_Eval_MaxReturn : 20.24196434020996
Agent1_Eval_MinReturn : -37.805564880371094
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -20.426959991455078
Agent1_Train_StdReturn : 15.75003719329834
Agent1_Train_MaxReturn : 4.132874488830566
Agent1_Train_MinReturn : -48.28291320800781
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 691500
Agent1_TimeSinceStart : 1081.4453146457672
Agent1_Critic_Loss : 0.4379335045814514
Agent1_Actor_Loss : -0.614330530166626
Agent1_Alpha_Loss : 0.783568263053894
Agent1_Temperature : 0.08792406498547244
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 461 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 462 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 463 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 464 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 465 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 466 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 467 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 468 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 469 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 470 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -18.815439224243164
Agent0_Eval_StdReturn : 23.300636291503906
Agent0_Eval_MaxReturn : 3.5303401947021484
Agent0_Eval_MinReturn : -73.34518432617188
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -18.290395736694336
Agent0_Train_StdReturn : 12.152237892150879
Agent0_Train_MaxReturn : 0.881169319152832
Agent0_Train_MinReturn : -46.68284225463867
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 706500
Agent0_TimeSinceStart : 1102.7108924388885
Agent0_Critic_Loss : 0.40774819254875183
Agent0_Actor_Loss : -0.44190850853919983
Agent0_Alpha_Loss : 0.7736782431602478
Agent0_Temperature : 0.0877017843611888
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -13.658421516418457
Agent1_Eval_StdReturn : 21.106170654296875
Agent1_Eval_MaxReturn : 13.135858535766602
Agent1_Eval_MinReturn : -51.003971099853516
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -19.05201530456543
Agent1_Train_StdReturn : 22.83321762084961
Agent1_Train_MaxReturn : 11.831985473632812
Agent1_Train_MinReturn : -67.1856460571289
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 706500
Agent1_TimeSinceStart : 1104.821313381195
Agent1_Critic_Loss : 0.4680587649345398
Agent1_Actor_Loss : -0.5731503963470459
Agent1_Alpha_Loss : 0.7825418710708618
Agent1_Temperature : 0.08767698332525069
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 471 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 472 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 473 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 474 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 475 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 476 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 477 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 478 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 479 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 480 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -18.682416915893555
Agent0_Eval_StdReturn : 11.318499565124512
Agent0_Eval_MaxReturn : -0.7295694351196289
Agent0_Eval_MinReturn : -34.107810974121094
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -9.174286842346191
Agent0_Train_StdReturn : 14.659464836120605
Agent0_Train_MaxReturn : 20.658660888671875
Agent0_Train_MinReturn : -24.290142059326172
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 721500
Agent0_TimeSinceStart : 1126.0970911979675
Agent0_Critic_Loss : 0.41108524799346924
Agent0_Actor_Loss : -0.5009208917617798
Agent0_Alpha_Loss : 0.761506199836731
Agent0_Temperature : 0.08745212312459179
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -13.16889762878418
Agent1_Eval_StdReturn : 25.08652687072754
Agent1_Eval_MaxReturn : 7.752100467681885
Agent1_Eval_MinReturn : -73.25115966796875
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -25.594985961914062
Agent1_Train_StdReturn : 23.696395874023438
Agent1_Train_MaxReturn : 15.865166664123535
Agent1_Train_MinReturn : -78.55741882324219
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 721500
Agent1_TimeSinceStart : 1128.20538854599
Agent1_Critic_Loss : 0.4717423915863037
Agent1_Actor_Loss : -0.5576149821281433
Agent1_Alpha_Loss : 0.7799418568611145
Agent1_Temperature : 0.08742790403830225
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 481 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 482 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 483 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 484 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 485 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 486 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 487 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 488 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 489 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 490 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -16.20736312866211
Agent0_Eval_StdReturn : 11.321547508239746
Agent0_Eval_MaxReturn : -0.41762542724609375
Agent0_Eval_MinReturn : -37.97825622558594
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -23.440439224243164
Agent0_Train_StdReturn : 15.348069190979004
Agent0_Train_MaxReturn : 0.30855655670166016
Agent0_Train_MinReturn : -50.74176788330078
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 736500
Agent0_TimeSinceStart : 1149.472259759903
Agent0_Critic_Loss : 0.4252140522003174
Agent0_Actor_Loss : -0.4980241358280182
Agent0_Alpha_Loss : 0.7907546758651733
Agent0_Temperature : 0.0872033517137562
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -21.10677719116211
Agent1_Eval_StdReturn : 24.814481735229492
Agent1_Eval_MaxReturn : 6.8977766036987305
Agent1_Eval_MinReturn : -71.96903228759766
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -18.827281951904297
Agent1_Train_StdReturn : 23.51673126220703
Agent1_Train_MaxReturn : 25.513164520263672
Agent1_Train_MinReturn : -60.18876266479492
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 736500
Agent1_TimeSinceStart : 1151.5858829021454
Agent1_Critic_Loss : 0.33870041370391846
Agent1_Actor_Loss : -0.7086285352706909
Agent1_Alpha_Loss : 0.7937291860580444
Agent1_Temperature : 0.08717745348092673
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 491 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 492 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 493 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 494 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 495 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 496 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 497 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 498 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 499 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 500 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -14.339963912963867
Agent0_Eval_StdReturn : 9.389639854431152
Agent0_Eval_MaxReturn : 0.07305145263671875
Agent0_Eval_MinReturn : -27.662446975708008
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -4.801074981689453
Agent0_Train_StdReturn : 17.103464126586914
Agent0_Train_MaxReturn : 31.355316162109375
Agent0_Train_MinReturn : -29.44696044921875
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 751500
Agent0_TimeSinceStart : 1172.8385100364685
Agent0_Critic_Loss : 0.5036094188690186
Agent0_Actor_Loss : -0.6024211049079895
Agent0_Alpha_Loss : 0.7744885683059692
Agent0_Temperature : 0.08695347731057211
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -11.095779418945312
Agent1_Eval_StdReturn : 14.256965637207031
Agent1_Eval_MaxReturn : 17.878345489501953
Agent1_Eval_MinReturn : -28.248044967651367
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -20.342437744140625
Agent1_Train_StdReturn : 22.49197769165039
Agent1_Train_MaxReturn : 10.361501693725586
Agent1_Train_MinReturn : -61.04387283325195
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 751500
Agent1_TimeSinceStart : 1174.948714017868
Agent1_Critic_Loss : 0.49778661131858826
Agent1_Actor_Loss : -0.6667494177818298
Agent1_Alpha_Loss : 0.8034722805023193
Agent1_Temperature : 0.08692695574665939
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 501 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 502 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 503 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 504 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 505 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 506 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 507 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 508 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 509 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 510 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -15.561635971069336
Agent0_Eval_StdReturn : 16.38744354248047
Agent0_Eval_MaxReturn : 10.529985427856445
Agent0_Eval_MinReturn : -53.8966064453125
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -13.449819564819336
Agent0_Train_StdReturn : 12.425263404846191
Agent0_Train_MaxReturn : 2.3360347747802734
Agent0_Train_MinReturn : -33.532867431640625
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 766500
Agent0_TimeSinceStart : 1196.1663432121277
Agent0_Critic_Loss : 0.5732828974723816
Agent0_Actor_Loss : -0.6306812763214111
Agent0_Alpha_Loss : 0.7880491018295288
Agent0_Temperature : 0.08670384688974973
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -29.15061378479004
Agent1_Eval_StdReturn : 19.74449920654297
Agent1_Eval_MaxReturn : 3.476235866546631
Agent1_Eval_MinReturn : -60.068397521972656
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -18.383899688720703
Agent1_Train_StdReturn : 12.023356437683105
Agent1_Train_MaxReturn : 2.431588649749756
Agent1_Train_MinReturn : -43.59556579589844
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 766500
Agent1_TimeSinceStart : 1198.2687819004059
Agent1_Critic_Loss : 0.4731128215789795
Agent1_Actor_Loss : -0.5569718480110168
Agent1_Alpha_Loss : 0.7900295257568359
Agent1_Temperature : 0.0866763369601835
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 511 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 512 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 513 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 514 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 515 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 516 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 517 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 518 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 519 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 520 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -25.724254608154297
Agent0_Eval_StdReturn : 16.67275047302246
Agent0_Eval_MaxReturn : -2.6990184783935547
Agent0_Eval_MinReturn : -58.368778228759766
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -22.157188415527344
Agent0_Train_StdReturn : 14.856510162353516
Agent0_Train_MaxReturn : 9.229297637939453
Agent0_Train_MinReturn : -36.95586013793945
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 781500
Agent0_TimeSinceStart : 1219.5242080688477
Agent0_Critic_Loss : 0.5486425161361694
Agent0_Actor_Loss : -0.4540291726589203
Agent0_Alpha_Loss : 0.7873449921607971
Agent0_Temperature : 0.08645343124952692
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -24.719234466552734
Agent1_Eval_StdReturn : 18.564924240112305
Agent1_Eval_MaxReturn : -0.3859872817993164
Agent1_Eval_MinReturn : -68.37382507324219
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -25.94744873046875
Agent1_Train_StdReturn : 13.784905433654785
Agent1_Train_MaxReturn : 3.7336645126342773
Agent1_Train_MinReturn : -42.03048324584961
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 781500
Agent1_TimeSinceStart : 1221.630880355835
Agent1_Critic_Loss : 0.45510631799697876
Agent1_Actor_Loss : -0.5846490859985352
Agent1_Alpha_Loss : 0.7934322357177734
Agent1_Temperature : 0.08642612986770705
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 521 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 522 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 523 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 524 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 525 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 526 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 527 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 528 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 529 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 530 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -16.114459991455078
Agent0_Eval_StdReturn : 8.550165176391602
Agent0_Eval_MaxReturn : 0.7789397239685059
Agent0_Eval_MinReturn : -26.09779930114746
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -15.465130805969238
Agent0_Train_StdReturn : 8.458101272583008
Agent0_Train_MaxReturn : -1.7432724237442017
Agent0_Train_MinReturn : -30.99311065673828
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 796500
Agent0_TimeSinceStart : 1242.8788585662842
Agent0_Critic_Loss : 0.632193922996521
Agent0_Actor_Loss : -0.5300925970077515
Agent0_Alpha_Loss : 0.7838946580886841
Agent0_Temperature : 0.08620367021153828
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -13.673948287963867
Agent1_Eval_StdReturn : 16.73320960998535
Agent1_Eval_MaxReturn : 5.387729644775391
Agent1_Eval_MinReturn : -38.37886047363281
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -19.793960571289062
Agent1_Train_StdReturn : 13.224245071411133
Agent1_Train_MaxReturn : -4.173349380493164
Agent1_Train_MinReturn : -50.776123046875
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 796500
Agent1_TimeSinceStart : 1244.995833158493
Agent1_Critic_Loss : 0.5272152423858643
Agent1_Actor_Loss : -0.7076741456985474
Agent1_Alpha_Loss : 0.7898743748664856
Agent1_Temperature : 0.08617654939087291
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 531 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 532 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 533 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 534 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 535 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 536 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 537 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 538 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 539 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 540 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -10.869070053100586
Agent0_Eval_StdReturn : 13.326254844665527
Agent0_Eval_MaxReturn : 23.625072479248047
Agent0_Eval_MinReturn : -22.344097137451172
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -6.8660149574279785
Agent0_Train_StdReturn : 18.619983673095703
Agent0_Train_MaxReturn : 30.588409423828125
Agent0_Train_MinReturn : -46.0888671875
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 811500
Agent0_TimeSinceStart : 1266.3563222885132
Agent0_Critic_Loss : 0.5437564849853516
Agent0_Actor_Loss : -0.6202126741409302
Agent0_Alpha_Loss : 0.7936533689498901
Agent0_Temperature : 0.0859546386811064
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -19.242494583129883
Agent1_Eval_StdReturn : 10.006893157958984
Agent1_Eval_MaxReturn : 0.593543529510498
Agent1_Eval_MinReturn : -31.296653747558594
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -9.834394454956055
Agent1_Train_StdReturn : 13.580496788024902
Agent1_Train_MaxReturn : 12.746612548828125
Agent1_Train_MinReturn : -29.460826873779297
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 811500
Agent1_TimeSinceStart : 1268.473313331604
Agent1_Critic_Loss : 0.563883364200592
Agent1_Actor_Loss : -0.5071003437042236
Agent1_Alpha_Loss : 0.7850542068481445
Agent1_Temperature : 0.08592822882099896
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 541 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 542 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 543 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 544 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 545 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 546 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 547 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 548 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 549 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 550 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -33.82734680175781
Agent0_Eval_StdReturn : 32.970245361328125
Agent0_Eval_MaxReturn : 25.756946563720703
Agent0_Eval_MinReturn : -88.48602294921875
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -17.905197143554688
Agent0_Train_StdReturn : 16.327051162719727
Agent0_Train_MaxReturn : 14.756505966186523
Agent0_Train_MinReturn : -40.087520599365234
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 826500
Agent0_TimeSinceStart : 1289.739850282669
Agent0_Critic_Loss : 0.5098102688789368
Agent0_Actor_Loss : -0.6237843632698059
Agent0_Alpha_Loss : 0.7938812971115112
Agent0_Temperature : 0.08570516829736073
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -13.661267280578613
Agent1_Eval_StdReturn : 14.614984512329102
Agent1_Eval_MaxReturn : 14.053361892700195
Agent1_Eval_MinReturn : -35.65163803100586
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -16.562589645385742
Agent1_Train_StdReturn : 16.47593116760254
Agent1_Train_MaxReturn : 11.840869903564453
Agent1_Train_MinReturn : -52.070823669433594
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 826500
Agent1_TimeSinceStart : 1291.8611545562744
Agent1_Critic_Loss : 0.6297222375869751
Agent1_Actor_Loss : -0.6046905517578125
Agent1_Alpha_Loss : 0.7677838802337646
Agent1_Temperature : 0.08568364807526578
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 551 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 552 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 553 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 554 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 555 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 556 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 557 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 558 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 559 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 560 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -7.691758155822754
Agent0_Eval_StdReturn : 14.637139320373535
Agent0_Eval_MaxReturn : 15.186752319335938
Agent0_Eval_MinReturn : -34.470680236816406
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -20.88557243347168
Agent0_Train_StdReturn : 18.824249267578125
Agent0_Train_MaxReturn : 11.659745216369629
Agent0_Train_MinReturn : -44.2237548828125
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 841500
Agent0_TimeSinceStart : 1313.2738065719604
Agent0_Critic_Loss : 0.5604289770126343
Agent0_Actor_Loss : -0.5987553596496582
Agent0_Alpha_Loss : 0.7861544489860535
Agent0_Temperature : 0.08545730961267572
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -15.43884563446045
Agent1_Eval_StdReturn : 9.639246940612793
Agent1_Eval_MaxReturn : -1.574556827545166
Agent1_Eval_MinReturn : -31.907304763793945
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -14.988142013549805
Agent1_Train_StdReturn : 9.886146545410156
Agent1_Train_MaxReturn : 0.6878180503845215
Agent1_Train_MinReturn : -28.871286392211914
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 841500
Agent1_TimeSinceStart : 1315.400502204895
Agent1_Critic_Loss : 0.4698182940483093
Agent1_Actor_Loss : -0.7229561805725098
Agent1_Alpha_Loss : 0.7739958763122559
Agent1_Temperature : 0.08544221103187576
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 561 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 562 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 563 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 564 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 565 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 566 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 567 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 568 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 569 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 570 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -7.683245658874512
Agent0_Eval_StdReturn : 14.33403491973877
Agent0_Eval_MaxReturn : 20.598709106445312
Agent0_Eval_MinReturn : -25.549423217773438
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -13.317173957824707
Agent0_Train_StdReturn : 17.1456298828125
Agent0_Train_MaxReturn : 16.223739624023438
Agent0_Train_MinReturn : -37.31197738647461
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 856500
Agent0_TimeSinceStart : 1336.7814092636108
Agent0_Critic_Loss : 0.5230754613876343
Agent0_Actor_Loss : -0.6297534704208374
Agent0_Alpha_Loss : 0.7831270694732666
Agent0_Temperature : 0.08521053703175725
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -17.921092987060547
Agent1_Eval_StdReturn : 8.759084701538086
Agent1_Eval_MaxReturn : 1.4177188873291016
Agent1_Eval_MinReturn : -29.664348602294922
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -18.23112678527832
Agent1_Train_StdReturn : 6.783214569091797
Agent1_Train_MaxReturn : -5.4629364013671875
Agent1_Train_MinReturn : -29.022781372070312
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 856500
Agent1_TimeSinceStart : 1338.918779373169
Agent1_Critic_Loss : 0.6769263744354248
Agent1_Actor_Loss : -0.6456489562988281
Agent1_Alpha_Loss : 0.7437583804130554
Agent1_Temperature : 0.08520309350759865
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 571 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 572 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 573 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 574 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 575 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 576 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 577 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 578 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 579 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 580 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -12.088865280151367
Agent0_Eval_StdReturn : 13.65489387512207
Agent0_Eval_MaxReturn : 11.902603149414062
Agent0_Eval_MinReturn : -34.05599594116211
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -7.099648952484131
Agent0_Train_StdReturn : 10.28886604309082
Agent0_Train_MaxReturn : 8.74123764038086
Agent0_Train_MinReturn : -21.67629623413086
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 871500
Agent0_TimeSinceStart : 1360.3592925071716
Agent0_Critic_Loss : 0.48443347215652466
Agent0_Actor_Loss : -0.7784448266029358
Agent0_Alpha_Loss : 0.7677946090698242
Agent0_Temperature : 0.08496468114836267
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -17.273923873901367
Agent1_Eval_StdReturn : 12.565878868103027
Agent1_Eval_MaxReturn : 2.638324022293091
Agent1_Eval_MinReturn : -38.21788024902344
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -12.988679885864258
Agent1_Train_StdReturn : 10.995747566223145
Agent1_Train_MaxReturn : 4.808548927307129
Agent1_Train_MinReturn : -27.39142608642578
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 871500
Agent1_TimeSinceStart : 1362.4844036102295
Agent1_Critic_Loss : 0.7638620138168335
Agent1_Actor_Loss : -0.611748993396759
Agent1_Alpha_Loss : 0.7475528717041016
Agent1_Temperature : 0.08496626201238747
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 581 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 582 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 583 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 584 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 585 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 586 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 587 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 588 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 589 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 590 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -14.005993843078613
Agent0_Eval_StdReturn : 13.170211791992188
Agent0_Eval_MaxReturn : 11.287948608398438
Agent0_Eval_MinReturn : -31.37089729309082
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -12.559844017028809
Agent0_Train_StdReturn : 10.286505699157715
Agent0_Train_MaxReturn : 4.232614994049072
Agent0_Train_MinReturn : -32.613887786865234
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 886500
Agent0_TimeSinceStart : 1383.8323452472687
Agent0_Critic_Loss : 0.6215417385101318
Agent0_Actor_Loss : -0.7103729248046875
Agent0_Alpha_Loss : 0.7698262333869934
Agent0_Temperature : 0.0847222085787723
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -11.348682403564453
Agent1_Eval_StdReturn : 15.924738883972168
Agent1_Eval_MaxReturn : 20.049898147583008
Agent1_Eval_MinReturn : -33.135318756103516
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -15.68036937713623
Agent1_Train_StdReturn : 12.016819953918457
Agent1_Train_MaxReturn : -2.252215623855591
Agent1_Train_MinReturn : -43.05107879638672
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 886500
Agent1_TimeSinceStart : 1385.9538724422455
Agent1_Critic_Loss : 0.5983598232269287
Agent1_Actor_Loss : -0.6520698070526123
Agent1_Alpha_Loss : 0.7689921855926514
Agent1_Temperature : 0.08472939575388289
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 591 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 592 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 593 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 594 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 595 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 596 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 597 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 598 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 599 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 600 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -13.444218635559082
Agent0_Eval_StdReturn : 8.9242582321167
Agent0_Eval_MaxReturn : 6.965387344360352
Agent0_Eval_MinReturn : -27.07086753845215
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -16.425039291381836
Agent0_Train_StdReturn : 9.193347930908203
Agent0_Train_MaxReturn : 1.2740826606750488
Agent0_Train_MinReturn : -30.74883270263672
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 901500
Agent0_TimeSinceStart : 1407.2816708087921
Agent0_Critic_Loss : 0.593779981136322
Agent0_Actor_Loss : -0.4704909324645996
Agent0_Alpha_Loss : 0.757310688495636
Agent0_Temperature : 0.08448198417757563
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -11.862855911254883
Agent1_Eval_StdReturn : 14.921660423278809
Agent1_Eval_MaxReturn : 26.073413848876953
Agent1_Eval_MinReturn : -28.19198226928711
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -19.401199340820312
Agent1_Train_StdReturn : 16.573123931884766
Agent1_Train_MaxReturn : 11.277783393859863
Agent1_Train_MinReturn : -44.513092041015625
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 901500
Agent1_TimeSinceStart : 1409.4078259468079
Agent1_Critic_Loss : 0.8406818509101868
Agent1_Actor_Loss : -0.6836596727371216
Agent1_Alpha_Loss : 0.7537076473236084
Agent1_Temperature : 0.08449227105731263
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 601 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 602 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 603 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 604 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 605 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 606 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 607 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 608 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 609 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 610 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -8.77269458770752
Agent0_Eval_StdReturn : 14.192977905273438
Agent0_Eval_MaxReturn : 13.910115242004395
Agent0_Eval_MinReturn : -34.085365295410156
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -14.621442794799805
Agent0_Train_StdReturn : 8.087564468383789
Agent0_Train_MaxReturn : 3.774186134338379
Agent0_Train_MinReturn : -24.26746368408203
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 916500
Agent0_TimeSinceStart : 1430.8085877895355
Agent0_Critic_Loss : 0.5208470225334167
Agent0_Actor_Loss : -0.6274526119232178
Agent0_Alpha_Loss : 0.773807168006897
Agent0_Temperature : 0.08424261833215886
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -14.227361679077148
Agent1_Eval_StdReturn : 8.024554252624512
Agent1_Eval_MaxReturn : -0.17542457580566406
Agent1_Eval_MinReturn : -25.862350463867188
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -18.584699630737305
Agent1_Train_StdReturn : 14.791499137878418
Agent1_Train_MaxReturn : 1.8332276344299316
Agent1_Train_MinReturn : -49.72434997558594
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 916500
Agent1_TimeSinceStart : 1432.9375026226044
Agent1_Critic_Loss : 0.6640942096710205
Agent1_Actor_Loss : -0.6347231864929199
Agent1_Alpha_Loss : 0.7649960517883301
Agent1_Temperature : 0.08425590332436797
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 611 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 612 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 613 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 614 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 615 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 616 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 617 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 618 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 619 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 620 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -13.226916313171387
Agent0_Eval_StdReturn : 7.148564338684082
Agent0_Eval_MaxReturn : 0.43575525283813477
Agent0_Eval_MinReturn : -22.915836334228516
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -13.759481430053711
Agent0_Train_StdReturn : 11.202042579650879
Agent0_Train_MaxReturn : 12.210187911987305
Agent0_Train_MinReturn : -25.94925308227539
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 931500
Agent0_TimeSinceStart : 1454.2771441936493
Agent0_Critic_Loss : 0.6633337736129761
Agent0_Actor_Loss : -0.6855429410934448
Agent0_Alpha_Loss : 0.7621778249740601
Agent0_Temperature : 0.08400319604353293
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -18.00420570373535
Agent1_Eval_StdReturn : 12.479301452636719
Agent1_Eval_MaxReturn : -2.665607452392578
Agent1_Eval_MinReturn : -37.08072280883789
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -14.710393905639648
Agent1_Train_StdReturn : 13.903753280639648
Agent1_Train_MaxReturn : 6.209540843963623
Agent1_Train_MinReturn : -44.07708740234375
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 931500
Agent1_TimeSinceStart : 1456.3969645500183
Agent1_Critic_Loss : 0.5808440446853638
Agent1_Actor_Loss : -0.7689645290374756
Agent1_Alpha_Loss : 0.7573369741439819
Agent1_Temperature : 0.08401833408293921
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 621 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 622 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 623 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 624 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 625 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 626 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 627 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 628 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 629 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 630 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -12.31031322479248
Agent0_Eval_StdReturn : 10.515352249145508
Agent0_Eval_MaxReturn : 1.6481800079345703
Agent0_Eval_MinReturn : -30.539731979370117
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -15.135839462280273
Agent0_Train_StdReturn : 17.137086868286133
Agent0_Train_MaxReturn : 10.412729263305664
Agent0_Train_MinReturn : -56.11969757080078
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 946500
Agent0_TimeSinceStart : 1477.710205078125
Agent0_Critic_Loss : 0.5274403095245361
Agent0_Actor_Loss : -0.7648862600326538
Agent0_Alpha_Loss : 0.764406144618988
Agent0_Temperature : 0.08376282963550918
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -11.624983787536621
Agent1_Eval_StdReturn : 11.854768753051758
Agent1_Eval_MaxReturn : 2.9059410095214844
Agent1_Eval_MinReturn : -32.84284973144531
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -14.264246940612793
Agent1_Train_StdReturn : 15.470765113830566
Agent1_Train_MaxReturn : 2.5915870666503906
Agent1_Train_MinReturn : -53.518821716308594
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 946500
Agent1_TimeSinceStart : 1479.8280246257782
Agent1_Critic_Loss : 0.7349923849105835
Agent1_Actor_Loss : -0.8288384675979614
Agent1_Alpha_Loss : 0.7710201740264893
Agent1_Temperature : 0.08378015597309711
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 631 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 632 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 633 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 634 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 635 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 636 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 637 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 638 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 639 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 640 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -18.740392684936523
Agent0_Eval_StdReturn : 12.769253730773926
Agent0_Eval_MaxReturn : -2.961282253265381
Agent0_Eval_MinReturn : -53.207855224609375
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -14.670995712280273
Agent0_Train_StdReturn : 16.329782485961914
Agent0_Train_MaxReturn : 7.8731184005737305
Agent0_Train_MinReturn : -39.06629180908203
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 961500
Agent0_TimeSinceStart : 1501.1410117149353
Agent0_Critic_Loss : 0.6064745187759399
Agent0_Actor_Loss : -0.7111109495162964
Agent0_Alpha_Loss : 0.7835531830787659
Agent0_Temperature : 0.08352165899318535
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -13.654722213745117
Agent1_Eval_StdReturn : 19.223180770874023
Agent1_Eval_MaxReturn : 6.997731685638428
Agent1_Eval_MinReturn : -63.1596794128418
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -8.948615074157715
Agent1_Train_StdReturn : 8.74585247039795
Agent1_Train_MaxReturn : 5.419884204864502
Agent1_Train_MinReturn : -25.24666404724121
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 961500
Agent1_TimeSinceStart : 1503.260179758072
Agent1_Critic_Loss : 0.6202746629714966
Agent1_Actor_Loss : -0.6444589495658875
Agent1_Alpha_Loss : 0.7730826139450073
Agent1_Temperature : 0.08354169545695002
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 641 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 642 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 643 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 644 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 645 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 646 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 647 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 648 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 649 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 650 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -12.925395011901855
Agent0_Eval_StdReturn : 15.954408645629883
Agent0_Eval_MaxReturn : 21.537599563598633
Agent0_Eval_MinReturn : -32.611473083496094
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -26.388545989990234
Agent0_Train_StdReturn : 23.20259666442871
Agent0_Train_MaxReturn : -2.4624271392822266
Agent0_Train_MinReturn : -81.17599487304688
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 976500
Agent0_TimeSinceStart : 1524.5477962493896
Agent0_Critic_Loss : 0.6288175582885742
Agent0_Actor_Loss : -0.6214629411697388
Agent0_Alpha_Loss : 0.7810289859771729
Agent0_Temperature : 0.08327988604215976
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -12.425644874572754
Agent1_Eval_StdReturn : 5.3505859375
Agent1_Eval_MaxReturn : -3.451214075088501
Agent1_Eval_MinReturn : -19.458215713500977
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -12.659565925598145
Agent1_Train_StdReturn : 7.773641586303711
Agent1_Train_MaxReturn : -0.7040500640869141
Agent1_Train_MinReturn : -27.882442474365234
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 976500
Agent1_TimeSinceStart : 1526.6600134372711
Agent1_Critic_Loss : 0.7654469013214111
Agent1_Actor_Loss : -0.7251179814338684
Agent1_Alpha_Loss : 0.7768290042877197
Agent1_Temperature : 0.08330317348686908
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 651 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 652 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 653 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 654 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 655 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 656 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 657 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 658 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 659 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 660 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -12.53868293762207
Agent0_Eval_StdReturn : 21.512258529663086
Agent0_Eval_MaxReturn : 23.199480056762695
Agent0_Eval_MinReturn : -57.57018280029297
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : 1.8014808893203735
Agent0_Train_StdReturn : 14.13829231262207
Agent0_Train_MaxReturn : 29.652233123779297
Agent0_Train_MinReturn : -22.678661346435547
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 991500
Agent0_TimeSinceStart : 1547.9443607330322
Agent0_Critic_Loss : 0.7896523475646973
Agent0_Actor_Loss : -0.6439770460128784
Agent0_Alpha_Loss : 0.7883672714233398
Agent0_Temperature : 0.08303730098372142
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -0.9397662878036499
Agent1_Eval_StdReturn : 15.491172790527344
Agent1_Eval_MaxReturn : 37.140907287597656
Agent1_Eval_MinReturn : -17.201311111450195
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -11.346064567565918
Agent1_Train_StdReturn : 24.9490966796875
Agent1_Train_MaxReturn : 36.14678955078125
Agent1_Train_MinReturn : -50.75545120239258
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 991500
Agent1_TimeSinceStart : 1550.0690007209778
Agent1_Critic_Loss : 0.608016312122345
Agent1_Actor_Loss : -0.7257465124130249
Agent1_Alpha_Loss : 0.7753965854644775
Agent1_Temperature : 0.08306419716694553
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 661 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 662 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 663 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 664 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 665 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 666 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 667 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 668 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 669 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 670 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -8.81252384185791
Agent0_Eval_StdReturn : 10.478836059570312
Agent0_Eval_MaxReturn : 5.367105484008789
Agent0_Eval_MinReturn : -30.22389793395996
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -16.43942642211914
Agent0_Train_StdReturn : 26.102062225341797
Agent0_Train_MaxReturn : 20.12076759338379
Agent0_Train_MinReturn : -60.2382698059082
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1006500
Agent0_TimeSinceStart : 1571.3541254997253
Agent0_Critic_Loss : 0.6711733341217041
Agent0_Actor_Loss : -0.6412985324859619
Agent0_Alpha_Loss : 0.7837647199630737
Agent0_Temperature : 0.08279557870445609
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -16.175609588623047
Agent1_Eval_StdReturn : 10.570747375488281
Agent1_Eval_MaxReturn : -0.07480812072753906
Agent1_Eval_MinReturn : -31.140884399414062
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : 2.914949655532837
Agent1_Train_StdReturn : 16.133243560791016
Agent1_Train_MaxReturn : 27.363046646118164
Agent1_Train_MinReturn : -38.009300231933594
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1006500
Agent1_TimeSinceStart : 1573.478236913681
Agent1_Critic_Loss : 0.48448288440704346
Agent1_Actor_Loss : -0.7605459690093994
Agent1_Alpha_Loss : 0.7857098579406738
Agent1_Temperature : 0.08282494229448285
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 671 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 672 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 673 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 674 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 675 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 676 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 677 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 678 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 679 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 680 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -14.201472282409668
Agent0_Eval_StdReturn : 15.694761276245117
Agent0_Eval_MaxReturn : 6.00663423538208
Agent0_Eval_MinReturn : -53.611671447753906
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -15.017781257629395
Agent0_Train_StdReturn : 12.718465805053711
Agent0_Train_MaxReturn : 6.21983528137207
Agent0_Train_MinReturn : -36.977073669433594
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1021500
Agent0_TimeSinceStart : 1594.7546951770782
Agent0_Critic_Loss : 0.6935122609138489
Agent0_Actor_Loss : -0.704451322555542
Agent0_Alpha_Loss : 0.7801515460014343
Agent0_Temperature : 0.08255500851288215
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -20.570484161376953
Agent1_Eval_StdReturn : 19.44145393371582
Agent1_Eval_MaxReturn : 5.9703850746154785
Agent1_Eval_MinReturn : -60.108463287353516
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -13.607769966125488
Agent1_Train_StdReturn : 16.56395149230957
Agent1_Train_MaxReturn : 22.908737182617188
Agent1_Train_MinReturn : -42.152381896972656
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1021500
Agent1_TimeSinceStart : 1596.8646216392517
Agent1_Critic_Loss : 0.550984799861908
Agent1_Actor_Loss : -0.7770935893058777
Agent1_Alpha_Loss : 0.7934627532958984
Agent1_Temperature : 0.08258501965083896
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 681 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 682 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 683 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 684 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 685 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 686 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 687 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 688 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 689 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 690 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -15.442312240600586
Agent0_Eval_StdReturn : 10.40921688079834
Agent0_Eval_MaxReturn : 10.118128776550293
Agent0_Eval_MinReturn : -29.949298858642578
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -18.39175796508789
Agent0_Train_StdReturn : 31.418973922729492
Agent0_Train_MaxReturn : 34.98305892944336
Agent0_Train_MinReturn : -65.59139251708984
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1036500
Agent0_TimeSinceStart : 1618.1933107376099
Agent0_Critic_Loss : 0.8065589070320129
Agent0_Actor_Loss : -0.7970783710479736
Agent0_Alpha_Loss : 0.7846521139144897
Agent0_Temperature : 0.08231486072445884
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -32.22282791137695
Agent1_Eval_StdReturn : 23.13103485107422
Agent1_Eval_MaxReturn : 4.89385986328125
Agent1_Eval_MinReturn : -64.5650405883789
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -16.347537994384766
Agent1_Train_StdReturn : 23.700775146484375
Agent1_Train_MaxReturn : 11.738007545471191
Agent1_Train_MinReturn : -68.27899932861328
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1036500
Agent1_TimeSinceStart : 1620.2972238063812
Agent1_Critic_Loss : 0.6120232939720154
Agent1_Actor_Loss : -0.7160544395446777
Agent1_Alpha_Loss : 0.7850010395050049
Agent1_Temperature : 0.08234480154442061
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 691 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 692 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 693 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 694 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 695 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 696 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 697 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 698 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 699 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 700 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -24.56451988220215
Agent0_Eval_StdReturn : 16.614418029785156
Agent0_Eval_MaxReturn : 0.23181724548339844
Agent0_Eval_MinReturn : -59.15684127807617
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -31.680309295654297
Agent0_Train_StdReturn : 32.346187591552734
Agent0_Train_MaxReturn : 26.009990692138672
Agent0_Train_MinReturn : -71.8961410522461
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1051500
Agent0_TimeSinceStart : 1641.4458892345428
Agent0_Critic_Loss : 0.6017895936965942
Agent0_Actor_Loss : -0.6241096258163452
Agent0_Alpha_Loss : 0.7776240110397339
Agent0_Temperature : 0.082074335098109
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -10.860429763793945
Agent1_Eval_StdReturn : 17.6812686920166
Agent1_Eval_MaxReturn : 23.337562561035156
Agent1_Eval_MinReturn : -32.304439544677734
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -18.643062591552734
Agent1_Train_StdReturn : 26.1021671295166
Agent1_Train_MaxReturn : 16.511627197265625
Agent1_Train_MinReturn : -66.93994903564453
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1051500
Agent1_TimeSinceStart : 1643.5472493171692
Agent1_Critic_Loss : 0.6663168668746948
Agent1_Actor_Loss : -0.7675338387489319
Agent1_Alpha_Loss : 0.7913153767585754
Agent1_Temperature : 0.08210513631894806
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 701 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 702 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 703 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 704 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 705 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 706 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 707 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 708 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 709 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 710 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -20.05789566040039
Agent0_Eval_StdReturn : 14.646476745605469
Agent0_Eval_MaxReturn : 6.817994594573975
Agent0_Eval_MinReturn : -40.43049621582031
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -19.54693603515625
Agent0_Train_StdReturn : 16.333703994750977
Agent0_Train_MaxReturn : 16.28660011291504
Agent0_Train_MinReturn : -38.387969970703125
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1066500
Agent0_TimeSinceStart : 1664.702434539795
Agent0_Critic_Loss : 0.8304016590118408
Agent0_Actor_Loss : -0.8291743993759155
Agent0_Alpha_Loss : 0.772918701171875
Agent0_Temperature : 0.08183411803065285
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -17.531003952026367
Agent1_Eval_StdReturn : 22.300952911376953
Agent1_Eval_MaxReturn : 10.366347312927246
Agent1_Eval_MinReturn : -53.12535858154297
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -10.900663375854492
Agent1_Train_StdReturn : 13.987112998962402
Agent1_Train_MaxReturn : 10.522375106811523
Agent1_Train_MinReturn : -32.50181198120117
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1066500
Agent1_TimeSinceStart : 1666.7990226745605
Agent1_Critic_Loss : 0.9469372034072876
Agent1_Actor_Loss : -0.7256104350090027
Agent1_Alpha_Loss : 0.7774869799613953
Agent1_Temperature : 0.08186594018758232
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 711 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 712 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 713 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 714 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 715 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 716 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 717 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 718 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 719 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 720 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -28.613183975219727
Agent0_Eval_StdReturn : 29.918291091918945
Agent0_Eval_MaxReturn : -1.901629090309143
Agent0_Eval_MinReturn : -103.51024627685547
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -18.64163589477539
Agent0_Train_StdReturn : 18.580753326416016
Agent0_Train_MaxReturn : 5.448374271392822
Agent0_Train_MinReturn : -43.71097946166992
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1081500
Agent0_TimeSinceStart : 1687.9655950069427
Agent0_Critic_Loss : 0.7535998821258545
Agent0_Actor_Loss : -0.8341034054756165
Agent0_Alpha_Loss : 0.7726315855979919
Agent0_Temperature : 0.08159482305056542
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -24.473222732543945
Agent1_Eval_StdReturn : 33.34992980957031
Agent1_Eval_MaxReturn : 14.917441368103027
Agent1_Eval_MinReturn : -84.16453552246094
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -18.99319076538086
Agent1_Train_StdReturn : 15.52662181854248
Agent1_Train_MaxReturn : 7.566123962402344
Agent1_Train_MinReturn : -39.88541030883789
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1081500
Agent1_TimeSinceStart : 1690.0797872543335
Agent1_Critic_Loss : 0.7207072973251343
Agent1_Actor_Loss : -0.9175344705581665
Agent1_Alpha_Loss : 0.7616899013519287
Agent1_Temperature : 0.08162746668930757
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 721 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 722 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 723 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 724 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 725 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 726 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 727 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 728 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 729 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 730 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -18.211153030395508
Agent0_Eval_StdReturn : 18.812644958496094
Agent0_Eval_MaxReturn : 14.3372220993042
Agent0_Eval_MinReturn : -53.778282165527344
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : 0.8335525393486023
Agent0_Train_StdReturn : 22.86427879333496
Agent0_Train_MaxReturn : 37.20066452026367
Agent0_Train_MinReturn : -45.34810256958008
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1096500
Agent0_TimeSinceStart : 1711.3749403953552
Agent0_Critic_Loss : 0.8489501476287842
Agent0_Actor_Loss : -0.6915085911750793
Agent0_Alpha_Loss : 0.7641445398330688
Agent0_Temperature : 0.08135727526380555
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -22.339481353759766
Agent1_Eval_StdReturn : 17.32491111755371
Agent1_Eval_MaxReturn : 5.379014015197754
Agent1_Eval_MinReturn : -54.56243133544922
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -7.488275051116943
Agent1_Train_StdReturn : 20.05997657775879
Agent1_Train_MaxReturn : 20.654407501220703
Agent1_Train_MinReturn : -43.36651611328125
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1096500
Agent1_TimeSinceStart : 1713.4913589954376
Agent1_Critic_Loss : 0.9450441002845764
Agent1_Actor_Loss : -0.9056471586227417
Agent1_Alpha_Loss : 0.7716138362884521
Agent1_Temperature : 0.0813909454345974
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 731 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 732 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 733 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 734 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 735 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 736 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 737 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 738 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 739 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 740 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -19.59185028076172
Agent0_Eval_StdReturn : 19.30384635925293
Agent0_Eval_MaxReturn : 5.2380900382995605
Agent0_Eval_MinReturn : -60.77667236328125
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -1.1439707279205322
Agent0_Train_StdReturn : 18.610258102416992
Agent0_Train_MaxReturn : 35.71495819091797
Agent0_Train_MinReturn : -27.847841262817383
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1111500
Agent0_TimeSinceStart : 1734.7988958358765
Agent0_Critic_Loss : 1.078979253768921
Agent0_Actor_Loss : -0.6970000863075256
Agent0_Alpha_Loss : 0.7639188766479492
Agent0_Temperature : 0.08112137302845605
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -17.543048858642578
Agent1_Eval_StdReturn : 17.91262435913086
Agent1_Eval_MaxReturn : 21.925668716430664
Agent1_Eval_MinReturn : -46.734397888183594
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -12.970181465148926
Agent1_Train_StdReturn : 14.835790634155273
Agent1_Train_MaxReturn : 12.875883102416992
Agent1_Train_MinReturn : -34.925209045410156
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1111500
Agent1_TimeSinceStart : 1736.9066636562347
Agent1_Critic_Loss : 0.7935011386871338
Agent1_Actor_Loss : -0.7731102108955383
Agent1_Alpha_Loss : 0.7662308216094971
Agent1_Temperature : 0.0811554616950534
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 741 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 742 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 743 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 744 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 745 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 746 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 747 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 748 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 749 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 750 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -20.729290008544922
Agent0_Eval_StdReturn : 21.553884506225586
Agent0_Eval_MaxReturn : 5.116559028625488
Agent0_Eval_MinReturn : -64.87542724609375
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -8.10988998413086
Agent0_Train_StdReturn : 10.898234367370605
Agent0_Train_MaxReturn : 7.303388595581055
Agent0_Train_MinReturn : -28.395282745361328
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1126500
Agent0_TimeSinceStart : 1758.145046710968
Agent0_Critic_Loss : 0.8215765953063965
Agent0_Actor_Loss : -0.8006057143211365
Agent0_Alpha_Loss : 0.765083909034729
Agent0_Temperature : 0.08088696136616665
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -14.887601852416992
Agent1_Eval_StdReturn : 8.910372734069824
Agent1_Eval_MaxReturn : -1.7695904970169067
Agent1_Eval_MinReturn : -30.068485260009766
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -15.313665390014648
Agent1_Train_StdReturn : 14.612607955932617
Agent1_Train_MaxReturn : 11.848662376403809
Agent1_Train_MinReturn : -43.37300491333008
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1126500
Agent1_TimeSinceStart : 1760.2562789916992
Agent1_Critic_Loss : 0.9193445444107056
Agent1_Actor_Loss : -0.9724810123443604
Agent1_Alpha_Loss : 0.7660731077194214
Agent1_Temperature : 0.08092210875215136
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 751 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 752 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 753 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 754 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 755 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 756 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 757 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 758 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 759 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 760 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -11.085664749145508
Agent0_Eval_StdReturn : 14.857172012329102
Agent0_Eval_MaxReturn : 6.290328025817871
Agent0_Eval_MinReturn : -35.86717224121094
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -14.901921272277832
Agent0_Train_StdReturn : 13.146871566772461
Agent0_Train_MaxReturn : 6.415423393249512
Agent0_Train_MinReturn : -41.28936767578125
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1141500
Agent0_TimeSinceStart : 1781.502420425415
Agent0_Critic_Loss : 0.918691873550415
Agent0_Actor_Loss : -0.8358731865882874
Agent0_Alpha_Loss : 0.7629591822624207
Agent0_Temperature : 0.08065471048066072
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -14.561666488647461
Agent1_Eval_StdReturn : 5.664705753326416
Agent1_Eval_MaxReturn : -6.458051681518555
Agent1_Eval_MinReturn : -25.420135498046875
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -22.82880210876465
Agent1_Train_StdReturn : 23.28759002685547
Agent1_Train_MaxReturn : 5.538827896118164
Agent1_Train_MinReturn : -76.0239028930664
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1141500
Agent1_TimeSinceStart : 1783.6052601337433
Agent1_Critic_Loss : 0.8496533632278442
Agent1_Actor_Loss : -0.8925936818122864
Agent1_Alpha_Loss : 0.7615989446640015
Agent1_Temperature : 0.08069020778935491
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 761 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 762 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 763 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 764 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 765 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 766 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 767 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 768 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 769 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 770 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -9.851509094238281
Agent0_Eval_StdReturn : 14.334662437438965
Agent0_Eval_MaxReturn : 10.7625150680542
Agent0_Eval_MinReturn : -41.63930130004883
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -11.609296798706055
Agent0_Train_StdReturn : 11.964192390441895
Agent0_Train_MaxReturn : 10.665520668029785
Agent0_Train_MinReturn : -27.498605728149414
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1156500
Agent0_TimeSinceStart : 1804.8663492202759
Agent0_Critic_Loss : 0.912746250629425
Agent0_Actor_Loss : -0.9122372269630432
Agent0_Alpha_Loss : 0.7590161561965942
Agent0_Temperature : 0.08042481121356479
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -9.085412979125977
Agent1_Eval_StdReturn : 12.266071319580078
Agent1_Eval_MaxReturn : 8.798611640930176
Agent1_Eval_MinReturn : -25.764245986938477
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -5.177054405212402
Agent1_Train_StdReturn : 12.270230293273926
Agent1_Train_MaxReturn : 21.469192504882812
Agent1_Train_MinReturn : -29.872920989990234
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1156500
Agent1_TimeSinceStart : 1806.9833312034607
Agent1_Critic_Loss : 0.8085459470748901
Agent1_Actor_Loss : -0.9313888549804688
Agent1_Alpha_Loss : 0.7546098232269287
Agent1_Temperature : 0.08046008515064779
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 771 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 772 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 773 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 774 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 775 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 776 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 777 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 778 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 779 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 780 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -16.381528854370117
Agent0_Eval_StdReturn : 13.807348251342773
Agent0_Eval_MaxReturn : 5.511739730834961
Agent0_Eval_MinReturn : -37.99274826049805
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -11.24791431427002
Agent0_Train_StdReturn : 11.226007461547852
Agent0_Train_MaxReturn : 4.635156631469727
Agent0_Train_MinReturn : -27.270906448364258
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1171500
Agent0_TimeSinceStart : 1828.2787821292877
Agent0_Critic_Loss : 1.0933706760406494
Agent0_Actor_Loss : -0.7932575941085815
Agent0_Alpha_Loss : 0.7348606586456299
Agent0_Temperature : 0.08019744685641493
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -18.702152252197266
Agent1_Eval_StdReturn : 15.244474411010742
Agent1_Eval_MaxReturn : 9.530086517333984
Agent1_Eval_MinReturn : -40.976871490478516
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -6.170466423034668
Agent1_Train_StdReturn : 12.41672420501709
Agent1_Train_MaxReturn : 15.034854888916016
Agent1_Train_MinReturn : -26.945695877075195
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1171500
Agent1_TimeSinceStart : 1830.395413160324
Agent1_Critic_Loss : 1.3793911933898926
Agent1_Actor_Loss : -0.7614885568618774
Agent1_Alpha_Loss : 0.761381983757019
Agent1_Temperature : 0.08023182351608198
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 781 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 782 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 783 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 784 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 785 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 786 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 787 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 788 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 789 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 790 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -16.049896240234375
Agent0_Eval_StdReturn : 14.786944389343262
Agent0_Eval_MaxReturn : 5.0688371658325195
Agent0_Eval_MinReturn : -51.733619689941406
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -10.734655380249023
Agent0_Train_StdReturn : 9.459723472595215
Agent0_Train_MaxReturn : 5.319699287414551
Agent0_Train_MinReturn : -27.815196990966797
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1186500
Agent0_TimeSinceStart : 1851.7176966667175
Agent0_Critic_Loss : 0.7076902389526367
Agent0_Actor_Loss : -0.9352530241012573
Agent0_Alpha_Loss : 0.7389354705810547
Agent0_Temperature : 0.079972873391681
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -8.549468994140625
Agent1_Eval_StdReturn : 13.33263874053955
Agent1_Eval_MaxReturn : 20.411943435668945
Agent1_Eval_MinReturn : -30.37885093688965
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -11.69304370880127
Agent1_Train_StdReturn : 17.3923397064209
Agent1_Train_MaxReturn : 17.35163116455078
Agent1_Train_MinReturn : -33.52793884277344
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1186500
Agent1_TimeSinceStart : 1853.839511871338
Agent1_Critic_Loss : 1.0982310771942139
Agent1_Actor_Loss : -0.8535616397857666
Agent1_Alpha_Loss : 0.740107536315918
Agent1_Temperature : 0.08000489399239877
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 791 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 792 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 793 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 794 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 795 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 796 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 797 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 798 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 799 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 800 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -12.150350570678711
Agent0_Eval_StdReturn : 16.497713088989258
Agent0_Eval_MaxReturn : 13.647440910339355
Agent0_Eval_MinReturn : -40.670257568359375
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -15.089941024780273
Agent0_Train_StdReturn : 20.381370544433594
Agent0_Train_MaxReturn : 30.826475143432617
Agent0_Train_MinReturn : -44.93117141723633
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1201500
Agent0_TimeSinceStart : 1875.1397712230682
Agent0_Critic_Loss : 0.8991501331329346
Agent0_Actor_Loss : -0.8657402992248535
Agent0_Alpha_Loss : 0.7486981749534607
Agent0_Temperature : 0.07974863932513207
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -9.091646194458008
Agent1_Eval_StdReturn : 15.318448066711426
Agent1_Eval_MaxReturn : 19.67654800415039
Agent1_Eval_MinReturn : -33.401126861572266
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -17.101591110229492
Agent1_Train_StdReturn : 9.420254707336426
Agent1_Train_MaxReturn : -1.9121193885803223
Agent1_Train_MinReturn : -29.75374984741211
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1201500
Agent1_TimeSinceStart : 1877.2672908306122
Agent1_Critic_Loss : 1.54478120803833
Agent1_Actor_Loss : -0.8634933233261108
Agent1_Alpha_Loss : 0.729407787322998
Agent1_Temperature : 0.079781325006502
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 801 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 802 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 803 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 804 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 805 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 806 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 807 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 808 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 809 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 810 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -8.481424331665039
Agent0_Eval_StdReturn : 10.032052040100098
Agent0_Eval_MaxReturn : 9.963314056396484
Agent0_Eval_MinReturn : -24.66253662109375
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -19.34965705871582
Agent0_Train_StdReturn : 16.35230255126953
Agent0_Train_MaxReturn : 2.0951104164123535
Agent0_Train_MinReturn : -55.43972396850586
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1216500
Agent0_TimeSinceStart : 1899.1463611125946
Agent0_Critic_Loss : 0.769088864326477
Agent0_Actor_Loss : -0.8334907293319702
Agent0_Alpha_Loss : 0.7575281858444214
Agent0_Temperature : 0.07952453850765183
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -13.036523818969727
Agent1_Eval_StdReturn : 13.357112884521484
Agent1_Eval_MaxReturn : 11.315698623657227
Agent1_Eval_MinReturn : -30.13408660888672
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -6.679925441741943
Agent1_Train_StdReturn : 10.375575065612793
Agent1_Train_MaxReturn : 5.7785444259643555
Agent1_Train_MinReturn : -22.461009979248047
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1216500
Agent1_TimeSinceStart : 1901.3227984905243
Agent1_Critic_Loss : 0.9464236497879028
Agent1_Actor_Loss : -0.9018146991729736
Agent1_Alpha_Loss : 0.7249716520309448
Agent1_Temperature : 0.07956037361760818
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 811 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 812 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 813 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 814 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 815 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 816 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 817 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 818 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 819 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 820 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -18.905506134033203
Agent0_Eval_StdReturn : 18.44426727294922
Agent0_Eval_MaxReturn : 6.797163486480713
Agent0_Eval_MinReturn : -49.64472198486328
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -16.86981201171875
Agent0_Train_StdReturn : 19.361101150512695
Agent0_Train_MaxReturn : 5.041080474853516
Agent0_Train_MinReturn : -67.99624633789062
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1231500
Agent0_TimeSinceStart : 1923.0171701908112
Agent0_Critic_Loss : 0.8610801100730896
Agent0_Actor_Loss : -0.8274770379066467
Agent0_Alpha_Loss : 0.7424829602241516
Agent0_Temperature : 0.07930102862976117
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -21.487668991088867
Agent1_Eval_StdReturn : 13.901433944702148
Agent1_Eval_MaxReturn : 9.269482612609863
Agent1_Eval_MinReturn : -41.9499397277832
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -10.297761917114258
Agent1_Train_StdReturn : 8.801233291625977
Agent1_Train_MaxReturn : 10.201249122619629
Agent1_Train_MinReturn : -20.414756774902344
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1231500
Agent1_TimeSinceStart : 1925.1689913272858
Agent1_Critic_Loss : 1.2628834247589111
Agent1_Actor_Loss : -0.8361291885375977
Agent1_Alpha_Loss : 0.7332097887992859
Agent1_Temperature : 0.07934151240631343
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 821 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 822 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 823 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 824 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 825 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 826 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 827 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 828 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 829 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 830 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -14.575016975402832
Agent0_Eval_StdReturn : 26.66568374633789
Agent0_Eval_MaxReturn : 9.798906326293945
Agent0_Eval_MinReturn : -88.26226043701172
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -10.491220474243164
Agent0_Train_StdReturn : 11.188508987426758
Agent0_Train_MaxReturn : 8.529216766357422
Agent0_Train_MinReturn : -34.84825897216797
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1246500
Agent0_TimeSinceStart : 1946.8241682052612
Agent0_Critic_Loss : 0.9755396842956543
Agent0_Actor_Loss : -0.971163272857666
Agent0_Alpha_Loss : 0.7364602088928223
Agent0_Temperature : 0.07907865067522168
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -16.969482421875
Agent1_Eval_StdReturn : 9.32276725769043
Agent1_Eval_MaxReturn : -1.0100736618041992
Agent1_Eval_MinReturn : -30.856510162353516
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -10.58298110961914
Agent1_Train_StdReturn : 4.876173496246338
Agent1_Train_MaxReturn : -1.9142866134643555
Agent1_Train_MinReturn : -16.922914505004883
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1246500
Agent1_TimeSinceStart : 1948.9865455627441
Agent1_Critic_Loss : 0.9447014331817627
Agent1_Actor_Loss : -0.9735966920852661
Agent1_Alpha_Loss : 0.7321714162826538
Agent1_Temperature : 0.07912398285021668
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 831 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 832 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 833 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 834 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 835 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 836 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 837 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 838 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 839 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 840 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -11.30725383758545
Agent0_Eval_StdReturn : 15.640364646911621
Agent0_Eval_MaxReturn : 13.214778900146484
Agent0_Eval_MinReturn : -34.729949951171875
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -7.537031650543213
Agent0_Train_StdReturn : 12.038749694824219
Agent0_Train_MaxReturn : 20.01540756225586
Agent0_Train_MinReturn : -22.864782333374023
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1261500
Agent0_TimeSinceStart : 1970.65008187294
Agent0_Critic_Loss : 0.6539629697799683
Agent0_Actor_Loss : -0.87218177318573
Agent0_Alpha_Loss : 0.7327343821525574
Agent0_Temperature : 0.07885686431209332
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -12.166547775268555
Agent1_Eval_StdReturn : 10.184351921081543
Agent1_Eval_MaxReturn : 9.371126174926758
Agent1_Eval_MinReturn : -21.970481872558594
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -10.892800331115723
Agent1_Train_StdReturn : 7.455057621002197
Agent1_Train_MaxReturn : -1.5652594566345215
Agent1_Train_MinReturn : -22.529565811157227
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1261500
Agent1_TimeSinceStart : 1972.8114025592804
Agent1_Critic_Loss : 0.7610769867897034
Agent1_Actor_Loss : -0.9902023673057556
Agent1_Alpha_Loss : 0.7352707982063293
Agent1_Temperature : 0.0789065887513169
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 841 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 842 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 843 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 844 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 845 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 846 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 847 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 848 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 849 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 850 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -9.795187950134277
Agent0_Eval_StdReturn : 14.05151653289795
Agent0_Eval_MaxReturn : 11.284119606018066
Agent0_Eval_MinReturn : -30.083391189575195
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -12.077268600463867
Agent0_Train_StdReturn : 17.70547866821289
Agent0_Train_MaxReturn : 21.286540985107422
Agent0_Train_MinReturn : -37.745975494384766
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1276500
Agent0_TimeSinceStart : 1994.4560430049896
Agent0_Critic_Loss : 0.7916216850280762
Agent0_Actor_Loss : -0.9508698582649231
Agent0_Alpha_Loss : 0.7321597337722778
Agent0_Temperature : 0.07863581692022183
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -13.35545539855957
Agent1_Eval_StdReturn : 12.887584686279297
Agent1_Eval_MaxReturn : -1.312628984451294
Agent1_Eval_MinReturn : -41.824676513671875
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -14.22063159942627
Agent1_Train_StdReturn : 12.459854125976562
Agent1_Train_MaxReturn : 4.334616661071777
Agent1_Train_MinReturn : -34.66630554199219
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1276500
Agent1_TimeSinceStart : 1996.6116914749146
Agent1_Critic_Loss : 0.7965351343154907
Agent1_Actor_Loss : -0.9960634112358093
Agent1_Alpha_Loss : 0.728036642074585
Agent1_Temperature : 0.07868924236878902
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 851 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 852 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 853 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 854 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 855 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 856 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 857 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 858 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 859 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 860 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : 3.377436876296997
Agent0_Eval_StdReturn : 19.981142044067383
Agent0_Eval_MaxReturn : 27.078495025634766
Agent0_Eval_MinReturn : -44.30461120605469
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -0.158617302775383
Agent0_Train_StdReturn : 20.304597854614258
Agent0_Train_MaxReturn : 36.447898864746094
Agent0_Train_MinReturn : -43.71048355102539
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1291500
Agent0_TimeSinceStart : 2018.2515225410461
Agent0_Critic_Loss : 0.6685746908187866
Agent0_Actor_Loss : -0.9852915406227112
Agent0_Alpha_Loss : 0.7384281158447266
Agent0_Temperature : 0.078415401371998
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -13.16071605682373
Agent1_Eval_StdReturn : 19.551029205322266
Agent1_Eval_MaxReturn : 22.261585235595703
Agent1_Eval_MinReturn : -47.334720611572266
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -10.028613090515137
Agent1_Train_StdReturn : 6.133648872375488
Agent1_Train_MaxReturn : -0.9549579620361328
Agent1_Train_MinReturn : -19.735450744628906
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1291500
Agent1_TimeSinceStart : 2020.4022834300995
Agent1_Critic_Loss : 0.9694724082946777
Agent1_Actor_Loss : -0.9423364996910095
Agent1_Alpha_Loss : 0.7350083589553833
Agent1_Temperature : 0.0784724100960566
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 861 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 862 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 863 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 864 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 865 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 866 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 867 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 868 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 869 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 870 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -4.1688995361328125
Agent0_Eval_StdReturn : 11.864398956298828
Agent0_Eval_MaxReturn : 18.129308700561523
Agent0_Eval_MinReturn : -17.719770431518555
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -8.597211837768555
Agent0_Train_StdReturn : 12.235462188720703
Agent0_Train_MaxReturn : 10.864042282104492
Agent0_Train_MinReturn : -35.09634780883789
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1306500
Agent0_TimeSinceStart : 2041.6083834171295
Agent0_Critic_Loss : 0.7489515542984009
Agent0_Actor_Loss : -0.9117146134376526
Agent0_Alpha_Loss : 0.7386837005615234
Agent0_Temperature : 0.07819516423035565
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -17.21455955505371
Agent1_Eval_StdReturn : 13.698384284973145
Agent1_Eval_MaxReturn : 8.084031105041504
Agent1_Eval_MinReturn : -44.1260986328125
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -5.400136470794678
Agent1_Train_StdReturn : 15.490127563476562
Agent1_Train_MaxReturn : 23.289196014404297
Agent1_Train_MinReturn : -28.195701599121094
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1306500
Agent1_TimeSinceStart : 2043.6856966018677
Agent1_Critic_Loss : 0.8676325678825378
Agent1_Actor_Loss : -0.9309941530227661
Agent1_Alpha_Loss : 0.7425716519355774
Agent1_Temperature : 0.07825385176987593
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 871 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 872 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 873 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 874 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 875 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 876 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 877 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 878 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 879 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 880 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -6.872669219970703
Agent0_Eval_StdReturn : 15.155577659606934
Agent0_Eval_MaxReturn : 14.612096786499023
Agent0_Eval_MinReturn : -37.860164642333984
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -6.842585563659668
Agent0_Train_StdReturn : 13.513245582580566
Agent0_Train_MaxReturn : 16.645835876464844
Agent0_Train_MinReturn : -30.71553611755371
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1321500
Agent0_TimeSinceStart : 2064.5913565158844
Agent0_Critic_Loss : 0.7252774238586426
Agent0_Actor_Loss : -0.7905806303024292
Agent0_Alpha_Loss : 0.7451280355453491
Agent0_Temperature : 0.07797526264603075
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -12.993115425109863
Agent1_Eval_StdReturn : 16.995594024658203
Agent1_Eval_MaxReturn : 11.167215347290039
Agent1_Eval_MinReturn : -38.61679458618164
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -16.536867141723633
Agent1_Train_StdReturn : 19.318147659301758
Agent1_Train_MaxReturn : 8.516965866088867
Agent1_Train_MinReturn : -52.06966018676758
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1321500
Agent1_TimeSinceStart : 2066.681787967682
Agent1_Critic_Loss : 1.1646013259887695
Agent1_Actor_Loss : -0.9822549819946289
Agent1_Alpha_Loss : 0.749794602394104
Agent1_Temperature : 0.07803466516218976
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 881 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 882 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 883 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 884 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 885 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 886 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 887 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 888 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 889 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 890 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -11.194991111755371
Agent0_Eval_StdReturn : 10.69239330291748
Agent0_Eval_MaxReturn : 5.013856410980225
Agent0_Eval_MinReturn : -27.102155685424805
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : 2.640721559524536
Agent0_Train_StdReturn : 9.4247465133667
Agent0_Train_MaxReturn : 21.224361419677734
Agent0_Train_MinReturn : -12.23182487487793
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1336500
Agent0_TimeSinceStart : 2087.6986935138702
Agent0_Critic_Loss : 0.8334084749221802
Agent0_Actor_Loss : -1.0291476249694824
Agent0_Alpha_Loss : 0.7371901273727417
Agent0_Temperature : 0.07775651434218493
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -16.628881454467773
Agent1_Eval_StdReturn : 20.831100463867188
Agent1_Eval_MaxReturn : 14.041227340698242
Agent1_Eval_MinReturn : -56.032379150390625
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -31.97952651977539
Agent1_Train_StdReturn : 22.045747756958008
Agent1_Train_MaxReturn : 4.014318466186523
Agent1_Train_MinReturn : -64.47321319580078
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1336500
Agent1_TimeSinceStart : 2089.85995721817
Agent1_Critic_Loss : 0.6326706409454346
Agent1_Actor_Loss : -1.0675034523010254
Agent1_Alpha_Loss : 0.7544616460800171
Agent1_Temperature : 0.07781437836838748
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 891 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 892 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 893 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 894 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 895 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 896 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 897 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 898 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 899 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 900 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -21.3038272857666
Agent0_Eval_StdReturn : 29.788846969604492
Agent0_Eval_MaxReturn : 10.065256118774414
Agent0_Eval_MinReturn : -87.43284606933594
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -13.012924194335938
Agent0_Train_StdReturn : 13.780510902404785
Agent0_Train_MaxReturn : 14.504828453063965
Agent0_Train_MinReturn : -29.218935012817383
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1351500
Agent0_TimeSinceStart : 2111.636254787445
Agent0_Critic_Loss : 0.9722472429275513
Agent0_Actor_Loss : -1.0260003805160522
Agent0_Alpha_Loss : 0.7425593137741089
Agent0_Temperature : 0.07753951858140044
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -19.05908966064453
Agent1_Eval_StdReturn : 23.984018325805664
Agent1_Eval_MaxReturn : 25.27109146118164
Agent1_Eval_MinReturn : -62.63861846923828
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -19.6478214263916
Agent1_Train_StdReturn : 23.15308380126953
Agent1_Train_MaxReturn : 12.893350601196289
Agent1_Train_MinReturn : -53.050392150878906
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1351500
Agent1_TimeSinceStart : 2113.7795379161835
Agent1_Critic_Loss : 0.7778348922729492
Agent1_Actor_Loss : -0.9633383750915527
Agent1_Alpha_Loss : 0.7565040588378906
Agent1_Temperature : 0.07759354304301774
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 901 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 902 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 903 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 904 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 905 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 906 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 907 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 908 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 909 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 910 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -22.5959529876709
Agent0_Eval_StdReturn : 10.524787902832031
Agent0_Eval_MaxReturn : -0.846057653427124
Agent0_Eval_MinReturn : -39.36714172363281
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -20.032909393310547
Agent0_Train_StdReturn : 20.46241569519043
Agent0_Train_MaxReturn : 22.53911781311035
Agent0_Train_MinReturn : -53.79219055175781
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1366500
Agent0_TimeSinceStart : 2135.33819437027
Agent0_Critic_Loss : 0.7759861350059509
Agent0_Actor_Loss : -0.9769884347915649
Agent0_Alpha_Loss : 0.7389833927154541
Agent0_Temperature : 0.07732325006848915
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -29.145553588867188
Agent1_Eval_StdReturn : 20.4165096282959
Agent1_Eval_MaxReturn : 4.881406784057617
Agent1_Eval_MinReturn : -60.57965850830078
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -38.76856231689453
Agent1_Train_StdReturn : 26.782594680786133
Agent1_Train_MaxReturn : -5.702797889709473
Agent1_Train_MinReturn : -83.1451416015625
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1366500
Agent1_TimeSinceStart : 2137.4796850681305
Agent1_Critic_Loss : 1.0370911359786987
Agent1_Actor_Loss : -0.9277138113975525
Agent1_Alpha_Loss : 0.7369436025619507
Agent1_Temperature : 0.07737344974567908
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 911 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 912 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 913 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 914 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 915 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 916 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 917 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 918 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 919 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 920 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -13.955450057983398
Agent0_Eval_StdReturn : 14.668907165527344
Agent0_Eval_MaxReturn : 11.304429054260254
Agent0_Eval_MinReturn : -40.18809509277344
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -13.577486991882324
Agent0_Train_StdReturn : 15.583105087280273
Agent0_Train_MaxReturn : 10.224839210510254
Agent0_Train_MinReturn : -37.73472213745117
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1381500
Agent0_TimeSinceStart : 2158.966572523117
Agent0_Critic_Loss : 0.8009937405586243
Agent0_Actor_Loss : -0.8934041261672974
Agent0_Alpha_Loss : 0.7324005365371704
Agent0_Temperature : 0.07710741369870354
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -24.327259063720703
Agent1_Eval_StdReturn : 23.038570404052734
Agent1_Eval_MaxReturn : 13.955163955688477
Agent1_Eval_MinReturn : -53.63517379760742
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -17.61128807067871
Agent1_Train_StdReturn : 21.353506088256836
Agent1_Train_MaxReturn : 15.913263320922852
Agent1_Train_MinReturn : -49.55812454223633
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1381500
Agent1_TimeSinceStart : 2161.0958726406097
Agent1_Critic_Loss : 1.209924578666687
Agent1_Actor_Loss : -0.8032400608062744
Agent1_Alpha_Loss : 0.7359374165534973
Agent1_Temperature : 0.07715509157786322
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 921 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 922 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 923 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 924 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 925 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 926 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 927 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 928 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 929 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 930 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -35.74639129638672
Agent0_Eval_StdReturn : 21.53893280029297
Agent0_Eval_MaxReturn : -4.643229961395264
Agent0_Eval_MinReturn : -79.17973327636719
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -32.26654052734375
Agent0_Train_StdReturn : 34.276939392089844
Agent0_Train_MaxReturn : 32.54798889160156
Agent0_Train_MinReturn : -87.38323211669922
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1396500
Agent0_TimeSinceStart : 2182.574224948883
Agent0_Critic_Loss : 0.9823324680328369
Agent0_Actor_Loss : -0.8472163677215576
Agent0_Alpha_Loss : 0.7268155813217163
Agent0_Temperature : 0.07689230018925106
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -21.66559600830078
Agent1_Eval_StdReturn : 23.871917724609375
Agent1_Eval_MaxReturn : 29.729616165161133
Agent1_Eval_MinReturn : -57.76145553588867
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -17.980329513549805
Agent1_Train_StdReturn : 11.355016708374023
Agent1_Train_MaxReturn : 3.578927993774414
Agent1_Train_MinReturn : -42.11135482788086
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1396500
Agent1_TimeSinceStart : 2184.702878713608
Agent1_Critic_Loss : 1.1346030235290527
Agent1_Actor_Loss : -1.0556095838546753
Agent1_Alpha_Loss : 0.7264606356620789
Agent1_Temperature : 0.07693854613716977
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 931 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 932 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 933 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 934 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 935 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 936 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 937 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 938 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 939 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 940 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -31.270503997802734
Agent0_Eval_StdReturn : 21.184736251831055
Agent0_Eval_MaxReturn : 6.000641345977783
Agent0_Eval_MinReturn : -54.26925277709961
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -24.534908294677734
Agent0_Train_StdReturn : 17.616352081298828
Agent0_Train_MaxReturn : 2.2769625186920166
Agent0_Train_MinReturn : -60.583152770996094
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1411500
Agent0_TimeSinceStart : 2206.1424419879913
Agent0_Critic_Loss : 1.3430589437484741
Agent0_Actor_Loss : -0.9029510021209717
Agent0_Alpha_Loss : 0.7384291291236877
Agent0_Temperature : 0.07667702165817111
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -25.415727615356445
Agent1_Eval_StdReturn : 25.06747817993164
Agent1_Eval_MaxReturn : 13.25984001159668
Agent1_Eval_MinReturn : -74.29475402832031
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -14.116037368774414
Agent1_Train_StdReturn : 21.55694007873535
Agent1_Train_MaxReturn : 27.301904678344727
Agent1_Train_MinReturn : -47.20875930786133
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1411500
Agent1_TimeSinceStart : 2208.2761771678925
Agent1_Critic_Loss : 1.4205906391143799
Agent1_Actor_Loss : -0.9826823472976685
Agent1_Alpha_Loss : 0.7271881103515625
Agent1_Temperature : 0.07672324133367667
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 941 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 942 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 943 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 944 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 945 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 946 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 947 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 948 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 949 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 950 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -30.982446670532227
Agent0_Eval_StdReturn : 25.074058532714844
Agent0_Eval_MaxReturn : -1.8764846324920654
Agent0_Eval_MinReturn : -73.20570373535156
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -22.730167388916016
Agent0_Train_StdReturn : 22.06521224975586
Agent0_Train_MaxReturn : 22.452259063720703
Agent0_Train_MinReturn : -61.41658401489258
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1426500
Agent0_TimeSinceStart : 2229.776652097702
Agent0_Critic_Loss : 1.316941738128662
Agent0_Actor_Loss : -0.9878000020980835
Agent0_Alpha_Loss : 0.7289561629295349
Agent0_Temperature : 0.07646221336246664
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -13.755589485168457
Agent1_Eval_StdReturn : 19.435253143310547
Agent1_Eval_MaxReturn : 13.119126319885254
Agent1_Eval_MinReturn : -49.970191955566406
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -26.492595672607422
Agent1_Train_StdReturn : 10.11664867401123
Agent1_Train_MaxReturn : -8.475244522094727
Agent1_Train_MinReturn : -41.261329650878906
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1426500
Agent1_TimeSinceStart : 2231.9124948978424
Agent1_Critic_Loss : 1.5576419830322266
Agent1_Actor_Loss : -0.9887363910675049
Agent1_Alpha_Loss : 0.7250492572784424
Agent1_Temperature : 0.07650879768480372
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 951 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 952 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 953 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 954 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 955 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 956 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 957 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 958 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 959 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 960 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -14.824989318847656
Agent0_Eval_StdReturn : 17.66851234436035
Agent0_Eval_MaxReturn : 17.334352493286133
Agent0_Eval_MinReturn : -48.56932830810547
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -12.96753978729248
Agent0_Train_StdReturn : 20.041309356689453
Agent0_Train_MaxReturn : 27.654935836791992
Agent0_Train_MinReturn : -53.27199935913086
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1441500
Agent0_TimeSinceStart : 2253.3994278907776
Agent0_Critic_Loss : 1.493804693222046
Agent0_Actor_Loss : -1.111204981803894
Agent0_Alpha_Loss : 0.7362891435623169
Agent0_Temperature : 0.07624773486091942
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -10.556106567382812
Agent1_Eval_StdReturn : 14.002869606018066
Agent1_Eval_MaxReturn : 19.165973663330078
Agent1_Eval_MinReturn : -29.745826721191406
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -7.584477424621582
Agent1_Train_StdReturn : 15.317058563232422
Agent1_Train_MaxReturn : 19.086811065673828
Agent1_Train_MinReturn : -40.68598556518555
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1441500
Agent1_TimeSinceStart : 2255.539062023163
Agent1_Critic_Loss : 1.4874004125595093
Agent1_Actor_Loss : -0.8533893823623657
Agent1_Alpha_Loss : 0.7323910593986511
Agent1_Temperature : 0.07629476799341185
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 961 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 962 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 963 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 964 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 965 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 966 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 967 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 968 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 969 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 970 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -13.332586288452148
Agent0_Eval_StdReturn : 22.58428955078125
Agent0_Eval_MaxReturn : 16.69947052001953
Agent0_Eval_MinReturn : -45.73582458496094
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -24.869619369506836
Agent0_Train_StdReturn : 22.56700897216797
Agent0_Train_MaxReturn : 7.877784252166748
Agent0_Train_MinReturn : -54.532596588134766
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1456500
Agent0_TimeSinceStart : 2277.020250082016
Agent0_Critic_Loss : 1.4573776721954346
Agent0_Actor_Loss : -1.1746960878372192
Agent0_Alpha_Loss : 0.7268126010894775
Agent0_Temperature : 0.07603403052503438
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -14.525854110717773
Agent1_Eval_StdReturn : 18.762664794921875
Agent1_Eval_MaxReturn : 6.700176239013672
Agent1_Eval_MinReturn : -53.42975616455078
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -15.002105712890625
Agent1_Train_StdReturn : 18.516693115234375
Agent1_Train_MaxReturn : 12.749534606933594
Agent1_Train_MinReturn : -52.21295166015625
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1456500
Agent1_TimeSinceStart : 2279.158966064453
Agent1_Critic_Loss : 1.2434121370315552
Agent1_Actor_Loss : -1.0376551151275635
Agent1_Alpha_Loss : 0.7279102802276611
Agent1_Temperature : 0.07608044996681103
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 971 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 972 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 973 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 974 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 975 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 976 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 977 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 978 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 979 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 980 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -8.078264236450195
Agent0_Eval_StdReturn : 16.90233612060547
Agent0_Eval_MaxReturn : 16.758432388305664
Agent0_Eval_MinReturn : -37.78252029418945
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -11.910024642944336
Agent0_Train_StdReturn : 10.982834815979004
Agent0_Train_MaxReturn : 8.534441947937012
Agent0_Train_MinReturn : -32.334632873535156
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1471500
Agent0_TimeSinceStart : 2300.633189678192
Agent0_Critic_Loss : 1.7464836835861206
Agent0_Actor_Loss : -0.931617021560669
Agent0_Alpha_Loss : 0.7123337984085083
Agent0_Temperature : 0.07582159866316185
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -7.543713569641113
Agent1_Eval_StdReturn : 7.766400337219238
Agent1_Eval_MaxReturn : 5.689845085144043
Agent1_Eval_MinReturn : -19.369163513183594
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -7.840401649475098
Agent1_Train_StdReturn : 13.282013893127441
Agent1_Train_MaxReturn : 11.285798072814941
Agent1_Train_MinReturn : -32.120269775390625
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1471500
Agent1_TimeSinceStart : 2302.774833917618
Agent1_Critic_Loss : 1.416022539138794
Agent1_Actor_Loss : -0.9919862151145935
Agent1_Alpha_Loss : 0.7268154621124268
Agent1_Temperature : 0.07586772003988805
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 981 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 982 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 983 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 984 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 985 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 986 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 987 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 988 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 989 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 990 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -6.035455703735352
Agent0_Eval_StdReturn : 21.89693260192871
Agent0_Eval_MaxReturn : 31.99154281616211
Agent0_Eval_MinReturn : -54.338443756103516
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -10.859064102172852
Agent0_Train_StdReturn : 17.664201736450195
Agent0_Train_MaxReturn : 16.9580135345459
Agent0_Train_MinReturn : -36.6263313293457
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1486500
Agent0_TimeSinceStart : 2324.283475637436
Agent0_Critic_Loss : 1.4621871709823608
Agent0_Actor_Loss : -1.1198499202728271
Agent0_Alpha_Loss : 0.7112252712249756
Agent0_Temperature : 0.0756113839991518
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -13.046841621398926
Agent1_Eval_StdReturn : 13.579036712646484
Agent1_Eval_MaxReturn : 3.594757556915283
Agent1_Eval_MinReturn : -42.2644157409668
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -9.60282039642334
Agent1_Train_StdReturn : 9.598381996154785
Agent1_Train_MaxReturn : -0.24756813049316406
Agent1_Train_MinReturn : -31.62193489074707
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1486500
Agent1_TimeSinceStart : 2326.4269502162933
Agent1_Critic_Loss : 1.1443405151367188
Agent1_Actor_Loss : -1.185337781906128
Agent1_Alpha_Loss : 0.7234877943992615
Agent1_Temperature : 0.0756568693001542
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 991 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 992 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 993 ************

Collecting data to be used for training...

Training agent.../home/harvey/anaconda3/envs/285final/lib/python3.7/site-packages/gym/core.py:318: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  "Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future."
/home/harvey/anaconda3/envs/285final/lib/python3.7/site-packages/gym/wrappers/step_api_compatibility.py:40: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  "Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future."
/home/harvey/anaconda3/envs/285final/lib/python3.7/site-packages/gym/core.py:257: DeprecationWarning: [33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.[0m
  "Function `env.seed(seed)` is marked as deprecated and will be removed in the future. "


Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 994 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 995 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 996 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 997 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 998 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 999 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...
./peersacv2_2ndrun.sh: 38: --seed: not found



LOGGING TO:  /home/harvey/Documents/cs285/CS285-Project/cs285/scripts/../../data/peersac_v2_3agents_eps1_HalfCheetah-v4_12-12-2022_16-23-46 



########################
logging outputs to  /home/harvey/Documents/cs285/CS285-Project/cs285/scripts/../../data/peersac_v2_3agents_eps1_HalfCheetah-v4_12-12-2022_16-23-46
########################
Using GPU id 0


********** Iteration 0 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -37.402889251708984
Agent0_Eval_StdReturn : 29.959867477416992
Agent0_Eval_MaxReturn : 2.8824901580810547
Agent0_Eval_MinReturn : -88.16786193847656
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -68.51490020751953
Agent0_Train_StdReturn : 35.8519172668457
Agent0_Train_MaxReturn : 10.17027473449707
Agent0_Train_MinReturn : -109.59283447265625
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1500
Agent0_TimeSinceStart : 2.1449713706970215
Agent0_Critic_Loss : 1.715803623199463
Agent0_Actor_Loss : -0.3432028293609619
Agent0_Alpha_Loss : 0.9863041639328003
Agent0_Temperature : 0.09997000449985415
Agent0_Initial_DataCollection_AverageReturn : -68.51490020751953
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -54.462310791015625
Agent1_Eval_StdReturn : 37.87112045288086
Agent1_Eval_MaxReturn : 15.620088577270508
Agent1_Eval_MinReturn : -98.72659301757812
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -41.37040710449219
Agent1_Train_StdReturn : 23.476428985595703
Agent1_Train_MaxReturn : -3.7883758544921875
Agent1_Train_MinReturn : -74.03202819824219
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1500
Agent1_TimeSinceStart : 4.169593572616577
Agent1_Critic_Loss : 1.1657971143722534
Agent1_Actor_Loss : -0.489025354385376
Agent1_Alpha_Loss : 0.980064868927002
Agent1_Temperature : 0.09997000449985606
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 1 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 2 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 3 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 4 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 5 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 6 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 7 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 8 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 9 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 10 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -23.91555404663086
Agent0_Eval_StdReturn : 36.396690368652344
Agent0_Eval_MaxReturn : 19.48440170288086
Agent0_Eval_MinReturn : -96.45121765136719
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -50.23561096191406
Agent0_Train_StdReturn : 25.51015853881836
Agent0_Train_MaxReturn : 2.222367286682129
Agent0_Train_MinReturn : -80.17941284179688
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 16500
Agent0_TimeSinceStart : 24.642149448394775
Agent0_Critic_Loss : 0.859268069267273
Agent0_Actor_Loss : -0.4422001540660858
Agent0_Alpha_Loss : 0.984131932258606
Agent0_Temperature : 0.0996705193621572
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -41.76715850830078
Agent1_Eval_StdReturn : 32.45429229736328
Agent1_Eval_MaxReturn : 17.20775604248047
Agent1_Eval_MinReturn : -96.88452911376953
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -50.48727798461914
Agent1_Train_StdReturn : 31.446962356567383
Agent1_Train_MaxReturn : -2.3715856075286865
Agent1_Train_MinReturn : -110.19876098632812
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 16500
Agent1_TimeSinceStart : 26.701791286468506
Agent1_Critic_Loss : 0.8242071270942688
Agent1_Actor_Loss : -0.5978373289108276
Agent1_Alpha_Loss : 0.9913411140441895
Agent1_Temperature : 0.09967041864865771
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 11 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 12 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 13 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 14 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 15 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 16 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 17 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 18 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 19 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 20 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -54.4146728515625
Agent0_Eval_StdReturn : 29.299518585205078
Agent0_Eval_MaxReturn : -3.030252456665039
Agent0_Eval_MinReturn : -112.00616455078125
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -42.122962951660156
Agent0_Train_StdReturn : 33.38285446166992
Agent0_Train_MaxReturn : 8.322027206420898
Agent0_Train_MinReturn : -115.837646484375
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 31500
Agent0_TimeSinceStart : 47.44803786277771
Agent0_Critic_Loss : 0.9875594973564148
Agent0_Actor_Loss : -0.4603153169155121
Agent0_Alpha_Loss : 0.9934805035591125
Agent0_Temperature : 0.09937189903597349
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -44.39208221435547
Agent1_Eval_StdReturn : 37.74639129638672
Agent1_Eval_MaxReturn : 16.940141677856445
Agent1_Eval_MinReturn : -112.73168182373047
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -29.703868865966797
Agent1_Train_StdReturn : 25.628751754760742
Agent1_Train_MaxReturn : 0.7001132965087891
Agent1_Train_MinReturn : -66.21515655517578
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 31500
Agent1_TimeSinceStart : 49.52030849456787
Agent1_Critic_Loss : 0.8050893545150757
Agent1_Actor_Loss : -0.49642840027809143
Agent1_Alpha_Loss : 0.9909679889678955
Agent1_Temperature : 0.09937173779425999
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 21 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 22 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 23 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 24 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 25 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 26 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 27 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 28 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 29 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 30 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -33.71171188354492
Agent0_Eval_StdReturn : 22.554655075073242
Agent0_Eval_MaxReturn : -2.0345535278320312
Agent0_Eval_MinReturn : -73.42320251464844
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -46.329307556152344
Agent0_Train_StdReturn : 18.40324592590332
Agent0_Train_MaxReturn : -5.066147327423096
Agent0_Train_MinReturn : -66.70167541503906
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 46500
Agent0_TimeSinceStart : 70.39909791946411
Agent0_Critic_Loss : 0.7971794605255127
Agent0_Actor_Loss : -0.3955150246620178
Agent0_Alpha_Loss : 0.989852786064148
Agent0_Temperature : 0.09907409799761885
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -36.81714630126953
Agent1_Eval_StdReturn : 23.335851669311523
Agent1_Eval_MaxReturn : -4.7169389724731445
Agent1_Eval_MinReturn : -85.56881713867188
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -53.330711364746094
Agent1_Train_StdReturn : 33.35007858276367
Agent1_Train_MaxReturn : 7.588226318359375
Agent1_Train_MinReturn : -85.77046203613281
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 46500
Agent1_TimeSinceStart : 72.47444558143616
Agent1_Critic_Loss : 0.8441203832626343
Agent1_Actor_Loss : -0.621477484703064
Agent1_Alpha_Loss : 0.9834251403808594
Agent1_Temperature : 0.09907406018154105
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 31 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 32 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 33 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 34 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 35 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 36 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 37 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 38 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 39 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 40 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -43.04814910888672
Agent0_Eval_StdReturn : 32.17839431762695
Agent0_Eval_MaxReturn : 0.7364044189453125
Agent0_Eval_MinReturn : -100.2462158203125
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -38.61564254760742
Agent0_Train_StdReturn : 38.854156494140625
Agent0_Train_MaxReturn : 20.940956115722656
Agent0_Train_MinReturn : -116.27200317382812
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 61500
Agent0_TimeSinceStart : 93.36810636520386
Agent0_Critic_Loss : 0.7907739877700806
Agent0_Actor_Loss : -0.5221840143203735
Agent0_Alpha_Loss : 0.9822091460227966
Agent0_Temperature : 0.09877769418986988
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -34.73299789428711
Agent1_Eval_StdReturn : 41.12437438964844
Agent1_Eval_MaxReturn : 26.9316463470459
Agent1_Eval_MinReturn : -92.31023406982422
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -37.83911895751953
Agent1_Train_StdReturn : 32.18024826049805
Agent1_Train_MaxReturn : 11.516632080078125
Agent1_Train_MinReturn : -101.08418273925781
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 61500
Agent1_TimeSinceStart : 95.44685530662537
Agent1_Critic_Loss : 0.6978700757026672
Agent1_Actor_Loss : -0.5253624320030212
Agent1_Alpha_Loss : 0.9788335561752319
Agent1_Temperature : 0.09877756782259886
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 41 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 42 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 43 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 44 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 45 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 46 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 47 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 48 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 49 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 50 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -46.934967041015625
Agent0_Eval_StdReturn : 31.348405838012695
Agent0_Eval_MaxReturn : -16.98957633972168
Agent0_Eval_MinReturn : -118.02684020996094
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -15.140853881835938
Agent0_Train_StdReturn : 24.39678955078125
Agent0_Train_MaxReturn : 40.97198486328125
Agent0_Train_MinReturn : -53.86602020263672
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 76500
Agent0_TimeSinceStart : 116.31305718421936
Agent0_Critic_Loss : 0.6611195802688599
Agent0_Actor_Loss : -0.5105288028717041
Agent0_Alpha_Loss : 0.9739531874656677
Agent0_Temperature : 0.09848289963040038
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -36.336097717285156
Agent1_Eval_StdReturn : 32.79088592529297
Agent1_Eval_MaxReturn : 24.158000946044922
Agent1_Eval_MinReturn : -70.31455993652344
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -29.5858154296875
Agent1_Train_StdReturn : 35.8078727722168
Agent1_Train_MaxReturn : 44.278663635253906
Agent1_Train_MinReturn : -76.22896575927734
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 76500
Agent1_TimeSinceStart : 118.40725588798523
Agent1_Critic_Loss : 0.6772318482398987
Agent1_Actor_Loss : -0.5262969732284546
Agent1_Alpha_Loss : 0.982785701751709
Agent1_Temperature : 0.09848275821373755
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 51 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 52 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 53 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 54 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 55 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 56 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 57 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 58 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 59 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 60 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -43.72178268432617
Agent0_Eval_StdReturn : 38.8220100402832
Agent0_Eval_MaxReturn : 35.61690902709961
Agent0_Eval_MinReturn : -104.31648254394531
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -52.030113220214844
Agent0_Train_StdReturn : 38.087100982666016
Agent0_Train_MaxReturn : 39.558963775634766
Agent0_Train_MinReturn : -98.00469207763672
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 91500
Agent0_TimeSinceStart : 139.45647978782654
Agent0_Critic_Loss : 0.6245212554931641
Agent0_Actor_Loss : -0.4247426986694336
Agent0_Alpha_Loss : 0.9661376476287842
Agent0_Temperature : 0.09818970216975532
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -30.328983306884766
Agent1_Eval_StdReturn : 15.20173454284668
Agent1_Eval_MaxReturn : -2.770376205444336
Agent1_Eval_MinReturn : -60.83476257324219
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -38.50912094116211
Agent1_Train_StdReturn : 39.56721878051758
Agent1_Train_MaxReturn : 16.756465911865234
Agent1_Train_MinReturn : -130.3779754638672
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 91500
Agent1_TimeSinceStart : 141.53972482681274
Agent1_Critic_Loss : 0.6105620265007019
Agent1_Actor_Loss : -0.5564115047454834
Agent1_Alpha_Loss : 0.9703361988067627
Agent1_Temperature : 0.09818930405035234
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 61 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 62 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 63 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 64 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 65 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 66 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 67 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 68 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 69 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 70 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -52.762855529785156
Agent0_Eval_StdReturn : 44.205299377441406
Agent0_Eval_MaxReturn : 15.64101791381836
Agent0_Eval_MinReturn : -142.34568786621094
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -49.44839859008789
Agent0_Train_StdReturn : 22.104602813720703
Agent0_Train_MaxReturn : -10.296367645263672
Agent0_Train_MinReturn : -82.19908142089844
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 106500
Agent0_TimeSinceStart : 162.44182872772217
Agent0_Critic_Loss : 0.6689488887786865
Agent0_Actor_Loss : -0.30811411142349243
Agent0_Alpha_Loss : 0.9603499174118042
Agent0_Temperature : 0.09789804591066706
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -11.847929954528809
Agent1_Eval_StdReturn : 23.670469284057617
Agent1_Eval_MaxReturn : 20.192594528198242
Agent1_Eval_MinReturn : -53.48154830932617
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -38.02881622314453
Agent1_Train_StdReturn : 31.219186782836914
Agent1_Train_MaxReturn : 3.945117950439453
Agent1_Train_MinReturn : -104.6073989868164
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 106500
Agent1_TimeSinceStart : 164.52820348739624
Agent1_Critic_Loss : 0.6293494701385498
Agent1_Actor_Loss : -0.5705143213272095
Agent1_Alpha_Loss : 0.9569061994552612
Agent1_Temperature : 0.09789783515036317
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 71 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 72 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 73 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 74 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 75 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 76 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 77 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 78 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 79 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 80 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -56.94144821166992
Agent0_Eval_StdReturn : 36.218387603759766
Agent0_Eval_MaxReturn : 5.019533157348633
Agent0_Eval_MinReturn : -114.47781372070312
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -39.97748565673828
Agent0_Train_StdReturn : 35.48146438598633
Agent0_Train_MaxReturn : 11.034629821777344
Agent0_Train_MinReturn : -89.38318634033203
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 121500
Agent0_TimeSinceStart : 185.49811935424805
Agent0_Critic_Loss : 0.5700304508209229
Agent0_Actor_Loss : -0.47591161727905273
Agent0_Alpha_Loss : 0.9490940570831299
Agent0_Temperature : 0.09760947079952008
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -33.63285446166992
Agent1_Eval_StdReturn : 20.059892654418945
Agent1_Eval_MaxReturn : 8.663753509521484
Agent1_Eval_MinReturn : -60.487937927246094
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -22.63499641418457
Agent1_Train_StdReturn : 26.519304275512695
Agent1_Train_MaxReturn : 10.277416229248047
Agent1_Train_MinReturn : -87.01278686523438
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 121500
Agent1_TimeSinceStart : 187.59097170829773
Agent1_Critic_Loss : 0.5817664861679077
Agent1_Actor_Loss : -0.49270516633987427
Agent1_Alpha_Loss : 0.9461566209793091
Agent1_Temperature : 0.09760911461694488
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 81 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 82 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 83 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 84 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 85 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 86 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 87 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 88 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 89 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 90 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -18.83267593383789
Agent0_Eval_StdReturn : 15.16438102722168
Agent0_Eval_MaxReturn : 5.713106632232666
Agent0_Eval_MinReturn : -44.82973098754883
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -24.416912078857422
Agent0_Train_StdReturn : 17.775209426879883
Agent0_Train_MaxReturn : 0.8707981109619141
Agent0_Train_MinReturn : -58.05852127075195
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 136500
Agent0_TimeSinceStart : 208.74099469184875
Agent0_Critic_Loss : 0.5475753545761108
Agent0_Actor_Loss : -0.6363674402236938
Agent0_Alpha_Loss : 0.9323199987411499
Agent0_Temperature : 0.09732457112416312
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -26.827835083007812
Agent1_Eval_StdReturn : 24.32474708557129
Agent1_Eval_MaxReturn : 37.67233657836914
Agent1_Eval_MinReturn : -58.71758270263672
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -29.234508514404297
Agent1_Train_StdReturn : 24.624916076660156
Agent1_Train_MaxReturn : -1.5855069160461426
Agent1_Train_MinReturn : -82.74052429199219
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 136500
Agent1_TimeSinceStart : 210.9225914478302
Agent1_Critic_Loss : 0.5042410492897034
Agent1_Actor_Loss : -0.5955747961997986
Agent1_Alpha_Loss : 0.9367141127586365
Agent1_Temperature : 0.09732402408973201
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 91 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 92 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 93 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 94 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 95 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 96 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 97 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 98 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 99 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 100 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -29.444652557373047
Agent0_Eval_StdReturn : 22.099498748779297
Agent0_Eval_MaxReturn : 7.326150894165039
Agent0_Eval_MinReturn : -58.50382995605469
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -14.757555961608887
Agent0_Train_StdReturn : 11.024503707885742
Agent0_Train_MaxReturn : -0.12058496475219727
Agent0_Train_MinReturn : -41.136993408203125
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 151500
Agent0_TimeSinceStart : 232.1692247390747
Agent0_Critic_Loss : 0.4772423505783081
Agent0_Actor_Loss : -0.5221172571182251
Agent0_Alpha_Loss : 0.8880226612091064
Agent0_Temperature : 0.09704510045243908
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -19.904706954956055
Agent1_Eval_StdReturn : 26.724220275878906
Agent1_Eval_MaxReturn : 10.418119430541992
Agent1_Eval_MinReturn : -87.53263854980469
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -23.447458267211914
Agent1_Train_StdReturn : 19.089914321899414
Agent1_Train_MaxReturn : 1.8365697860717773
Agent1_Train_MinReturn : -56.6861572265625
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 151500
Agent1_TimeSinceStart : 234.22912287712097
Agent1_Critic_Loss : 0.4125604033470154
Agent1_Actor_Loss : -0.707768440246582
Agent1_Alpha_Loss : 0.8971108198165894
Agent1_Temperature : 0.0970436132970357
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 101 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 102 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 103 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 104 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 105 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 106 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 107 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 108 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 109 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 110 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -30.767642974853516
Agent0_Eval_StdReturn : 17.50433921813965
Agent0_Eval_MaxReturn : -0.7569875717163086
Agent0_Eval_MinReturn : -62.048851013183594
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -23.379776000976562
Agent0_Train_StdReturn : 8.86280632019043
Agent0_Train_MaxReturn : -13.470674514770508
Agent0_Train_MinReturn : -38.76492691040039
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 166500
Agent0_TimeSinceStart : 254.97918391227722
Agent0_Critic_Loss : 0.5106647610664368
Agent0_Actor_Loss : -0.45430633425712585
Agent0_Alpha_Loss : 0.8220301866531372
Agent0_Temperature : 0.09677501457882966
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -31.079681396484375
Agent1_Eval_StdReturn : 7.5414934158325195
Agent1_Eval_MaxReturn : -18.115276336669922
Agent1_Eval_MinReturn : -42.8000373840332
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -16.983463287353516
Agent1_Train_StdReturn : 15.189926147460938
Agent1_Train_MaxReturn : -1.2720222473144531
Agent1_Train_MinReturn : -53.7143440246582
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 166500
Agent1_TimeSinceStart : 257.05828738212585
Agent1_Critic_Loss : 0.4368811845779419
Agent1_Actor_Loss : -0.7464069128036499
Agent1_Alpha_Loss : 0.8406094312667847
Agent1_Temperature : 0.09677101011721238
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 111 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 112 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 113 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 114 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 115 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 116 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 117 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 118 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 119 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 120 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -20.88374137878418
Agent0_Eval_StdReturn : 14.174619674682617
Agent0_Eval_MaxReturn : 4.246062755584717
Agent0_Eval_MinReturn : -40.55828094482422
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -20.741641998291016
Agent0_Train_StdReturn : 10.192222595214844
Agent0_Train_MaxReturn : 1.752439022064209
Agent0_Train_MinReturn : -36.037391662597656
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 181500
Agent0_TimeSinceStart : 277.874285697937
Agent0_Critic_Loss : 0.5201339721679688
Agent0_Actor_Loss : -0.422872394323349
Agent0_Alpha_Loss : 0.7886238098144531
Agent0_Temperature : 0.09651591844458478
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -31.238265991210938
Agent1_Eval_StdReturn : 16.09378433227539
Agent1_Eval_MaxReturn : -7.596423625946045
Agent1_Eval_MinReturn : -56.38445281982422
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -23.652019500732422
Agent1_Train_StdReturn : 14.572884559631348
Agent1_Train_MaxReturn : 7.34368371963501
Agent1_Train_MinReturn : -53.63733673095703
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 181500
Agent1_TimeSinceStart : 279.93636298179626
Agent1_Critic_Loss : 0.44199109077453613
Agent1_Actor_Loss : -0.6862270832061768
Agent1_Alpha_Loss : 0.791344165802002
Agent1_Temperature : 0.09650866215102405
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 121 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 122 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 123 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 124 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 125 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 126 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 127 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 128 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 129 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 130 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -27.926334381103516
Agent0_Eval_StdReturn : 9.467351913452148
Agent0_Eval_MaxReturn : -8.975711822509766
Agent0_Eval_MinReturn : -39.29246520996094
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -27.27530288696289
Agent0_Train_StdReturn : 10.95773983001709
Agent0_Train_MaxReturn : -10.473200798034668
Agent0_Train_MinReturn : -47.45228576660156
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 196500
Agent0_TimeSinceStart : 300.65662240982056
Agent0_Critic_Loss : 0.45977354049682617
Agent0_Actor_Loss : -0.4179542362689972
Agent0_Alpha_Loss : 0.7858771085739136
Agent0_Temperature : 0.0962665421815333
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -33.37521743774414
Agent1_Eval_StdReturn : 11.096887588500977
Agent1_Eval_MaxReturn : -13.519022941589355
Agent1_Eval_MinReturn : -52.051910400390625
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -25.00204849243164
Agent1_Train_StdReturn : 6.33139181137085
Agent1_Train_MaxReturn : -15.062255859375
Agent1_Train_MinReturn : -35.988521575927734
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 196500
Agent1_TimeSinceStart : 302.7184669971466
Agent1_Critic_Loss : 0.46405088901519775
Agent1_Actor_Loss : -0.6285388469696045
Agent1_Alpha_Loss : 0.7820494174957275
Agent1_Temperature : 0.09625616381430681
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 131 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 132 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 133 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 134 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 135 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 136 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 137 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 138 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 139 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 140 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -23.519750595092773
Agent0_Eval_StdReturn : 15.197402000427246
Agent0_Eval_MaxReturn : 4.695085525512695
Agent0_Eval_MinReturn : -45.464698791503906
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -32.95502471923828
Agent0_Train_StdReturn : 9.782207489013672
Agent0_Train_MaxReturn : -15.930069923400879
Agent0_Train_MinReturn : -46.802696228027344
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 211500
Agent0_TimeSinceStart : 323.50502276420593
Agent0_Critic_Loss : 0.4417003393173218
Agent0_Actor_Loss : -0.41691136360168457
Agent0_Alpha_Loss : 0.780207633972168
Agent0_Temperature : 0.09602078137677841
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -21.26649284362793
Agent1_Eval_StdReturn : 15.819012641906738
Agent1_Eval_MaxReturn : -0.38559412956237793
Agent1_Eval_MinReturn : -54.704959869384766
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -28.739843368530273
Agent1_Train_StdReturn : 15.642762184143066
Agent1_Train_MaxReturn : -12.895857810974121
Agent1_Train_MinReturn : -65.59808349609375
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 211500
Agent1_TimeSinceStart : 325.5755977630615
Agent1_Critic_Loss : 0.3858966827392578
Agent1_Actor_Loss : -0.5920645594596863
Agent1_Alpha_Loss : 0.8160032629966736
Agent1_Temperature : 0.09600694172873044
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 141 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 142 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 143 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 144 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 145 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 146 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 147 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 148 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 149 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 150 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -28.1939697265625
Agent0_Eval_StdReturn : 13.960450172424316
Agent0_Eval_MaxReturn : -10.298070907592773
Agent0_Eval_MinReturn : -53.43170928955078
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -28.597814559936523
Agent0_Train_StdReturn : 9.148052215576172
Agent0_Train_MaxReturn : -13.346701622009277
Agent0_Train_MinReturn : -46.98386764526367
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 226500
Agent0_TimeSinceStart : 346.28654074668884
Agent0_Critic_Loss : 0.3562975823879242
Agent0_Actor_Loss : -0.5277118682861328
Agent0_Alpha_Loss : 0.7915433049201965
Agent0_Temperature : 0.0957752553508145
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -24.112308502197266
Agent1_Eval_StdReturn : 15.152573585510254
Agent1_Eval_MaxReturn : 6.5834245681762695
Agent1_Eval_MinReturn : -43.852516174316406
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -20.190866470336914
Agent1_Train_StdReturn : 9.12331771850586
Agent1_Train_MaxReturn : 0.14342880249023438
Agent1_Train_MinReturn : -30.758987426757812
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 226500
Agent1_TimeSinceStart : 348.35152649879456
Agent1_Critic_Loss : 0.3734341263771057
Agent1_Actor_Loss : -0.5671097040176392
Agent1_Alpha_Loss : 0.8059293031692505
Agent1_Temperature : 0.09575606524920333
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 151 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 152 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 153 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 154 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 155 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 156 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 157 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 158 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 159 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 160 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -25.204833984375
Agent0_Eval_StdReturn : 11.708731651306152
Agent0_Eval_MaxReturn : -4.343748569488525
Agent0_Eval_MinReturn : -47.12419128417969
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -19.054582595825195
Agent0_Train_StdReturn : 15.484556198120117
Agent0_Train_MaxReturn : 18.519432067871094
Agent0_Train_MinReturn : -38.156734466552734
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 241500
Agent0_TimeSinceStart : 369.103732585907
Agent0_Critic_Loss : 0.4418940544128418
Agent0_Actor_Loss : -0.49285465478897095
Agent0_Alpha_Loss : 0.800083577632904
Agent0_Temperature : 0.09552755966466112
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -27.416723251342773
Agent1_Eval_StdReturn : 11.337067604064941
Agent1_Eval_MaxReturn : -10.333407402038574
Agent1_Eval_MinReturn : -47.17497253417969
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -23.22572898864746
Agent1_Train_StdReturn : 11.740751266479492
Agent1_Train_MaxReturn : -4.436774730682373
Agent1_Train_MinReturn : -46.06743621826172
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 241500
Agent1_TimeSinceStart : 371.1717689037323
Agent1_Critic_Loss : 0.5150948762893677
Agent1_Actor_Loss : -0.6063558459281921
Agent1_Alpha_Loss : 0.8357057571411133
Agent1_Temperature : 0.09550216267422923
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 161 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 162 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 163 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 164 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 165 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 166 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 167 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 168 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 169 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 170 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -22.155757904052734
Agent0_Eval_StdReturn : 16.179601669311523
Agent0_Eval_MaxReturn : 12.295085906982422
Agent0_Eval_MinReturn : -43.36664581298828
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -23.729684829711914
Agent0_Train_StdReturn : 11.769902229309082
Agent0_Train_MaxReturn : -9.187591552734375
Agent0_Train_MinReturn : -53.92979431152344
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 256500
Agent0_TimeSinceStart : 391.8771970272064
Agent0_Critic_Loss : 0.32645654678344727
Agent0_Actor_Loss : -0.34486010670661926
Agent0_Alpha_Loss : 0.7950134873390198
Agent0_Temperature : 0.09527660947134277
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -18.02213478088379
Agent1_Eval_StdReturn : 11.25052261352539
Agent1_Eval_MaxReturn : -3.393223285675049
Agent1_Eval_MinReturn : -41.452423095703125
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -21.535785675048828
Agent1_Train_StdReturn : 12.459490776062012
Agent1_Train_MaxReturn : -0.09596538543701172
Agent1_Train_MinReturn : -37.55775451660156
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 256500
Agent1_TimeSinceStart : 393.9425220489502
Agent1_Critic_Loss : 0.302630752325058
Agent1_Actor_Loss : -0.4640001654624939
Agent1_Alpha_Loss : 0.8033294677734375
Agent1_Temperature : 0.09524684318721896
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 171 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 172 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 173 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 174 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 175 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 176 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 177 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 178 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 179 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 180 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -25.514184951782227
Agent0_Eval_StdReturn : 15.488993644714355
Agent0_Eval_MaxReturn : 2.4832701683044434
Agent0_Eval_MinReturn : -51.94955825805664
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -22.428421020507812
Agent0_Train_StdReturn : 5.748612403869629
Agent0_Train_MaxReturn : -12.550745964050293
Agent0_Train_MinReturn : -32.879493713378906
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 271500
Agent0_TimeSinceStart : 414.6645317077637
Agent0_Critic_Loss : 0.4610532522201538
Agent0_Actor_Loss : -0.4308801293373108
Agent0_Alpha_Loss : 0.7677969932556152
Agent0_Temperature : 0.09502497041679314
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -12.967350959777832
Agent1_Eval_StdReturn : 7.969706058502197
Agent1_Eval_MaxReturn : -3.8396964073181152
Agent1_Eval_MinReturn : -27.958669662475586
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -24.472042083740234
Agent1_Train_StdReturn : 21.196258544921875
Agent1_Train_MaxReturn : 16.082571029663086
Agent1_Train_MinReturn : -62.66522216796875
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 271500
Agent1_TimeSinceStart : 416.7086956501007
Agent1_Critic_Loss : 0.359713613986969
Agent1_Actor_Loss : -0.617526650428772
Agent1_Alpha_Loss : 0.8059419393539429
Agent1_Temperature : 0.09499105460929712
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 181 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 182 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 183 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 184 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 185 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 186 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 187 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 188 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 189 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 190 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -16.642990112304688
Agent0_Eval_StdReturn : 18.252405166625977
Agent0_Eval_MaxReturn : 12.778963088989258
Agent0_Eval_MinReturn : -53.057518005371094
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -16.450563430786133
Agent0_Train_StdReturn : 10.989173889160156
Agent0_Train_MaxReturn : -1.6186285018920898
Agent0_Train_MinReturn : -35.02390670776367
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 286500
Agent0_TimeSinceStart : 437.40969467163086
Agent0_Critic_Loss : 0.35467466711997986
Agent0_Actor_Loss : -0.3836682438850403
Agent0_Alpha_Loss : 0.7777705788612366
Agent0_Temperature : 0.09477488891768783
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -24.005855560302734
Agent1_Eval_StdReturn : 9.256022453308105
Agent1_Eval_MaxReturn : -8.834857940673828
Agent1_Eval_MinReturn : -37.57427215576172
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -22.10171127319336
Agent1_Train_StdReturn : 11.252330780029297
Agent1_Train_MaxReturn : -8.962278366088867
Agent1_Train_MinReturn : -38.74756622314453
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 286500
Agent1_TimeSinceStart : 439.4673080444336
Agent1_Critic_Loss : 0.3140887916088104
Agent1_Actor_Loss : -0.5815757513046265
Agent1_Alpha_Loss : 0.798014223575592
Agent1_Temperature : 0.09473492419390815
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 191 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 192 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 193 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 194 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 195 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 196 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 197 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 198 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 199 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 200 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -23.182857513427734
Agent0_Eval_StdReturn : 19.7374324798584
Agent0_Eval_MaxReturn : 5.638155937194824
Agent0_Eval_MinReturn : -61.58277893066406
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -17.979690551757812
Agent0_Train_StdReturn : 11.477479934692383
Agent0_Train_MaxReturn : -0.46777820587158203
Agent0_Train_MinReturn : -41.137046813964844
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 301500
Agent0_TimeSinceStart : 460.2107093334198
Agent0_Critic_Loss : 0.29808151721954346
Agent0_Actor_Loss : -0.41844767332077026
Agent0_Alpha_Loss : 0.7884504795074463
Agent0_Temperature : 0.09452629468104648
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -19.60263442993164
Agent1_Eval_StdReturn : 9.430371284484863
Agent1_Eval_MaxReturn : -9.52389907836914
Agent1_Eval_MinReturn : -41.741912841796875
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -22.64647674560547
Agent1_Train_StdReturn : 20.30595588684082
Agent1_Train_MaxReturn : 0.556675910949707
Agent1_Train_MinReturn : -65.47058868408203
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 301500
Agent1_TimeSinceStart : 462.2624590396881
Agent1_Critic_Loss : 0.26779142022132874
Agent1_Actor_Loss : -0.5618029832839966
Agent1_Alpha_Loss : 0.8041840195655823
Agent1_Temperature : 0.09447905397417984
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 201 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 202 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 203 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 204 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 205 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 206 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 207 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 208 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 209 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 210 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -16.834436416625977
Agent0_Eval_StdReturn : 5.489479064941406
Agent0_Eval_MaxReturn : -8.895668029785156
Agent0_Eval_MinReturn : -24.466964721679688
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -15.260477066040039
Agent0_Train_StdReturn : 11.939260482788086
Agent0_Train_MaxReturn : 8.224030494689941
Agent0_Train_MinReturn : -32.36702346801758
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 316500
Agent0_TimeSinceStart : 482.9295959472656
Agent0_Critic_Loss : 0.2859153151512146
Agent0_Actor_Loss : -0.3250885307788849
Agent0_Alpha_Loss : 0.7727420330047607
Agent0_Temperature : 0.09427620928925301
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -15.209630966186523
Agent1_Eval_StdReturn : 9.738685607910156
Agent1_Eval_MaxReturn : -2.1514415740966797
Agent1_Eval_MinReturn : -34.27082061767578
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -15.098068237304688
Agent1_Train_StdReturn : 14.361947059631348
Agent1_Train_MaxReturn : 5.692083358764648
Agent1_Train_MinReturn : -41.763580322265625
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 316500
Agent1_TimeSinceStart : 484.98220229148865
Agent1_Critic_Loss : 0.24216662347316742
Agent1_Actor_Loss : -0.5256650447845459
Agent1_Alpha_Loss : 0.7859071493148804
Agent1_Temperature : 0.0942237852170736
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 211 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 212 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 213 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 214 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 215 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 216 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 217 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 218 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 219 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 220 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -24.440153121948242
Agent0_Eval_StdReturn : 10.320208549499512
Agent0_Eval_MaxReturn : -11.086820602416992
Agent0_Eval_MinReturn : -41.61936950683594
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -16.37552261352539
Agent0_Train_StdReturn : 8.917698860168457
Agent0_Train_MaxReturn : -2.2386178970336914
Agent0_Train_MinReturn : -35.08063507080078
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 331500
Agent0_TimeSinceStart : 505.73636627197266
Agent0_Critic_Loss : 0.27453064918518066
Agent0_Actor_Loss : -0.2726828455924988
Agent0_Alpha_Loss : 0.7738845944404602
Agent0_Temperature : 0.09402493249027753
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -13.533790588378906
Agent1_Eval_StdReturn : 16.100234985351562
Agent1_Eval_MaxReturn : 14.346391677856445
Agent1_Eval_MinReturn : -44.485015869140625
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -19.28213119506836
Agent1_Train_StdReturn : 16.66891860961914
Agent1_Train_MaxReturn : 7.489724159240723
Agent1_Train_MinReturn : -53.477020263671875
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 331500
Agent1_TimeSinceStart : 507.8005828857422
Agent1_Critic_Loss : 0.22121810913085938
Agent1_Actor_Loss : -0.5803021788597107
Agent1_Alpha_Loss : 0.7763712406158447
Agent1_Temperature : 0.09396939435605729
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 221 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 222 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 223 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 224 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 225 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 226 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 227 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 228 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 229 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 230 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -23.29505729675293
Agent0_Eval_StdReturn : 9.816821098327637
Agent0_Eval_MaxReturn : -8.378107070922852
Agent0_Eval_MinReturn : -39.772056579589844
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -24.711734771728516
Agent0_Train_StdReturn : 11.530563354492188
Agent0_Train_MaxReturn : -5.971344947814941
Agent0_Train_MinReturn : -44.714805603027344
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 346500
Agent0_TimeSinceStart : 528.5176236629486
Agent0_Critic_Loss : 0.24280433356761932
Agent0_Actor_Loss : -0.38147494196891785
Agent0_Alpha_Loss : 0.7693901658058167
Agent0_Temperature : 0.09377368595503001
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -22.141942977905273
Agent1_Eval_StdReturn : 23.49115562438965
Agent1_Eval_MaxReturn : 13.136165618896484
Agent1_Eval_MinReturn : -54.332908630371094
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -15.963635444641113
Agent1_Train_StdReturn : 12.240062713623047
Agent1_Train_MaxReturn : 2.281604290008545
Agent1_Train_MinReturn : -38.98141098022461
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 346500
Agent1_TimeSinceStart : 530.5802264213562
Agent1_Critic_Loss : 0.2722749710083008
Agent1_Actor_Loss : -0.5057464241981506
Agent1_Alpha_Loss : 0.7964900732040405
Agent1_Temperature : 0.09371546117565607
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 231 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 232 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 233 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 234 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 235 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 236 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 237 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 238 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 239 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 240 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -11.281886100769043
Agent0_Eval_StdReturn : 14.613313674926758
Agent0_Eval_MaxReturn : 12.651994705200195
Agent0_Eval_MinReturn : -31.262256622314453
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -17.237852096557617
Agent0_Train_StdReturn : 11.36341667175293
Agent0_Train_MaxReturn : 9.542861938476562
Agent0_Train_MinReturn : -29.696273803710938
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 361500
Agent0_TimeSinceStart : 551.3148362636566
Agent0_Critic_Loss : 0.24154458940029144
Agent0_Actor_Loss : -0.40000420808792114
Agent0_Alpha_Loss : 0.7888218760490417
Agent0_Temperature : 0.0935213291305389
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -14.188435554504395
Agent1_Eval_StdReturn : 22.246265411376953
Agent1_Eval_MaxReturn : 20.72504997253418
Agent1_Eval_MinReturn : -46.26112365722656
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -27.403432846069336
Agent1_Train_StdReturn : 10.972180366516113
Agent1_Train_MaxReturn : -12.427263259887695
Agent1_Train_MinReturn : -47.70875549316406
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 361500
Agent1_TimeSinceStart : 553.3747029304504
Agent1_Critic_Loss : 0.3092811703681946
Agent1_Actor_Loss : -0.5406836271286011
Agent1_Alpha_Loss : 0.7957779169082642
Agent1_Temperature : 0.09346076573438206
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 241 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 242 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 243 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 244 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 245 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 246 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 247 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 248 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 249 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 250 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -25.413028717041016
Agent0_Eval_StdReturn : 22.131824493408203
Agent0_Eval_MaxReturn : 5.747021675109863
Agent0_Eval_MinReturn : -81.7874755859375
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -16.812053680419922
Agent0_Train_StdReturn : 21.83034324645996
Agent0_Train_MaxReturn : 2.614469051361084
Agent0_Train_MinReturn : -76.43199157714844
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 376500
Agent0_TimeSinceStart : 573.9874665737152
Agent0_Critic_Loss : 0.22156287729740143
Agent0_Actor_Loss : -0.3588688373565674
Agent0_Alpha_Loss : 0.7785330414772034
Agent0_Temperature : 0.09326861589151432
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -25.069589614868164
Agent1_Eval_StdReturn : 12.658096313476562
Agent1_Eval_MaxReturn : -9.556476593017578
Agent1_Eval_MinReturn : -54.11137390136719
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -15.532852172851562
Agent1_Train_StdReturn : 16.342899322509766
Agent1_Train_MaxReturn : 19.179737091064453
Agent1_Train_MinReturn : -35.47442626953125
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 376500
Agent1_TimeSinceStart : 576.0316162109375
Agent1_Critic_Loss : 0.23057740926742554
Agent1_Actor_Loss : -0.5553212761878967
Agent1_Alpha_Loss : 0.8062822818756104
Agent1_Temperature : 0.09320439294076945
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 251 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 252 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 253 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 254 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 255 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 256 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 257 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 258 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 259 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 260 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -22.067852020263672
Agent0_Eval_StdReturn : 19.949623107910156
Agent0_Eval_MaxReturn : 14.280997276306152
Agent0_Eval_MinReturn : -56.17497253417969
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : 0.9741851091384888
Agent0_Train_StdReturn : 12.435647010803223
Agent0_Train_MaxReturn : 25.781818389892578
Agent0_Train_MinReturn : -20.203397750854492
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 391500
Agent0_TimeSinceStart : 596.6293296813965
Agent0_Critic_Loss : 0.2918989062309265
Agent0_Actor_Loss : -0.4057426154613495
Agent0_Alpha_Loss : 0.7847590446472168
Agent0_Temperature : 0.09301579903860381
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -25.279991149902344
Agent1_Eval_StdReturn : 23.872486114501953
Agent1_Eval_MaxReturn : 6.143393516540527
Agent1_Eval_MinReturn : -81.24803161621094
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -21.101408004760742
Agent1_Train_StdReturn : 23.282503128051758
Agent1_Train_MaxReturn : 17.1980037689209
Agent1_Train_MinReturn : -60.66034698486328
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 391500
Agent1_TimeSinceStart : 598.6660280227661
Agent1_Critic_Loss : 0.35103023052215576
Agent1_Actor_Loss : -0.45326465368270874
Agent1_Alpha_Loss : 0.8069970607757568
Agent1_Temperature : 0.09294715321576939
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 261 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 262 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 263 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 264 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 265 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 266 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 267 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 268 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 269 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 270 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -22.86374282836914
Agent0_Eval_StdReturn : 22.648298263549805
Agent0_Eval_MaxReturn : 12.71311092376709
Agent0_Eval_MinReturn : -55.66093444824219
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -6.475412845611572
Agent0_Train_StdReturn : 31.328170776367188
Agent0_Train_MaxReturn : 41.81034469604492
Agent0_Train_MinReturn : -53.318626403808594
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 406500
Agent0_TimeSinceStart : 619.2337779998779
Agent0_Critic_Loss : 0.2768988609313965
Agent0_Actor_Loss : -0.34961432218551636
Agent0_Alpha_Loss : 0.7861909866333008
Agent0_Temperature : 0.09275960842400781
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -13.672192573547363
Agent1_Eval_StdReturn : 14.852211952209473
Agent1_Eval_MaxReturn : 4.951673984527588
Agent1_Eval_MinReturn : -42.61935043334961
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -31.37396812438965
Agent1_Train_StdReturn : 17.7661190032959
Agent1_Train_MaxReturn : 2.020401954650879
Agent1_Train_MinReturn : -61.086387634277344
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 406500
Agent1_TimeSinceStart : 621.2778918743134
Agent1_Critic_Loss : 0.30948084592819214
Agent1_Actor_Loss : -0.6339108943939209
Agent1_Alpha_Loss : 0.7954014539718628
Agent1_Temperature : 0.09268933049967681
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 271 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 272 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 273 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 274 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 275 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 276 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 277 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 278 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 279 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 280 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -24.263530731201172
Agent0_Eval_StdReturn : 16.103404998779297
Agent0_Eval_MaxReturn : -0.28548717498779297
Agent0_Eval_MinReturn : -57.235443115234375
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -31.921184539794922
Agent0_Train_StdReturn : 21.66221046447754
Agent0_Train_MaxReturn : 0.5751638412475586
Agent0_Train_MinReturn : -67.64543151855469
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 421500
Agent0_TimeSinceStart : 641.901451587677
Agent0_Critic_Loss : 0.26769882440567017
Agent0_Actor_Loss : -0.48555663228034973
Agent0_Alpha_Loss : 0.7681726813316345
Agent0_Temperature : 0.09250348509085103
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -18.675392150878906
Agent1_Eval_StdReturn : 18.813934326171875
Agent1_Eval_MaxReturn : 29.488367080688477
Agent1_Eval_MinReturn : -40.71168518066406
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -19.3332576751709
Agent1_Train_StdReturn : 18.772783279418945
Agent1_Train_MaxReturn : 14.11131477355957
Agent1_Train_MinReturn : -44.97947692871094
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 421500
Agent1_TimeSinceStart : 643.9558494091034
Agent1_Critic_Loss : 0.26722121238708496
Agent1_Actor_Loss : -0.5769151449203491
Agent1_Alpha_Loss : 0.8111541271209717
Agent1_Temperature : 0.0924317086128364
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 281 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 282 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 283 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 284 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 285 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 286 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 287 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 288 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 289 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 290 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -25.209232330322266
Agent0_Eval_StdReturn : 21.18598747253418
Agent0_Eval_MaxReturn : 7.603050231933594
Agent0_Eval_MinReturn : -56.278160095214844
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -20.7010440826416
Agent0_Train_StdReturn : 15.803474426269531
Agent0_Train_MaxReturn : 7.370441436767578
Agent0_Train_MinReturn : -47.5135383605957
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 436500
Agent0_TimeSinceStart : 664.5280404090881
Agent0_Critic_Loss : 0.3377474248409271
Agent0_Actor_Loss : -0.4439707398414612
Agent0_Alpha_Loss : 0.7806147336959839
Agent0_Temperature : 0.09224866946727557
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -16.544105529785156
Agent1_Eval_StdReturn : 24.70606231689453
Agent1_Eval_MaxReturn : 17.474958419799805
Agent1_Eval_MinReturn : -71.1980209350586
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -19.186769485473633
Agent1_Train_StdReturn : 19.92337989807129
Agent1_Train_MaxReturn : 4.1470208168029785
Agent1_Train_MinReturn : -72.58134460449219
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 436500
Agent1_TimeSinceStart : 666.5798561573029
Agent1_Critic_Loss : 0.3275989890098572
Agent1_Actor_Loss : -0.5675286650657654
Agent1_Alpha_Loss : 0.7977250814437866
Agent1_Temperature : 0.09217512644443648
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 291 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 292 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 293 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 294 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 295 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 296 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 297 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 298 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 299 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 300 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -20.810169219970703
Agent0_Eval_StdReturn : 19.753664016723633
Agent0_Eval_MaxReturn : 19.3043155670166
Agent0_Eval_MinReturn : -46.19401931762695
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -25.004430770874023
Agent0_Train_StdReturn : 21.718950271606445
Agent0_Train_MaxReturn : 3.190286159515381
Agent0_Train_MinReturn : -64.66511535644531
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 451500
Agent0_TimeSinceStart : 687.2047498226166
Agent0_Critic_Loss : 0.32145002484321594
Agent0_Actor_Loss : -0.4336237609386444
Agent0_Alpha_Loss : 0.7983766794204712
Agent0_Temperature : 0.09199441816617436
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -13.7927885055542
Agent1_Eval_StdReturn : 22.00375747680664
Agent1_Eval_MaxReturn : 11.394819259643555
Agent1_Eval_MinReturn : -64.40591430664062
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -15.238960266113281
Agent1_Train_StdReturn : 20.620824813842773
Agent1_Train_MaxReturn : 14.537681579589844
Agent1_Train_MinReturn : -45.85527801513672
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 451500
Agent1_TimeSinceStart : 689.2384016513824
Agent1_Critic_Loss : 0.32500720024108887
Agent1_Actor_Loss : -0.58185213804245
Agent1_Alpha_Loss : 0.7930086255073547
Agent1_Temperature : 0.09191891347763123
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 301 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 302 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 303 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 304 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 305 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 306 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 307 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 308 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 309 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 310 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -19.438772201538086
Agent0_Eval_StdReturn : 22.85051918029785
Agent0_Eval_MaxReturn : 40.415618896484375
Agent0_Eval_MinReturn : -40.983299255371094
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -12.88322639465332
Agent0_Train_StdReturn : 27.251541137695312
Agent0_Train_MaxReturn : 44.63874435424805
Agent0_Train_MinReturn : -69.44587707519531
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 466500
Agent0_TimeSinceStart : 709.850358247757
Agent0_Critic_Loss : 0.35300883650779724
Agent0_Actor_Loss : -0.4780850410461426
Agent0_Alpha_Loss : 0.7913732528686523
Agent0_Temperature : 0.09173880140103956
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -24.722148895263672
Agent1_Eval_StdReturn : 16.873397827148438
Agent1_Eval_MaxReturn : -1.6646194458007812
Agent1_Eval_MinReturn : -60.575443267822266
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -16.8466854095459
Agent1_Train_StdReturn : 16.341018676757812
Agent1_Train_MaxReturn : 4.055912017822266
Agent1_Train_MinReturn : -52.70538330078125
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 466500
Agent1_TimeSinceStart : 711.9053480625153
Agent1_Critic_Loss : 0.3651657700538635
Agent1_Actor_Loss : -0.5078121423721313
Agent1_Alpha_Loss : 0.7837432026863098
Agent1_Temperature : 0.09166337168990596
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 311 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 312 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 313 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 314 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 315 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 316 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 317 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 318 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 319 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 320 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -16.693052291870117
Agent0_Eval_StdReturn : 18.080591201782227
Agent0_Eval_MaxReturn : 8.324410438537598
Agent0_Eval_MinReturn : -46.566131591796875
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -17.251731872558594
Agent0_Train_StdReturn : 10.113831520080566
Agent0_Train_MaxReturn : 2.060420036315918
Agent0_Train_MinReturn : -33.10677719116211
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 481500
Agent0_TimeSinceStart : 732.5540804862976
Agent0_Critic_Loss : 0.3338434398174286
Agent0_Actor_Loss : -0.5211151242256165
Agent0_Alpha_Loss : 0.7938306331634521
Agent0_Temperature : 0.09148211776484526
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -13.722424507141113
Agent1_Eval_StdReturn : 12.981816291809082
Agent1_Eval_MaxReturn : 3.1821160316467285
Agent1_Eval_MinReturn : -36.329017639160156
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -24.52604103088379
Agent1_Train_StdReturn : 13.167064666748047
Agent1_Train_MaxReturn : -0.6586706638336182
Agent1_Train_MinReturn : -43.49568176269531
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 481500
Agent1_TimeSinceStart : 734.610063791275
Agent1_Critic_Loss : 0.3973739445209503
Agent1_Actor_Loss : -0.6562386751174927
Agent1_Alpha_Loss : 0.7919934988021851
Agent1_Temperature : 0.09140932746725346
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 321 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 322 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 323 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 324 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 325 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 326 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 327 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 328 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 329 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 330 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -23.442127227783203
Agent0_Eval_StdReturn : 12.401371002197266
Agent0_Eval_MaxReturn : -14.896387100219727
Agent0_Eval_MinReturn : -56.32659912109375
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -14.619461059570312
Agent0_Train_StdReturn : 12.37103271484375
Agent0_Train_MaxReturn : 4.220873832702637
Agent0_Train_MinReturn : -42.821449279785156
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 496500
Agent0_TimeSinceStart : 755.2102818489075
Agent0_Critic_Loss : 0.34227651357650757
Agent0_Actor_Loss : -0.49015194177627563
Agent0_Alpha_Loss : 0.7843832969665527
Agent0_Temperature : 0.09122597480362415
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -22.32973289489746
Agent1_Eval_StdReturn : 7.552016258239746
Agent1_Eval_MaxReturn : -7.809701919555664
Agent1_Eval_MinReturn : -33.30739974975586
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -27.224822998046875
Agent1_Train_StdReturn : 18.263124465942383
Agent1_Train_MaxReturn : 1.5657994747161865
Agent1_Train_MinReturn : -61.164878845214844
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 496500
Agent1_TimeSinceStart : 757.2701704502106
Agent1_Critic_Loss : 0.3484386205673218
Agent1_Actor_Loss : -0.6473129987716675
Agent1_Alpha_Loss : 0.7777743339538574
Agent1_Temperature : 0.0911557716470665
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 331 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 332 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 333 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 334 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 335 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 336 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 337 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 338 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 339 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 340 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -16.581073760986328
Agent0_Eval_StdReturn : 8.70246696472168
Agent0_Eval_MaxReturn : -6.4341630935668945
Agent0_Eval_MinReturn : -31.619304656982422
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -14.996225357055664
Agent0_Train_StdReturn : 16.568002700805664
Agent0_Train_MaxReturn : 16.837413787841797
Agent0_Train_MinReturn : -39.869422912597656
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 511500
Agent0_TimeSinceStart : 778.1784546375275
Agent0_Critic_Loss : 0.30954450368881226
Agent0_Actor_Loss : -0.3898780941963196
Agent0_Alpha_Loss : 0.7854546904563904
Agent0_Temperature : 0.09097056333923276
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -21.8474063873291
Agent1_Eval_StdReturn : 14.524008750915527
Agent1_Eval_MaxReturn : 4.271660804748535
Agent1_Eval_MinReturn : -45.8021125793457
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -27.691631317138672
Agent1_Train_StdReturn : 20.68902587890625
Agent1_Train_MaxReturn : -2.3704681396484375
Agent1_Train_MinReturn : -65.98509216308594
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 511500
Agent1_TimeSinceStart : 780.2367424964905
Agent1_Critic_Loss : 0.36609381437301636
Agent1_Actor_Loss : -0.47877973318099976
Agent1_Alpha_Loss : 0.7798566818237305
Agent1_Temperature : 0.09090340606826992
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 341 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 342 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 343 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 344 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 345 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 346 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 347 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 348 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 349 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 350 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -14.07818603515625
Agent0_Eval_StdReturn : 10.909381866455078
Agent0_Eval_MaxReturn : 2.7400918006896973
Agent0_Eval_MinReturn : -32.11608123779297
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -18.106605529785156
Agent0_Train_StdReturn : 10.93648910522461
Agent0_Train_MaxReturn : -0.5720691680908203
Agent0_Train_MinReturn : -39.17164611816406
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 526500
Agent0_TimeSinceStart : 801.0215213298798
Agent0_Critic_Loss : 0.3923066258430481
Agent0_Actor_Loss : -0.5253956317901611
Agent0_Alpha_Loss : 0.7750826478004456
Agent0_Temperature : 0.09071655842535688
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -20.130168914794922
Agent1_Eval_StdReturn : 17.874229431152344
Agent1_Eval_MaxReturn : 5.395743370056152
Agent1_Eval_MinReturn : -58.215084075927734
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -12.712677001953125
Agent1_Train_StdReturn : 6.229047775268555
Agent1_Train_MaxReturn : -4.986265659332275
Agent1_Train_MinReturn : -23.117769241333008
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 526500
Agent1_TimeSinceStart : 803.0980026721954
Agent1_Critic_Loss : 0.4059273898601532
Agent1_Actor_Loss : -0.6257137060165405
Agent1_Alpha_Loss : 0.7796672582626343
Agent1_Temperature : 0.09065143796303281
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 351 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 352 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 353 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 354 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 355 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 356 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 357 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 358 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 359 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 360 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -21.30446434020996
Agent0_Eval_StdReturn : 24.995744705200195
Agent0_Eval_MaxReturn : 30.533470153808594
Agent0_Eval_MinReturn : -58.730831146240234
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -12.3490571975708
Agent0_Train_StdReturn : 15.812942504882812
Agent0_Train_MaxReturn : 19.706954956054688
Agent0_Train_MinReturn : -42.52070617675781
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 541500
Agent0_TimeSinceStart : 823.8782081604004
Agent0_Critic_Loss : 0.353329598903656
Agent0_Actor_Loss : -0.5314981937408447
Agent0_Alpha_Loss : 0.7704370021820068
Agent0_Temperature : 0.09046309404630544
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -27.320510864257812
Agent1_Eval_StdReturn : 12.575575828552246
Agent1_Eval_MaxReturn : -11.832725524902344
Agent1_Eval_MinReturn : -53.462276458740234
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -22.19598388671875
Agent1_Train_StdReturn : 15.032611846923828
Agent1_Train_MaxReturn : -1.3937023878097534
Agent1_Train_MinReturn : -56.22062301635742
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 541500
Agent1_TimeSinceStart : 825.9386007785797
Agent1_Critic_Loss : 0.3880499303340912
Agent1_Actor_Loss : -0.6676984429359436
Agent1_Alpha_Loss : 0.7915647029876709
Agent1_Temperature : 0.09039976981256632
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 361 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 362 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 363 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 364 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 365 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 366 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 367 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 368 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 369 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 370 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -11.054123878479004
Agent0_Eval_StdReturn : 13.579546928405762
Agent0_Eval_MaxReturn : 11.95913028717041
Agent0_Eval_MinReturn : -34.96487045288086
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -14.609376907348633
Agent0_Train_StdReturn : 16.792207717895508
Agent0_Train_MaxReturn : 17.357681274414062
Agent0_Train_MinReturn : -47.03812789916992
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 556500
Agent0_TimeSinceStart : 846.6296155452728
Agent0_Critic_Loss : 0.4483591914176941
Agent0_Actor_Loss : -0.507468581199646
Agent0_Alpha_Loss : 0.777197539806366
Agent0_Temperature : 0.09020923384100507
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -23.706348419189453
Agent1_Eval_StdReturn : 13.375577926635742
Agent1_Eval_MaxReturn : 2.978182077407837
Agent1_Eval_MinReturn : -44.25049591064453
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -17.34799575805664
Agent1_Train_StdReturn : 13.994400024414062
Agent1_Train_MaxReturn : 8.299437522888184
Agent1_Train_MinReturn : -34.95197296142578
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 556500
Agent1_TimeSinceStart : 848.6829195022583
Agent1_Critic_Loss : 0.4095737338066101
Agent1_Actor_Loss : -0.5987250804901123
Agent1_Alpha_Loss : 0.7762559652328491
Agent1_Temperature : 0.09014843909640356
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 371 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 372 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 373 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 374 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 375 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 376 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 377 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 378 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 379 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 380 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -24.579992294311523
Agent0_Eval_StdReturn : 14.21782112121582
Agent0_Eval_MaxReturn : -1.2908400297164917
Agent0_Eval_MinReturn : -47.359840393066406
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -16.921741485595703
Agent0_Train_StdReturn : 12.384235382080078
Agent0_Train_MaxReturn : 7.604168891906738
Agent0_Train_MinReturn : -41.77024841308594
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 571500
Agent0_TimeSinceStart : 869.3084182739258
Agent0_Critic_Loss : 0.4132230281829834
Agent0_Actor_Loss : -0.4720035791397095
Agent0_Alpha_Loss : 0.7683382034301758
Agent0_Temperature : 0.08995699558147861
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -15.715370178222656
Agent1_Eval_StdReturn : 12.728795051574707
Agent1_Eval_MaxReturn : 8.217905044555664
Agent1_Eval_MinReturn : -37.874542236328125
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -19.479143142700195
Agent1_Train_StdReturn : 13.287662506103516
Agent1_Train_MaxReturn : 3.0131590366363525
Agent1_Train_MinReturn : -38.823081970214844
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 571500
Agent1_TimeSinceStart : 871.3562891483307
Agent1_Critic_Loss : 0.3452942669391632
Agent1_Actor_Loss : -0.6767685413360596
Agent1_Alpha_Loss : 0.77814120054245
Agent1_Temperature : 0.08989788822832008
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 381 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 382 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 383 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 384 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 385 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 386 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 387 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 388 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 389 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 390 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -21.56639862060547
Agent0_Eval_StdReturn : 12.57038688659668
Agent0_Eval_MaxReturn : -7.579676628112793
Agent0_Eval_MinReturn : -44.25579071044922
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -12.462485313415527
Agent0_Train_StdReturn : 6.726092338562012
Agent0_Train_MaxReturn : 1.477391242980957
Agent0_Train_MinReturn : -22.951141357421875
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 586500
Agent0_TimeSinceStart : 892.0455319881439
Agent0_Critic_Loss : 0.3417307734489441
Agent0_Actor_Loss : -0.5329445600509644
Agent0_Alpha_Loss : 0.7842623591423035
Agent0_Temperature : 0.08970722158038294
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -19.374677658081055
Agent1_Eval_StdReturn : 14.141448020935059
Agent1_Eval_MaxReturn : -1.4208316802978516
Agent1_Eval_MinReturn : -44.54280471801758
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -23.079906463623047
Agent1_Train_StdReturn : 14.043539047241211
Agent1_Train_MaxReturn : -2.8329505920410156
Agent1_Train_MinReturn : -49.422096252441406
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 586500
Agent1_TimeSinceStart : 894.1010065078735
Agent1_Critic_Loss : 0.40343567728996277
Agent1_Actor_Loss : -0.6550102233886719
Agent1_Alpha_Loss : 0.7581074237823486
Agent1_Temperature : 0.08964927886648394
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 391 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 392 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 393 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 394 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 395 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 396 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 397 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 398 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 399 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 400 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -19.115259170532227
Agent0_Eval_StdReturn : 12.327378273010254
Agent0_Eval_MaxReturn : -5.303356170654297
Agent0_Eval_MinReturn : -46.81766891479492
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -20.7404842376709
Agent0_Train_StdReturn : 22.054216384887695
Agent0_Train_MaxReturn : 21.63334083557129
Agent0_Train_MinReturn : -60.045387268066406
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 601500
Agent0_TimeSinceStart : 914.8076205253601
Agent0_Critic_Loss : 0.3775748312473297
Agent0_Actor_Loss : -0.46556198596954346
Agent0_Alpha_Loss : 0.7683945894241333
Agent0_Temperature : 0.08945790106558134
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -20.37146759033203
Agent1_Eval_StdReturn : 6.914867401123047
Agent1_Eval_MaxReturn : -7.70777702331543
Agent1_Eval_MinReturn : -31.99854278564453
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -19.321147918701172
Agent1_Train_StdReturn : 10.182555198669434
Agent1_Train_MaxReturn : 3.503124952316284
Agent1_Train_MinReturn : -33.83456039428711
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 601500
Agent1_TimeSinceStart : 916.862283706665
Agent1_Critic_Loss : 0.47056689858436584
Agent1_Actor_Loss : -0.5597981810569763
Agent1_Alpha_Loss : 0.7515952587127686
Agent1_Temperature : 0.08940287433933918
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 401 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 402 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 403 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 404 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 405 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 406 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 407 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 408 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 409 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 410 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -14.543493270874023
Agent0_Eval_StdReturn : 12.776885032653809
Agent0_Eval_MaxReturn : 7.924971580505371
Agent0_Eval_MinReturn : -34.679359436035156
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -13.116701126098633
Agent0_Train_StdReturn : 6.936010837554932
Agent0_Train_MaxReturn : -3.6207213401794434
Agent0_Train_MinReturn : -26.188751220703125
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 616500
Agent0_TimeSinceStart : 937.5539391040802
Agent0_Critic_Loss : 0.42409276962280273
Agent0_Actor_Loss : -0.4388878047466278
Agent0_Alpha_Loss : 0.7871904373168945
Agent0_Temperature : 0.0892089356927311
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -19.336782455444336
Agent1_Eval_StdReturn : 10.311163902282715
Agent1_Eval_MaxReturn : 1.9575157165527344
Agent1_Eval_MinReturn : -36.83098220825195
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -17.968019485473633
Agent1_Train_StdReturn : 13.190056800842285
Agent1_Train_MaxReturn : -0.1585240364074707
Agent1_Train_MinReturn : -50.516456604003906
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 616500
Agent1_TimeSinceStart : 939.6263868808746
Agent1_Critic_Loss : 0.4132380187511444
Agent1_Actor_Loss : -0.6205552816390991
Agent1_Alpha_Loss : 0.7551363706588745
Agent1_Temperature : 0.0891579039644749
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 411 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 412 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 413 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 414 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 415 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 416 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 417 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 418 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 419 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 420 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -24.739521026611328
Agent0_Eval_StdReturn : 17.69223403930664
Agent0_Eval_MaxReturn : 11.377243995666504
Agent0_Eval_MinReturn : -55.88905334472656
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -11.430936813354492
Agent0_Train_StdReturn : 16.38728904724121
Agent0_Train_MaxReturn : 23.427337646484375
Agent0_Train_MinReturn : -29.135406494140625
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 631500
Agent0_TimeSinceStart : 960.3461089134216
Agent0_Critic_Loss : 0.43879687786102295
Agent0_Actor_Loss : -0.5059113502502441
Agent0_Alpha_Loss : 0.7675846815109253
Agent0_Temperature : 0.08895819685767006
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -13.182065963745117
Agent1_Eval_StdReturn : 9.990313529968262
Agent1_Eval_MaxReturn : 14.311903953552246
Agent1_Eval_MinReturn : -23.07171630859375
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -18.75420379638672
Agent1_Train_StdReturn : 11.378400802612305
Agent1_Train_MaxReturn : 5.158900260925293
Agent1_Train_MinReturn : -39.781471252441406
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 631500
Agent1_TimeSinceStart : 962.4047522544861
Agent1_Critic_Loss : 0.34421417117118835
Agent1_Actor_Loss : -0.7152687311172485
Agent1_Alpha_Loss : 0.7717792391777039
Agent1_Temperature : 0.08891325016801646
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 421 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 422 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 423 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 424 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 425 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 426 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 427 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 428 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 429 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 430 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -17.3409481048584
Agent0_Eval_StdReturn : 21.05257797241211
Agent0_Eval_MaxReturn : 8.369288444519043
Agent0_Eval_MinReturn : -51.1655158996582
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -17.846616744995117
Agent0_Train_StdReturn : 14.23659896850586
Agent0_Train_MaxReturn : 3.797335624694824
Agent0_Train_MinReturn : -40.024436950683594
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 646500
Agent0_TimeSinceStart : 983.0825860500336
Agent0_Critic_Loss : 0.4214019179344177
Agent0_Actor_Loss : -0.4971740245819092
Agent0_Alpha_Loss : 0.7776720523834229
Agent0_Temperature : 0.08870639334438642
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -20.07147979736328
Agent1_Eval_StdReturn : 14.886123657226562
Agent1_Eval_MaxReturn : 12.131964683532715
Agent1_Eval_MinReturn : -42.36559295654297
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -7.143959045410156
Agent1_Train_StdReturn : 12.218351364135742
Agent1_Train_MaxReturn : 10.142400741577148
Agent1_Train_MinReturn : -28.24764633178711
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 646500
Agent1_TimeSinceStart : 985.1394889354706
Agent1_Critic_Loss : 0.3664857745170593
Agent1_Actor_Loss : -0.554129958152771
Agent1_Alpha_Loss : 0.7729469537734985
Agent1_Temperature : 0.08866776681957375
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 431 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 432 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 433 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 434 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 435 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 436 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 437 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 438 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 439 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 440 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -13.895833015441895
Agent0_Eval_StdReturn : 18.00188446044922
Agent0_Eval_MaxReturn : 11.246768951416016
Agent0_Eval_MinReturn : -45.88405227661133
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -21.802764892578125
Agent0_Train_StdReturn : 11.137162208557129
Agent0_Train_MaxReturn : -7.668822765350342
Agent0_Train_MinReturn : -44.99763488769531
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 661500
Agent0_TimeSinceStart : 1005.8247554302216
Agent0_Critic_Loss : 0.42966312170028687
Agent0_Actor_Loss : -0.38965776562690735
Agent0_Alpha_Loss : 0.7962244749069214
Agent0_Temperature : 0.08845499964931633
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -25.40813636779785
Agent1_Eval_StdReturn : 13.994773864746094
Agent1_Eval_MaxReturn : -3.6241343021392822
Agent1_Eval_MinReturn : -48.03012466430664
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -15.349291801452637
Agent1_Train_StdReturn : 19.365102767944336
Agent1_Train_MaxReturn : 23.495887756347656
Agent1_Train_MinReturn : -46.371002197265625
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 661500
Agent1_TimeSinceStart : 1007.8806688785553
Agent1_Critic_Loss : 0.3168865442276001
Agent1_Actor_Loss : -0.6022745370864868
Agent1_Alpha_Loss : 0.7914738655090332
Agent1_Temperature : 0.08842025115126144
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 441 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 442 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 443 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 444 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 445 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 446 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 447 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 448 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 449 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 450 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -13.786158561706543
Agent0_Eval_StdReturn : 11.450437545776367
Agent0_Eval_MaxReturn : 12.633161544799805
Agent0_Eval_MinReturn : -28.356826782226562
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -15.307952880859375
Agent0_Train_StdReturn : 12.567571640014648
Agent0_Train_MaxReturn : 5.17082405090332
Agent0_Train_MinReturn : -39.96877670288086
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 676500
Agent0_TimeSinceStart : 1028.5003259181976
Agent0_Critic_Loss : 0.4448821246623993
Agent0_Actor_Loss : -0.4277225732803345
Agent0_Alpha_Loss : 0.7700904607772827
Agent0_Temperature : 0.08820391026932957
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -12.066048622131348
Agent1_Eval_StdReturn : 10.13454818725586
Agent1_Eval_MaxReturn : -0.692851185798645
Agent1_Eval_MinReturn : -34.40960693359375
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -18.769927978515625
Agent1_Train_StdReturn : 14.488950729370117
Agent1_Train_MaxReturn : 0.6472107172012329
Agent1_Train_MinReturn : -49.95293426513672
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 676500
Agent1_TimeSinceStart : 1030.539692401886
Agent1_Critic_Loss : 0.33078983426094055
Agent1_Actor_Loss : -0.6683016419410706
Agent1_Alpha_Loss : 0.7840918302536011
Agent1_Temperature : 0.08817169886163385
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 451 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 452 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 453 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 454 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 455 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 456 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 457 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 458 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 459 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 460 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -17.88398551940918
Agent0_Eval_StdReturn : 20.08487892150879
Agent0_Eval_MaxReturn : 9.94140338897705
Agent0_Eval_MinReturn : -61.09196472167969
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -19.56681251525879
Agent0_Train_StdReturn : 15.398813247680664
Agent0_Train_MaxReturn : -1.2075632810592651
Agent0_Train_MinReturn : -52.77657699584961
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 691500
Agent0_TimeSinceStart : 1051.315229177475
Agent0_Critic_Loss : 0.4113115072250366
Agent0_Actor_Loss : -0.5976359248161316
Agent0_Alpha_Loss : 0.7812236547470093
Agent0_Temperature : 0.0879528330811661
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -20.491405487060547
Agent1_Eval_StdReturn : 16.883386611938477
Agent1_Eval_MaxReturn : 20.24196434020996
Agent1_Eval_MinReturn : -37.805564880371094
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -20.426959991455078
Agent1_Train_StdReturn : 15.75003719329834
Agent1_Train_MaxReturn : 4.132874488830566
Agent1_Train_MinReturn : -48.28291320800781
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 691500
Agent1_TimeSinceStart : 1053.4044301509857
Agent1_Critic_Loss : 0.4379335045814514
Agent1_Actor_Loss : -0.614330530166626
Agent1_Alpha_Loss : 0.783568263053894
Agent1_Temperature : 0.08792406498547244
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 461 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 462 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 463 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 464 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 465 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 466 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 467 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 468 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 469 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 470 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -18.815439224243164
Agent0_Eval_StdReturn : 23.300636291503906
Agent0_Eval_MaxReturn : 3.5303401947021484
Agent0_Eval_MinReturn : -73.34518432617188
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -18.290395736694336
Agent0_Train_StdReturn : 12.152237892150879
Agent0_Train_MaxReturn : 0.881169319152832
Agent0_Train_MinReturn : -46.68284225463867
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 706500
Agent0_TimeSinceStart : 1074.290640592575
Agent0_Critic_Loss : 0.40774819254875183
Agent0_Actor_Loss : -0.44190850853919983
Agent0_Alpha_Loss : 0.7736782431602478
Agent0_Temperature : 0.0877017843611888
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -13.658421516418457
Agent1_Eval_StdReturn : 21.106170654296875
Agent1_Eval_MaxReturn : 13.135858535766602
Agent1_Eval_MinReturn : -51.003971099853516
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -19.05201530456543
Agent1_Train_StdReturn : 22.83321762084961
Agent1_Train_MaxReturn : 11.831985473632812
Agent1_Train_MinReturn : -67.1856460571289
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 706500
Agent1_TimeSinceStart : 1076.3635804653168
Agent1_Critic_Loss : 0.4680587649345398
Agent1_Actor_Loss : -0.5731503963470459
Agent1_Alpha_Loss : 0.7825418710708618
Agent1_Temperature : 0.08767698332525069
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 471 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 472 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 473 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 474 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 475 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 476 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 477 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 478 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 479 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 480 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -18.682416915893555
Agent0_Eval_StdReturn : 11.318499565124512
Agent0_Eval_MaxReturn : -0.7295694351196289
Agent0_Eval_MinReturn : -34.107810974121094
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -9.174286842346191
Agent0_Train_StdReturn : 14.659464836120605
Agent0_Train_MaxReturn : 20.658660888671875
Agent0_Train_MinReturn : -24.290142059326172
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 721500
Agent0_TimeSinceStart : 1097.2425355911255
Agent0_Critic_Loss : 0.41108524799346924
Agent0_Actor_Loss : -0.5009208917617798
Agent0_Alpha_Loss : 0.761506199836731
Agent0_Temperature : 0.08745212312459179
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -13.16889762878418
Agent1_Eval_StdReturn : 25.08652687072754
Agent1_Eval_MaxReturn : 7.752100467681885
Agent1_Eval_MinReturn : -73.25115966796875
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -25.594985961914062
Agent1_Train_StdReturn : 23.696395874023438
Agent1_Train_MaxReturn : 15.865166664123535
Agent1_Train_MinReturn : -78.55741882324219
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 721500
Agent1_TimeSinceStart : 1099.3308737277985
Agent1_Critic_Loss : 0.4717423915863037
Agent1_Actor_Loss : -0.5576149821281433
Agent1_Alpha_Loss : 0.7799418568611145
Agent1_Temperature : 0.08742790403830225
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 481 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 482 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 483 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 484 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 485 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 486 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 487 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 488 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 489 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 490 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -16.20736312866211
Agent0_Eval_StdReturn : 11.321547508239746
Agent0_Eval_MaxReturn : -0.41762542724609375
Agent0_Eval_MinReturn : -37.97825622558594
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -23.440439224243164
Agent0_Train_StdReturn : 15.348069190979004
Agent0_Train_MaxReturn : 0.30855655670166016
Agent0_Train_MinReturn : -50.74176788330078
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 736500
Agent0_TimeSinceStart : 1120.2986388206482
Agent0_Critic_Loss : 0.4252140522003174
Agent0_Actor_Loss : -0.4980241358280182
Agent0_Alpha_Loss : 0.7907546758651733
Agent0_Temperature : 0.0872033517137562
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -21.10677719116211
Agent1_Eval_StdReturn : 24.814481735229492
Agent1_Eval_MaxReturn : 6.8977766036987305
Agent1_Eval_MinReturn : -71.96903228759766
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -18.827281951904297
Agent1_Train_StdReturn : 23.51673126220703
Agent1_Train_MaxReturn : 25.513164520263672
Agent1_Train_MinReturn : -60.18876266479492
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 736500
Agent1_TimeSinceStart : 1122.3792779445648
Agent1_Critic_Loss : 0.33870041370391846
Agent1_Actor_Loss : -0.7086285352706909
Agent1_Alpha_Loss : 0.7937291860580444
Agent1_Temperature : 0.08717745348092673
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 491 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 492 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 493 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 494 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 495 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 496 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 497 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 498 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 499 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 500 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -14.339963912963867
Agent0_Eval_StdReturn : 9.389639854431152
Agent0_Eval_MaxReturn : 0.07305145263671875
Agent0_Eval_MinReturn : -27.662446975708008
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -4.801074981689453
Agent0_Train_StdReturn : 17.103464126586914
Agent0_Train_MaxReturn : 31.355316162109375
Agent0_Train_MinReturn : -29.44696044921875
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 751500
Agent0_TimeSinceStart : 1143.3545055389404
Agent0_Critic_Loss : 0.5036094188690186
Agent0_Actor_Loss : -0.6024211049079895
Agent0_Alpha_Loss : 0.7744885683059692
Agent0_Temperature : 0.08695347731057211
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -11.095779418945312
Agent1_Eval_StdReturn : 14.256965637207031
Agent1_Eval_MaxReturn : 17.878345489501953
Agent1_Eval_MinReturn : -28.248044967651367
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -20.342437744140625
Agent1_Train_StdReturn : 22.49197769165039
Agent1_Train_MaxReturn : 10.361501693725586
Agent1_Train_MinReturn : -61.04387283325195
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 751500
Agent1_TimeSinceStart : 1145.4370596408844
Agent1_Critic_Loss : 0.49778661131858826
Agent1_Actor_Loss : -0.6667494177818298
Agent1_Alpha_Loss : 0.8034722805023193
Agent1_Temperature : 0.08692695574665939
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 501 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 502 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 503 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 504 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 505 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 506 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 507 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 508 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 509 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 510 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -15.561635971069336
Agent0_Eval_StdReturn : 16.38744354248047
Agent0_Eval_MaxReturn : 10.529985427856445
Agent0_Eval_MinReturn : -53.8966064453125
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -13.449819564819336
Agent0_Train_StdReturn : 12.425263404846191
Agent0_Train_MaxReturn : 2.3360347747802734
Agent0_Train_MinReturn : -33.532867431640625
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 766500
Agent0_TimeSinceStart : 1166.4206745624542
Agent0_Critic_Loss : 0.5732828974723816
Agent0_Actor_Loss : -0.6306812763214111
Agent0_Alpha_Loss : 0.7880491018295288
Agent0_Temperature : 0.08670384688974973
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -29.15061378479004
Agent1_Eval_StdReturn : 19.74449920654297
Agent1_Eval_MaxReturn : 3.476235866546631
Agent1_Eval_MinReturn : -60.068397521972656
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -18.383899688720703
Agent1_Train_StdReturn : 12.023356437683105
Agent1_Train_MaxReturn : 2.431588649749756
Agent1_Train_MinReturn : -43.59556579589844
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 766500
Agent1_TimeSinceStart : 1168.501413822174
Agent1_Critic_Loss : 0.4731128215789795
Agent1_Actor_Loss : -0.5569718480110168
Agent1_Alpha_Loss : 0.7900295257568359
Agent1_Temperature : 0.0866763369601835
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 511 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 512 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 513 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 514 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 515 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 516 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 517 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 518 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 519 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 520 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -25.724254608154297
Agent0_Eval_StdReturn : 16.67275047302246
Agent0_Eval_MaxReturn : -2.6990184783935547
Agent0_Eval_MinReturn : -58.368778228759766
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -22.157188415527344
Agent0_Train_StdReturn : 14.856510162353516
Agent0_Train_MaxReturn : 9.229297637939453
Agent0_Train_MinReturn : -36.95586013793945
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 781500
Agent0_TimeSinceStart : 1189.472989320755
Agent0_Critic_Loss : 0.5486425161361694
Agent0_Actor_Loss : -0.4540291726589203
Agent0_Alpha_Loss : 0.7873449921607971
Agent0_Temperature : 0.08645343124952692
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -24.719234466552734
Agent1_Eval_StdReturn : 18.564924240112305
Agent1_Eval_MaxReturn : -0.3859872817993164
Agent1_Eval_MinReturn : -68.37382507324219
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -25.94744873046875
Agent1_Train_StdReturn : 13.784905433654785
Agent1_Train_MaxReturn : 3.7336645126342773
Agent1_Train_MinReturn : -42.03048324584961
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 781500
Agent1_TimeSinceStart : 1191.54350066185
Agent1_Critic_Loss : 0.45510631799697876
Agent1_Actor_Loss : -0.5846490859985352
Agent1_Alpha_Loss : 0.7934322357177734
Agent1_Temperature : 0.08642612986770705
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 521 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 522 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 523 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 524 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 525 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 526 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 527 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 528 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 529 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 530 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -16.114459991455078
Agent0_Eval_StdReturn : 8.550165176391602
Agent0_Eval_MaxReturn : 0.7789397239685059
Agent0_Eval_MinReturn : -26.09779930114746
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -15.465130805969238
Agent0_Train_StdReturn : 8.458101272583008
Agent0_Train_MaxReturn : -1.7432724237442017
Agent0_Train_MinReturn : -30.99311065673828
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 796500
Agent0_TimeSinceStart : 1212.4942371845245
Agent0_Critic_Loss : 0.632193922996521
Agent0_Actor_Loss : -0.5300925970077515
Agent0_Alpha_Loss : 0.7838946580886841
Agent0_Temperature : 0.08620367021153828
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -13.673948287963867
Agent1_Eval_StdReturn : 16.73320960998535
Agent1_Eval_MaxReturn : 5.387729644775391
Agent1_Eval_MinReturn : -38.37886047363281
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -19.793960571289062
Agent1_Train_StdReturn : 13.224245071411133
Agent1_Train_MaxReturn : -4.173349380493164
Agent1_Train_MinReturn : -50.776123046875
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 796500
Agent1_TimeSinceStart : 1214.5697758197784
Agent1_Critic_Loss : 0.5272152423858643
Agent1_Actor_Loss : -0.7076741456985474
Agent1_Alpha_Loss : 0.7898743748664856
Agent1_Temperature : 0.08617654939087291
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 531 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 532 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 533 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 534 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 535 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 536 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 537 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 538 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 539 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 540 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -10.869070053100586
Agent0_Eval_StdReturn : 13.326254844665527
Agent0_Eval_MaxReturn : 23.625072479248047
Agent0_Eval_MinReturn : -22.344097137451172
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -6.8660149574279785
Agent0_Train_StdReturn : 18.619983673095703
Agent0_Train_MaxReturn : 30.588409423828125
Agent0_Train_MinReturn : -46.0888671875
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 811500
Agent0_TimeSinceStart : 1235.5418586730957
Agent0_Critic_Loss : 0.5437564849853516
Agent0_Actor_Loss : -0.6202126741409302
Agent0_Alpha_Loss : 0.7936533689498901
Agent0_Temperature : 0.0859546386811064
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -19.242494583129883
Agent1_Eval_StdReturn : 10.006893157958984
Agent1_Eval_MaxReturn : 0.593543529510498
Agent1_Eval_MinReturn : -31.296653747558594
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -9.834394454956055
Agent1_Train_StdReturn : 13.580496788024902
Agent1_Train_MaxReturn : 12.746612548828125
Agent1_Train_MinReturn : -29.460826873779297
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 811500
Agent1_TimeSinceStart : 1237.6316306591034
Agent1_Critic_Loss : 0.563883364200592
Agent1_Actor_Loss : -0.5071003437042236
Agent1_Alpha_Loss : 0.7850542068481445
Agent1_Temperature : 0.08592822882099896
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 541 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 542 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 543 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 544 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 545 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 546 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 547 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 548 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 549 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 550 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -33.82734680175781
Agent0_Eval_StdReturn : 32.970245361328125
Agent0_Eval_MaxReturn : 25.756946563720703
Agent0_Eval_MinReturn : -88.48602294921875
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -17.905197143554688
Agent0_Train_StdReturn : 16.327051162719727
Agent0_Train_MaxReturn : 14.756505966186523
Agent0_Train_MinReturn : -40.087520599365234
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 826500
Agent0_TimeSinceStart : 1258.6530230045319
Agent0_Critic_Loss : 0.5098102688789368
Agent0_Actor_Loss : -0.6237843632698059
Agent0_Alpha_Loss : 0.7938812971115112
Agent0_Temperature : 0.08570516829736073
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -13.661267280578613
Agent1_Eval_StdReturn : 14.614984512329102
Agent1_Eval_MaxReturn : 14.053361892700195
Agent1_Eval_MinReturn : -35.65163803100586
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -16.562589645385742
Agent1_Train_StdReturn : 16.47593116760254
Agent1_Train_MaxReturn : 11.840869903564453
Agent1_Train_MinReturn : -52.070823669433594
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 826500
Agent1_TimeSinceStart : 1260.7517051696777
Agent1_Critic_Loss : 0.6297222375869751
Agent1_Actor_Loss : -0.6046905517578125
Agent1_Alpha_Loss : 0.7677838802337646
Agent1_Temperature : 0.08568364807526578
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 551 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 552 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 553 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 554 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 555 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 556 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 557 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 558 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 559 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 560 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -7.691758155822754
Agent0_Eval_StdReturn : 14.637139320373535
Agent0_Eval_MaxReturn : 15.186752319335938
Agent0_Eval_MinReturn : -34.470680236816406
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -20.88557243347168
Agent0_Train_StdReturn : 18.824249267578125
Agent0_Train_MaxReturn : 11.659745216369629
Agent0_Train_MinReturn : -44.2237548828125
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 841500
Agent0_TimeSinceStart : 1281.8160586357117
Agent0_Critic_Loss : 0.5604289770126343
Agent0_Actor_Loss : -0.5987553596496582
Agent0_Alpha_Loss : 0.7861544489860535
Agent0_Temperature : 0.08545730961267572
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -15.43884563446045
Agent1_Eval_StdReturn : 9.639246940612793
Agent1_Eval_MaxReturn : -1.574556827545166
Agent1_Eval_MinReturn : -31.907304763793945
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -14.988142013549805
Agent1_Train_StdReturn : 9.886146545410156
Agent1_Train_MaxReturn : 0.6878180503845215
Agent1_Train_MinReturn : -28.871286392211914
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 841500
Agent1_TimeSinceStart : 1283.911103963852
Agent1_Critic_Loss : 0.4698182940483093
Agent1_Actor_Loss : -0.7229561805725098
Agent1_Alpha_Loss : 0.7739958763122559
Agent1_Temperature : 0.08544221103187576
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 561 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 562 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 563 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 564 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 565 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 566 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 567 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 568 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 569 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 570 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -7.683245658874512
Agent0_Eval_StdReturn : 14.33403491973877
Agent0_Eval_MaxReturn : 20.598709106445312
Agent0_Eval_MinReturn : -25.549423217773438
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -13.317173957824707
Agent0_Train_StdReturn : 17.1456298828125
Agent0_Train_MaxReturn : 16.223739624023438
Agent0_Train_MinReturn : -37.31197738647461
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 856500
Agent0_TimeSinceStart : 1304.9643394947052
Agent0_Critic_Loss : 0.5230754613876343
Agent0_Actor_Loss : -0.6297534704208374
Agent0_Alpha_Loss : 0.7831270694732666
Agent0_Temperature : 0.08521053703175725
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -17.921092987060547
Agent1_Eval_StdReturn : 8.759084701538086
Agent1_Eval_MaxReturn : 1.4177188873291016
Agent1_Eval_MinReturn : -29.664348602294922
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -18.23112678527832
Agent1_Train_StdReturn : 6.783214569091797
Agent1_Train_MaxReturn : -5.4629364013671875
Agent1_Train_MinReturn : -29.022781372070312
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 856500
Agent1_TimeSinceStart : 1307.0634126663208
Agent1_Critic_Loss : 0.6769263744354248
Agent1_Actor_Loss : -0.6456489562988281
Agent1_Alpha_Loss : 0.7437583804130554
Agent1_Temperature : 0.08520309350759865
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 571 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 572 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 573 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 574 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 575 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 576 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 577 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 578 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 579 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 580 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -12.088865280151367
Agent0_Eval_StdReturn : 13.65489387512207
Agent0_Eval_MaxReturn : 11.902603149414062
Agent0_Eval_MinReturn : -34.05599594116211
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -7.099648952484131
Agent0_Train_StdReturn : 10.28886604309082
Agent0_Train_MaxReturn : 8.74123764038086
Agent0_Train_MinReturn : -21.67629623413086
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 871500
Agent0_TimeSinceStart : 1328.1530640125275
Agent0_Critic_Loss : 0.48443347215652466
Agent0_Actor_Loss : -0.7784448266029358
Agent0_Alpha_Loss : 0.7677946090698242
Agent0_Temperature : 0.08496468114836267
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -17.273923873901367
Agent1_Eval_StdReturn : 12.565878868103027
Agent1_Eval_MaxReturn : 2.638324022293091
Agent1_Eval_MinReturn : -38.21788024902344
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -12.988679885864258
Agent1_Train_StdReturn : 10.995747566223145
Agent1_Train_MaxReturn : 4.808548927307129
Agent1_Train_MinReturn : -27.39142608642578
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 871500
Agent1_TimeSinceStart : 1330.2509293556213
Agent1_Critic_Loss : 0.7638620138168335
Agent1_Actor_Loss : -0.611748993396759
Agent1_Alpha_Loss : 0.7475528717041016
Agent1_Temperature : 0.08496626201238747
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 581 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 582 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 583 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 584 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 585 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 586 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 587 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 588 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 589 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 590 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -14.005993843078613
Agent0_Eval_StdReturn : 13.170211791992188
Agent0_Eval_MaxReturn : 11.287948608398438
Agent0_Eval_MinReturn : -31.37089729309082
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -12.559844017028809
Agent0_Train_StdReturn : 10.286505699157715
Agent0_Train_MaxReturn : 4.232614994049072
Agent0_Train_MinReturn : -32.613887786865234
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 886500
Agent0_TimeSinceStart : 1351.3647191524506
Agent0_Critic_Loss : 0.6215417385101318
Agent0_Actor_Loss : -0.7103729248046875
Agent0_Alpha_Loss : 0.7698262333869934
Agent0_Temperature : 0.0847222085787723
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -11.348682403564453
Agent1_Eval_StdReturn : 15.924738883972168
Agent1_Eval_MaxReturn : 20.049898147583008
Agent1_Eval_MinReturn : -33.135318756103516
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -15.68036937713623
Agent1_Train_StdReturn : 12.016819953918457
Agent1_Train_MaxReturn : -2.252215623855591
Agent1_Train_MinReturn : -43.05107879638672
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 886500
Agent1_TimeSinceStart : 1353.4684500694275
Agent1_Critic_Loss : 0.5983598232269287
Agent1_Actor_Loss : -0.6520698070526123
Agent1_Alpha_Loss : 0.7689921855926514
Agent1_Temperature : 0.08472939575388289
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 591 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 592 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 593 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 594 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 595 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 596 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 597 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 598 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 599 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 600 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -13.444218635559082
Agent0_Eval_StdReturn : 8.9242582321167
Agent0_Eval_MaxReturn : 6.965387344360352
Agent0_Eval_MinReturn : -27.07086753845215
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -16.425039291381836
Agent0_Train_StdReturn : 9.193347930908203
Agent0_Train_MaxReturn : 1.2740826606750488
Agent0_Train_MinReturn : -30.74883270263672
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 901500
Agent0_TimeSinceStart : 1374.5657467842102
Agent0_Critic_Loss : 0.593779981136322
Agent0_Actor_Loss : -0.4704909324645996
Agent0_Alpha_Loss : 0.757310688495636
Agent0_Temperature : 0.08448198417757563
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -11.862855911254883
Agent1_Eval_StdReturn : 14.921660423278809
Agent1_Eval_MaxReturn : 26.073413848876953
Agent1_Eval_MinReturn : -28.19198226928711
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -19.401199340820312
Agent1_Train_StdReturn : 16.573123931884766
Agent1_Train_MaxReturn : 11.277783393859863
Agent1_Train_MinReturn : -44.513092041015625
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 901500
Agent1_TimeSinceStart : 1376.6640183925629
Agent1_Critic_Loss : 0.8406818509101868
Agent1_Actor_Loss : -0.6836596727371216
Agent1_Alpha_Loss : 0.7537076473236084
Agent1_Temperature : 0.08449227105731263
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 601 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 602 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 603 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 604 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 605 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 606 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 607 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 608 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 609 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 610 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -8.77269458770752
Agent0_Eval_StdReturn : 14.192977905273438
Agent0_Eval_MaxReturn : 13.910115242004395
Agent0_Eval_MinReturn : -34.085365295410156
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -14.621442794799805
Agent0_Train_StdReturn : 8.087564468383789
Agent0_Train_MaxReturn : 3.774186134338379
Agent0_Train_MinReturn : -24.26746368408203
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 916500
Agent0_TimeSinceStart : 1397.7947237491608
Agent0_Critic_Loss : 0.5208470225334167
Agent0_Actor_Loss : -0.6274526119232178
Agent0_Alpha_Loss : 0.773807168006897
Agent0_Temperature : 0.08424261833215886
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -14.227361679077148
Agent1_Eval_StdReturn : 8.024554252624512
Agent1_Eval_MaxReturn : -0.17542457580566406
Agent1_Eval_MinReturn : -25.862350463867188
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -18.584699630737305
Agent1_Train_StdReturn : 14.791499137878418
Agent1_Train_MaxReturn : 1.8332276344299316
Agent1_Train_MinReturn : -49.72434997558594
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 916500
Agent1_TimeSinceStart : 1399.8922386169434
Agent1_Critic_Loss : 0.6640942096710205
Agent1_Actor_Loss : -0.6347231864929199
Agent1_Alpha_Loss : 0.7649960517883301
Agent1_Temperature : 0.08425590332436797
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 611 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 612 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 613 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 614 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 615 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 616 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 617 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 618 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 619 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 620 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -13.226916313171387
Agent0_Eval_StdReturn : 7.148564338684082
Agent0_Eval_MaxReturn : 0.43575525283813477
Agent0_Eval_MinReturn : -22.915836334228516
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -13.759481430053711
Agent0_Train_StdReturn : 11.202042579650879
Agent0_Train_MaxReturn : 12.210187911987305
Agent0_Train_MinReturn : -25.94925308227539
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 931500
Agent0_TimeSinceStart : 1421.0400123596191
Agent0_Critic_Loss : 0.6633337736129761
Agent0_Actor_Loss : -0.6855429410934448
Agent0_Alpha_Loss : 0.7621778249740601
Agent0_Temperature : 0.08400319604353293
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -18.00420570373535
Agent1_Eval_StdReturn : 12.479301452636719
Agent1_Eval_MaxReturn : -2.665607452392578
Agent1_Eval_MinReturn : -37.08072280883789
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -14.710393905639648
Agent1_Train_StdReturn : 13.903753280639648
Agent1_Train_MaxReturn : 6.209540843963623
Agent1_Train_MinReturn : -44.07708740234375
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 931500
Agent1_TimeSinceStart : 1423.1438751220703
Agent1_Critic_Loss : 0.5808440446853638
Agent1_Actor_Loss : -0.7689645290374756
Agent1_Alpha_Loss : 0.7573369741439819
Agent1_Temperature : 0.08401833408293921
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 621 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 622 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 623 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 624 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 625 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 626 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 627 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 628 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 629 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 630 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -12.31031322479248
Agent0_Eval_StdReturn : 10.515352249145508
Agent0_Eval_MaxReturn : 1.6481800079345703
Agent0_Eval_MinReturn : -30.539731979370117
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -15.135839462280273
Agent0_Train_StdReturn : 17.137086868286133
Agent0_Train_MaxReturn : 10.412729263305664
Agent0_Train_MinReturn : -56.11969757080078
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 946500
Agent0_TimeSinceStart : 1444.2404680252075
Agent0_Critic_Loss : 0.5274403095245361
Agent0_Actor_Loss : -0.7648862600326538
Agent0_Alpha_Loss : 0.764406144618988
Agent0_Temperature : 0.08376282963550918
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -11.624983787536621
Agent1_Eval_StdReturn : 11.854768753051758
Agent1_Eval_MaxReturn : 2.9059410095214844
Agent1_Eval_MinReturn : -32.84284973144531
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -14.264246940612793
Agent1_Train_StdReturn : 15.470765113830566
Agent1_Train_MaxReturn : 2.5915870666503906
Agent1_Train_MinReturn : -53.518821716308594
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 946500
Agent1_TimeSinceStart : 1446.3356170654297
Agent1_Critic_Loss : 0.7349923849105835
Agent1_Actor_Loss : -0.8288384675979614
Agent1_Alpha_Loss : 0.7710201740264893
Agent1_Temperature : 0.08378015597309711
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 631 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 632 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 633 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 634 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 635 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 636 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 637 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 638 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 639 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 640 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -18.740392684936523
Agent0_Eval_StdReturn : 12.769253730773926
Agent0_Eval_MaxReturn : -2.961282253265381
Agent0_Eval_MinReturn : -53.207855224609375
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -14.670995712280273
Agent0_Train_StdReturn : 16.329782485961914
Agent0_Train_MaxReturn : 7.8731184005737305
Agent0_Train_MinReturn : -39.06629180908203
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 961500
Agent0_TimeSinceStart : 1467.4241659641266
Agent0_Critic_Loss : 0.6064745187759399
Agent0_Actor_Loss : -0.7111109495162964
Agent0_Alpha_Loss : 0.7835531830787659
Agent0_Temperature : 0.08352165899318535
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -13.654722213745117
Agent1_Eval_StdReturn : 19.223180770874023
Agent1_Eval_MaxReturn : 6.997731685638428
Agent1_Eval_MinReturn : -63.1596794128418
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -8.948615074157715
Agent1_Train_StdReturn : 8.74585247039795
Agent1_Train_MaxReturn : 5.419884204864502
Agent1_Train_MinReturn : -25.24666404724121
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 961500
Agent1_TimeSinceStart : 1469.5238738059998
Agent1_Critic_Loss : 0.6202746629714966
Agent1_Actor_Loss : -0.6444589495658875
Agent1_Alpha_Loss : 0.7730826139450073
Agent1_Temperature : 0.08354169545695002
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 641 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 642 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 643 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 644 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 645 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 646 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 647 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 648 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 649 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 650 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -12.925395011901855
Agent0_Eval_StdReturn : 15.954408645629883
Agent0_Eval_MaxReturn : 21.537599563598633
Agent0_Eval_MinReturn : -32.611473083496094
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -26.388545989990234
Agent0_Train_StdReturn : 23.20259666442871
Agent0_Train_MaxReturn : -2.4624271392822266
Agent0_Train_MinReturn : -81.17599487304688
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 976500
Agent0_TimeSinceStart : 1490.5863590240479
Agent0_Critic_Loss : 0.6288175582885742
Agent0_Actor_Loss : -0.6214629411697388
Agent0_Alpha_Loss : 0.7810289859771729
Agent0_Temperature : 0.08327988604215976
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -12.425644874572754
Agent1_Eval_StdReturn : 5.3505859375
Agent1_Eval_MaxReturn : -3.451214075088501
Agent1_Eval_MinReturn : -19.458215713500977
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -12.659565925598145
Agent1_Train_StdReturn : 7.773641586303711
Agent1_Train_MaxReturn : -0.7040500640869141
Agent1_Train_MinReturn : -27.882442474365234
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 976500
Agent1_TimeSinceStart : 1492.6775107383728
Agent1_Critic_Loss : 0.7654469013214111
Agent1_Actor_Loss : -0.7251179814338684
Agent1_Alpha_Loss : 0.7768290042877197
Agent1_Temperature : 0.08330317348686908
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 651 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 652 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 653 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 654 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 655 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 656 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 657 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 658 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 659 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 660 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -12.53868293762207
Agent0_Eval_StdReturn : 21.512258529663086
Agent0_Eval_MaxReturn : 23.199480056762695
Agent0_Eval_MinReturn : -57.57018280029297
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : 1.8014808893203735
Agent0_Train_StdReturn : 14.13829231262207
Agent0_Train_MaxReturn : 29.652233123779297
Agent0_Train_MinReturn : -22.678661346435547
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 991500
Agent0_TimeSinceStart : 1513.7039506435394
Agent0_Critic_Loss : 0.7896523475646973
Agent0_Actor_Loss : -0.6439770460128784
Agent0_Alpha_Loss : 0.7883672714233398
Agent0_Temperature : 0.08303730098372142
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -0.9397662878036499
Agent1_Eval_StdReturn : 15.491172790527344
Agent1_Eval_MaxReturn : 37.140907287597656
Agent1_Eval_MinReturn : -17.201311111450195
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -11.346064567565918
Agent1_Train_StdReturn : 24.9490966796875
Agent1_Train_MaxReturn : 36.14678955078125
Agent1_Train_MinReturn : -50.75545120239258
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 991500
Agent1_TimeSinceStart : 1515.791508436203
Agent1_Critic_Loss : 0.608016312122345
Agent1_Actor_Loss : -0.7257465124130249
Agent1_Alpha_Loss : 0.7753965854644775
Agent1_Temperature : 0.08306419716694553
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 661 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 662 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 663 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 664 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 665 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 666 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 667 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 668 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 669 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 670 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -8.81252384185791
Agent0_Eval_StdReturn : 10.478836059570312
Agent0_Eval_MaxReturn : 5.367105484008789
Agent0_Eval_MinReturn : -30.22389793395996
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -16.43942642211914
Agent0_Train_StdReturn : 26.102062225341797
Agent0_Train_MaxReturn : 20.12076759338379
Agent0_Train_MinReturn : -60.2382698059082
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1006500
Agent0_TimeSinceStart : 1536.8020050525665
Agent0_Critic_Loss : 0.6711733341217041
Agent0_Actor_Loss : -0.6412985324859619
Agent0_Alpha_Loss : 0.7837647199630737
Agent0_Temperature : 0.08279557870445609
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -16.175609588623047
Agent1_Eval_StdReturn : 10.570747375488281
Agent1_Eval_MaxReturn : -0.07480812072753906
Agent1_Eval_MinReturn : -31.140884399414062
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : 2.914949655532837
Agent1_Train_StdReturn : 16.133243560791016
Agent1_Train_MaxReturn : 27.363046646118164
Agent1_Train_MinReturn : -38.009300231933594
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1006500
Agent1_TimeSinceStart : 1538.8948838710785
Agent1_Critic_Loss : 0.48448288440704346
Agent1_Actor_Loss : -0.7605459690093994
Agent1_Alpha_Loss : 0.7857098579406738
Agent1_Temperature : 0.08282494229448285
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 671 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 672 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 673 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 674 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 675 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 676 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 677 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 678 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 679 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 680 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -14.201472282409668
Agent0_Eval_StdReturn : 15.694761276245117
Agent0_Eval_MaxReturn : 6.00663423538208
Agent0_Eval_MinReturn : -53.611671447753906
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -15.017781257629395
Agent0_Train_StdReturn : 12.718465805053711
Agent0_Train_MaxReturn : 6.21983528137207
Agent0_Train_MinReturn : -36.977073669433594
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1021500
Agent0_TimeSinceStart : 1559.9183914661407
Agent0_Critic_Loss : 0.6935122609138489
Agent0_Actor_Loss : -0.704451322555542
Agent0_Alpha_Loss : 0.7801515460014343
Agent0_Temperature : 0.08255500851288215
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -20.570484161376953
Agent1_Eval_StdReturn : 19.44145393371582
Agent1_Eval_MaxReturn : 5.9703850746154785
Agent1_Eval_MinReturn : -60.108463287353516
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -13.607769966125488
Agent1_Train_StdReturn : 16.56395149230957
Agent1_Train_MaxReturn : 22.908737182617188
Agent1_Train_MinReturn : -42.152381896972656
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1021500
Agent1_TimeSinceStart : 1562.013310432434
Agent1_Critic_Loss : 0.550984799861908
Agent1_Actor_Loss : -0.7770935893058777
Agent1_Alpha_Loss : 0.7934627532958984
Agent1_Temperature : 0.08258501965083896
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 681 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 682 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 683 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 684 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 685 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 686 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 687 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 688 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 689 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 690 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -15.442312240600586
Agent0_Eval_StdReturn : 10.40921688079834
Agent0_Eval_MaxReturn : 10.118128776550293
Agent0_Eval_MinReturn : -29.949298858642578
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -18.39175796508789
Agent0_Train_StdReturn : 31.418973922729492
Agent0_Train_MaxReturn : 34.98305892944336
Agent0_Train_MinReturn : -65.59139251708984
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1036500
Agent0_TimeSinceStart : 1583.0139722824097
Agent0_Critic_Loss : 0.8065589070320129
Agent0_Actor_Loss : -0.7970783710479736
Agent0_Alpha_Loss : 0.7846521139144897
Agent0_Temperature : 0.08231486072445884
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -32.22282791137695
Agent1_Eval_StdReturn : 23.13103485107422
Agent1_Eval_MaxReturn : 4.89385986328125
Agent1_Eval_MinReturn : -64.5650405883789
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -16.347537994384766
Agent1_Train_StdReturn : 23.700775146484375
Agent1_Train_MaxReturn : 11.738007545471191
Agent1_Train_MinReturn : -68.27899932861328
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1036500
Agent1_TimeSinceStart : 1585.1010794639587
Agent1_Critic_Loss : 0.6120232939720154
Agent1_Actor_Loss : -0.7160544395446777
Agent1_Alpha_Loss : 0.7850010395050049
Agent1_Temperature : 0.08234480154442061
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 691 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 692 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 693 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 694 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 695 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 696 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 697 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 698 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 699 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 700 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -24.56451988220215
Agent0_Eval_StdReturn : 16.614418029785156
Agent0_Eval_MaxReturn : 0.23181724548339844
Agent0_Eval_MinReturn : -59.15684127807617
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -31.680309295654297
Agent0_Train_StdReturn : 32.346187591552734
Agent0_Train_MaxReturn : 26.009990692138672
Agent0_Train_MinReturn : -71.8961410522461
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1051500
Agent0_TimeSinceStart : 1606.061027765274
Agent0_Critic_Loss : 0.6017895936965942
Agent0_Actor_Loss : -0.6241096258163452
Agent0_Alpha_Loss : 0.7776240110397339
Agent0_Temperature : 0.082074335098109
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -10.860429763793945
Agent1_Eval_StdReturn : 17.6812686920166
Agent1_Eval_MaxReturn : 23.337562561035156
Agent1_Eval_MinReturn : -32.304439544677734
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -18.643062591552734
Agent1_Train_StdReturn : 26.1021671295166
Agent1_Train_MaxReturn : 16.511627197265625
Agent1_Train_MinReturn : -66.93994903564453
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1051500
Agent1_TimeSinceStart : 1608.1522510051727
Agent1_Critic_Loss : 0.6663168668746948
Agent1_Actor_Loss : -0.7675338387489319
Agent1_Alpha_Loss : 0.7913153767585754
Agent1_Temperature : 0.08210513631894806
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 701 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 702 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 703 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 704 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 705 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 706 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 707 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 708 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 709 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 710 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -20.05789566040039
Agent0_Eval_StdReturn : 14.646476745605469
Agent0_Eval_MaxReturn : 6.817994594573975
Agent0_Eval_MinReturn : -40.43049621582031
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -19.54693603515625
Agent0_Train_StdReturn : 16.333703994750977
Agent0_Train_MaxReturn : 16.28660011291504
Agent0_Train_MinReturn : -38.387969970703125
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1066500
Agent0_TimeSinceStart : 1629.1610176563263
Agent0_Critic_Loss : 0.8304016590118408
Agent0_Actor_Loss : -0.8291743993759155
Agent0_Alpha_Loss : 0.772918701171875
Agent0_Temperature : 0.08183411803065285
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -17.531003952026367
Agent1_Eval_StdReturn : 22.300952911376953
Agent1_Eval_MaxReturn : 10.366347312927246
Agent1_Eval_MinReturn : -53.12535858154297
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -10.900663375854492
Agent1_Train_StdReturn : 13.987112998962402
Agent1_Train_MaxReturn : 10.522375106811523
Agent1_Train_MinReturn : -32.50181198120117
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1066500
Agent1_TimeSinceStart : 1631.247407913208
Agent1_Critic_Loss : 0.9469372034072876
Agent1_Actor_Loss : -0.7256104350090027
Agent1_Alpha_Loss : 0.7774869799613953
Agent1_Temperature : 0.08186594018758232
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 711 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 712 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 713 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 714 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 715 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 716 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 717 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 718 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 719 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 720 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -28.613183975219727
Agent0_Eval_StdReturn : 29.918291091918945
Agent0_Eval_MaxReturn : -1.901629090309143
Agent0_Eval_MinReturn : -103.51024627685547
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -18.64163589477539
Agent0_Train_StdReturn : 18.580753326416016
Agent0_Train_MaxReturn : 5.448374271392822
Agent0_Train_MinReturn : -43.71097946166992
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1081500
Agent0_TimeSinceStart : 1652.286726474762
Agent0_Critic_Loss : 0.7535998821258545
Agent0_Actor_Loss : -0.8341034054756165
Agent0_Alpha_Loss : 0.7726315855979919
Agent0_Temperature : 0.08159482305056542
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -24.473222732543945
Agent1_Eval_StdReturn : 33.34992980957031
Agent1_Eval_MaxReturn : 14.917441368103027
Agent1_Eval_MinReturn : -84.16453552246094
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -18.99319076538086
Agent1_Train_StdReturn : 15.52662181854248
Agent1_Train_MaxReturn : 7.566123962402344
Agent1_Train_MinReturn : -39.88541030883789
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1081500
Agent1_TimeSinceStart : 1654.3801460266113
Agent1_Critic_Loss : 0.7207072973251343
Agent1_Actor_Loss : -0.9175344705581665
Agent1_Alpha_Loss : 0.7616899013519287
Agent1_Temperature : 0.08162746668930757
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 721 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 722 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 723 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 724 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 725 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 726 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 727 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 728 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 729 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 730 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -18.211153030395508
Agent0_Eval_StdReturn : 18.812644958496094
Agent0_Eval_MaxReturn : 14.3372220993042
Agent0_Eval_MinReturn : -53.778282165527344
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : 0.8335525393486023
Agent0_Train_StdReturn : 22.86427879333496
Agent0_Train_MaxReturn : 37.20066452026367
Agent0_Train_MinReturn : -45.34810256958008
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1096500
Agent0_TimeSinceStart : 1675.4055180549622
Agent0_Critic_Loss : 0.8489501476287842
Agent0_Actor_Loss : -0.6915085911750793
Agent0_Alpha_Loss : 0.7641445398330688
Agent0_Temperature : 0.08135727526380555
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -22.339481353759766
Agent1_Eval_StdReturn : 17.32491111755371
Agent1_Eval_MaxReturn : 5.379014015197754
Agent1_Eval_MinReturn : -54.56243133544922
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -7.488275051116943
Agent1_Train_StdReturn : 20.05997657775879
Agent1_Train_MaxReturn : 20.654407501220703
Agent1_Train_MinReturn : -43.36651611328125
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1096500
Agent1_TimeSinceStart : 1677.4891035556793
Agent1_Critic_Loss : 0.9450441002845764
Agent1_Actor_Loss : -0.9056471586227417
Agent1_Alpha_Loss : 0.7716138362884521
Agent1_Temperature : 0.0813909454345974
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 731 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 732 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 733 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 734 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 735 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 736 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 737 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 738 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 739 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 740 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -19.59185028076172
Agent0_Eval_StdReturn : 19.30384635925293
Agent0_Eval_MaxReturn : 5.2380900382995605
Agent0_Eval_MinReturn : -60.77667236328125
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -1.1439707279205322
Agent0_Train_StdReturn : 18.610258102416992
Agent0_Train_MaxReturn : 35.71495819091797
Agent0_Train_MinReturn : -27.847841262817383
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1111500
Agent0_TimeSinceStart : 1698.5359210968018
Agent0_Critic_Loss : 1.078979253768921
Agent0_Actor_Loss : -0.6970000863075256
Agent0_Alpha_Loss : 0.7639188766479492
Agent0_Temperature : 0.08112137302845605
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -17.543048858642578
Agent1_Eval_StdReturn : 17.91262435913086
Agent1_Eval_MaxReturn : 21.925668716430664
Agent1_Eval_MinReturn : -46.734397888183594
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -12.970181465148926
Agent1_Train_StdReturn : 14.835790634155273
Agent1_Train_MaxReturn : 12.875883102416992
Agent1_Train_MinReturn : -34.925209045410156
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1111500
Agent1_TimeSinceStart : 1700.6209909915924
Agent1_Critic_Loss : 0.7935011386871338
Agent1_Actor_Loss : -0.7731102108955383
Agent1_Alpha_Loss : 0.7662308216094971
Agent1_Temperature : 0.0811554616950534
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 741 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 742 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 743 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 744 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 745 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 746 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 747 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 748 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 749 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 750 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -20.729290008544922
Agent0_Eval_StdReturn : 21.553884506225586
Agent0_Eval_MaxReturn : 5.116559028625488
Agent0_Eval_MinReturn : -64.87542724609375
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -8.10988998413086
Agent0_Train_StdReturn : 10.898234367370605
Agent0_Train_MaxReturn : 7.303388595581055
Agent0_Train_MinReturn : -28.395282745361328
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1126500
Agent0_TimeSinceStart : 1721.6405909061432
Agent0_Critic_Loss : 0.8215765953063965
Agent0_Actor_Loss : -0.8006057143211365
Agent0_Alpha_Loss : 0.765083909034729
Agent0_Temperature : 0.08088696136616665
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -14.887601852416992
Agent1_Eval_StdReturn : 8.910372734069824
Agent1_Eval_MaxReturn : -1.7695904970169067
Agent1_Eval_MinReturn : -30.068485260009766
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -15.313665390014648
Agent1_Train_StdReturn : 14.612607955932617
Agent1_Train_MaxReturn : 11.848662376403809
Agent1_Train_MinReturn : -43.37300491333008
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1126500
Agent1_TimeSinceStart : 1723.7385773658752
Agent1_Critic_Loss : 0.9193445444107056
Agent1_Actor_Loss : -0.9724810123443604
Agent1_Alpha_Loss : 0.7660731077194214
Agent1_Temperature : 0.08092210875215136
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 751 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 752 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 753 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 754 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 755 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 756 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 757 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 758 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 759 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 760 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -11.085664749145508
Agent0_Eval_StdReturn : 14.857172012329102
Agent0_Eval_MaxReturn : 6.290328025817871
Agent0_Eval_MinReturn : -35.86717224121094
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -14.901921272277832
Agent0_Train_StdReturn : 13.146871566772461
Agent0_Train_MaxReturn : 6.415423393249512
Agent0_Train_MinReturn : -41.28936767578125
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1141500
Agent0_TimeSinceStart : 1744.8100018501282
Agent0_Critic_Loss : 0.918691873550415
Agent0_Actor_Loss : -0.8358731865882874
Agent0_Alpha_Loss : 0.7629591822624207
Agent0_Temperature : 0.08065471048066072
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -14.561666488647461
Agent1_Eval_StdReturn : 5.664705753326416
Agent1_Eval_MaxReturn : -6.458051681518555
Agent1_Eval_MinReturn : -25.420135498046875
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -22.82880210876465
Agent1_Train_StdReturn : 23.28759002685547
Agent1_Train_MaxReturn : 5.538827896118164
Agent1_Train_MinReturn : -76.0239028930664
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1141500
Agent1_TimeSinceStart : 1746.9005243778229
Agent1_Critic_Loss : 0.8496533632278442
Agent1_Actor_Loss : -0.8925936818122864
Agent1_Alpha_Loss : 0.7615989446640015
Agent1_Temperature : 0.08069020778935491
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 761 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 762 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 763 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 764 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 765 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 766 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 767 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 768 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 769 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 770 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -9.851509094238281
Agent0_Eval_StdReturn : 14.334662437438965
Agent0_Eval_MaxReturn : 10.7625150680542
Agent0_Eval_MinReturn : -41.63930130004883
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -11.609296798706055
Agent0_Train_StdReturn : 11.964192390441895
Agent0_Train_MaxReturn : 10.665520668029785
Agent0_Train_MinReturn : -27.498605728149414
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1156500
Agent0_TimeSinceStart : 1768.0057470798492
Agent0_Critic_Loss : 0.912746250629425
Agent0_Actor_Loss : -0.9122372269630432
Agent0_Alpha_Loss : 0.7590161561965942
Agent0_Temperature : 0.08042481121356479
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -9.085412979125977
Agent1_Eval_StdReturn : 12.266071319580078
Agent1_Eval_MaxReturn : 8.798611640930176
Agent1_Eval_MinReturn : -25.764245986938477
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -5.177054405212402
Agent1_Train_StdReturn : 12.270230293273926
Agent1_Train_MaxReturn : 21.469192504882812
Agent1_Train_MinReturn : -29.872920989990234
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1156500
Agent1_TimeSinceStart : 1770.1026666164398
Agent1_Critic_Loss : 0.8085459470748901
Agent1_Actor_Loss : -0.9313888549804688
Agent1_Alpha_Loss : 0.7546098232269287
Agent1_Temperature : 0.08046008515064779
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 771 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 772 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 773 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 774 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 775 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 776 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 777 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 778 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 779 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 780 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -16.381528854370117
Agent0_Eval_StdReturn : 13.807348251342773
Agent0_Eval_MaxReturn : 5.511739730834961
Agent0_Eval_MinReturn : -37.99274826049805
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -11.24791431427002
Agent0_Train_StdReturn : 11.226007461547852
Agent0_Train_MaxReturn : 4.635156631469727
Agent0_Train_MinReturn : -27.270906448364258
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1171500
Agent0_TimeSinceStart : 1791.2407729625702
Agent0_Critic_Loss : 1.0933706760406494
Agent0_Actor_Loss : -0.7932575941085815
Agent0_Alpha_Loss : 0.7348606586456299
Agent0_Temperature : 0.08019744685641493
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -18.702152252197266
Agent1_Eval_StdReturn : 15.244474411010742
Agent1_Eval_MaxReturn : 9.530086517333984
Agent1_Eval_MinReturn : -40.976871490478516
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -6.170466423034668
Agent1_Train_StdReturn : 12.41672420501709
Agent1_Train_MaxReturn : 15.034854888916016
Agent1_Train_MinReturn : -26.945695877075195
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1171500
Agent1_TimeSinceStart : 1793.3354849815369
Agent1_Critic_Loss : 1.3793911933898926
Agent1_Actor_Loss : -0.7614885568618774
Agent1_Alpha_Loss : 0.761381983757019
Agent1_Temperature : 0.08023182351608198
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 781 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 782 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 783 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 784 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 785 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 786 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 787 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 788 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 789 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 790 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -16.049896240234375
Agent0_Eval_StdReturn : 14.786944389343262
Agent0_Eval_MaxReturn : 5.0688371658325195
Agent0_Eval_MinReturn : -51.733619689941406
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -10.734655380249023
Agent0_Train_StdReturn : 9.459723472595215
Agent0_Train_MaxReturn : 5.319699287414551
Agent0_Train_MinReturn : -27.815196990966797
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1186500
Agent0_TimeSinceStart : 1814.4539210796356
Agent0_Critic_Loss : 0.7076902389526367
Agent0_Actor_Loss : -0.9352530241012573
Agent0_Alpha_Loss : 0.7389354705810547
Agent0_Temperature : 0.079972873391681
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -8.549468994140625
Agent1_Eval_StdReturn : 13.33263874053955
Agent1_Eval_MaxReturn : 20.411943435668945
Agent1_Eval_MinReturn : -30.37885093688965
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -11.69304370880127
Agent1_Train_StdReturn : 17.3923397064209
Agent1_Train_MaxReturn : 17.35163116455078
Agent1_Train_MinReturn : -33.52793884277344
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1186500
Agent1_TimeSinceStart : 1816.551873922348
Agent1_Critic_Loss : 1.0982310771942139
Agent1_Actor_Loss : -0.8535616397857666
Agent1_Alpha_Loss : 0.740107536315918
Agent1_Temperature : 0.08000489399239877
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 791 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 792 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 793 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 794 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 795 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 796 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 797 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 798 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 799 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 800 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -12.150350570678711
Agent0_Eval_StdReturn : 16.497713088989258
Agent0_Eval_MaxReturn : 13.647440910339355
Agent0_Eval_MinReturn : -40.670257568359375
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -15.089941024780273
Agent0_Train_StdReturn : 20.381370544433594
Agent0_Train_MaxReturn : 30.826475143432617
Agent0_Train_MinReturn : -44.93117141723633
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1201500
Agent0_TimeSinceStart : 1837.6740837097168
Agent0_Critic_Loss : 0.8991501331329346
Agent0_Actor_Loss : -0.8657402992248535
Agent0_Alpha_Loss : 0.7486981749534607
Agent0_Temperature : 0.07974863932513207
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -9.091646194458008
Agent1_Eval_StdReturn : 15.318448066711426
Agent1_Eval_MaxReturn : 19.67654800415039
Agent1_Eval_MinReturn : -33.401126861572266
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -17.101591110229492
Agent1_Train_StdReturn : 9.420254707336426
Agent1_Train_MaxReturn : -1.9121193885803223
Agent1_Train_MinReturn : -29.75374984741211
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1201500
Agent1_TimeSinceStart : 1839.7737407684326
Agent1_Critic_Loss : 1.54478120803833
Agent1_Actor_Loss : -0.8634933233261108
Agent1_Alpha_Loss : 0.729407787322998
Agent1_Temperature : 0.079781325006502
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 801 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 802 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 803 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 804 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 805 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 806 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 807 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 808 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 809 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 810 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -8.481424331665039
Agent0_Eval_StdReturn : 10.032052040100098
Agent0_Eval_MaxReturn : 9.963314056396484
Agent0_Eval_MinReturn : -24.66253662109375
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -19.34965705871582
Agent0_Train_StdReturn : 16.35230255126953
Agent0_Train_MaxReturn : 2.0951104164123535
Agent0_Train_MinReturn : -55.43972396850586
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1216500
Agent0_TimeSinceStart : 1860.8495388031006
Agent0_Critic_Loss : 0.769088864326477
Agent0_Actor_Loss : -0.8334907293319702
Agent0_Alpha_Loss : 0.7575281858444214
Agent0_Temperature : 0.07952453850765183
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -13.036523818969727
Agent1_Eval_StdReturn : 13.357112884521484
Agent1_Eval_MaxReturn : 11.315698623657227
Agent1_Eval_MinReturn : -30.13408660888672
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -6.679925441741943
Agent1_Train_StdReturn : 10.375575065612793
Agent1_Train_MaxReturn : 5.7785444259643555
Agent1_Train_MinReturn : -22.461009979248047
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1216500
Agent1_TimeSinceStart : 1862.9462485313416
Agent1_Critic_Loss : 0.9464236497879028
Agent1_Actor_Loss : -0.9018146991729736
Agent1_Alpha_Loss : 0.7249716520309448
Agent1_Temperature : 0.07956037361760818
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 811 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 812 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 813 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 814 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 815 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 816 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 817 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 818 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 819 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 820 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -18.905506134033203
Agent0_Eval_StdReturn : 18.44426727294922
Agent0_Eval_MaxReturn : 6.797163486480713
Agent0_Eval_MinReturn : -49.64472198486328
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -16.86981201171875
Agent0_Train_StdReturn : 19.361101150512695
Agent0_Train_MaxReturn : 5.041080474853516
Agent0_Train_MinReturn : -67.99624633789062
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1231500
Agent0_TimeSinceStart : 1884.0784153938293
Agent0_Critic_Loss : 0.8610801100730896
Agent0_Actor_Loss : -0.8274770379066467
Agent0_Alpha_Loss : 0.7424829602241516
Agent0_Temperature : 0.07930102862976117
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -21.487668991088867
Agent1_Eval_StdReturn : 13.901433944702148
Agent1_Eval_MaxReturn : 9.269482612609863
Agent1_Eval_MinReturn : -41.9499397277832
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -10.297761917114258
Agent1_Train_StdReturn : 8.801233291625977
Agent1_Train_MaxReturn : 10.201249122619629
Agent1_Train_MinReturn : -20.414756774902344
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1231500
Agent1_TimeSinceStart : 1886.1761803627014
Agent1_Critic_Loss : 1.2628834247589111
Agent1_Actor_Loss : -0.8361291885375977
Agent1_Alpha_Loss : 0.7332097887992859
Agent1_Temperature : 0.07934151240631343
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 821 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 822 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 823 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 824 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 825 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 826 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 827 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 828 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 829 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 830 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -14.575016975402832
Agent0_Eval_StdReturn : 26.66568374633789
Agent0_Eval_MaxReturn : 9.798906326293945
Agent0_Eval_MinReturn : -88.26226043701172
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -10.491220474243164
Agent0_Train_StdReturn : 11.188508987426758
Agent0_Train_MaxReturn : 8.529216766357422
Agent0_Train_MinReturn : -34.84825897216797
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1246500
Agent0_TimeSinceStart : 1907.3049983978271
Agent0_Critic_Loss : 0.9755396842956543
Agent0_Actor_Loss : -0.971163272857666
Agent0_Alpha_Loss : 0.7364602088928223
Agent0_Temperature : 0.07907865067522168
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -16.969482421875
Agent1_Eval_StdReturn : 9.32276725769043
Agent1_Eval_MaxReturn : -1.0100736618041992
Agent1_Eval_MinReturn : -30.856510162353516
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -10.58298110961914
Agent1_Train_StdReturn : 4.876173496246338
Agent1_Train_MaxReturn : -1.9142866134643555
Agent1_Train_MinReturn : -16.922914505004883
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1246500
Agent1_TimeSinceStart : 1909.4082877635956
Agent1_Critic_Loss : 0.9447014331817627
Agent1_Actor_Loss : -0.9735966920852661
Agent1_Alpha_Loss : 0.7321714162826538
Agent1_Temperature : 0.07912398285021668
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 831 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 832 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 833 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 834 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 835 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 836 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 837 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 838 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 839 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 840 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -11.30725383758545
Agent0_Eval_StdReturn : 15.640364646911621
Agent0_Eval_MaxReturn : 13.214778900146484
Agent0_Eval_MinReturn : -34.729949951171875
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -7.537031650543213
Agent0_Train_StdReturn : 12.038749694824219
Agent0_Train_MaxReturn : 20.01540756225586
Agent0_Train_MinReturn : -22.864782333374023
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1261500
Agent0_TimeSinceStart : 1930.5503282546997
Agent0_Critic_Loss : 0.6539629697799683
Agent0_Actor_Loss : -0.87218177318573
Agent0_Alpha_Loss : 0.7327343821525574
Agent0_Temperature : 0.07885686431209332
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -12.166547775268555
Agent1_Eval_StdReturn : 10.184351921081543
Agent1_Eval_MaxReturn : 9.371126174926758
Agent1_Eval_MinReturn : -21.970481872558594
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -10.892800331115723
Agent1_Train_StdReturn : 7.455057621002197
Agent1_Train_MaxReturn : -1.5652594566345215
Agent1_Train_MinReturn : -22.529565811157227
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1261500
Agent1_TimeSinceStart : 1932.6499617099762
Agent1_Critic_Loss : 0.7610769867897034
Agent1_Actor_Loss : -0.9902023673057556
Agent1_Alpha_Loss : 0.7352707982063293
Agent1_Temperature : 0.0789065887513169
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 841 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 842 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 843 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 844 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 845 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 846 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 847 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 848 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 849 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 850 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -9.795187950134277
Agent0_Eval_StdReturn : 14.05151653289795
Agent0_Eval_MaxReturn : 11.284119606018066
Agent0_Eval_MinReturn : -30.083391189575195
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -12.077268600463867
Agent0_Train_StdReturn : 17.70547866821289
Agent0_Train_MaxReturn : 21.286540985107422
Agent0_Train_MinReturn : -37.745975494384766
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1276500
Agent0_TimeSinceStart : 1953.7423193454742
Agent0_Critic_Loss : 0.7916216850280762
Agent0_Actor_Loss : -0.9508698582649231
Agent0_Alpha_Loss : 0.7321597337722778
Agent0_Temperature : 0.07863581692022183
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -13.35545539855957
Agent1_Eval_StdReturn : 12.887584686279297
Agent1_Eval_MaxReturn : -1.312628984451294
Agent1_Eval_MinReturn : -41.824676513671875
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -14.22063159942627
Agent1_Train_StdReturn : 12.459854125976562
Agent1_Train_MaxReturn : 4.334616661071777
Agent1_Train_MinReturn : -34.66630554199219
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1276500
Agent1_TimeSinceStart : 1955.8420176506042
Agent1_Critic_Loss : 0.7965351343154907
Agent1_Actor_Loss : -0.9960634112358093
Agent1_Alpha_Loss : 0.728036642074585
Agent1_Temperature : 0.07868924236878902
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 851 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 852 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 853 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 854 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 855 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 856 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 857 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 858 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 859 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 860 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : 3.377436876296997
Agent0_Eval_StdReturn : 19.981142044067383
Agent0_Eval_MaxReturn : 27.078495025634766
Agent0_Eval_MinReturn : -44.30461120605469
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -0.158617302775383
Agent0_Train_StdReturn : 20.304597854614258
Agent0_Train_MaxReturn : 36.447898864746094
Agent0_Train_MinReturn : -43.71048355102539
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1291500
Agent0_TimeSinceStart : 1976.9094758033752
Agent0_Critic_Loss : 0.6685746908187866
Agent0_Actor_Loss : -0.9852915406227112
Agent0_Alpha_Loss : 0.7384281158447266
Agent0_Temperature : 0.078415401371998
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -13.16071605682373
Agent1_Eval_StdReturn : 19.551029205322266
Agent1_Eval_MaxReturn : 22.261585235595703
Agent1_Eval_MinReturn : -47.334720611572266
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -10.028613090515137
Agent1_Train_StdReturn : 6.133648872375488
Agent1_Train_MaxReturn : -0.9549579620361328
Agent1_Train_MinReturn : -19.735450744628906
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1291500
Agent1_TimeSinceStart : 1979.009646654129
Agent1_Critic_Loss : 0.9694724082946777
Agent1_Actor_Loss : -0.9423364996910095
Agent1_Alpha_Loss : 0.7350083589553833
Agent1_Temperature : 0.0784724100960566
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 861 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 862 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 863 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 864 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 865 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 866 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 867 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 868 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 869 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 870 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -4.1688995361328125
Agent0_Eval_StdReturn : 11.864398956298828
Agent0_Eval_MaxReturn : 18.129308700561523
Agent0_Eval_MinReturn : -17.719770431518555
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -8.597211837768555
Agent0_Train_StdReturn : 12.235462188720703
Agent0_Train_MaxReturn : 10.864042282104492
Agent0_Train_MinReturn : -35.09634780883789
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1306500
Agent0_TimeSinceStart : 2000.1060571670532
Agent0_Critic_Loss : 0.7489515542984009
Agent0_Actor_Loss : -0.9117146134376526
Agent0_Alpha_Loss : 0.7386837005615234
Agent0_Temperature : 0.07819516423035565
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -17.21455955505371
Agent1_Eval_StdReturn : 13.698384284973145
Agent1_Eval_MaxReturn : 8.084031105041504
Agent1_Eval_MinReturn : -44.1260986328125
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -5.400136470794678
Agent1_Train_StdReturn : 15.490127563476562
Agent1_Train_MaxReturn : 23.289196014404297
Agent1_Train_MinReturn : -28.195701599121094
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1306500
Agent1_TimeSinceStart : 2002.191701412201
Agent1_Critic_Loss : 0.8676325678825378
Agent1_Actor_Loss : -0.9309941530227661
Agent1_Alpha_Loss : 0.7425716519355774
Agent1_Temperature : 0.07825385176987593
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 871 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 872 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 873 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 874 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 875 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 876 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 877 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 878 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 879 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 880 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -6.872669219970703
Agent0_Eval_StdReturn : 15.155577659606934
Agent0_Eval_MaxReturn : 14.612096786499023
Agent0_Eval_MinReturn : -37.860164642333984
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -6.842585563659668
Agent0_Train_StdReturn : 13.513245582580566
Agent0_Train_MaxReturn : 16.645835876464844
Agent0_Train_MinReturn : -30.71553611755371
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1321500
Agent0_TimeSinceStart : 2023.2210006713867
Agent0_Critic_Loss : 0.7252774238586426
Agent0_Actor_Loss : -0.7905806303024292
Agent0_Alpha_Loss : 0.7451280355453491
Agent0_Temperature : 0.07797526264603075
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -12.993115425109863
Agent1_Eval_StdReturn : 16.995594024658203
Agent1_Eval_MaxReturn : 11.167215347290039
Agent1_Eval_MinReturn : -38.61679458618164
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -16.536867141723633
Agent1_Train_StdReturn : 19.318147659301758
Agent1_Train_MaxReturn : 8.516965866088867
Agent1_Train_MinReturn : -52.06966018676758
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1321500
Agent1_TimeSinceStart : 2025.2779853343964
Agent1_Critic_Loss : 1.1646013259887695
Agent1_Actor_Loss : -0.9822549819946289
Agent1_Alpha_Loss : 0.749794602394104
Agent1_Temperature : 0.07803466516218976
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 881 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 882 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 883 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 884 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 885 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 886 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 887 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 888 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 889 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 890 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -11.194991111755371
Agent0_Eval_StdReturn : 10.69239330291748
Agent0_Eval_MaxReturn : 5.013856410980225
Agent0_Eval_MinReturn : -27.102155685424805
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : 2.640721559524536
Agent0_Train_StdReturn : 9.4247465133667
Agent0_Train_MaxReturn : 21.224361419677734
Agent0_Train_MinReturn : -12.23182487487793
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1336500
Agent0_TimeSinceStart : 2057.4010875225067
Agent0_Critic_Loss : 0.8334084749221802
Agent0_Actor_Loss : -1.0291476249694824
Agent0_Alpha_Loss : 0.7371901273727417
Agent0_Temperature : 0.07775651434218493
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -16.628881454467773
Agent1_Eval_StdReturn : 20.831100463867188
Agent1_Eval_MaxReturn : 14.041227340698242
Agent1_Eval_MinReturn : -56.032379150390625
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -31.97952651977539
Agent1_Train_StdReturn : 22.045747756958008
Agent1_Train_MaxReturn : 4.014318466186523
Agent1_Train_MinReturn : -64.47321319580078
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1336500
Agent1_TimeSinceStart : 2061.607573032379
Agent1_Critic_Loss : 0.6326706409454346
Agent1_Actor_Loss : -1.0675034523010254
Agent1_Alpha_Loss : 0.7544616460800171
Agent1_Temperature : 0.07781437836838748
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 891 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 892 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 893 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 894 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 895 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 896 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 897 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 898 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 899 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 900 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -21.3038272857666
Agent0_Eval_StdReturn : 29.788846969604492
Agent0_Eval_MaxReturn : 10.065256118774414
Agent0_Eval_MinReturn : -87.43284606933594
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -13.012924194335938
Agent0_Train_StdReturn : 13.780510902404785
Agent0_Train_MaxReturn : 14.504828453063965
Agent0_Train_MinReturn : -29.218935012817383
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1351500
Agent0_TimeSinceStart : 2086.287351131439
Agent0_Critic_Loss : 0.9722472429275513
Agent0_Actor_Loss : -1.0260003805160522
Agent0_Alpha_Loss : 0.7425593137741089
Agent0_Temperature : 0.07753951858140044
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -19.05908966064453
Agent1_Eval_StdReturn : 23.984018325805664
Agent1_Eval_MaxReturn : 25.27109146118164
Agent1_Eval_MinReturn : -62.63861846923828
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -19.6478214263916
Agent1_Train_StdReturn : 23.15308380126953
Agent1_Train_MaxReturn : 12.893350601196289
Agent1_Train_MinReturn : -53.050392150878906
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1351500
Agent1_TimeSinceStart : 2088.7427456378937
Agent1_Critic_Loss : 0.7778348922729492
Agent1_Actor_Loss : -0.9633383750915527
Agent1_Alpha_Loss : 0.7565040588378906
Agent1_Temperature : 0.07759354304301774
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 901 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 902 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 903 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 904 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 905 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 906 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 907 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 908 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 909 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 910 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -22.5959529876709
Agent0_Eval_StdReturn : 10.524787902832031
Agent0_Eval_MaxReturn : -0.846057653427124
Agent0_Eval_MinReturn : -39.36714172363281
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -20.032909393310547
Agent0_Train_StdReturn : 20.46241569519043
Agent0_Train_MaxReturn : 22.53911781311035
Agent0_Train_MinReturn : -53.79219055175781
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1366500
Agent0_TimeSinceStart : 2111.5191791057587
Agent0_Critic_Loss : 0.7759861350059509
Agent0_Actor_Loss : -0.9769884347915649
Agent0_Alpha_Loss : 0.7389833927154541
Agent0_Temperature : 0.07732325006848915
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -29.145553588867188
Agent1_Eval_StdReturn : 20.4165096282959
Agent1_Eval_MaxReturn : 4.881406784057617
Agent1_Eval_MinReturn : -60.57965850830078
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -38.76856231689453
Agent1_Train_StdReturn : 26.782594680786133
Agent1_Train_MaxReturn : -5.702797889709473
Agent1_Train_MinReturn : -83.1451416015625
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1366500
Agent1_TimeSinceStart : 2113.733673810959
Agent1_Critic_Loss : 1.0370911359786987
Agent1_Actor_Loss : -0.9277138113975525
Agent1_Alpha_Loss : 0.7369436025619507
Agent1_Temperature : 0.07737344974567908
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 911 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 912 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 913 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 914 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 915 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 916 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 917 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 918 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 919 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 920 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -13.955450057983398
Agent0_Eval_StdReturn : 14.668907165527344
Agent0_Eval_MaxReturn : 11.304429054260254
Agent0_Eval_MinReturn : -40.18809509277344
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -13.577486991882324
Agent0_Train_StdReturn : 15.583105087280273
Agent0_Train_MaxReturn : 10.224839210510254
Agent0_Train_MinReturn : -37.73472213745117
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1381500
Agent0_TimeSinceStart : 2135.2995121479034
Agent0_Critic_Loss : 0.8009937405586243
Agent0_Actor_Loss : -0.8934041261672974
Agent0_Alpha_Loss : 0.7324005365371704
Agent0_Temperature : 0.07710741369870354
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -24.327259063720703
Agent1_Eval_StdReturn : 23.038570404052734
Agent1_Eval_MaxReturn : 13.955163955688477
Agent1_Eval_MinReturn : -53.63517379760742
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -17.61128807067871
Agent1_Train_StdReturn : 21.353506088256836
Agent1_Train_MaxReturn : 15.913263320922852
Agent1_Train_MinReturn : -49.55812454223633
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1381500
Agent1_TimeSinceStart : 2137.3871965408325
Agent1_Critic_Loss : 1.209924578666687
Agent1_Actor_Loss : -0.8032400608062744
Agent1_Alpha_Loss : 0.7359374165534973
Agent1_Temperature : 0.07715509157786322
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 921 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 922 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 923 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 924 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 925 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 926 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 927 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 928 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 929 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 930 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -35.74639129638672
Agent0_Eval_StdReturn : 21.53893280029297
Agent0_Eval_MaxReturn : -4.643229961395264
Agent0_Eval_MinReturn : -79.17973327636719
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -32.26654052734375
Agent0_Train_StdReturn : 34.276939392089844
Agent0_Train_MaxReturn : 32.54798889160156
Agent0_Train_MinReturn : -87.38323211669922
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1396500
Agent0_TimeSinceStart : 2158.3792560100555
Agent0_Critic_Loss : 0.9823324680328369
Agent0_Actor_Loss : -0.8472163677215576
Agent0_Alpha_Loss : 0.7268155813217163
Agent0_Temperature : 0.07689230018925106
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -21.66559600830078
Agent1_Eval_StdReturn : 23.871917724609375
Agent1_Eval_MaxReturn : 29.729616165161133
Agent1_Eval_MinReturn : -57.76145553588867
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -17.980329513549805
Agent1_Train_StdReturn : 11.355016708374023
Agent1_Train_MaxReturn : 3.578927993774414
Agent1_Train_MinReturn : -42.11135482788086
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1396500
Agent1_TimeSinceStart : 2160.459774494171
Agent1_Critic_Loss : 1.1346030235290527
Agent1_Actor_Loss : -1.0556095838546753
Agent1_Alpha_Loss : 0.7264606356620789
Agent1_Temperature : 0.07693854613716977
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 931 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 932 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 933 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 934 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 935 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 936 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 937 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 938 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 939 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 940 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -31.270503997802734
Agent0_Eval_StdReturn : 21.184736251831055
Agent0_Eval_MaxReturn : 6.000641345977783
Agent0_Eval_MinReturn : -54.26925277709961
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -24.534908294677734
Agent0_Train_StdReturn : 17.616352081298828
Agent0_Train_MaxReturn : 2.2769625186920166
Agent0_Train_MinReturn : -60.583152770996094
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1411500
Agent0_TimeSinceStart : 2181.7483053207397
Agent0_Critic_Loss : 1.3430589437484741
Agent0_Actor_Loss : -0.9029510021209717
Agent0_Alpha_Loss : 0.7384291291236877
Agent0_Temperature : 0.07667702165817111
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -25.415727615356445
Agent1_Eval_StdReturn : 25.06747817993164
Agent1_Eval_MaxReturn : 13.25984001159668
Agent1_Eval_MinReturn : -74.29475402832031
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -14.116037368774414
Agent1_Train_StdReturn : 21.55694007873535
Agent1_Train_MaxReturn : 27.301904678344727
Agent1_Train_MinReturn : -47.20875930786133
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1411500
Agent1_TimeSinceStart : 2183.829015493393
Agent1_Critic_Loss : 1.4205906391143799
Agent1_Actor_Loss : -0.9826823472976685
Agent1_Alpha_Loss : 0.7271881103515625
Agent1_Temperature : 0.07672324133367667
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 941 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 942 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 943 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 944 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 945 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 946 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 947 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 948 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 949 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 950 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -30.982446670532227
Agent0_Eval_StdReturn : 25.074058532714844
Agent0_Eval_MaxReturn : -1.8764846324920654
Agent0_Eval_MinReturn : -73.20570373535156
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -22.730167388916016
Agent0_Train_StdReturn : 22.06521224975586
Agent0_Train_MaxReturn : 22.452259063720703
Agent0_Train_MinReturn : -61.41658401489258
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1426500
Agent0_TimeSinceStart : 2204.667430639267
Agent0_Critic_Loss : 1.316941738128662
Agent0_Actor_Loss : -0.9878000020980835
Agent0_Alpha_Loss : 0.7289561629295349
Agent0_Temperature : 0.07646221336246664
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -13.755589485168457
Agent1_Eval_StdReturn : 19.435253143310547
Agent1_Eval_MaxReturn : 13.119126319885254
Agent1_Eval_MinReturn : -49.970191955566406
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -26.492595672607422
Agent1_Train_StdReturn : 10.11664867401123
Agent1_Train_MaxReturn : -8.475244522094727
Agent1_Train_MinReturn : -41.261329650878906
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1426500
Agent1_TimeSinceStart : 2206.7363970279694
Agent1_Critic_Loss : 1.5576419830322266
Agent1_Actor_Loss : -0.9887363910675049
Agent1_Alpha_Loss : 0.7250492572784424
Agent1_Temperature : 0.07650879768480372
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 951 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 952 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 953 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 954 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 955 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 956 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 957 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 958 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 959 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 960 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -14.824989318847656
Agent0_Eval_StdReturn : 17.66851234436035
Agent0_Eval_MaxReturn : 17.334352493286133
Agent0_Eval_MinReturn : -48.56932830810547
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -12.96753978729248
Agent0_Train_StdReturn : 20.041309356689453
Agent0_Train_MaxReturn : 27.654935836791992
Agent0_Train_MinReturn : -53.27199935913086
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1441500
Agent0_TimeSinceStart : 2227.5545465946198
Agent0_Critic_Loss : 1.493804693222046
Agent0_Actor_Loss : -1.111204981803894
Agent0_Alpha_Loss : 0.7362891435623169
Agent0_Temperature : 0.07624773486091942
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -10.556106567382812
Agent1_Eval_StdReturn : 14.002869606018066
Agent1_Eval_MaxReturn : 19.165973663330078
Agent1_Eval_MinReturn : -29.745826721191406
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -7.584477424621582
Agent1_Train_StdReturn : 15.317058563232422
Agent1_Train_MaxReturn : 19.086811065673828
Agent1_Train_MinReturn : -40.68598556518555
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1441500
Agent1_TimeSinceStart : 2229.636733531952
Agent1_Critic_Loss : 1.4874004125595093
Agent1_Actor_Loss : -0.8533893823623657
Agent1_Alpha_Loss : 0.7323910593986511
Agent1_Temperature : 0.07629476799341185
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 961 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 962 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 963 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 964 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 965 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 966 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 967 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 968 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 969 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 970 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -13.332586288452148
Agent0_Eval_StdReturn : 22.58428955078125
Agent0_Eval_MaxReturn : 16.69947052001953
Agent0_Eval_MinReturn : -45.73582458496094
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -24.869619369506836
Agent0_Train_StdReturn : 22.56700897216797
Agent0_Train_MaxReturn : 7.877784252166748
Agent0_Train_MinReturn : -54.532596588134766
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1456500
Agent0_TimeSinceStart : 2251.7804136276245
Agent0_Critic_Loss : 1.4573776721954346
Agent0_Actor_Loss : -1.1746960878372192
Agent0_Alpha_Loss : 0.7268126010894775
Agent0_Temperature : 0.07603403052503438
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -14.525854110717773
Agent1_Eval_StdReturn : 18.762664794921875
Agent1_Eval_MaxReturn : 6.700176239013672
Agent1_Eval_MinReturn : -53.42975616455078
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -15.002105712890625
Agent1_Train_StdReturn : 18.516693115234375
Agent1_Train_MaxReturn : 12.749534606933594
Agent1_Train_MinReturn : -52.21295166015625
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1456500
Agent1_TimeSinceStart : 2253.88991522789
Agent1_Critic_Loss : 1.2434121370315552
Agent1_Actor_Loss : -1.0376551151275635
Agent1_Alpha_Loss : 0.7279102802276611
Agent1_Temperature : 0.07608044996681103
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 971 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 972 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 973 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 974 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 975 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 976 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 977 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 978 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 979 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 980 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -8.078264236450195
Agent0_Eval_StdReturn : 16.90233612060547
Agent0_Eval_MaxReturn : 16.758432388305664
Agent0_Eval_MinReturn : -37.78252029418945
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -11.910024642944336
Agent0_Train_StdReturn : 10.982834815979004
Agent0_Train_MaxReturn : 8.534441947937012
Agent0_Train_MinReturn : -32.334632873535156
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1471500
Agent0_TimeSinceStart : 2274.9437522888184
Agent0_Critic_Loss : 1.7464836835861206
Agent0_Actor_Loss : -0.931617021560669
Agent0_Alpha_Loss : 0.7123337984085083
Agent0_Temperature : 0.07582159866316185
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -7.543713569641113
Agent1_Eval_StdReturn : 7.766400337219238
Agent1_Eval_MaxReturn : 5.689845085144043
Agent1_Eval_MinReturn : -19.369163513183594
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -7.840401649475098
Agent1_Train_StdReturn : 13.282013893127441
Agent1_Train_MaxReturn : 11.285798072814941
Agent1_Train_MinReturn : -32.120269775390625
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1471500
Agent1_TimeSinceStart : 2277.0274505615234
Agent1_Critic_Loss : 1.416022539138794
Agent1_Actor_Loss : -0.9919862151145935
Agent1_Alpha_Loss : 0.7268154621124268
Agent1_Temperature : 0.07586772003988805
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 981 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 982 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 983 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 984 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 985 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 986 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 987 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 988 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 989 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 990 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -6.035455703735352
Agent0_Eval_StdReturn : 21.89693260192871
Agent0_Eval_MaxReturn : 31.99154281616211
Agent0_Eval_MinReturn : -54.338443756103516
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -10.859064102172852
Agent0_Train_StdReturn : 17.664201736450195
Agent0_Train_MaxReturn : 16.9580135345459
Agent0_Train_MinReturn : -36.6263313293457
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1486500
Agent0_TimeSinceStart : 2297.9666504859924
Agent0_Critic_Loss : 1.4621871709823608
Agent0_Actor_Loss : -1.1198499202728271
Agent0_Alpha_Loss : 0.7112252712249756
Agent0_Temperature : 0.0756113839991518
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -13.046841621398926
Agent1_Eval_StdReturn : 13.579036712646484
Agent1_Eval_MaxReturn : 3.594757556915283
Agent1_Eval_MinReturn : -42.2644157409668
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -9.60282039642334
Agent1_Train_StdReturn : 9.598381996154785
Agent1_Train_MaxReturn : -0.24756813049316406
Agent1_Train_MinReturn : -31.62193489074707
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1486500
Agent1_TimeSinceStart : 2300.05762386322
Agent1_Critic_Loss : 1.1443405151367188
Agent1_Actor_Loss : -1.185337781906128
Agent1_Alpha_Loss : 0.7234877943992615
Agent1_Temperature : 0.0756568693001542
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 991 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 992 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 993 ************

Collecting data to be used for training...

Training agent.../home/harvey/anaconda3/envs/285final/lib/python3.7/site-packages/gym/core.py:318: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  "Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future."
/home/harvey/anaconda3/envs/285final/lib/python3.7/site-packages/gym/wrappers/step_api_compatibility.py:40: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  "Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future."
/home/harvey/anaconda3/envs/285final/lib/python3.7/site-packages/gym/core.py:257: DeprecationWarning: [33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.[0m
  "Function `env.seed(seed)` is marked as deprecated and will be removed in the future. "


Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 994 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 995 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 996 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 997 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 998 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 999 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...
./peersacv2_2ndrun.sh: 48: --seed: not found



LOGGING TO:  /home/harvey/Documents/cs285/CS285-Project/cs285/scripts/../../data/peersac_v2_5agents_eps1_HalfCheetah-v4_12-12-2022_17-02-29 



########################
logging outputs to  /home/harvey/Documents/cs285/CS285-Project/cs285/scripts/../../data/peersac_v2_5agents_eps1_HalfCheetah-v4_12-12-2022_17-02-29
########################
Using GPU id 0


********** Iteration 0 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -37.402889251708984
Agent0_Eval_StdReturn : 29.959867477416992
Agent0_Eval_MaxReturn : 2.8824901580810547
Agent0_Eval_MinReturn : -88.16786193847656
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -68.51490020751953
Agent0_Train_StdReturn : 35.8519172668457
Agent0_Train_MaxReturn : 10.17027473449707
Agent0_Train_MinReturn : -109.59283447265625
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1500
Agent0_TimeSinceStart : 2.22151780128479
Agent0_Critic_Loss : 1.715803623199463
Agent0_Actor_Loss : -0.3432028293609619
Agent0_Alpha_Loss : 0.9863041639328003
Agent0_Temperature : 0.09997000449985415
Agent0_Initial_DataCollection_AverageReturn : -68.51490020751953
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -54.462310791015625
Agent1_Eval_StdReturn : 37.87112045288086
Agent1_Eval_MaxReturn : 15.620088577270508
Agent1_Eval_MinReturn : -98.72659301757812
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -41.37040710449219
Agent1_Train_StdReturn : 23.476428985595703
Agent1_Train_MaxReturn : -3.7883758544921875
Agent1_Train_MinReturn : -74.03202819824219
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1500
Agent1_TimeSinceStart : 4.299197435379028
Agent1_Critic_Loss : 1.1657971143722534
Agent1_Actor_Loss : -0.489025354385376
Agent1_Alpha_Loss : 0.980064868927002
Agent1_Temperature : 0.09997000449985606
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 1 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 2 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 3 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 4 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 5 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 6 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 7 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 8 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 9 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 10 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -23.91555404663086
Agent0_Eval_StdReturn : 36.396690368652344
Agent0_Eval_MaxReturn : 19.48440170288086
Agent0_Eval_MinReturn : -96.45121765136719
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -50.23561096191406
Agent0_Train_StdReturn : 25.51015853881836
Agent0_Train_MaxReturn : 2.222367286682129
Agent0_Train_MinReturn : -80.17941284179688
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 16500
Agent0_TimeSinceStart : 25.931362628936768
Agent0_Critic_Loss : 0.859268069267273
Agent0_Actor_Loss : -0.4422001540660858
Agent0_Alpha_Loss : 0.984131932258606
Agent0_Temperature : 0.0996705193621572
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -41.76715850830078
Agent1_Eval_StdReturn : 32.45429229736328
Agent1_Eval_MaxReturn : 17.20775604248047
Agent1_Eval_MinReturn : -96.88452911376953
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -50.48727798461914
Agent1_Train_StdReturn : 31.446962356567383
Agent1_Train_MaxReturn : -2.3715856075286865
Agent1_Train_MinReturn : -110.19876098632812
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 16500
Agent1_TimeSinceStart : 28.051570892333984
Agent1_Critic_Loss : 0.8242071270942688
Agent1_Actor_Loss : -0.5978373289108276
Agent1_Alpha_Loss : 0.9913411140441895
Agent1_Temperature : 0.09967041864865771
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 11 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 12 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 13 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 14 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 15 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 16 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 17 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 18 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 19 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 20 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -54.4146728515625
Agent0_Eval_StdReturn : 29.299518585205078
Agent0_Eval_MaxReturn : -3.030252456665039
Agent0_Eval_MinReturn : -112.00616455078125
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -42.122962951660156
Agent0_Train_StdReturn : 33.38285446166992
Agent0_Train_MaxReturn : 8.322027206420898
Agent0_Train_MinReturn : -115.837646484375
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 31500
Agent0_TimeSinceStart : 49.328919649124146
Agent0_Critic_Loss : 0.9875594973564148
Agent0_Actor_Loss : -0.4603153169155121
Agent0_Alpha_Loss : 0.9934805035591125
Agent0_Temperature : 0.09937189903597349
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -44.39208221435547
Agent1_Eval_StdReturn : 37.74639129638672
Agent1_Eval_MaxReturn : 16.940141677856445
Agent1_Eval_MinReturn : -112.73168182373047
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -29.703868865966797
Agent1_Train_StdReturn : 25.628751754760742
Agent1_Train_MaxReturn : 0.7001132965087891
Agent1_Train_MinReturn : -66.21515655517578
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 31500
Agent1_TimeSinceStart : 51.43697190284729
Agent1_Critic_Loss : 0.8050893545150757
Agent1_Actor_Loss : -0.49642840027809143
Agent1_Alpha_Loss : 0.9909679889678955
Agent1_Temperature : 0.09937173779425999
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 21 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 22 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 23 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 24 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 25 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 26 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 27 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 28 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 29 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 30 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -33.71171188354492
Agent0_Eval_StdReturn : 22.554655075073242
Agent0_Eval_MaxReturn : -2.0345535278320312
Agent0_Eval_MinReturn : -73.42320251464844
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -46.329307556152344
Agent0_Train_StdReturn : 18.40324592590332
Agent0_Train_MaxReturn : -5.066147327423096
Agent0_Train_MinReturn : -66.70167541503906
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 46500
Agent0_TimeSinceStart : 72.47565293312073
Agent0_Critic_Loss : 0.7971794605255127
Agent0_Actor_Loss : -0.3955150246620178
Agent0_Alpha_Loss : 0.989852786064148
Agent0_Temperature : 0.09907409799761885
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -36.81714630126953
Agent1_Eval_StdReturn : 23.335851669311523
Agent1_Eval_MaxReturn : -4.7169389724731445
Agent1_Eval_MinReturn : -85.56881713867188
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -53.330711364746094
Agent1_Train_StdReturn : 33.35007858276367
Agent1_Train_MaxReturn : 7.588226318359375
Agent1_Train_MinReturn : -85.77046203613281
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 46500
Agent1_TimeSinceStart : 74.57273960113525
Agent1_Critic_Loss : 0.8441203832626343
Agent1_Actor_Loss : -0.621477484703064
Agent1_Alpha_Loss : 0.9834251403808594
Agent1_Temperature : 0.09907406018154105
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 31 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 32 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 33 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 34 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 35 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 36 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 37 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 38 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 39 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 40 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -43.04814910888672
Agent0_Eval_StdReturn : 32.17839431762695
Agent0_Eval_MaxReturn : 0.7364044189453125
Agent0_Eval_MinReturn : -100.2462158203125
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -38.61564254760742
Agent0_Train_StdReturn : 38.854156494140625
Agent0_Train_MaxReturn : 20.940956115722656
Agent0_Train_MinReturn : -116.27200317382812
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 61500
Agent0_TimeSinceStart : 95.66199350357056
Agent0_Critic_Loss : 0.7907739877700806
Agent0_Actor_Loss : -0.5221840143203735
Agent0_Alpha_Loss : 0.9822091460227966
Agent0_Temperature : 0.09877769418986988
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -34.73299789428711
Agent1_Eval_StdReturn : 41.12437438964844
Agent1_Eval_MaxReturn : 26.9316463470459
Agent1_Eval_MinReturn : -92.31023406982422
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -37.83911895751953
Agent1_Train_StdReturn : 32.18024826049805
Agent1_Train_MaxReturn : 11.516632080078125
Agent1_Train_MinReturn : -101.08418273925781
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 61500
Agent1_TimeSinceStart : 97.76831722259521
Agent1_Critic_Loss : 0.6978700757026672
Agent1_Actor_Loss : -0.5253624320030212
Agent1_Alpha_Loss : 0.9788335561752319
Agent1_Temperature : 0.09877756782259886
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 41 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 42 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 43 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 44 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 45 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 46 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 47 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 48 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 49 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 50 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -46.934967041015625
Agent0_Eval_StdReturn : 31.348405838012695
Agent0_Eval_MaxReturn : -16.98957633972168
Agent0_Eval_MinReturn : -118.02684020996094
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -15.140853881835938
Agent0_Train_StdReturn : 24.39678955078125
Agent0_Train_MaxReturn : 40.97198486328125
Agent0_Train_MinReturn : -53.86602020263672
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 76500
Agent0_TimeSinceStart : 118.83175206184387
Agent0_Critic_Loss : 0.6611195802688599
Agent0_Actor_Loss : -0.5105288028717041
Agent0_Alpha_Loss : 0.9739531874656677
Agent0_Temperature : 0.09848289963040038
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -36.336097717285156
Agent1_Eval_StdReturn : 32.79088592529297
Agent1_Eval_MaxReturn : 24.158000946044922
Agent1_Eval_MinReturn : -70.31455993652344
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -29.5858154296875
Agent1_Train_StdReturn : 35.8078727722168
Agent1_Train_MaxReturn : 44.278663635253906
Agent1_Train_MinReturn : -76.22896575927734
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 76500
Agent1_TimeSinceStart : 120.9379312992096
Agent1_Critic_Loss : 0.6772318482398987
Agent1_Actor_Loss : -0.5262969732284546
Agent1_Alpha_Loss : 0.982785701751709
Agent1_Temperature : 0.09848275821373755
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 51 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 52 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 53 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 54 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 55 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 56 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 57 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 58 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 59 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 60 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -43.72178268432617
Agent0_Eval_StdReturn : 38.8220100402832
Agent0_Eval_MaxReturn : 35.61690902709961
Agent0_Eval_MinReturn : -104.31648254394531
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -52.030113220214844
Agent0_Train_StdReturn : 38.087100982666016
Agent0_Train_MaxReturn : 39.558963775634766
Agent0_Train_MinReturn : -98.00469207763672
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 91500
Agent0_TimeSinceStart : 142.0300669670105
Agent0_Critic_Loss : 0.6245212554931641
Agent0_Actor_Loss : -0.4247426986694336
Agent0_Alpha_Loss : 0.9661376476287842
Agent0_Temperature : 0.09818970216975532
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -30.328983306884766
Agent1_Eval_StdReturn : 15.20173454284668
Agent1_Eval_MaxReturn : -2.770376205444336
Agent1_Eval_MinReturn : -60.83476257324219
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -38.50912094116211
Agent1_Train_StdReturn : 39.56721878051758
Agent1_Train_MaxReturn : 16.756465911865234
Agent1_Train_MinReturn : -130.3779754638672
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 91500
Agent1_TimeSinceStart : 144.1340537071228
Agent1_Critic_Loss : 0.6105620265007019
Agent1_Actor_Loss : -0.5564115047454834
Agent1_Alpha_Loss : 0.9703361988067627
Agent1_Temperature : 0.09818930405035234
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 61 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 62 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 63 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 64 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 65 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 66 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 67 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 68 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 69 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 70 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -52.762855529785156
Agent0_Eval_StdReturn : 44.205299377441406
Agent0_Eval_MaxReturn : 15.64101791381836
Agent0_Eval_MinReturn : -142.34568786621094
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -49.44839859008789
Agent0_Train_StdReturn : 22.104602813720703
Agent0_Train_MaxReturn : -10.296367645263672
Agent0_Train_MinReturn : -82.19908142089844
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 106500
Agent0_TimeSinceStart : 165.48670101165771
Agent0_Critic_Loss : 0.6689488887786865
Agent0_Actor_Loss : -0.30811411142349243
Agent0_Alpha_Loss : 0.9603499174118042
Agent0_Temperature : 0.09789804591066706
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -11.847929954528809
Agent1_Eval_StdReturn : 23.670469284057617
Agent1_Eval_MaxReturn : 20.192594528198242
Agent1_Eval_MinReturn : -53.48154830932617
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -38.02881622314453
Agent1_Train_StdReturn : 31.219186782836914
Agent1_Train_MaxReturn : 3.945117950439453
Agent1_Train_MinReturn : -104.6073989868164
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 106500
Agent1_TimeSinceStart : 167.59659671783447
Agent1_Critic_Loss : 0.6293494701385498
Agent1_Actor_Loss : -0.5705143213272095
Agent1_Alpha_Loss : 0.9569061994552612
Agent1_Temperature : 0.09789783515036317
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 71 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 72 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 73 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 74 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 75 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 76 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 77 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 78 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 79 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 80 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -56.94144821166992
Agent0_Eval_StdReturn : 36.218387603759766
Agent0_Eval_MaxReturn : 5.019533157348633
Agent0_Eval_MinReturn : -114.47781372070312
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -39.97748565673828
Agent0_Train_StdReturn : 35.48146438598633
Agent0_Train_MaxReturn : 11.034629821777344
Agent0_Train_MinReturn : -89.38318634033203
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 121500
Agent0_TimeSinceStart : 188.70103693008423
Agent0_Critic_Loss : 0.5700304508209229
Agent0_Actor_Loss : -0.47591161727905273
Agent0_Alpha_Loss : 0.9490940570831299
Agent0_Temperature : 0.09760947079952008
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -33.63285446166992
Agent1_Eval_StdReturn : 20.059892654418945
Agent1_Eval_MaxReturn : 8.663753509521484
Agent1_Eval_MinReturn : -60.487937927246094
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -22.63499641418457
Agent1_Train_StdReturn : 26.519304275512695
Agent1_Train_MaxReturn : 10.277416229248047
Agent1_Train_MinReturn : -87.01278686523438
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 121500
Agent1_TimeSinceStart : 190.8010447025299
Agent1_Critic_Loss : 0.5817664861679077
Agent1_Actor_Loss : -0.49270516633987427
Agent1_Alpha_Loss : 0.9461566209793091
Agent1_Temperature : 0.09760911461694488
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 81 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 82 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 83 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 84 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 85 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 86 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 87 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 88 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 89 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 90 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -18.83267593383789
Agent0_Eval_StdReturn : 15.16438102722168
Agent0_Eval_MaxReturn : 5.713106632232666
Agent0_Eval_MinReturn : -44.82973098754883
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -24.416912078857422
Agent0_Train_StdReturn : 17.775209426879883
Agent0_Train_MaxReturn : 0.8707981109619141
Agent0_Train_MinReturn : -58.05852127075195
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 136500
Agent0_TimeSinceStart : 211.84703826904297
Agent0_Critic_Loss : 0.5475753545761108
Agent0_Actor_Loss : -0.6363674402236938
Agent0_Alpha_Loss : 0.9323199987411499
Agent0_Temperature : 0.09732457112416312
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -26.827835083007812
Agent1_Eval_StdReturn : 24.32474708557129
Agent1_Eval_MaxReturn : 37.67233657836914
Agent1_Eval_MinReturn : -58.71758270263672
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -29.234508514404297
Agent1_Train_StdReturn : 24.624916076660156
Agent1_Train_MaxReturn : -1.5855069160461426
Agent1_Train_MinReturn : -82.74052429199219
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 136500
Agent1_TimeSinceStart : 213.9500334262848
Agent1_Critic_Loss : 0.5042410492897034
Agent1_Actor_Loss : -0.5955747961997986
Agent1_Alpha_Loss : 0.9367141127586365
Agent1_Temperature : 0.09732402408973201
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 91 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 92 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 93 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 94 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 95 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 96 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 97 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 98 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 99 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 100 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -29.444652557373047
Agent0_Eval_StdReturn : 22.099498748779297
Agent0_Eval_MaxReturn : 7.326150894165039
Agent0_Eval_MinReturn : -58.50382995605469
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -14.757555961608887
Agent0_Train_StdReturn : 11.024503707885742
Agent0_Train_MaxReturn : -0.12058496475219727
Agent0_Train_MinReturn : -41.136993408203125
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 151500
Agent0_TimeSinceStart : 235.11360001564026
Agent0_Critic_Loss : 0.4772423505783081
Agent0_Actor_Loss : -0.5221172571182251
Agent0_Alpha_Loss : 0.8880226612091064
Agent0_Temperature : 0.09704510045243908
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -19.904706954956055
Agent1_Eval_StdReturn : 26.724220275878906
Agent1_Eval_MaxReturn : 10.418119430541992
Agent1_Eval_MinReturn : -87.53263854980469
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -23.447458267211914
Agent1_Train_StdReturn : 19.089914321899414
Agent1_Train_MaxReturn : 1.8365697860717773
Agent1_Train_MinReturn : -56.6861572265625
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 151500
Agent1_TimeSinceStart : 237.21121549606323
Agent1_Critic_Loss : 0.4125604033470154
Agent1_Actor_Loss : -0.707768440246582
Agent1_Alpha_Loss : 0.8971108198165894
Agent1_Temperature : 0.0970436132970357
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 101 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 102 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 103 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 104 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 105 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 106 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 107 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 108 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 109 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 110 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -30.767642974853516
Agent0_Eval_StdReturn : 17.50433921813965
Agent0_Eval_MaxReturn : -0.7569875717163086
Agent0_Eval_MinReturn : -62.048851013183594
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -23.379776000976562
Agent0_Train_StdReturn : 8.86280632019043
Agent0_Train_MaxReturn : -13.470674514770508
Agent0_Train_MinReturn : -38.76492691040039
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 166500
Agent0_TimeSinceStart : 258.361985206604
Agent0_Critic_Loss : 0.5106647610664368
Agent0_Actor_Loss : -0.45430633425712585
Agent0_Alpha_Loss : 0.8220301866531372
Agent0_Temperature : 0.09677501457882966
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -31.079681396484375
Agent1_Eval_StdReturn : 7.5414934158325195
Agent1_Eval_MaxReturn : -18.115276336669922
Agent1_Eval_MinReturn : -42.8000373840332
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -16.983463287353516
Agent1_Train_StdReturn : 15.189926147460938
Agent1_Train_MaxReturn : -1.2720222473144531
Agent1_Train_MinReturn : -53.7143440246582
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 166500
Agent1_TimeSinceStart : 260.4771406650543
Agent1_Critic_Loss : 0.4368811845779419
Agent1_Actor_Loss : -0.7464069128036499
Agent1_Alpha_Loss : 0.8406094312667847
Agent1_Temperature : 0.09677101011721238
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 111 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 112 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 113 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 114 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 115 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 116 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 117 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 118 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 119 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 120 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -20.88374137878418
Agent0_Eval_StdReturn : 14.174619674682617
Agent0_Eval_MaxReturn : 4.246062755584717
Agent0_Eval_MinReturn : -40.55828094482422
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -20.741641998291016
Agent0_Train_StdReturn : 10.192222595214844
Agent0_Train_MaxReturn : 1.752439022064209
Agent0_Train_MinReturn : -36.037391662597656
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 181500
Agent0_TimeSinceStart : 281.70862317085266
Agent0_Critic_Loss : 0.5201339721679688
Agent0_Actor_Loss : -0.422872394323349
Agent0_Alpha_Loss : 0.7886238098144531
Agent0_Temperature : 0.09651591844458478
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -31.238265991210938
Agent1_Eval_StdReturn : 16.09378433227539
Agent1_Eval_MaxReturn : -7.596423625946045
Agent1_Eval_MinReturn : -56.38445281982422
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -23.652019500732422
Agent1_Train_StdReturn : 14.572884559631348
Agent1_Train_MaxReturn : 7.34368371963501
Agent1_Train_MinReturn : -53.63733673095703
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 181500
Agent1_TimeSinceStart : 283.82438588142395
Agent1_Critic_Loss : 0.44199109077453613
Agent1_Actor_Loss : -0.6862270832061768
Agent1_Alpha_Loss : 0.791344165802002
Agent1_Temperature : 0.09650866215102405
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 121 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 122 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 123 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 124 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 125 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 126 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 127 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 128 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 129 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 130 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -27.926334381103516
Agent0_Eval_StdReturn : 9.467351913452148
Agent0_Eval_MaxReturn : -8.975711822509766
Agent0_Eval_MinReturn : -39.29246520996094
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -27.27530288696289
Agent0_Train_StdReturn : 10.95773983001709
Agent0_Train_MaxReturn : -10.473200798034668
Agent0_Train_MinReturn : -47.45228576660156
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 196500
Agent0_TimeSinceStart : 305.1353988647461
Agent0_Critic_Loss : 0.45977354049682617
Agent0_Actor_Loss : -0.4179542362689972
Agent0_Alpha_Loss : 0.7858771085739136
Agent0_Temperature : 0.0962665421815333
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -33.37521743774414
Agent1_Eval_StdReturn : 11.096887588500977
Agent1_Eval_MaxReturn : -13.519022941589355
Agent1_Eval_MinReturn : -52.051910400390625
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -25.00204849243164
Agent1_Train_StdReturn : 6.33139181137085
Agent1_Train_MaxReturn : -15.062255859375
Agent1_Train_MinReturn : -35.988521575927734
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 196500
Agent1_TimeSinceStart : 307.2482943534851
Agent1_Critic_Loss : 0.46405088901519775
Agent1_Actor_Loss : -0.6285388469696045
Agent1_Alpha_Loss : 0.7820494174957275
Agent1_Temperature : 0.09625616381430681
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 131 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 132 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 133 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 134 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 135 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 136 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 137 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 138 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 139 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 140 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -23.519750595092773
Agent0_Eval_StdReturn : 15.197402000427246
Agent0_Eval_MaxReturn : 4.695085525512695
Agent0_Eval_MinReturn : -45.464698791503906
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -32.95502471923828
Agent0_Train_StdReturn : 9.782207489013672
Agent0_Train_MaxReturn : -15.930069923400879
Agent0_Train_MinReturn : -46.802696228027344
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 211500
Agent0_TimeSinceStart : 328.4894154071808
Agent0_Critic_Loss : 0.4417003393173218
Agent0_Actor_Loss : -0.41691136360168457
Agent0_Alpha_Loss : 0.780207633972168
Agent0_Temperature : 0.09602078137677841
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -21.26649284362793
Agent1_Eval_StdReturn : 15.819012641906738
Agent1_Eval_MaxReturn : -0.38559412956237793
Agent1_Eval_MinReturn : -54.704959869384766
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -28.739843368530273
Agent1_Train_StdReturn : 15.642762184143066
Agent1_Train_MaxReturn : -12.895857810974121
Agent1_Train_MinReturn : -65.59808349609375
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 211500
Agent1_TimeSinceStart : 330.6062898635864
Agent1_Critic_Loss : 0.3858966827392578
Agent1_Actor_Loss : -0.5920645594596863
Agent1_Alpha_Loss : 0.8160032629966736
Agent1_Temperature : 0.09600694172873044
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 141 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 142 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 143 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 144 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 145 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 146 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 147 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 148 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 149 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 150 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -28.1939697265625
Agent0_Eval_StdReturn : 13.960450172424316
Agent0_Eval_MaxReturn : -10.298070907592773
Agent0_Eval_MinReturn : -53.43170928955078
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -28.597814559936523
Agent0_Train_StdReturn : 9.148052215576172
Agent0_Train_MaxReturn : -13.346701622009277
Agent0_Train_MinReturn : -46.98386764526367
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 226500
Agent0_TimeSinceStart : 351.832391500473
Agent0_Critic_Loss : 0.3562975823879242
Agent0_Actor_Loss : -0.5277118682861328
Agent0_Alpha_Loss : 0.7915433049201965
Agent0_Temperature : 0.0957752553508145
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -24.112308502197266
Agent1_Eval_StdReturn : 15.152573585510254
Agent1_Eval_MaxReturn : 6.5834245681762695
Agent1_Eval_MinReturn : -43.852516174316406
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -20.190866470336914
Agent1_Train_StdReturn : 9.12331771850586
Agent1_Train_MaxReturn : 0.14342880249023438
Agent1_Train_MinReturn : -30.758987426757812
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 226500
Agent1_TimeSinceStart : 353.9433898925781
Agent1_Critic_Loss : 0.3734341263771057
Agent1_Actor_Loss : -0.5671097040176392
Agent1_Alpha_Loss : 0.8059293031692505
Agent1_Temperature : 0.09575606524920333
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 151 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 152 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 153 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 154 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 155 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 156 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 157 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 158 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 159 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 160 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -25.204833984375
Agent0_Eval_StdReturn : 11.708731651306152
Agent0_Eval_MaxReturn : -4.343748569488525
Agent0_Eval_MinReturn : -47.12419128417969
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -19.054582595825195
Agent0_Train_StdReturn : 15.484556198120117
Agent0_Train_MaxReturn : 18.519432067871094
Agent0_Train_MinReturn : -38.156734466552734
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 241500
Agent0_TimeSinceStart : 375.1218149662018
Agent0_Critic_Loss : 0.4418940544128418
Agent0_Actor_Loss : -0.49285465478897095
Agent0_Alpha_Loss : 0.800083577632904
Agent0_Temperature : 0.09552755966466112
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -27.416723251342773
Agent1_Eval_StdReturn : 11.337067604064941
Agent1_Eval_MaxReturn : -10.333407402038574
Agent1_Eval_MinReturn : -47.17497253417969
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -23.22572898864746
Agent1_Train_StdReturn : 11.740751266479492
Agent1_Train_MaxReturn : -4.436774730682373
Agent1_Train_MinReturn : -46.06743621826172
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 241500
Agent1_TimeSinceStart : 377.2359983921051
Agent1_Critic_Loss : 0.5150948762893677
Agent1_Actor_Loss : -0.6063558459281921
Agent1_Alpha_Loss : 0.8357057571411133
Agent1_Temperature : 0.09550216267422923
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 161 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 162 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 163 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 164 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 165 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 166 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 167 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 168 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 169 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 170 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -22.155757904052734
Agent0_Eval_StdReturn : 16.179601669311523
Agent0_Eval_MaxReturn : 12.295085906982422
Agent0_Eval_MinReturn : -43.36664581298828
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -23.729684829711914
Agent0_Train_StdReturn : 11.769902229309082
Agent0_Train_MaxReturn : -9.187591552734375
Agent0_Train_MinReturn : -53.92979431152344
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 256500
Agent0_TimeSinceStart : 398.4244589805603
Agent0_Critic_Loss : 0.32645654678344727
Agent0_Actor_Loss : -0.34486010670661926
Agent0_Alpha_Loss : 0.7950134873390198
Agent0_Temperature : 0.09527660947134277
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -18.02213478088379
Agent1_Eval_StdReturn : 11.25052261352539
Agent1_Eval_MaxReturn : -3.393223285675049
Agent1_Eval_MinReturn : -41.452423095703125
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -21.535785675048828
Agent1_Train_StdReturn : 12.459490776062012
Agent1_Train_MaxReturn : -0.09596538543701172
Agent1_Train_MinReturn : -37.55775451660156
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 256500
Agent1_TimeSinceStart : 400.5321292877197
Agent1_Critic_Loss : 0.302630752325058
Agent1_Actor_Loss : -0.4640001654624939
Agent1_Alpha_Loss : 0.8033294677734375
Agent1_Temperature : 0.09524684318721896
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 171 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 172 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 173 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 174 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 175 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 176 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 177 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 178 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 179 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 180 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -25.514184951782227
Agent0_Eval_StdReturn : 15.488993644714355
Agent0_Eval_MaxReturn : 2.4832701683044434
Agent0_Eval_MinReturn : -51.94955825805664
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -22.428421020507812
Agent0_Train_StdReturn : 5.748612403869629
Agent0_Train_MaxReturn : -12.550745964050293
Agent0_Train_MinReturn : -32.879493713378906
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 271500
Agent0_TimeSinceStart : 421.7062957286835
Agent0_Critic_Loss : 0.4610532522201538
Agent0_Actor_Loss : -0.4308801293373108
Agent0_Alpha_Loss : 0.7677969932556152
Agent0_Temperature : 0.09502497041679314
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -12.967350959777832
Agent1_Eval_StdReturn : 7.969706058502197
Agent1_Eval_MaxReturn : -3.8396964073181152
Agent1_Eval_MinReturn : -27.958669662475586
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -24.472042083740234
Agent1_Train_StdReturn : 21.196258544921875
Agent1_Train_MaxReturn : 16.082571029663086
Agent1_Train_MinReturn : -62.66522216796875
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 271500
Agent1_TimeSinceStart : 423.8164961338043
Agent1_Critic_Loss : 0.359713613986969
Agent1_Actor_Loss : -0.617526650428772
Agent1_Alpha_Loss : 0.8059419393539429
Agent1_Temperature : 0.09499105460929712
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 181 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 182 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 183 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 184 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 185 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 186 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 187 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 188 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 189 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 190 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -16.642990112304688
Agent0_Eval_StdReturn : 18.252405166625977
Agent0_Eval_MaxReturn : 12.778963088989258
Agent0_Eval_MinReturn : -53.057518005371094
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -16.450563430786133
Agent0_Train_StdReturn : 10.989173889160156
Agent0_Train_MaxReturn : -1.6186285018920898
Agent0_Train_MinReturn : -35.02390670776367
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 286500
Agent0_TimeSinceStart : 445.0092031955719
Agent0_Critic_Loss : 0.35467466711997986
Agent0_Actor_Loss : -0.3836682438850403
Agent0_Alpha_Loss : 0.7777705788612366
Agent0_Temperature : 0.09477488891768783
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -24.005855560302734
Agent1_Eval_StdReturn : 9.256022453308105
Agent1_Eval_MaxReturn : -8.834857940673828
Agent1_Eval_MinReturn : -37.57427215576172
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -22.10171127319336
Agent1_Train_StdReturn : 11.252330780029297
Agent1_Train_MaxReturn : -8.962278366088867
Agent1_Train_MinReturn : -38.74756622314453
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 286500
Agent1_TimeSinceStart : 447.11201214790344
Agent1_Critic_Loss : 0.3140887916088104
Agent1_Actor_Loss : -0.5815757513046265
Agent1_Alpha_Loss : 0.798014223575592
Agent1_Temperature : 0.09473492419390815
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 191 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 192 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 193 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 194 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 195 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 196 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 197 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 198 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 199 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 200 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -23.182857513427734
Agent0_Eval_StdReturn : 19.7374324798584
Agent0_Eval_MaxReturn : 5.638155937194824
Agent0_Eval_MinReturn : -61.58277893066406
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -17.979690551757812
Agent0_Train_StdReturn : 11.477479934692383
Agent0_Train_MaxReturn : -0.46777820587158203
Agent0_Train_MinReturn : -41.137046813964844
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 301500
Agent0_TimeSinceStart : 468.30072808265686
Agent0_Critic_Loss : 0.29808151721954346
Agent0_Actor_Loss : -0.41844767332077026
Agent0_Alpha_Loss : 0.7884504795074463
Agent0_Temperature : 0.09452629468104648
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -19.60263442993164
Agent1_Eval_StdReturn : 9.430371284484863
Agent1_Eval_MaxReturn : -9.52389907836914
Agent1_Eval_MinReturn : -41.741912841796875
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -22.64647674560547
Agent1_Train_StdReturn : 20.30595588684082
Agent1_Train_MaxReturn : 0.556675910949707
Agent1_Train_MinReturn : -65.47058868408203
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 301500
Agent1_TimeSinceStart : 470.409188747406
Agent1_Critic_Loss : 0.26779142022132874
Agent1_Actor_Loss : -0.5618029832839966
Agent1_Alpha_Loss : 0.8041840195655823
Agent1_Temperature : 0.09447905397417984
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 201 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 202 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 203 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 204 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 205 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 206 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 207 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 208 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 209 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 210 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -16.834436416625977
Agent0_Eval_StdReturn : 5.489479064941406
Agent0_Eval_MaxReturn : -8.895668029785156
Agent0_Eval_MinReturn : -24.466964721679688
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -15.260477066040039
Agent0_Train_StdReturn : 11.939260482788086
Agent0_Train_MaxReturn : 8.224030494689941
Agent0_Train_MinReturn : -32.36702346801758
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 316500
Agent0_TimeSinceStart : 491.5984320640564
Agent0_Critic_Loss : 0.2859153151512146
Agent0_Actor_Loss : -0.3250885307788849
Agent0_Alpha_Loss : 0.7727420330047607
Agent0_Temperature : 0.09427620928925301
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -15.209630966186523
Agent1_Eval_StdReturn : 9.738685607910156
Agent1_Eval_MaxReturn : -2.1514415740966797
Agent1_Eval_MinReturn : -34.27082061767578
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -15.098068237304688
Agent1_Train_StdReturn : 14.361947059631348
Agent1_Train_MaxReturn : 5.692083358764648
Agent1_Train_MinReturn : -41.763580322265625
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 316500
Agent1_TimeSinceStart : 493.703982591629
Agent1_Critic_Loss : 0.24216662347316742
Agent1_Actor_Loss : -0.5256650447845459
Agent1_Alpha_Loss : 0.7859071493148804
Agent1_Temperature : 0.0942237852170736
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 211 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 212 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 213 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 214 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 215 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 216 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 217 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 218 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 219 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 220 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -24.440153121948242
Agent0_Eval_StdReturn : 10.320208549499512
Agent0_Eval_MaxReturn : -11.086820602416992
Agent0_Eval_MinReturn : -41.61936950683594
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -16.37552261352539
Agent0_Train_StdReturn : 8.917698860168457
Agent0_Train_MaxReturn : -2.2386178970336914
Agent0_Train_MinReturn : -35.08063507080078
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 331500
Agent0_TimeSinceStart : 514.880640745163
Agent0_Critic_Loss : 0.27453064918518066
Agent0_Actor_Loss : -0.2726828455924988
Agent0_Alpha_Loss : 0.7738845944404602
Agent0_Temperature : 0.09402493249027753
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -13.533790588378906
Agent1_Eval_StdReturn : 16.100234985351562
Agent1_Eval_MaxReturn : 14.346391677856445
Agent1_Eval_MinReturn : -44.485015869140625
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -19.28213119506836
Agent1_Train_StdReturn : 16.66891860961914
Agent1_Train_MaxReturn : 7.489724159240723
Agent1_Train_MinReturn : -53.477020263671875
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 331500
Agent1_TimeSinceStart : 516.9937262535095
Agent1_Critic_Loss : 0.22121810913085938
Agent1_Actor_Loss : -0.5803021788597107
Agent1_Alpha_Loss : 0.7763712406158447
Agent1_Temperature : 0.09396939435605729
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 221 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 222 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 223 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 224 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 225 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 226 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 227 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 228 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 229 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 230 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -23.29505729675293
Agent0_Eval_StdReturn : 9.816821098327637
Agent0_Eval_MaxReturn : -8.378107070922852
Agent0_Eval_MinReturn : -39.772056579589844
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -24.711734771728516
Agent0_Train_StdReturn : 11.530563354492188
Agent0_Train_MaxReturn : -5.971344947814941
Agent0_Train_MinReturn : -44.714805603027344
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 346500
Agent0_TimeSinceStart : 538.1666924953461
Agent0_Critic_Loss : 0.24280433356761932
Agent0_Actor_Loss : -0.38147494196891785
Agent0_Alpha_Loss : 0.7693901658058167
Agent0_Temperature : 0.09377368595503001
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -22.141942977905273
Agent1_Eval_StdReturn : 23.49115562438965
Agent1_Eval_MaxReturn : 13.136165618896484
Agent1_Eval_MinReturn : -54.332908630371094
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -15.963635444641113
Agent1_Train_StdReturn : 12.240062713623047
Agent1_Train_MaxReturn : 2.281604290008545
Agent1_Train_MinReturn : -38.98141098022461
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 346500
Agent1_TimeSinceStart : 540.2666833400726
Agent1_Critic_Loss : 0.2722749710083008
Agent1_Actor_Loss : -0.5057464241981506
Agent1_Alpha_Loss : 0.7964900732040405
Agent1_Temperature : 0.09371546117565607
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 231 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 232 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 233 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 234 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 235 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 236 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 237 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 238 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 239 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 240 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -11.281886100769043
Agent0_Eval_StdReturn : 14.613313674926758
Agent0_Eval_MaxReturn : 12.651994705200195
Agent0_Eval_MinReturn : -31.262256622314453
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -17.237852096557617
Agent0_Train_StdReturn : 11.36341667175293
Agent0_Train_MaxReturn : 9.542861938476562
Agent0_Train_MinReturn : -29.696273803710938
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 361500
Agent0_TimeSinceStart : 561.4041984081268
Agent0_Critic_Loss : 0.24154458940029144
Agent0_Actor_Loss : -0.40000420808792114
Agent0_Alpha_Loss : 0.7888218760490417
Agent0_Temperature : 0.0935213291305389
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -14.188435554504395
Agent1_Eval_StdReturn : 22.246265411376953
Agent1_Eval_MaxReturn : 20.72504997253418
Agent1_Eval_MinReturn : -46.26112365722656
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -27.403432846069336
Agent1_Train_StdReturn : 10.972180366516113
Agent1_Train_MaxReturn : -12.427263259887695
Agent1_Train_MinReturn : -47.70875549316406
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 361500
Agent1_TimeSinceStart : 563.5046489238739
Agent1_Critic_Loss : 0.3092811703681946
Agent1_Actor_Loss : -0.5406836271286011
Agent1_Alpha_Loss : 0.7957779169082642
Agent1_Temperature : 0.09346076573438206
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 241 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 242 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 243 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 244 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 245 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 246 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 247 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 248 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 249 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 250 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -25.413028717041016
Agent0_Eval_StdReturn : 22.131824493408203
Agent0_Eval_MaxReturn : 5.747021675109863
Agent0_Eval_MinReturn : -81.7874755859375
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -16.812053680419922
Agent0_Train_StdReturn : 21.83034324645996
Agent0_Train_MaxReturn : 2.614469051361084
Agent0_Train_MinReturn : -76.43199157714844
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 376500
Agent0_TimeSinceStart : 584.6200814247131
Agent0_Critic_Loss : 0.22156287729740143
Agent0_Actor_Loss : -0.3588688373565674
Agent0_Alpha_Loss : 0.7785330414772034
Agent0_Temperature : 0.09326861589151432
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -25.069589614868164
Agent1_Eval_StdReturn : 12.658096313476562
Agent1_Eval_MaxReturn : -9.556476593017578
Agent1_Eval_MinReturn : -54.11137390136719
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -15.532852172851562
Agent1_Train_StdReturn : 16.342899322509766
Agent1_Train_MaxReturn : 19.179737091064453
Agent1_Train_MinReturn : -35.47442626953125
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 376500
Agent1_TimeSinceStart : 586.7138969898224
Agent1_Critic_Loss : 0.23057740926742554
Agent1_Actor_Loss : -0.5553212761878967
Agent1_Alpha_Loss : 0.8062822818756104
Agent1_Temperature : 0.09320439294076945
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 251 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 252 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 253 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 254 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 255 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 256 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 257 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 258 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 259 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 260 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -22.067852020263672
Agent0_Eval_StdReturn : 19.949623107910156
Agent0_Eval_MaxReturn : 14.280997276306152
Agent0_Eval_MinReturn : -56.17497253417969
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : 0.9741851091384888
Agent0_Train_StdReturn : 12.435647010803223
Agent0_Train_MaxReturn : 25.781818389892578
Agent0_Train_MinReturn : -20.203397750854492
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 391500
Agent0_TimeSinceStart : 607.8485169410706
Agent0_Critic_Loss : 0.2918989062309265
Agent0_Actor_Loss : -0.4057426154613495
Agent0_Alpha_Loss : 0.7847590446472168
Agent0_Temperature : 0.09301579903860381
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -25.279991149902344
Agent1_Eval_StdReturn : 23.872486114501953
Agent1_Eval_MaxReturn : 6.143393516540527
Agent1_Eval_MinReturn : -81.24803161621094
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -21.101408004760742
Agent1_Train_StdReturn : 23.282503128051758
Agent1_Train_MaxReturn : 17.1980037689209
Agent1_Train_MinReturn : -60.66034698486328
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 391500
Agent1_TimeSinceStart : 609.9349398612976
Agent1_Critic_Loss : 0.35103023052215576
Agent1_Actor_Loss : -0.45326465368270874
Agent1_Alpha_Loss : 0.8069970607757568
Agent1_Temperature : 0.09294715321576939
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 261 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 262 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 263 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 264 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 265 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 266 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 267 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 268 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 269 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 270 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -22.86374282836914
Agent0_Eval_StdReturn : 22.648298263549805
Agent0_Eval_MaxReturn : 12.71311092376709
Agent0_Eval_MinReturn : -55.66093444824219
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -6.475412845611572
Agent0_Train_StdReturn : 31.328170776367188
Agent0_Train_MaxReturn : 41.81034469604492
Agent0_Train_MinReturn : -53.318626403808594
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 406500
Agent0_TimeSinceStart : 630.9970996379852
Agent0_Critic_Loss : 0.2768988609313965
Agent0_Actor_Loss : -0.34961432218551636
Agent0_Alpha_Loss : 0.7861909866333008
Agent0_Temperature : 0.09275960842400781
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -13.672192573547363
Agent1_Eval_StdReturn : 14.852211952209473
Agent1_Eval_MaxReturn : 4.951673984527588
Agent1_Eval_MinReturn : -42.61935043334961
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -31.37396812438965
Agent1_Train_StdReturn : 17.7661190032959
Agent1_Train_MaxReturn : 2.020401954650879
Agent1_Train_MinReturn : -61.086387634277344
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 406500
Agent1_TimeSinceStart : 633.0899314880371
Agent1_Critic_Loss : 0.30948084592819214
Agent1_Actor_Loss : -0.6339108943939209
Agent1_Alpha_Loss : 0.7954014539718628
Agent1_Temperature : 0.09268933049967681
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 271 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 272 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 273 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 274 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 275 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 276 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 277 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 278 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 279 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 280 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -24.263530731201172
Agent0_Eval_StdReturn : 16.103404998779297
Agent0_Eval_MaxReturn : -0.28548717498779297
Agent0_Eval_MinReturn : -57.235443115234375
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -31.921184539794922
Agent0_Train_StdReturn : 21.66221046447754
Agent0_Train_MaxReturn : 0.5751638412475586
Agent0_Train_MinReturn : -67.64543151855469
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 421500
Agent0_TimeSinceStart : 654.1874432563782
Agent0_Critic_Loss : 0.26769882440567017
Agent0_Actor_Loss : -0.48555663228034973
Agent0_Alpha_Loss : 0.7681726813316345
Agent0_Temperature : 0.09250348509085103
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -18.675392150878906
Agent1_Eval_StdReturn : 18.813934326171875
Agent1_Eval_MaxReturn : 29.488367080688477
Agent1_Eval_MinReturn : -40.71168518066406
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -19.3332576751709
Agent1_Train_StdReturn : 18.772783279418945
Agent1_Train_MaxReturn : 14.11131477355957
Agent1_Train_MinReturn : -44.97947692871094
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 421500
Agent1_TimeSinceStart : 656.2816731929779
Agent1_Critic_Loss : 0.26722121238708496
Agent1_Actor_Loss : -0.5769151449203491
Agent1_Alpha_Loss : 0.8111541271209717
Agent1_Temperature : 0.0924317086128364
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 281 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 282 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 283 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 284 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 285 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 286 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 287 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 288 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 289 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 290 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -25.209232330322266
Agent0_Eval_StdReturn : 21.18598747253418
Agent0_Eval_MaxReturn : 7.603050231933594
Agent0_Eval_MinReturn : -56.278160095214844
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -20.7010440826416
Agent0_Train_StdReturn : 15.803474426269531
Agent0_Train_MaxReturn : 7.370441436767578
Agent0_Train_MinReturn : -47.5135383605957
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 436500
Agent0_TimeSinceStart : 677.325825214386
Agent0_Critic_Loss : 0.3377474248409271
Agent0_Actor_Loss : -0.4439707398414612
Agent0_Alpha_Loss : 0.7806147336959839
Agent0_Temperature : 0.09224866946727557
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -16.544105529785156
Agent1_Eval_StdReturn : 24.70606231689453
Agent1_Eval_MaxReturn : 17.474958419799805
Agent1_Eval_MinReturn : -71.1980209350586
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -19.186769485473633
Agent1_Train_StdReturn : 19.92337989807129
Agent1_Train_MaxReturn : 4.1470208168029785
Agent1_Train_MinReturn : -72.58134460449219
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 436500
Agent1_TimeSinceStart : 679.4254460334778
Agent1_Critic_Loss : 0.3275989890098572
Agent1_Actor_Loss : -0.5675286650657654
Agent1_Alpha_Loss : 0.7977250814437866
Agent1_Temperature : 0.09217512644443648
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 291 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 292 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 293 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 294 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 295 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 296 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 297 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 298 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 299 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 300 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -20.810169219970703
Agent0_Eval_StdReturn : 19.753664016723633
Agent0_Eval_MaxReturn : 19.3043155670166
Agent0_Eval_MinReturn : -46.19401931762695
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -25.004430770874023
Agent0_Train_StdReturn : 21.718950271606445
Agent0_Train_MaxReturn : 3.190286159515381
Agent0_Train_MinReturn : -64.66511535644531
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 451500
Agent0_TimeSinceStart : 700.497551202774
Agent0_Critic_Loss : 0.32145002484321594
Agent0_Actor_Loss : -0.4336237609386444
Agent0_Alpha_Loss : 0.7983766794204712
Agent0_Temperature : 0.09199441816617436
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -13.7927885055542
Agent1_Eval_StdReturn : 22.00375747680664
Agent1_Eval_MaxReturn : 11.394819259643555
Agent1_Eval_MinReturn : -64.40591430664062
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -15.238960266113281
Agent1_Train_StdReturn : 20.620824813842773
Agent1_Train_MaxReturn : 14.537681579589844
Agent1_Train_MinReturn : -45.85527801513672
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 451500
Agent1_TimeSinceStart : 702.5916383266449
Agent1_Critic_Loss : 0.32500720024108887
Agent1_Actor_Loss : -0.58185213804245
Agent1_Alpha_Loss : 0.7930086255073547
Agent1_Temperature : 0.09191891347763123
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 301 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 302 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 303 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 304 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 305 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 306 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 307 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 308 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 309 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 310 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -19.438772201538086
Agent0_Eval_StdReturn : 22.85051918029785
Agent0_Eval_MaxReturn : 40.415618896484375
Agent0_Eval_MinReturn : -40.983299255371094
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -12.88322639465332
Agent0_Train_StdReturn : 27.251541137695312
Agent0_Train_MaxReturn : 44.63874435424805
Agent0_Train_MinReturn : -69.44587707519531
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 466500
Agent0_TimeSinceStart : 723.614015340805
Agent0_Critic_Loss : 0.35300883650779724
Agent0_Actor_Loss : -0.4780850410461426
Agent0_Alpha_Loss : 0.7913732528686523
Agent0_Temperature : 0.09173880140103956
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -24.722148895263672
Agent1_Eval_StdReturn : 16.873397827148438
Agent1_Eval_MaxReturn : -1.6646194458007812
Agent1_Eval_MinReturn : -60.575443267822266
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -16.8466854095459
Agent1_Train_StdReturn : 16.341018676757812
Agent1_Train_MaxReturn : 4.055912017822266
Agent1_Train_MinReturn : -52.70538330078125
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 466500
Agent1_TimeSinceStart : 725.7143514156342
Agent1_Critic_Loss : 0.3651657700538635
Agent1_Actor_Loss : -0.5078121423721313
Agent1_Alpha_Loss : 0.7837432026863098
Agent1_Temperature : 0.09166337168990596
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 311 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 312 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 313 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 314 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 315 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 316 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 317 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 318 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 319 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 320 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -16.693052291870117
Agent0_Eval_StdReturn : 18.080591201782227
Agent0_Eval_MaxReturn : 8.324410438537598
Agent0_Eval_MinReturn : -46.566131591796875
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -17.251731872558594
Agent0_Train_StdReturn : 10.113831520080566
Agent0_Train_MaxReturn : 2.060420036315918
Agent0_Train_MinReturn : -33.10677719116211
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 481500
Agent0_TimeSinceStart : 746.7905566692352
Agent0_Critic_Loss : 0.3338434398174286
Agent0_Actor_Loss : -0.5211151242256165
Agent0_Alpha_Loss : 0.7938306331634521
Agent0_Temperature : 0.09148211776484526
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -13.722424507141113
Agent1_Eval_StdReturn : 12.981816291809082
Agent1_Eval_MaxReturn : 3.1821160316467285
Agent1_Eval_MinReturn : -36.329017639160156
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -24.52604103088379
Agent1_Train_StdReturn : 13.167064666748047
Agent1_Train_MaxReturn : -0.6586706638336182
Agent1_Train_MinReturn : -43.49568176269531
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 481500
Agent1_TimeSinceStart : 748.8818264007568
Agent1_Critic_Loss : 0.3973739445209503
Agent1_Actor_Loss : -0.6562386751174927
Agent1_Alpha_Loss : 0.7919934988021851
Agent1_Temperature : 0.09140932746725346
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 321 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 322 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 323 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 324 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 325 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 326 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 327 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 328 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 329 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 330 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -23.442127227783203
Agent0_Eval_StdReturn : 12.401371002197266
Agent0_Eval_MaxReturn : -14.896387100219727
Agent0_Eval_MinReturn : -56.32659912109375
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -14.619461059570312
Agent0_Train_StdReturn : 12.37103271484375
Agent0_Train_MaxReturn : 4.220873832702637
Agent0_Train_MinReturn : -42.821449279785156
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 496500
Agent0_TimeSinceStart : 769.9845917224884
Agent0_Critic_Loss : 0.34227651357650757
Agent0_Actor_Loss : -0.49015194177627563
Agent0_Alpha_Loss : 0.7843832969665527
Agent0_Temperature : 0.09122597480362415
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -22.32973289489746
Agent1_Eval_StdReturn : 7.552016258239746
Agent1_Eval_MaxReturn : -7.809701919555664
Agent1_Eval_MinReturn : -33.30739974975586
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -27.224822998046875
Agent1_Train_StdReturn : 18.263124465942383
Agent1_Train_MaxReturn : 1.5657994747161865
Agent1_Train_MinReturn : -61.164878845214844
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 496500
Agent1_TimeSinceStart : 772.0896444320679
Agent1_Critic_Loss : 0.3484386205673218
Agent1_Actor_Loss : -0.6473129987716675
Agent1_Alpha_Loss : 0.7777743339538574
Agent1_Temperature : 0.0911557716470665
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 331 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 332 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 333 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 334 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 335 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 336 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 337 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 338 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 339 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 340 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -16.581073760986328
Agent0_Eval_StdReturn : 8.70246696472168
Agent0_Eval_MaxReturn : -6.4341630935668945
Agent0_Eval_MinReturn : -31.619304656982422
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -14.996225357055664
Agent0_Train_StdReturn : 16.568002700805664
Agent0_Train_MaxReturn : 16.837413787841797
Agent0_Train_MinReturn : -39.869422912597656
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 511500
Agent0_TimeSinceStart : 793.2386105060577
Agent0_Critic_Loss : 0.30954450368881226
Agent0_Actor_Loss : -0.3898780941963196
Agent0_Alpha_Loss : 0.7854546904563904
Agent0_Temperature : 0.09097056333923276
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -21.8474063873291
Agent1_Eval_StdReturn : 14.524008750915527
Agent1_Eval_MaxReturn : 4.271660804748535
Agent1_Eval_MinReturn : -45.8021125793457
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -27.691631317138672
Agent1_Train_StdReturn : 20.68902587890625
Agent1_Train_MaxReturn : -2.3704681396484375
Agent1_Train_MinReturn : -65.98509216308594
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 511500
Agent1_TimeSinceStart : 795.3418304920197
Agent1_Critic_Loss : 0.36609381437301636
Agent1_Actor_Loss : -0.47877973318099976
Agent1_Alpha_Loss : 0.7798566818237305
Agent1_Temperature : 0.09090340606826992
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 341 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 342 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 343 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 344 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 345 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 346 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 347 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 348 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 349 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 350 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -14.07818603515625
Agent0_Eval_StdReturn : 10.909381866455078
Agent0_Eval_MaxReturn : 2.7400918006896973
Agent0_Eval_MinReturn : -32.11608123779297
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -18.106605529785156
Agent0_Train_StdReturn : 10.93648910522461
Agent0_Train_MaxReturn : -0.5720691680908203
Agent0_Train_MinReturn : -39.17164611816406
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 526500
Agent0_TimeSinceStart : 816.4763858318329
Agent0_Critic_Loss : 0.3923066258430481
Agent0_Actor_Loss : -0.5253956317901611
Agent0_Alpha_Loss : 0.7750826478004456
Agent0_Temperature : 0.09071655842535688
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -20.130168914794922
Agent1_Eval_StdReturn : 17.874229431152344
Agent1_Eval_MaxReturn : 5.395743370056152
Agent1_Eval_MinReturn : -58.215084075927734
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -12.712677001953125
Agent1_Train_StdReturn : 6.229047775268555
Agent1_Train_MaxReturn : -4.986265659332275
Agent1_Train_MinReturn : -23.117769241333008
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 526500
Agent1_TimeSinceStart : 818.5848140716553
Agent1_Critic_Loss : 0.4059273898601532
Agent1_Actor_Loss : -0.6257137060165405
Agent1_Alpha_Loss : 0.7796672582626343
Agent1_Temperature : 0.09065143796303281
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 351 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 352 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 353 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 354 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 355 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 356 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 357 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 358 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 359 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 360 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -21.30446434020996
Agent0_Eval_StdReturn : 24.995744705200195
Agent0_Eval_MaxReturn : 30.533470153808594
Agent0_Eval_MinReturn : -58.730831146240234
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -12.3490571975708
Agent0_Train_StdReturn : 15.812942504882812
Agent0_Train_MaxReturn : 19.706954956054688
Agent0_Train_MinReturn : -42.52070617675781
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 541500
Agent0_TimeSinceStart : 839.6777379512787
Agent0_Critic_Loss : 0.353329598903656
Agent0_Actor_Loss : -0.5314981937408447
Agent0_Alpha_Loss : 0.7704370021820068
Agent0_Temperature : 0.09046309404630544
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -27.320510864257812
Agent1_Eval_StdReturn : 12.575575828552246
Agent1_Eval_MaxReturn : -11.832725524902344
Agent1_Eval_MinReturn : -53.462276458740234
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -22.19598388671875
Agent1_Train_StdReturn : 15.032611846923828
Agent1_Train_MaxReturn : -1.3937023878097534
Agent1_Train_MinReturn : -56.22062301635742
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 541500
Agent1_TimeSinceStart : 841.766654253006
Agent1_Critic_Loss : 0.3880499303340912
Agent1_Actor_Loss : -0.6676984429359436
Agent1_Alpha_Loss : 0.7915647029876709
Agent1_Temperature : 0.09039976981256632
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 361 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 362 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 363 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 364 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 365 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 366 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 367 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 368 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 369 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 370 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -11.054123878479004
Agent0_Eval_StdReturn : 13.579546928405762
Agent0_Eval_MaxReturn : 11.95913028717041
Agent0_Eval_MinReturn : -34.96487045288086
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -14.609376907348633
Agent0_Train_StdReturn : 16.792207717895508
Agent0_Train_MaxReturn : 17.357681274414062
Agent0_Train_MinReturn : -47.03812789916992
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 556500
Agent0_TimeSinceStart : 862.8883473873138
Agent0_Critic_Loss : 0.4483591914176941
Agent0_Actor_Loss : -0.507468581199646
Agent0_Alpha_Loss : 0.777197539806366
Agent0_Temperature : 0.09020923384100507
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -23.706348419189453
Agent1_Eval_StdReturn : 13.375577926635742
Agent1_Eval_MaxReturn : 2.978182077407837
Agent1_Eval_MinReturn : -44.25049591064453
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -17.34799575805664
Agent1_Train_StdReturn : 13.994400024414062
Agent1_Train_MaxReturn : 8.299437522888184
Agent1_Train_MinReturn : -34.95197296142578
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 556500
Agent1_TimeSinceStart : 864.9950153827667
Agent1_Critic_Loss : 0.4095737338066101
Agent1_Actor_Loss : -0.5987250804901123
Agent1_Alpha_Loss : 0.7762559652328491
Agent1_Temperature : 0.09014843909640356
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 371 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 372 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 373 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 374 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 375 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 376 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 377 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 378 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 379 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 380 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -24.579992294311523
Agent0_Eval_StdReturn : 14.21782112121582
Agent0_Eval_MaxReturn : -1.2908400297164917
Agent0_Eval_MinReturn : -47.359840393066406
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -16.921741485595703
Agent0_Train_StdReturn : 12.384235382080078
Agent0_Train_MaxReturn : 7.604168891906738
Agent0_Train_MinReturn : -41.77024841308594
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 571500
Agent0_TimeSinceStart : 886.1540064811707
Agent0_Critic_Loss : 0.4132230281829834
Agent0_Actor_Loss : -0.4720035791397095
Agent0_Alpha_Loss : 0.7683382034301758
Agent0_Temperature : 0.08995699558147861
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -15.715370178222656
Agent1_Eval_StdReturn : 12.728795051574707
Agent1_Eval_MaxReturn : 8.217905044555664
Agent1_Eval_MinReturn : -37.874542236328125
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -19.479143142700195
Agent1_Train_StdReturn : 13.287662506103516
Agent1_Train_MaxReturn : 3.0131590366363525
Agent1_Train_MinReturn : -38.823081970214844
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 571500
Agent1_TimeSinceStart : 888.2633657455444
Agent1_Critic_Loss : 0.3452942669391632
Agent1_Actor_Loss : -0.6767685413360596
Agent1_Alpha_Loss : 0.77814120054245
Agent1_Temperature : 0.08989788822832008
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 381 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 382 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 383 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 384 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 385 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 386 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 387 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 388 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 389 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 390 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -21.56639862060547
Agent0_Eval_StdReturn : 12.57038688659668
Agent0_Eval_MaxReturn : -7.579676628112793
Agent0_Eval_MinReturn : -44.25579071044922
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -12.462485313415527
Agent0_Train_StdReturn : 6.726092338562012
Agent0_Train_MaxReturn : 1.477391242980957
Agent0_Train_MinReturn : -22.951141357421875
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 586500
Agent0_TimeSinceStart : 909.5061550140381
Agent0_Critic_Loss : 0.3417307734489441
Agent0_Actor_Loss : -0.5329445600509644
Agent0_Alpha_Loss : 0.7842623591423035
Agent0_Temperature : 0.08970722158038294
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -19.374677658081055
Agent1_Eval_StdReturn : 14.141448020935059
Agent1_Eval_MaxReturn : -1.4208316802978516
Agent1_Eval_MinReturn : -44.54280471801758
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -23.079906463623047
Agent1_Train_StdReturn : 14.043539047241211
Agent1_Train_MaxReturn : -2.8329505920410156
Agent1_Train_MinReturn : -49.422096252441406
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 586500
Agent1_TimeSinceStart : 911.6112203598022
Agent1_Critic_Loss : 0.40343567728996277
Agent1_Actor_Loss : -0.6550102233886719
Agent1_Alpha_Loss : 0.7581074237823486
Agent1_Temperature : 0.08964927886648394
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 391 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 392 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 393 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 394 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 395 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 396 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 397 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 398 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 399 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 400 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -19.115259170532227
Agent0_Eval_StdReturn : 12.327378273010254
Agent0_Eval_MaxReturn : -5.303356170654297
Agent0_Eval_MinReturn : -46.81766891479492
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -20.7404842376709
Agent0_Train_StdReturn : 22.054216384887695
Agent0_Train_MaxReturn : 21.63334083557129
Agent0_Train_MinReturn : -60.045387268066406
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 601500
Agent0_TimeSinceStart : 932.8078727722168
Agent0_Critic_Loss : 0.3775748312473297
Agent0_Actor_Loss : -0.46556198596954346
Agent0_Alpha_Loss : 0.7683945894241333
Agent0_Temperature : 0.08945790106558134
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -20.37146759033203
Agent1_Eval_StdReturn : 6.914867401123047
Agent1_Eval_MaxReturn : -7.70777702331543
Agent1_Eval_MinReturn : -31.99854278564453
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -19.321147918701172
Agent1_Train_StdReturn : 10.182555198669434
Agent1_Train_MaxReturn : 3.503124952316284
Agent1_Train_MinReturn : -33.83456039428711
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 601500
Agent1_TimeSinceStart : 934.9162306785583
Agent1_Critic_Loss : 0.47056689858436584
Agent1_Actor_Loss : -0.5597981810569763
Agent1_Alpha_Loss : 0.7515952587127686
Agent1_Temperature : 0.08940287433933918
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 401 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 402 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 403 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 404 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 405 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 406 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 407 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 408 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 409 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 410 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -14.543493270874023
Agent0_Eval_StdReturn : 12.776885032653809
Agent0_Eval_MaxReturn : 7.924971580505371
Agent0_Eval_MinReturn : -34.679359436035156
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -13.116701126098633
Agent0_Train_StdReturn : 6.936010837554932
Agent0_Train_MaxReturn : -3.6207213401794434
Agent0_Train_MinReturn : -26.188751220703125
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 616500
Agent0_TimeSinceStart : 956.1220502853394
Agent0_Critic_Loss : 0.42409276962280273
Agent0_Actor_Loss : -0.4388878047466278
Agent0_Alpha_Loss : 0.7871904373168945
Agent0_Temperature : 0.0892089356927311
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -19.336782455444336
Agent1_Eval_StdReturn : 10.311163902282715
Agent1_Eval_MaxReturn : 1.9575157165527344
Agent1_Eval_MinReturn : -36.83098220825195
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -17.968019485473633
Agent1_Train_StdReturn : 13.190056800842285
Agent1_Train_MaxReturn : -0.1585240364074707
Agent1_Train_MinReturn : -50.516456604003906
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 616500
Agent1_TimeSinceStart : 958.2298774719238
Agent1_Critic_Loss : 0.4132380187511444
Agent1_Actor_Loss : -0.6205552816390991
Agent1_Alpha_Loss : 0.7551363706588745
Agent1_Temperature : 0.0891579039644749
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 411 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 412 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 413 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 414 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 415 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 416 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 417 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 418 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 419 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 420 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -24.739521026611328
Agent0_Eval_StdReturn : 17.69223403930664
Agent0_Eval_MaxReturn : 11.377243995666504
Agent0_Eval_MinReturn : -55.88905334472656
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -11.430936813354492
Agent0_Train_StdReturn : 16.38728904724121
Agent0_Train_MaxReturn : 23.427337646484375
Agent0_Train_MinReturn : -29.135406494140625
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 631500
Agent0_TimeSinceStart : 979.3731060028076
Agent0_Critic_Loss : 0.43879687786102295
Agent0_Actor_Loss : -0.5059113502502441
Agent0_Alpha_Loss : 0.7675846815109253
Agent0_Temperature : 0.08895819685767006
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -13.182065963745117
Agent1_Eval_StdReturn : 9.990313529968262
Agent1_Eval_MaxReturn : 14.311903953552246
Agent1_Eval_MinReturn : -23.07171630859375
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -18.75420379638672
Agent1_Train_StdReturn : 11.378400802612305
Agent1_Train_MaxReturn : 5.158900260925293
Agent1_Train_MinReturn : -39.781471252441406
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 631500
Agent1_TimeSinceStart : 981.479558467865
Agent1_Critic_Loss : 0.34421417117118835
Agent1_Actor_Loss : -0.7152687311172485
Agent1_Alpha_Loss : 0.7717792391777039
Agent1_Temperature : 0.08891325016801646
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 421 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 422 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 423 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 424 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 425 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 426 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 427 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 428 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 429 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 430 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -17.3409481048584
Agent0_Eval_StdReturn : 21.05257797241211
Agent0_Eval_MaxReturn : 8.369288444519043
Agent0_Eval_MinReturn : -51.1655158996582
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -17.846616744995117
Agent0_Train_StdReturn : 14.23659896850586
Agent0_Train_MaxReturn : 3.797335624694824
Agent0_Train_MinReturn : -40.024436950683594
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 646500
Agent0_TimeSinceStart : 1002.6774632930756
Agent0_Critic_Loss : 0.4214019179344177
Agent0_Actor_Loss : -0.4971740245819092
Agent0_Alpha_Loss : 0.7776720523834229
Agent0_Temperature : 0.08870639334438642
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -20.07147979736328
Agent1_Eval_StdReturn : 14.886123657226562
Agent1_Eval_MaxReturn : 12.131964683532715
Agent1_Eval_MinReturn : -42.36559295654297
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -7.143959045410156
Agent1_Train_StdReturn : 12.218351364135742
Agent1_Train_MaxReturn : 10.142400741577148
Agent1_Train_MinReturn : -28.24764633178711
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 646500
Agent1_TimeSinceStart : 1004.7925744056702
Agent1_Critic_Loss : 0.3664857745170593
Agent1_Actor_Loss : -0.554129958152771
Agent1_Alpha_Loss : 0.7729469537734985
Agent1_Temperature : 0.08866776681957375
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 431 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 432 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 433 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 434 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 435 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 436 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 437 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 438 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 439 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 440 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -13.895833015441895
Agent0_Eval_StdReturn : 18.00188446044922
Agent0_Eval_MaxReturn : 11.246768951416016
Agent0_Eval_MinReturn : -45.88405227661133
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -21.802764892578125
Agent0_Train_StdReturn : 11.137162208557129
Agent0_Train_MaxReturn : -7.668822765350342
Agent0_Train_MinReturn : -44.99763488769531
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 661500
Agent0_TimeSinceStart : 1025.9542791843414
Agent0_Critic_Loss : 0.42966312170028687
Agent0_Actor_Loss : -0.38965776562690735
Agent0_Alpha_Loss : 0.7962244749069214
Agent0_Temperature : 0.08845499964931633
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -25.40813636779785
Agent1_Eval_StdReturn : 13.994773864746094
Agent1_Eval_MaxReturn : -3.6241343021392822
Agent1_Eval_MinReturn : -48.03012466430664
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -15.349291801452637
Agent1_Train_StdReturn : 19.365102767944336
Agent1_Train_MaxReturn : 23.495887756347656
Agent1_Train_MinReturn : -46.371002197265625
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 661500
Agent1_TimeSinceStart : 1028.0593564510345
Agent1_Critic_Loss : 0.3168865442276001
Agent1_Actor_Loss : -0.6022745370864868
Agent1_Alpha_Loss : 0.7914738655090332
Agent1_Temperature : 0.08842025115126144
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 441 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 442 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 443 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 444 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 445 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 446 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 447 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 448 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 449 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 450 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -13.786158561706543
Agent0_Eval_StdReturn : 11.450437545776367
Agent0_Eval_MaxReturn : 12.633161544799805
Agent0_Eval_MinReturn : -28.356826782226562
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -15.307952880859375
Agent0_Train_StdReturn : 12.567571640014648
Agent0_Train_MaxReturn : 5.17082405090332
Agent0_Train_MinReturn : -39.96877670288086
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 676500
Agent0_TimeSinceStart : 1049.2270016670227
Agent0_Critic_Loss : 0.4448821246623993
Agent0_Actor_Loss : -0.4277225732803345
Agent0_Alpha_Loss : 0.7700904607772827
Agent0_Temperature : 0.08820391026932957
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -12.066048622131348
Agent1_Eval_StdReturn : 10.13454818725586
Agent1_Eval_MaxReturn : -0.692851185798645
Agent1_Eval_MinReturn : -34.40960693359375
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -18.769927978515625
Agent1_Train_StdReturn : 14.488950729370117
Agent1_Train_MaxReturn : 0.6472107172012329
Agent1_Train_MinReturn : -49.95293426513672
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 676500
Agent1_TimeSinceStart : 1051.3322145938873
Agent1_Critic_Loss : 0.33078983426094055
Agent1_Actor_Loss : -0.6683016419410706
Agent1_Alpha_Loss : 0.7840918302536011
Agent1_Temperature : 0.08817169886163385
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 451 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 452 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 453 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 454 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 455 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 456 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 457 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 458 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 459 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 460 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -17.88398551940918
Agent0_Eval_StdReturn : 20.08487892150879
Agent0_Eval_MaxReturn : 9.94140338897705
Agent0_Eval_MinReturn : -61.09196472167969
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -19.56681251525879
Agent0_Train_StdReturn : 15.398813247680664
Agent0_Train_MaxReturn : -1.2075632810592651
Agent0_Train_MinReturn : -52.77657699584961
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 691500
Agent0_TimeSinceStart : 1072.4359986782074
Agent0_Critic_Loss : 0.4113115072250366
Agent0_Actor_Loss : -0.5976359248161316
Agent0_Alpha_Loss : 0.7812236547470093
Agent0_Temperature : 0.0879528330811661
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -20.491405487060547
Agent1_Eval_StdReturn : 16.883386611938477
Agent1_Eval_MaxReturn : 20.24196434020996
Agent1_Eval_MinReturn : -37.805564880371094
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -20.426959991455078
Agent1_Train_StdReturn : 15.75003719329834
Agent1_Train_MaxReturn : 4.132874488830566
Agent1_Train_MinReturn : -48.28291320800781
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 691500
Agent1_TimeSinceStart : 1074.5483136177063
Agent1_Critic_Loss : 0.4379335045814514
Agent1_Actor_Loss : -0.614330530166626
Agent1_Alpha_Loss : 0.783568263053894
Agent1_Temperature : 0.08792406498547244
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 461 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 462 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 463 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 464 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 465 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 466 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 467 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 468 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 469 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 470 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -18.815439224243164
Agent0_Eval_StdReturn : 23.300636291503906
Agent0_Eval_MaxReturn : 3.5303401947021484
Agent0_Eval_MinReturn : -73.34518432617188
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -18.290395736694336
Agent0_Train_StdReturn : 12.152237892150879
Agent0_Train_MaxReturn : 0.881169319152832
Agent0_Train_MinReturn : -46.68284225463867
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 706500
Agent0_TimeSinceStart : 1095.6542325019836
Agent0_Critic_Loss : 0.40774819254875183
Agent0_Actor_Loss : -0.44190850853919983
Agent0_Alpha_Loss : 0.7736782431602478
Agent0_Temperature : 0.0877017843611888
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -13.658421516418457
Agent1_Eval_StdReturn : 21.106170654296875
Agent1_Eval_MaxReturn : 13.135858535766602
Agent1_Eval_MinReturn : -51.003971099853516
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -19.05201530456543
Agent1_Train_StdReturn : 22.83321762084961
Agent1_Train_MaxReturn : 11.831985473632812
Agent1_Train_MinReturn : -67.1856460571289
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 706500
Agent1_TimeSinceStart : 1097.754364490509
Agent1_Critic_Loss : 0.4680587649345398
Agent1_Actor_Loss : -0.5731503963470459
Agent1_Alpha_Loss : 0.7825418710708618
Agent1_Temperature : 0.08767698332525069
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 471 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 472 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 473 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 474 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 475 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 476 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 477 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 478 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 479 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 480 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -18.682416915893555
Agent0_Eval_StdReturn : 11.318499565124512
Agent0_Eval_MaxReturn : -0.7295694351196289
Agent0_Eval_MinReturn : -34.107810974121094
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -9.174286842346191
Agent0_Train_StdReturn : 14.659464836120605
Agent0_Train_MaxReturn : 20.658660888671875
Agent0_Train_MinReturn : -24.290142059326172
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 721500
Agent0_TimeSinceStart : 1118.8551244735718
Agent0_Critic_Loss : 0.41108524799346924
Agent0_Actor_Loss : -0.5009208917617798
Agent0_Alpha_Loss : 0.761506199836731
Agent0_Temperature : 0.08745212312459179
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -13.16889762878418
Agent1_Eval_StdReturn : 25.08652687072754
Agent1_Eval_MaxReturn : 7.752100467681885
Agent1_Eval_MinReturn : -73.25115966796875
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -25.594985961914062
Agent1_Train_StdReturn : 23.696395874023438
Agent1_Train_MaxReturn : 15.865166664123535
Agent1_Train_MinReturn : -78.55741882324219
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 721500
Agent1_TimeSinceStart : 1120.95361495018
Agent1_Critic_Loss : 0.4717423915863037
Agent1_Actor_Loss : -0.5576149821281433
Agent1_Alpha_Loss : 0.7799418568611145
Agent1_Temperature : 0.08742790403830225
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 481 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 482 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 483 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 484 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 485 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 486 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 487 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 488 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 489 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 490 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -16.20736312866211
Agent0_Eval_StdReturn : 11.321547508239746
Agent0_Eval_MaxReturn : -0.41762542724609375
Agent0_Eval_MinReturn : -37.97825622558594
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -23.440439224243164
Agent0_Train_StdReturn : 15.348069190979004
Agent0_Train_MaxReturn : 0.30855655670166016
Agent0_Train_MinReturn : -50.74176788330078
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 736500
Agent0_TimeSinceStart : 1142.048674583435
Agent0_Critic_Loss : 0.4252140522003174
Agent0_Actor_Loss : -0.4980241358280182
Agent0_Alpha_Loss : 0.7907546758651733
Agent0_Temperature : 0.0872033517137562
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -21.10677719116211
Agent1_Eval_StdReturn : 24.814481735229492
Agent1_Eval_MaxReturn : 6.8977766036987305
Agent1_Eval_MinReturn : -71.96903228759766
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -18.827281951904297
Agent1_Train_StdReturn : 23.51673126220703
Agent1_Train_MaxReturn : 25.513164520263672
Agent1_Train_MinReturn : -60.18876266479492
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 736500
Agent1_TimeSinceStart : 1144.1452927589417
Agent1_Critic_Loss : 0.33870041370391846
Agent1_Actor_Loss : -0.7086285352706909
Agent1_Alpha_Loss : 0.7937291860580444
Agent1_Temperature : 0.08717745348092673
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 491 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 492 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 493 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 494 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 495 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 496 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 497 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 498 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 499 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 500 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -14.339963912963867
Agent0_Eval_StdReturn : 9.389639854431152
Agent0_Eval_MaxReturn : 0.07305145263671875
Agent0_Eval_MinReturn : -27.662446975708008
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -4.801074981689453
Agent0_Train_StdReturn : 17.103464126586914
Agent0_Train_MaxReturn : 31.355316162109375
Agent0_Train_MinReturn : -29.44696044921875
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 751500
Agent0_TimeSinceStart : 1165.2379796504974
Agent0_Critic_Loss : 0.5036094188690186
Agent0_Actor_Loss : -0.6024211049079895
Agent0_Alpha_Loss : 0.7744885683059692
Agent0_Temperature : 0.08695347731057211
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -11.095779418945312
Agent1_Eval_StdReturn : 14.256965637207031
Agent1_Eval_MaxReturn : 17.878345489501953
Agent1_Eval_MinReturn : -28.248044967651367
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -20.342437744140625
Agent1_Train_StdReturn : 22.49197769165039
Agent1_Train_MaxReturn : 10.361501693725586
Agent1_Train_MinReturn : -61.04387283325195
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 751500
Agent1_TimeSinceStart : 1167.3236935138702
Agent1_Critic_Loss : 0.49778661131858826
Agent1_Actor_Loss : -0.6667494177818298
Agent1_Alpha_Loss : 0.8034722805023193
Agent1_Temperature : 0.08692695574665939
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 501 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 502 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 503 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 504 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 505 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 506 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 507 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 508 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 509 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 510 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -15.561635971069336
Agent0_Eval_StdReturn : 16.38744354248047
Agent0_Eval_MaxReturn : 10.529985427856445
Agent0_Eval_MinReturn : -53.8966064453125
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -13.449819564819336
Agent0_Train_StdReturn : 12.425263404846191
Agent0_Train_MaxReturn : 2.3360347747802734
Agent0_Train_MinReturn : -33.532867431640625
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 766500
Agent0_TimeSinceStart : 1188.368938922882
Agent0_Critic_Loss : 0.5732828974723816
Agent0_Actor_Loss : -0.6306812763214111
Agent0_Alpha_Loss : 0.7880491018295288
Agent0_Temperature : 0.08670384688974973
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -29.15061378479004
Agent1_Eval_StdReturn : 19.74449920654297
Agent1_Eval_MaxReturn : 3.476235866546631
Agent1_Eval_MinReturn : -60.068397521972656
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -18.383899688720703
Agent1_Train_StdReturn : 12.023356437683105
Agent1_Train_MaxReturn : 2.431588649749756
Agent1_Train_MinReturn : -43.59556579589844
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 766500
Agent1_TimeSinceStart : 1190.4543435573578
Agent1_Critic_Loss : 0.4731128215789795
Agent1_Actor_Loss : -0.5569718480110168
Agent1_Alpha_Loss : 0.7900295257568359
Agent1_Temperature : 0.0866763369601835
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 511 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 512 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 513 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 514 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 515 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 516 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 517 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 518 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 519 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 520 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -25.724254608154297
Agent0_Eval_StdReturn : 16.67275047302246
Agent0_Eval_MaxReturn : -2.6990184783935547
Agent0_Eval_MinReturn : -58.368778228759766
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -22.157188415527344
Agent0_Train_StdReturn : 14.856510162353516
Agent0_Train_MaxReturn : 9.229297637939453
Agent0_Train_MinReturn : -36.95586013793945
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 781500
Agent0_TimeSinceStart : 1211.563878774643
Agent0_Critic_Loss : 0.5486425161361694
Agent0_Actor_Loss : -0.4540291726589203
Agent0_Alpha_Loss : 0.7873449921607971
Agent0_Temperature : 0.08645343124952692
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -24.719234466552734
Agent1_Eval_StdReturn : 18.564924240112305
Agent1_Eval_MaxReturn : -0.3859872817993164
Agent1_Eval_MinReturn : -68.37382507324219
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -25.94744873046875
Agent1_Train_StdReturn : 13.784905433654785
Agent1_Train_MaxReturn : 3.7336645126342773
Agent1_Train_MinReturn : -42.03048324584961
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 781500
Agent1_TimeSinceStart : 1213.6525583267212
Agent1_Critic_Loss : 0.45510631799697876
Agent1_Actor_Loss : -0.5846490859985352
Agent1_Alpha_Loss : 0.7934322357177734
Agent1_Temperature : 0.08642612986770705
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 521 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 522 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 523 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 524 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 525 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 526 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 527 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 528 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 529 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 530 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -16.114459991455078
Agent0_Eval_StdReturn : 8.550165176391602
Agent0_Eval_MaxReturn : 0.7789397239685059
Agent0_Eval_MinReturn : -26.09779930114746
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -15.465130805969238
Agent0_Train_StdReturn : 8.458101272583008
Agent0_Train_MaxReturn : -1.7432724237442017
Agent0_Train_MinReturn : -30.99311065673828
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 796500
Agent0_TimeSinceStart : 1234.7295303344727
Agent0_Critic_Loss : 0.632193922996521
Agent0_Actor_Loss : -0.5300925970077515
Agent0_Alpha_Loss : 0.7838946580886841
Agent0_Temperature : 0.08620367021153828
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -13.673948287963867
Agent1_Eval_StdReturn : 16.73320960998535
Agent1_Eval_MaxReturn : 5.387729644775391
Agent1_Eval_MinReturn : -38.37886047363281
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -19.793960571289062
Agent1_Train_StdReturn : 13.224245071411133
Agent1_Train_MaxReturn : -4.173349380493164
Agent1_Train_MinReturn : -50.776123046875
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 796500
Agent1_TimeSinceStart : 1236.827961921692
Agent1_Critic_Loss : 0.5272152423858643
Agent1_Actor_Loss : -0.7076741456985474
Agent1_Alpha_Loss : 0.7898743748664856
Agent1_Temperature : 0.08617654939087291
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 531 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 532 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 533 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 534 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 535 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 536 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 537 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 538 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 539 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 540 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -10.869070053100586
Agent0_Eval_StdReturn : 13.326254844665527
Agent0_Eval_MaxReturn : 23.625072479248047
Agent0_Eval_MinReturn : -22.344097137451172
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -6.8660149574279785
Agent0_Train_StdReturn : 18.619983673095703
Agent0_Train_MaxReturn : 30.588409423828125
Agent0_Train_MinReturn : -46.0888671875
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 811500
Agent0_TimeSinceStart : 1257.9391593933105
Agent0_Critic_Loss : 0.5437564849853516
Agent0_Actor_Loss : -0.6202126741409302
Agent0_Alpha_Loss : 0.7936533689498901
Agent0_Temperature : 0.0859546386811064
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -19.242494583129883
Agent1_Eval_StdReturn : 10.006893157958984
Agent1_Eval_MaxReturn : 0.593543529510498
Agent1_Eval_MinReturn : -31.296653747558594
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -9.834394454956055
Agent1_Train_StdReturn : 13.580496788024902
Agent1_Train_MaxReturn : 12.746612548828125
Agent1_Train_MinReturn : -29.460826873779297
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 811500
Agent1_TimeSinceStart : 1260.0386333465576
Agent1_Critic_Loss : 0.563883364200592
Agent1_Actor_Loss : -0.5071003437042236
Agent1_Alpha_Loss : 0.7850542068481445
Agent1_Temperature : 0.08592822882099896
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 541 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 542 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 543 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 544 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 545 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 546 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 547 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 548 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 549 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 550 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -33.82734680175781
Agent0_Eval_StdReturn : 32.970245361328125
Agent0_Eval_MaxReturn : 25.756946563720703
Agent0_Eval_MinReturn : -88.48602294921875
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -17.905197143554688
Agent0_Train_StdReturn : 16.327051162719727
Agent0_Train_MaxReturn : 14.756505966186523
Agent0_Train_MinReturn : -40.087520599365234
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 826500
Agent0_TimeSinceStart : 1281.1287121772766
Agent0_Critic_Loss : 0.5098102688789368
Agent0_Actor_Loss : -0.6237843632698059
Agent0_Alpha_Loss : 0.7938812971115112
Agent0_Temperature : 0.08570516829736073
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -13.661267280578613
Agent1_Eval_StdReturn : 14.614984512329102
Agent1_Eval_MaxReturn : 14.053361892700195
Agent1_Eval_MinReturn : -35.65163803100586
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -16.562589645385742
Agent1_Train_StdReturn : 16.47593116760254
Agent1_Train_MaxReturn : 11.840869903564453
Agent1_Train_MinReturn : -52.070823669433594
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 826500
Agent1_TimeSinceStart : 1283.231913805008
Agent1_Critic_Loss : 0.6297222375869751
Agent1_Actor_Loss : -0.6046905517578125
Agent1_Alpha_Loss : 0.7677838802337646
Agent1_Temperature : 0.08568364807526578
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 551 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 552 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 553 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 554 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 555 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 556 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 557 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 558 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 559 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 560 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -7.691758155822754
Agent0_Eval_StdReturn : 14.637139320373535
Agent0_Eval_MaxReturn : 15.186752319335938
Agent0_Eval_MinReturn : -34.470680236816406
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -20.88557243347168
Agent0_Train_StdReturn : 18.824249267578125
Agent0_Train_MaxReturn : 11.659745216369629
Agent0_Train_MinReturn : -44.2237548828125
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 841500
Agent0_TimeSinceStart : 1304.3911399841309
Agent0_Critic_Loss : 0.5604289770126343
Agent0_Actor_Loss : -0.5987553596496582
Agent0_Alpha_Loss : 0.7861544489860535
Agent0_Temperature : 0.08545730961267572
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -15.43884563446045
Agent1_Eval_StdReturn : 9.639246940612793
Agent1_Eval_MaxReturn : -1.574556827545166
Agent1_Eval_MinReturn : -31.907304763793945
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -14.988142013549805
Agent1_Train_StdReturn : 9.886146545410156
Agent1_Train_MaxReturn : 0.6878180503845215
Agent1_Train_MinReturn : -28.871286392211914
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 841500
Agent1_TimeSinceStart : 1306.4987046718597
Agent1_Critic_Loss : 0.4698182940483093
Agent1_Actor_Loss : -0.7229561805725098
Agent1_Alpha_Loss : 0.7739958763122559
Agent1_Temperature : 0.08544221103187576
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 561 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 562 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 563 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 564 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 565 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 566 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 567 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 568 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 569 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 570 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -7.683245658874512
Agent0_Eval_StdReturn : 14.33403491973877
Agent0_Eval_MaxReturn : 20.598709106445312
Agent0_Eval_MinReturn : -25.549423217773438
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -13.317173957824707
Agent0_Train_StdReturn : 17.1456298828125
Agent0_Train_MaxReturn : 16.223739624023438
Agent0_Train_MinReturn : -37.31197738647461
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 856500
Agent0_TimeSinceStart : 1328.316339969635
Agent0_Critic_Loss : 0.5230754613876343
Agent0_Actor_Loss : -0.6297534704208374
Agent0_Alpha_Loss : 0.7831270694732666
Agent0_Temperature : 0.08521053703175725
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -17.921092987060547
Agent1_Eval_StdReturn : 8.759084701538086
Agent1_Eval_MaxReturn : 1.4177188873291016
Agent1_Eval_MinReturn : -29.664348602294922
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -18.23112678527832
Agent1_Train_StdReturn : 6.783214569091797
Agent1_Train_MaxReturn : -5.4629364013671875
Agent1_Train_MinReturn : -29.022781372070312
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 856500
Agent1_TimeSinceStart : 1330.492371559143
Agent1_Critic_Loss : 0.6769263744354248
Agent1_Actor_Loss : -0.6456489562988281
Agent1_Alpha_Loss : 0.7437583804130554
Agent1_Temperature : 0.08520309350759865
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 571 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 572 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 573 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 574 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 575 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 576 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 577 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 578 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 579 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 580 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -12.088865280151367
Agent0_Eval_StdReturn : 13.65489387512207
Agent0_Eval_MaxReturn : 11.902603149414062
Agent0_Eval_MinReturn : -34.05599594116211
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -7.099648952484131
Agent0_Train_StdReturn : 10.28886604309082
Agent0_Train_MaxReturn : 8.74123764038086
Agent0_Train_MinReturn : -21.67629623413086
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 871500
Agent0_TimeSinceStart : 1352.2106382846832
Agent0_Critic_Loss : 0.48443347215652466
Agent0_Actor_Loss : -0.7784448266029358
Agent0_Alpha_Loss : 0.7677946090698242
Agent0_Temperature : 0.08496468114836267
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -17.273923873901367
Agent1_Eval_StdReturn : 12.565878868103027
Agent1_Eval_MaxReturn : 2.638324022293091
Agent1_Eval_MinReturn : -38.21788024902344
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -12.988679885864258
Agent1_Train_StdReturn : 10.995747566223145
Agent1_Train_MaxReturn : 4.808548927307129
Agent1_Train_MinReturn : -27.39142608642578
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 871500
Agent1_TimeSinceStart : 1354.3729152679443
Agent1_Critic_Loss : 0.7638620138168335
Agent1_Actor_Loss : -0.611748993396759
Agent1_Alpha_Loss : 0.7475528717041016
Agent1_Temperature : 0.08496626201238747
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 581 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 582 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 583 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 584 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 585 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 586 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 587 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 588 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 589 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 590 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -14.005993843078613
Agent0_Eval_StdReturn : 13.170211791992188
Agent0_Eval_MaxReturn : 11.287948608398438
Agent0_Eval_MinReturn : -31.37089729309082
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -12.559844017028809
Agent0_Train_StdReturn : 10.286505699157715
Agent0_Train_MaxReturn : 4.232614994049072
Agent0_Train_MinReturn : -32.613887786865234
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 886500
Agent0_TimeSinceStart : 1376.0346381664276
Agent0_Critic_Loss : 0.6215417385101318
Agent0_Actor_Loss : -0.7103729248046875
Agent0_Alpha_Loss : 0.7698262333869934
Agent0_Temperature : 0.0847222085787723
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -11.348682403564453
Agent1_Eval_StdReturn : 15.924738883972168
Agent1_Eval_MaxReturn : 20.049898147583008
Agent1_Eval_MinReturn : -33.135318756103516
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -15.68036937713623
Agent1_Train_StdReturn : 12.016819953918457
Agent1_Train_MaxReturn : -2.252215623855591
Agent1_Train_MinReturn : -43.05107879638672
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 886500
Agent1_TimeSinceStart : 1378.195725440979
Agent1_Critic_Loss : 0.5983598232269287
Agent1_Actor_Loss : -0.6520698070526123
Agent1_Alpha_Loss : 0.7689921855926514
Agent1_Temperature : 0.08472939575388289
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 591 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 592 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 593 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 594 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 595 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 596 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 597 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 598 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 599 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 600 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -13.444218635559082
Agent0_Eval_StdReturn : 8.9242582321167
Agent0_Eval_MaxReturn : 6.965387344360352
Agent0_Eval_MinReturn : -27.07086753845215
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -16.425039291381836
Agent0_Train_StdReturn : 9.193347930908203
Agent0_Train_MaxReturn : 1.2740826606750488
Agent0_Train_MinReturn : -30.74883270263672
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 901500
Agent0_TimeSinceStart : 1399.909040927887
Agent0_Critic_Loss : 0.593779981136322
Agent0_Actor_Loss : -0.4704909324645996
Agent0_Alpha_Loss : 0.757310688495636
Agent0_Temperature : 0.08448198417757563
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -11.862855911254883
Agent1_Eval_StdReturn : 14.921660423278809
Agent1_Eval_MaxReturn : 26.073413848876953
Agent1_Eval_MinReturn : -28.19198226928711
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -19.401199340820312
Agent1_Train_StdReturn : 16.573123931884766
Agent1_Train_MaxReturn : 11.277783393859863
Agent1_Train_MinReturn : -44.513092041015625
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 901500
Agent1_TimeSinceStart : 1402.0618557929993
Agent1_Critic_Loss : 0.8406818509101868
Agent1_Actor_Loss : -0.6836596727371216
Agent1_Alpha_Loss : 0.7537076473236084
Agent1_Temperature : 0.08449227105731263
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 601 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 602 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 603 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 604 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 605 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 606 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 607 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 608 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 609 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 610 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -8.77269458770752
Agent0_Eval_StdReturn : 14.192977905273438
Agent0_Eval_MaxReturn : 13.910115242004395
Agent0_Eval_MinReturn : -34.085365295410156
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -14.621442794799805
Agent0_Train_StdReturn : 8.087564468383789
Agent0_Train_MaxReturn : 3.774186134338379
Agent0_Train_MinReturn : -24.26746368408203
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 916500
Agent0_TimeSinceStart : 1423.7220602035522
Agent0_Critic_Loss : 0.5208470225334167
Agent0_Actor_Loss : -0.6274526119232178
Agent0_Alpha_Loss : 0.773807168006897
Agent0_Temperature : 0.08424261833215886
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -14.227361679077148
Agent1_Eval_StdReturn : 8.024554252624512
Agent1_Eval_MaxReturn : -0.17542457580566406
Agent1_Eval_MinReturn : -25.862350463867188
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -18.584699630737305
Agent1_Train_StdReturn : 14.791499137878418
Agent1_Train_MaxReturn : 1.8332276344299316
Agent1_Train_MinReturn : -49.72434997558594
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 916500
Agent1_TimeSinceStart : 1425.8741319179535
Agent1_Critic_Loss : 0.6640942096710205
Agent1_Actor_Loss : -0.6347231864929199
Agent1_Alpha_Loss : 0.7649960517883301
Agent1_Temperature : 0.08425590332436797
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 611 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 612 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 613 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 614 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 615 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 616 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 617 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 618 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 619 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 620 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -13.226916313171387
Agent0_Eval_StdReturn : 7.148564338684082
Agent0_Eval_MaxReturn : 0.43575525283813477
Agent0_Eval_MinReturn : -22.915836334228516
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -13.759481430053711
Agent0_Train_StdReturn : 11.202042579650879
Agent0_Train_MaxReturn : 12.210187911987305
Agent0_Train_MinReturn : -25.94925308227539
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 931500
Agent0_TimeSinceStart : 1447.4638402462006
Agent0_Critic_Loss : 0.6633337736129761
Agent0_Actor_Loss : -0.6855429410934448
Agent0_Alpha_Loss : 0.7621778249740601
Agent0_Temperature : 0.08400319604353293
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -18.00420570373535
Agent1_Eval_StdReturn : 12.479301452636719
Agent1_Eval_MaxReturn : -2.665607452392578
Agent1_Eval_MinReturn : -37.08072280883789
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -14.710393905639648
Agent1_Train_StdReturn : 13.903753280639648
Agent1_Train_MaxReturn : 6.209540843963623
Agent1_Train_MinReturn : -44.07708740234375
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 931500
Agent1_TimeSinceStart : 1449.6139900684357
Agent1_Critic_Loss : 0.5808440446853638
Agent1_Actor_Loss : -0.7689645290374756
Agent1_Alpha_Loss : 0.7573369741439819
Agent1_Temperature : 0.08401833408293921
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 621 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 622 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 623 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 624 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 625 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 626 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 627 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 628 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 629 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 630 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -12.31031322479248
Agent0_Eval_StdReturn : 10.515352249145508
Agent0_Eval_MaxReturn : 1.6481800079345703
Agent0_Eval_MinReturn : -30.539731979370117
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -15.135839462280273
Agent0_Train_StdReturn : 17.137086868286133
Agent0_Train_MaxReturn : 10.412729263305664
Agent0_Train_MinReturn : -56.11969757080078
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 946500
Agent0_TimeSinceStart : 1471.2817969322205
Agent0_Critic_Loss : 0.5274403095245361
Agent0_Actor_Loss : -0.7648862600326538
Agent0_Alpha_Loss : 0.764406144618988
Agent0_Temperature : 0.08376282963550918
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -11.624983787536621
Agent1_Eval_StdReturn : 11.854768753051758
Agent1_Eval_MaxReturn : 2.9059410095214844
Agent1_Eval_MinReturn : -32.84284973144531
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -14.264246940612793
Agent1_Train_StdReturn : 15.470765113830566
Agent1_Train_MaxReturn : 2.5915870666503906
Agent1_Train_MinReturn : -53.518821716308594
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 946500
Agent1_TimeSinceStart : 1473.4346780776978
Agent1_Critic_Loss : 0.7349923849105835
Agent1_Actor_Loss : -0.8288384675979614
Agent1_Alpha_Loss : 0.7710201740264893
Agent1_Temperature : 0.08378015597309711
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 631 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 632 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 633 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 634 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 635 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 636 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 637 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 638 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 639 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 640 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -18.740392684936523
Agent0_Eval_StdReturn : 12.769253730773926
Agent0_Eval_MaxReturn : -2.961282253265381
Agent0_Eval_MinReturn : -53.207855224609375
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -14.670995712280273
Agent0_Train_StdReturn : 16.329782485961914
Agent0_Train_MaxReturn : 7.8731184005737305
Agent0_Train_MinReturn : -39.06629180908203
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 961500
Agent0_TimeSinceStart : 1495.0570015907288
Agent0_Critic_Loss : 0.6064745187759399
Agent0_Actor_Loss : -0.7111109495162964
Agent0_Alpha_Loss : 0.7835531830787659
Agent0_Temperature : 0.08352165899318535
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -13.654722213745117
Agent1_Eval_StdReturn : 19.223180770874023
Agent1_Eval_MaxReturn : 6.997731685638428
Agent1_Eval_MinReturn : -63.1596794128418
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -8.948615074157715
Agent1_Train_StdReturn : 8.74585247039795
Agent1_Train_MaxReturn : 5.419884204864502
Agent1_Train_MinReturn : -25.24666404724121
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 961500
Agent1_TimeSinceStart : 1497.2013866901398
Agent1_Critic_Loss : 0.6202746629714966
Agent1_Actor_Loss : -0.6444589495658875
Agent1_Alpha_Loss : 0.7730826139450073
Agent1_Temperature : 0.08354169545695002
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 641 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 642 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 643 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 644 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 645 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 646 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 647 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 648 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 649 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 650 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -12.925395011901855
Agent0_Eval_StdReturn : 15.954408645629883
Agent0_Eval_MaxReturn : 21.537599563598633
Agent0_Eval_MinReturn : -32.611473083496094
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -26.388545989990234
Agent0_Train_StdReturn : 23.20259666442871
Agent0_Train_MaxReturn : -2.4624271392822266
Agent0_Train_MinReturn : -81.17599487304688
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 976500
Agent0_TimeSinceStart : 1518.7763423919678
Agent0_Critic_Loss : 0.6288175582885742
Agent0_Actor_Loss : -0.6214629411697388
Agent0_Alpha_Loss : 0.7810289859771729
Agent0_Temperature : 0.08327988604215976
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -12.425644874572754
Agent1_Eval_StdReturn : 5.3505859375
Agent1_Eval_MaxReturn : -3.451214075088501
Agent1_Eval_MinReturn : -19.458215713500977
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -12.659565925598145
Agent1_Train_StdReturn : 7.773641586303711
Agent1_Train_MaxReturn : -0.7040500640869141
Agent1_Train_MinReturn : -27.882442474365234
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 976500
Agent1_TimeSinceStart : 1520.9133479595184
Agent1_Critic_Loss : 0.7654469013214111
Agent1_Actor_Loss : -0.7251179814338684
Agent1_Alpha_Loss : 0.7768290042877197
Agent1_Temperature : 0.08330317348686908
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 651 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 652 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 653 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 654 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 655 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 656 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 657 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 658 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 659 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 660 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -12.53868293762207
Agent0_Eval_StdReturn : 21.512258529663086
Agent0_Eval_MaxReturn : 23.199480056762695
Agent0_Eval_MinReturn : -57.57018280029297
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : 1.8014808893203735
Agent0_Train_StdReturn : 14.13829231262207
Agent0_Train_MaxReturn : 29.652233123779297
Agent0_Train_MinReturn : -22.678661346435547
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 991500
Agent0_TimeSinceStart : 1542.4565689563751
Agent0_Critic_Loss : 0.7896523475646973
Agent0_Actor_Loss : -0.6439770460128784
Agent0_Alpha_Loss : 0.7883672714233398
Agent0_Temperature : 0.08303730098372142
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -0.9397662878036499
Agent1_Eval_StdReturn : 15.491172790527344
Agent1_Eval_MaxReturn : 37.140907287597656
Agent1_Eval_MinReturn : -17.201311111450195
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -11.346064567565918
Agent1_Train_StdReturn : 24.9490966796875
Agent1_Train_MaxReturn : 36.14678955078125
Agent1_Train_MinReturn : -50.75545120239258
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 991500
Agent1_TimeSinceStart : 1544.5947873592377
Agent1_Critic_Loss : 0.608016312122345
Agent1_Actor_Loss : -0.7257465124130249
Agent1_Alpha_Loss : 0.7753965854644775
Agent1_Temperature : 0.08306419716694553
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 661 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 662 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 663 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 664 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 665 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 666 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 667 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 668 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 669 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 670 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -8.81252384185791
Agent0_Eval_StdReturn : 10.478836059570312
Agent0_Eval_MaxReturn : 5.367105484008789
Agent0_Eval_MinReturn : -30.22389793395996
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -16.43942642211914
Agent0_Train_StdReturn : 26.102062225341797
Agent0_Train_MaxReturn : 20.12076759338379
Agent0_Train_MinReturn : -60.2382698059082
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1006500
Agent0_TimeSinceStart : 1566.0434679985046
Agent0_Critic_Loss : 0.6711733341217041
Agent0_Actor_Loss : -0.6412985324859619
Agent0_Alpha_Loss : 0.7837647199630737
Agent0_Temperature : 0.08279557870445609
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -16.175609588623047
Agent1_Eval_StdReturn : 10.570747375488281
Agent1_Eval_MaxReturn : -0.07480812072753906
Agent1_Eval_MinReturn : -31.140884399414062
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : 2.914949655532837
Agent1_Train_StdReturn : 16.133243560791016
Agent1_Train_MaxReturn : 27.363046646118164
Agent1_Train_MinReturn : -38.009300231933594
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1006500
Agent1_TimeSinceStart : 1568.1763145923615
Agent1_Critic_Loss : 0.48448288440704346
Agent1_Actor_Loss : -0.7605459690093994
Agent1_Alpha_Loss : 0.7857098579406738
Agent1_Temperature : 0.08282494229448285
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 671 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 672 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 673 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 674 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 675 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 676 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 677 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 678 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 679 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 680 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -14.201472282409668
Agent0_Eval_StdReturn : 15.694761276245117
Agent0_Eval_MaxReturn : 6.00663423538208
Agent0_Eval_MinReturn : -53.611671447753906
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -15.017781257629395
Agent0_Train_StdReturn : 12.718465805053711
Agent0_Train_MaxReturn : 6.21983528137207
Agent0_Train_MinReturn : -36.977073669433594
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1021500
Agent0_TimeSinceStart : 1589.6340749263763
Agent0_Critic_Loss : 0.6935122609138489
Agent0_Actor_Loss : -0.704451322555542
Agent0_Alpha_Loss : 0.7801515460014343
Agent0_Temperature : 0.08255500851288215
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -20.570484161376953
Agent1_Eval_StdReturn : 19.44145393371582
Agent1_Eval_MaxReturn : 5.9703850746154785
Agent1_Eval_MinReturn : -60.108463287353516
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -13.607769966125488
Agent1_Train_StdReturn : 16.56395149230957
Agent1_Train_MaxReturn : 22.908737182617188
Agent1_Train_MinReturn : -42.152381896972656
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1021500
Agent1_TimeSinceStart : 1591.772688627243
Agent1_Critic_Loss : 0.550984799861908
Agent1_Actor_Loss : -0.7770935893058777
Agent1_Alpha_Loss : 0.7934627532958984
Agent1_Temperature : 0.08258501965083896
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 681 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 682 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 683 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 684 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 685 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 686 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 687 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 688 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 689 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 690 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -15.442312240600586
Agent0_Eval_StdReturn : 10.40921688079834
Agent0_Eval_MaxReturn : 10.118128776550293
Agent0_Eval_MinReturn : -29.949298858642578
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -18.39175796508789
Agent0_Train_StdReturn : 31.418973922729492
Agent0_Train_MaxReturn : 34.98305892944336
Agent0_Train_MinReturn : -65.59139251708984
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1036500
Agent0_TimeSinceStart : 1613.2638647556305
Agent0_Critic_Loss : 0.8065589070320129
Agent0_Actor_Loss : -0.7970783710479736
Agent0_Alpha_Loss : 0.7846521139144897
Agent0_Temperature : 0.08231486072445884
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -32.22282791137695
Agent1_Eval_StdReturn : 23.13103485107422
Agent1_Eval_MaxReturn : 4.89385986328125
Agent1_Eval_MinReturn : -64.5650405883789
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -16.347537994384766
Agent1_Train_StdReturn : 23.700775146484375
Agent1_Train_MaxReturn : 11.738007545471191
Agent1_Train_MinReturn : -68.27899932861328
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1036500
Agent1_TimeSinceStart : 1615.407727241516
Agent1_Critic_Loss : 0.6120232939720154
Agent1_Actor_Loss : -0.7160544395446777
Agent1_Alpha_Loss : 0.7850010395050049
Agent1_Temperature : 0.08234480154442061
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 691 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 692 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 693 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 694 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 695 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 696 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 697 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 698 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 699 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 700 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -24.56451988220215
Agent0_Eval_StdReturn : 16.614418029785156
Agent0_Eval_MaxReturn : 0.23181724548339844
Agent0_Eval_MinReturn : -59.15684127807617
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -31.680309295654297
Agent0_Train_StdReturn : 32.346187591552734
Agent0_Train_MaxReturn : 26.009990692138672
Agent0_Train_MinReturn : -71.8961410522461
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1051500
Agent0_TimeSinceStart : 1636.8233387470245
Agent0_Critic_Loss : 0.6017895936965942
Agent0_Actor_Loss : -0.6241096258163452
Agent0_Alpha_Loss : 0.7776240110397339
Agent0_Temperature : 0.082074335098109
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -10.860429763793945
Agent1_Eval_StdReturn : 17.6812686920166
Agent1_Eval_MaxReturn : 23.337562561035156
Agent1_Eval_MinReturn : -32.304439544677734
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -18.643062591552734
Agent1_Train_StdReturn : 26.1021671295166
Agent1_Train_MaxReturn : 16.511627197265625
Agent1_Train_MinReturn : -66.93994903564453
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1051500
Agent1_TimeSinceStart : 1638.964303970337
Agent1_Critic_Loss : 0.6663168668746948
Agent1_Actor_Loss : -0.7675338387489319
Agent1_Alpha_Loss : 0.7913153767585754
Agent1_Temperature : 0.08210513631894806
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 701 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 702 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 703 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 704 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 705 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 706 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 707 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 708 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 709 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 710 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -20.05789566040039
Agent0_Eval_StdReturn : 14.646476745605469
Agent0_Eval_MaxReturn : 6.817994594573975
Agent0_Eval_MinReturn : -40.43049621582031
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -19.54693603515625
Agent0_Train_StdReturn : 16.333703994750977
Agent0_Train_MaxReturn : 16.28660011291504
Agent0_Train_MinReturn : -38.387969970703125
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1066500
Agent0_TimeSinceStart : 1660.4405381679535
Agent0_Critic_Loss : 0.8304016590118408
Agent0_Actor_Loss : -0.8291743993759155
Agent0_Alpha_Loss : 0.772918701171875
Agent0_Temperature : 0.08183411803065285
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -17.531003952026367
Agent1_Eval_StdReturn : 22.300952911376953
Agent1_Eval_MaxReturn : 10.366347312927246
Agent1_Eval_MinReturn : -53.12535858154297
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -10.900663375854492
Agent1_Train_StdReturn : 13.987112998962402
Agent1_Train_MaxReturn : 10.522375106811523
Agent1_Train_MinReturn : -32.50181198120117
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1066500
Agent1_TimeSinceStart : 1662.5732533931732
Agent1_Critic_Loss : 0.9469372034072876
Agent1_Actor_Loss : -0.7256104350090027
Agent1_Alpha_Loss : 0.7774869799613953
Agent1_Temperature : 0.08186594018758232
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 711 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 712 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 713 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 714 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 715 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 716 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 717 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 718 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 719 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 720 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -28.613183975219727
Agent0_Eval_StdReturn : 29.918291091918945
Agent0_Eval_MaxReturn : -1.901629090309143
Agent0_Eval_MinReturn : -103.51024627685547
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -18.64163589477539
Agent0_Train_StdReturn : 18.580753326416016
Agent0_Train_MaxReturn : 5.448374271392822
Agent0_Train_MinReturn : -43.71097946166992
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1081500
Agent0_TimeSinceStart : 1684.0008072853088
Agent0_Critic_Loss : 0.7535998821258545
Agent0_Actor_Loss : -0.8341034054756165
Agent0_Alpha_Loss : 0.7726315855979919
Agent0_Temperature : 0.08159482305056542
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -24.473222732543945
Agent1_Eval_StdReturn : 33.34992980957031
Agent1_Eval_MaxReturn : 14.917441368103027
Agent1_Eval_MinReturn : -84.16453552246094
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -18.99319076538086
Agent1_Train_StdReturn : 15.52662181854248
Agent1_Train_MaxReturn : 7.566123962402344
Agent1_Train_MinReturn : -39.88541030883789
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1081500
Agent1_TimeSinceStart : 1686.1287405490875
Agent1_Critic_Loss : 0.7207072973251343
Agent1_Actor_Loss : -0.9175344705581665
Agent1_Alpha_Loss : 0.7616899013519287
Agent1_Temperature : 0.08162746668930757
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 721 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 722 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 723 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 724 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 725 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 726 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 727 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 728 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 729 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 730 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -18.211153030395508
Agent0_Eval_StdReturn : 18.812644958496094
Agent0_Eval_MaxReturn : 14.3372220993042
Agent0_Eval_MinReturn : -53.778282165527344
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : 0.8335525393486023
Agent0_Train_StdReturn : 22.86427879333496
Agent0_Train_MaxReturn : 37.20066452026367
Agent0_Train_MinReturn : -45.34810256958008
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1096500
Agent0_TimeSinceStart : 1707.5843784809113
Agent0_Critic_Loss : 0.8489501476287842
Agent0_Actor_Loss : -0.6915085911750793
Agent0_Alpha_Loss : 0.7641445398330688
Agent0_Temperature : 0.08135727526380555
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -22.339481353759766
Agent1_Eval_StdReturn : 17.32491111755371
Agent1_Eval_MaxReturn : 5.379014015197754
Agent1_Eval_MinReturn : -54.56243133544922
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -7.488275051116943
Agent1_Train_StdReturn : 20.05997657775879
Agent1_Train_MaxReturn : 20.654407501220703
Agent1_Train_MinReturn : -43.36651611328125
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1096500
Agent1_TimeSinceStart : 1709.7070825099945
Agent1_Critic_Loss : 0.9450441002845764
Agent1_Actor_Loss : -0.9056471586227417
Agent1_Alpha_Loss : 0.7716138362884521
Agent1_Temperature : 0.0813909454345974
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 731 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 732 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 733 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 734 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 735 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 736 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 737 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 738 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 739 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 740 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -19.59185028076172
Agent0_Eval_StdReturn : 19.30384635925293
Agent0_Eval_MaxReturn : 5.2380900382995605
Agent0_Eval_MinReturn : -60.77667236328125
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -1.1439707279205322
Agent0_Train_StdReturn : 18.610258102416992
Agent0_Train_MaxReturn : 35.71495819091797
Agent0_Train_MinReturn : -27.847841262817383
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1111500
Agent0_TimeSinceStart : 1731.1656942367554
Agent0_Critic_Loss : 1.078979253768921
Agent0_Actor_Loss : -0.6970000863075256
Agent0_Alpha_Loss : 0.7639188766479492
Agent0_Temperature : 0.08112137302845605
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -17.543048858642578
Agent1_Eval_StdReturn : 17.91262435913086
Agent1_Eval_MaxReturn : 21.925668716430664
Agent1_Eval_MinReturn : -46.734397888183594
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -12.970181465148926
Agent1_Train_StdReturn : 14.835790634155273
Agent1_Train_MaxReturn : 12.875883102416992
Agent1_Train_MinReturn : -34.925209045410156
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1111500
Agent1_TimeSinceStart : 1733.307959318161
Agent1_Critic_Loss : 0.7935011386871338
Agent1_Actor_Loss : -0.7731102108955383
Agent1_Alpha_Loss : 0.7662308216094971
Agent1_Temperature : 0.0811554616950534
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 741 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 742 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 743 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 744 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 745 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 746 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 747 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 748 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 749 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 750 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -20.729290008544922
Agent0_Eval_StdReturn : 21.553884506225586
Agent0_Eval_MaxReturn : 5.116559028625488
Agent0_Eval_MinReturn : -64.87542724609375
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -8.10988998413086
Agent0_Train_StdReturn : 10.898234367370605
Agent0_Train_MaxReturn : 7.303388595581055
Agent0_Train_MinReturn : -28.395282745361328
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1126500
Agent0_TimeSinceStart : 1754.7545795440674
Agent0_Critic_Loss : 0.8215765953063965
Agent0_Actor_Loss : -0.8006057143211365
Agent0_Alpha_Loss : 0.765083909034729
Agent0_Temperature : 0.08088696136616665
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -14.887601852416992
Agent1_Eval_StdReturn : 8.910372734069824
Agent1_Eval_MaxReturn : -1.7695904970169067
Agent1_Eval_MinReturn : -30.068485260009766
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -15.313665390014648
Agent1_Train_StdReturn : 14.612607955932617
Agent1_Train_MaxReturn : 11.848662376403809
Agent1_Train_MinReturn : -43.37300491333008
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1126500
Agent1_TimeSinceStart : 1756.8967883586884
Agent1_Critic_Loss : 0.9193445444107056
Agent1_Actor_Loss : -0.9724810123443604
Agent1_Alpha_Loss : 0.7660731077194214
Agent1_Temperature : 0.08092210875215136
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 751 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 752 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 753 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 754 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 755 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 756 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 757 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 758 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 759 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 760 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -11.085664749145508
Agent0_Eval_StdReturn : 14.857172012329102
Agent0_Eval_MaxReturn : 6.290328025817871
Agent0_Eval_MinReturn : -35.86717224121094
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -14.901921272277832
Agent0_Train_StdReturn : 13.146871566772461
Agent0_Train_MaxReturn : 6.415423393249512
Agent0_Train_MinReturn : -41.28936767578125
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1141500
Agent0_TimeSinceStart : 1778.3906223773956
Agent0_Critic_Loss : 0.918691873550415
Agent0_Actor_Loss : -0.8358731865882874
Agent0_Alpha_Loss : 0.7629591822624207
Agent0_Temperature : 0.08065471048066072
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -14.561666488647461
Agent1_Eval_StdReturn : 5.664705753326416
Agent1_Eval_MaxReturn : -6.458051681518555
Agent1_Eval_MinReturn : -25.420135498046875
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -22.82880210876465
Agent1_Train_StdReturn : 23.28759002685547
Agent1_Train_MaxReturn : 5.538827896118164
Agent1_Train_MinReturn : -76.0239028930664
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1141500
Agent1_TimeSinceStart : 1780.53169631958
Agent1_Critic_Loss : 0.8496533632278442
Agent1_Actor_Loss : -0.8925936818122864
Agent1_Alpha_Loss : 0.7615989446640015
Agent1_Temperature : 0.08069020778935491
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 761 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 762 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 763 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 764 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 765 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 766 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 767 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 768 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 769 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 770 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -9.851509094238281
Agent0_Eval_StdReturn : 14.334662437438965
Agent0_Eval_MaxReturn : 10.7625150680542
Agent0_Eval_MinReturn : -41.63930130004883
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -11.609296798706055
Agent0_Train_StdReturn : 11.964192390441895
Agent0_Train_MaxReturn : 10.665520668029785
Agent0_Train_MinReturn : -27.498605728149414
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1156500
Agent0_TimeSinceStart : 1802.0257182121277
Agent0_Critic_Loss : 0.912746250629425
Agent0_Actor_Loss : -0.9122372269630432
Agent0_Alpha_Loss : 0.7590161561965942
Agent0_Temperature : 0.08042481121356479
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -9.085412979125977
Agent1_Eval_StdReturn : 12.266071319580078
Agent1_Eval_MaxReturn : 8.798611640930176
Agent1_Eval_MinReturn : -25.764245986938477
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -5.177054405212402
Agent1_Train_StdReturn : 12.270230293273926
Agent1_Train_MaxReturn : 21.469192504882812
Agent1_Train_MinReturn : -29.872920989990234
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1156500
Agent1_TimeSinceStart : 1804.1614727973938
Agent1_Critic_Loss : 0.8085459470748901
Agent1_Actor_Loss : -0.9313888549804688
Agent1_Alpha_Loss : 0.7546098232269287
Agent1_Temperature : 0.08046008515064779
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 771 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 772 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 773 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 774 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 775 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 776 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 777 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 778 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 779 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 780 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -16.381528854370117
Agent0_Eval_StdReturn : 13.807348251342773
Agent0_Eval_MaxReturn : 5.511739730834961
Agent0_Eval_MinReturn : -37.99274826049805
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -11.24791431427002
Agent0_Train_StdReturn : 11.226007461547852
Agent0_Train_MaxReturn : 4.635156631469727
Agent0_Train_MinReturn : -27.270906448364258
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1171500
Agent0_TimeSinceStart : 1825.1248371601105
Agent0_Critic_Loss : 1.0933706760406494
Agent0_Actor_Loss : -0.7932575941085815
Agent0_Alpha_Loss : 0.7348606586456299
Agent0_Temperature : 0.08019744685641493
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -18.702152252197266
Agent1_Eval_StdReturn : 15.244474411010742
Agent1_Eval_MaxReturn : 9.530086517333984
Agent1_Eval_MinReturn : -40.976871490478516
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -6.170466423034668
Agent1_Train_StdReturn : 12.41672420501709
Agent1_Train_MaxReturn : 15.034854888916016
Agent1_Train_MinReturn : -26.945695877075195
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1171500
Agent1_TimeSinceStart : 1827.1485238075256
Agent1_Critic_Loss : 1.3793911933898926
Agent1_Actor_Loss : -0.7614885568618774
Agent1_Alpha_Loss : 0.761381983757019
Agent1_Temperature : 0.08023182351608198
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 781 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 782 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 783 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 784 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 785 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 786 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 787 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 788 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 789 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 790 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -16.049896240234375
Agent0_Eval_StdReturn : 14.786944389343262
Agent0_Eval_MaxReturn : 5.0688371658325195
Agent0_Eval_MinReturn : -51.733619689941406
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -10.734655380249023
Agent0_Train_StdReturn : 9.459723472595215
Agent0_Train_MaxReturn : 5.319699287414551
Agent0_Train_MinReturn : -27.815196990966797
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1186500
Agent0_TimeSinceStart : 1847.5248172283173
Agent0_Critic_Loss : 0.7076902389526367
Agent0_Actor_Loss : -0.9352530241012573
Agent0_Alpha_Loss : 0.7389354705810547
Agent0_Temperature : 0.079972873391681
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -8.549468994140625
Agent1_Eval_StdReturn : 13.33263874053955
Agent1_Eval_MaxReturn : 20.411943435668945
Agent1_Eval_MinReturn : -30.37885093688965
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -11.69304370880127
Agent1_Train_StdReturn : 17.3923397064209
Agent1_Train_MaxReturn : 17.35163116455078
Agent1_Train_MinReturn : -33.52793884277344
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1186500
Agent1_TimeSinceStart : 1849.5542652606964
Agent1_Critic_Loss : 1.0982310771942139
Agent1_Actor_Loss : -0.8535616397857666
Agent1_Alpha_Loss : 0.740107536315918
Agent1_Temperature : 0.08000489399239877
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 791 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 792 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 793 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 794 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 795 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 796 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 797 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 798 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 799 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 800 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -12.150350570678711
Agent0_Eval_StdReturn : 16.497713088989258
Agent0_Eval_MaxReturn : 13.647440910339355
Agent0_Eval_MinReturn : -40.670257568359375
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -15.089941024780273
Agent0_Train_StdReturn : 20.381370544433594
Agent0_Train_MaxReturn : 30.826475143432617
Agent0_Train_MinReturn : -44.93117141723633
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1201500
Agent0_TimeSinceStart : 1869.9630863666534
Agent0_Critic_Loss : 0.8991501331329346
Agent0_Actor_Loss : -0.8657402992248535
Agent0_Alpha_Loss : 0.7486981749534607
Agent0_Temperature : 0.07974863932513207
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -9.091646194458008
Agent1_Eval_StdReturn : 15.318448066711426
Agent1_Eval_MaxReturn : 19.67654800415039
Agent1_Eval_MinReturn : -33.401126861572266
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -17.101591110229492
Agent1_Train_StdReturn : 9.420254707336426
Agent1_Train_MaxReturn : -1.9121193885803223
Agent1_Train_MinReturn : -29.75374984741211
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1201500
Agent1_TimeSinceStart : 1872.0005609989166
Agent1_Critic_Loss : 1.54478120803833
Agent1_Actor_Loss : -0.8634933233261108
Agent1_Alpha_Loss : 0.729407787322998
Agent1_Temperature : 0.079781325006502
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 801 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 802 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 803 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 804 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 805 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 806 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 807 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 808 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 809 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 810 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -8.481424331665039
Agent0_Eval_StdReturn : 10.032052040100098
Agent0_Eval_MaxReturn : 9.963314056396484
Agent0_Eval_MinReturn : -24.66253662109375
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -19.34965705871582
Agent0_Train_StdReturn : 16.35230255126953
Agent0_Train_MaxReturn : 2.0951104164123535
Agent0_Train_MinReturn : -55.43972396850586
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1216500
Agent0_TimeSinceStart : 1892.530972957611
Agent0_Critic_Loss : 0.769088864326477
Agent0_Actor_Loss : -0.8334907293319702
Agent0_Alpha_Loss : 0.7575281858444214
Agent0_Temperature : 0.07952453850765183
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -13.036523818969727
Agent1_Eval_StdReturn : 13.357112884521484
Agent1_Eval_MaxReturn : 11.315698623657227
Agent1_Eval_MinReturn : -30.13408660888672
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -6.679925441741943
Agent1_Train_StdReturn : 10.375575065612793
Agent1_Train_MaxReturn : 5.7785444259643555
Agent1_Train_MinReturn : -22.461009979248047
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1216500
Agent1_TimeSinceStart : 1894.5871250629425
Agent1_Critic_Loss : 0.9464236497879028
Agent1_Actor_Loss : -0.9018146991729736
Agent1_Alpha_Loss : 0.7249716520309448
Agent1_Temperature : 0.07956037361760818
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 811 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 812 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 813 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 814 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 815 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 816 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 817 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 818 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 819 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 820 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -18.905506134033203
Agent0_Eval_StdReturn : 18.44426727294922
Agent0_Eval_MaxReturn : 6.797163486480713
Agent0_Eval_MinReturn : -49.64472198486328
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -16.86981201171875
Agent0_Train_StdReturn : 19.361101150512695
Agent0_Train_MaxReturn : 5.041080474853516
Agent0_Train_MinReturn : -67.99624633789062
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1231500
Agent0_TimeSinceStart : 1915.147712945938
Agent0_Critic_Loss : 0.8610801100730896
Agent0_Actor_Loss : -0.8274770379066467
Agent0_Alpha_Loss : 0.7424829602241516
Agent0_Temperature : 0.07930102862976117
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -21.487668991088867
Agent1_Eval_StdReturn : 13.901433944702148
Agent1_Eval_MaxReturn : 9.269482612609863
Agent1_Eval_MinReturn : -41.9499397277832
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -10.297761917114258
Agent1_Train_StdReturn : 8.801233291625977
Agent1_Train_MaxReturn : 10.201249122619629
Agent1_Train_MinReturn : -20.414756774902344
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1231500
Agent1_TimeSinceStart : 1917.1987850666046
Agent1_Critic_Loss : 1.2628834247589111
Agent1_Actor_Loss : -0.8361291885375977
Agent1_Alpha_Loss : 0.7332097887992859
Agent1_Temperature : 0.07934151240631343
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 821 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 822 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 823 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 824 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 825 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 826 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 827 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 828 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 829 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 830 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -14.575016975402832
Agent0_Eval_StdReturn : 26.66568374633789
Agent0_Eval_MaxReturn : 9.798906326293945
Agent0_Eval_MinReturn : -88.26226043701172
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -10.491220474243164
Agent0_Train_StdReturn : 11.188508987426758
Agent0_Train_MaxReturn : 8.529216766357422
Agent0_Train_MinReturn : -34.84825897216797
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1246500
Agent0_TimeSinceStart : 1937.7046740055084
Agent0_Critic_Loss : 0.9755396842956543
Agent0_Actor_Loss : -0.971163272857666
Agent0_Alpha_Loss : 0.7364602088928223
Agent0_Temperature : 0.07907865067522168
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -16.969482421875
Agent1_Eval_StdReturn : 9.32276725769043
Agent1_Eval_MaxReturn : -1.0100736618041992
Agent1_Eval_MinReturn : -30.856510162353516
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -10.58298110961914
Agent1_Train_StdReturn : 4.876173496246338
Agent1_Train_MaxReturn : -1.9142866134643555
Agent1_Train_MinReturn : -16.922914505004883
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1246500
Agent1_TimeSinceStart : 1939.755807876587
Agent1_Critic_Loss : 0.9447014331817627
Agent1_Actor_Loss : -0.9735966920852661
Agent1_Alpha_Loss : 0.7321714162826538
Agent1_Temperature : 0.07912398285021668
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 831 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 832 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 833 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 834 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 835 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 836 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 837 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 838 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 839 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 840 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -11.30725383758545
Agent0_Eval_StdReturn : 15.640364646911621
Agent0_Eval_MaxReturn : 13.214778900146484
Agent0_Eval_MinReturn : -34.729949951171875
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -7.537031650543213
Agent0_Train_StdReturn : 12.038749694824219
Agent0_Train_MaxReturn : 20.01540756225586
Agent0_Train_MinReturn : -22.864782333374023
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1261500
Agent0_TimeSinceStart : 1960.2758600711823
Agent0_Critic_Loss : 0.6539629697799683
Agent0_Actor_Loss : -0.87218177318573
Agent0_Alpha_Loss : 0.7327343821525574
Agent0_Temperature : 0.07885686431209332
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -12.166547775268555
Agent1_Eval_StdReturn : 10.184351921081543
Agent1_Eval_MaxReturn : 9.371126174926758
Agent1_Eval_MinReturn : -21.970481872558594
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -10.892800331115723
Agent1_Train_StdReturn : 7.455057621002197
Agent1_Train_MaxReturn : -1.5652594566345215
Agent1_Train_MinReturn : -22.529565811157227
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1261500
Agent1_TimeSinceStart : 1962.3138535022736
Agent1_Critic_Loss : 0.7610769867897034
Agent1_Actor_Loss : -0.9902023673057556
Agent1_Alpha_Loss : 0.7352707982063293
Agent1_Temperature : 0.0789065887513169
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 841 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 842 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 843 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 844 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 845 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 846 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 847 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 848 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 849 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 850 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -9.795187950134277
Agent0_Eval_StdReturn : 14.05151653289795
Agent0_Eval_MaxReturn : 11.284119606018066
Agent0_Eval_MinReturn : -30.083391189575195
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -12.077268600463867
Agent0_Train_StdReturn : 17.70547866821289
Agent0_Train_MaxReturn : 21.286540985107422
Agent0_Train_MinReturn : -37.745975494384766
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1276500
Agent0_TimeSinceStart : 1982.845703125
Agent0_Critic_Loss : 0.7916216850280762
Agent0_Actor_Loss : -0.9508698582649231
Agent0_Alpha_Loss : 0.7321597337722778
Agent0_Temperature : 0.07863581692022183
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -13.35545539855957
Agent1_Eval_StdReturn : 12.887584686279297
Agent1_Eval_MaxReturn : -1.312628984451294
Agent1_Eval_MinReturn : -41.824676513671875
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -14.22063159942627
Agent1_Train_StdReturn : 12.459854125976562
Agent1_Train_MaxReturn : 4.334616661071777
Agent1_Train_MinReturn : -34.66630554199219
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1276500
Agent1_TimeSinceStart : 1984.889251947403
Agent1_Critic_Loss : 0.7965351343154907
Agent1_Actor_Loss : -0.9960634112358093
Agent1_Alpha_Loss : 0.728036642074585
Agent1_Temperature : 0.07868924236878902
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 851 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 852 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 853 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 854 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 855 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 856 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 857 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 858 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 859 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 860 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : 3.377436876296997
Agent0_Eval_StdReturn : 19.981142044067383
Agent0_Eval_MaxReturn : 27.078495025634766
Agent0_Eval_MinReturn : -44.30461120605469
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -0.158617302775383
Agent0_Train_StdReturn : 20.304597854614258
Agent0_Train_MaxReturn : 36.447898864746094
Agent0_Train_MinReturn : -43.71048355102539
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1291500
Agent0_TimeSinceStart : 2005.582573890686
Agent0_Critic_Loss : 0.6685746908187866
Agent0_Actor_Loss : -0.9852915406227112
Agent0_Alpha_Loss : 0.7384281158447266
Agent0_Temperature : 0.078415401371998
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -13.16071605682373
Agent1_Eval_StdReturn : 19.551029205322266
Agent1_Eval_MaxReturn : 22.261585235595703
Agent1_Eval_MinReturn : -47.334720611572266
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -10.028613090515137
Agent1_Train_StdReturn : 6.133648872375488
Agent1_Train_MaxReturn : -0.9549579620361328
Agent1_Train_MinReturn : -19.735450744628906
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1291500
Agent1_TimeSinceStart : 2007.6618151664734
Agent1_Critic_Loss : 0.9694724082946777
Agent1_Actor_Loss : -0.9423364996910095
Agent1_Alpha_Loss : 0.7350083589553833
Agent1_Temperature : 0.0784724100960566
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 861 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 862 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 863 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 864 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 865 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 866 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 867 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 868 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 869 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 870 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -4.1688995361328125
Agent0_Eval_StdReturn : 11.864398956298828
Agent0_Eval_MaxReturn : 18.129308700561523
Agent0_Eval_MinReturn : -17.719770431518555
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -8.597211837768555
Agent0_Train_StdReturn : 12.235462188720703
Agent0_Train_MaxReturn : 10.864042282104492
Agent0_Train_MinReturn : -35.09634780883789
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1306500
Agent0_TimeSinceStart : 2028.5452494621277
Agent0_Critic_Loss : 0.7489515542984009
Agent0_Actor_Loss : -0.9117146134376526
Agent0_Alpha_Loss : 0.7386837005615234
Agent0_Temperature : 0.07819516423035565
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -17.21455955505371
Agent1_Eval_StdReturn : 13.698384284973145
Agent1_Eval_MaxReturn : 8.084031105041504
Agent1_Eval_MinReturn : -44.1260986328125
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -5.400136470794678
Agent1_Train_StdReturn : 15.490127563476562
Agent1_Train_MaxReturn : 23.289196014404297
Agent1_Train_MinReturn : -28.195701599121094
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1306500
Agent1_TimeSinceStart : 2030.6194784641266
Agent1_Critic_Loss : 0.8676325678825378
Agent1_Actor_Loss : -0.9309941530227661
Agent1_Alpha_Loss : 0.7425716519355774
Agent1_Temperature : 0.07825385176987593
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 871 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 872 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 873 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 874 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 875 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 876 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 877 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 878 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 879 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 880 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -6.872669219970703
Agent0_Eval_StdReturn : 15.155577659606934
Agent0_Eval_MaxReturn : 14.612096786499023
Agent0_Eval_MinReturn : -37.860164642333984
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -6.842585563659668
Agent0_Train_StdReturn : 13.513245582580566
Agent0_Train_MaxReturn : 16.645835876464844
Agent0_Train_MinReturn : -30.71553611755371
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1321500
Agent0_TimeSinceStart : 2051.5352807044983
Agent0_Critic_Loss : 0.7252774238586426
Agent0_Actor_Loss : -0.7905806303024292
Agent0_Alpha_Loss : 0.7451280355453491
Agent0_Temperature : 0.07797526264603075
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -12.993115425109863
Agent1_Eval_StdReturn : 16.995594024658203
Agent1_Eval_MaxReturn : 11.167215347290039
Agent1_Eval_MinReturn : -38.61679458618164
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -16.536867141723633
Agent1_Train_StdReturn : 19.318147659301758
Agent1_Train_MaxReturn : 8.516965866088867
Agent1_Train_MinReturn : -52.06966018676758
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1321500
Agent1_TimeSinceStart : 2053.615180015564
Agent1_Critic_Loss : 1.1646013259887695
Agent1_Actor_Loss : -0.9822549819946289
Agent1_Alpha_Loss : 0.749794602394104
Agent1_Temperature : 0.07803466516218976
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 881 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 882 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 883 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 884 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 885 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 886 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 887 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 888 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 889 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 890 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -11.194991111755371
Agent0_Eval_StdReturn : 10.69239330291748
Agent0_Eval_MaxReturn : 5.013856410980225
Agent0_Eval_MinReturn : -27.102155685424805
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : 2.640721559524536
Agent0_Train_StdReturn : 9.4247465133667
Agent0_Train_MaxReturn : 21.224361419677734
Agent0_Train_MinReturn : -12.23182487487793
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1336500
Agent0_TimeSinceStart : 2074.5328452587128
Agent0_Critic_Loss : 0.8334084749221802
Agent0_Actor_Loss : -1.0291476249694824
Agent0_Alpha_Loss : 0.7371901273727417
Agent0_Temperature : 0.07775651434218493
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -16.628881454467773
Agent1_Eval_StdReturn : 20.831100463867188
Agent1_Eval_MaxReturn : 14.041227340698242
Agent1_Eval_MinReturn : -56.032379150390625
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -31.97952651977539
Agent1_Train_StdReturn : 22.045747756958008
Agent1_Train_MaxReturn : 4.014318466186523
Agent1_Train_MinReturn : -64.47321319580078
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1336500
Agent1_TimeSinceStart : 2076.6005375385284
Agent1_Critic_Loss : 0.6326706409454346
Agent1_Actor_Loss : -1.0675034523010254
Agent1_Alpha_Loss : 0.7544616460800171
Agent1_Temperature : 0.07781437836838748
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 891 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 892 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 893 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 894 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 895 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 896 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 897 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 898 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 899 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 900 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -21.3038272857666
Agent0_Eval_StdReturn : 29.788846969604492
Agent0_Eval_MaxReturn : 10.065256118774414
Agent0_Eval_MinReturn : -87.43284606933594
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -13.012924194335938
Agent0_Train_StdReturn : 13.780510902404785
Agent0_Train_MaxReturn : 14.504828453063965
Agent0_Train_MinReturn : -29.218935012817383
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1351500
Agent0_TimeSinceStart : 2097.468044281006
Agent0_Critic_Loss : 0.9722472429275513
Agent0_Actor_Loss : -1.0260003805160522
Agent0_Alpha_Loss : 0.7425593137741089
Agent0_Temperature : 0.07753951858140044
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -19.05908966064453
Agent1_Eval_StdReturn : 23.984018325805664
Agent1_Eval_MaxReturn : 25.27109146118164
Agent1_Eval_MinReturn : -62.63861846923828
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -19.6478214263916
Agent1_Train_StdReturn : 23.15308380126953
Agent1_Train_MaxReturn : 12.893350601196289
Agent1_Train_MinReturn : -53.050392150878906
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1351500
Agent1_TimeSinceStart : 2099.5376074314117
Agent1_Critic_Loss : 0.7778348922729492
Agent1_Actor_Loss : -0.9633383750915527
Agent1_Alpha_Loss : 0.7565040588378906
Agent1_Temperature : 0.07759354304301774
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 901 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 902 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 903 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 904 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 905 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 906 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 907 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 908 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 909 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 910 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -22.5959529876709
Agent0_Eval_StdReturn : 10.524787902832031
Agent0_Eval_MaxReturn : -0.846057653427124
Agent0_Eval_MinReturn : -39.36714172363281
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -20.032909393310547
Agent0_Train_StdReturn : 20.46241569519043
Agent0_Train_MaxReturn : 22.53911781311035
Agent0_Train_MinReturn : -53.79219055175781
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1366500
Agent0_TimeSinceStart : 2120.433936357498
Agent0_Critic_Loss : 0.7759861350059509
Agent0_Actor_Loss : -0.9769884347915649
Agent0_Alpha_Loss : 0.7389833927154541
Agent0_Temperature : 0.07732325006848915
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -29.145553588867188
Agent1_Eval_StdReturn : 20.4165096282959
Agent1_Eval_MaxReturn : 4.881406784057617
Agent1_Eval_MinReturn : -60.57965850830078
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -38.76856231689453
Agent1_Train_StdReturn : 26.782594680786133
Agent1_Train_MaxReturn : -5.702797889709473
Agent1_Train_MinReturn : -83.1451416015625
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1366500
Agent1_TimeSinceStart : 2122.545181751251
Agent1_Critic_Loss : 1.0370911359786987
Agent1_Actor_Loss : -0.9277138113975525
Agent1_Alpha_Loss : 0.7369436025619507
Agent1_Temperature : 0.07737344974567908
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 911 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 912 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 913 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 914 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 915 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 916 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 917 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 918 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 919 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 920 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -13.955450057983398
Agent0_Eval_StdReturn : 14.668907165527344
Agent0_Eval_MaxReturn : 11.304429054260254
Agent0_Eval_MinReturn : -40.18809509277344
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -13.577486991882324
Agent0_Train_StdReturn : 15.583105087280273
Agent0_Train_MaxReturn : 10.224839210510254
Agent0_Train_MinReturn : -37.73472213745117
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1381500
Agent0_TimeSinceStart : 2143.433142900467
Agent0_Critic_Loss : 0.8009937405586243
Agent0_Actor_Loss : -0.8934041261672974
Agent0_Alpha_Loss : 0.7324005365371704
Agent0_Temperature : 0.07710741369870354
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -24.327259063720703
Agent1_Eval_StdReturn : 23.038570404052734
Agent1_Eval_MaxReturn : 13.955163955688477
Agent1_Eval_MinReturn : -53.63517379760742
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -17.61128807067871
Agent1_Train_StdReturn : 21.353506088256836
Agent1_Train_MaxReturn : 15.913263320922852
Agent1_Train_MinReturn : -49.55812454223633
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1381500
Agent1_TimeSinceStart : 2145.5152745246887
Agent1_Critic_Loss : 1.209924578666687
Agent1_Actor_Loss : -0.8032400608062744
Agent1_Alpha_Loss : 0.7359374165534973
Agent1_Temperature : 0.07715509157786322
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 921 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 922 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 923 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 924 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 925 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 926 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 927 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 928 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 929 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 930 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -35.74639129638672
Agent0_Eval_StdReturn : 21.53893280029297
Agent0_Eval_MaxReturn : -4.643229961395264
Agent0_Eval_MinReturn : -79.17973327636719
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -32.26654052734375
Agent0_Train_StdReturn : 34.276939392089844
Agent0_Train_MaxReturn : 32.54798889160156
Agent0_Train_MinReturn : -87.38323211669922
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1396500
Agent0_TimeSinceStart : 2166.4358394145966
Agent0_Critic_Loss : 0.9823324680328369
Agent0_Actor_Loss : -0.8472163677215576
Agent0_Alpha_Loss : 0.7268155813217163
Agent0_Temperature : 0.07689230018925106
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -21.66559600830078
Agent1_Eval_StdReturn : 23.871917724609375
Agent1_Eval_MaxReturn : 29.729616165161133
Agent1_Eval_MinReturn : -57.76145553588867
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -17.980329513549805
Agent1_Train_StdReturn : 11.355016708374023
Agent1_Train_MaxReturn : 3.578927993774414
Agent1_Train_MinReturn : -42.11135482788086
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1396500
Agent1_TimeSinceStart : 2168.5191490650177
Agent1_Critic_Loss : 1.1346030235290527
Agent1_Actor_Loss : -1.0556095838546753
Agent1_Alpha_Loss : 0.7264606356620789
Agent1_Temperature : 0.07693854613716977
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 931 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 932 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 933 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 934 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 935 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 936 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 937 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 938 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 939 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 940 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -31.270503997802734
Agent0_Eval_StdReturn : 21.184736251831055
Agent0_Eval_MaxReturn : 6.000641345977783
Agent0_Eval_MinReturn : -54.26925277709961
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -24.534908294677734
Agent0_Train_StdReturn : 17.616352081298828
Agent0_Train_MaxReturn : 2.2769625186920166
Agent0_Train_MinReturn : -60.583152770996094
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1411500
Agent0_TimeSinceStart : 2189.43314743042
Agent0_Critic_Loss : 1.3430589437484741
Agent0_Actor_Loss : -0.9029510021209717
Agent0_Alpha_Loss : 0.7384291291236877
Agent0_Temperature : 0.07667702165817111
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -25.415727615356445
Agent1_Eval_StdReturn : 25.06747817993164
Agent1_Eval_MaxReturn : 13.25984001159668
Agent1_Eval_MinReturn : -74.29475402832031
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -14.116037368774414
Agent1_Train_StdReturn : 21.55694007873535
Agent1_Train_MaxReturn : 27.301904678344727
Agent1_Train_MinReturn : -47.20875930786133
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1411500
Agent1_TimeSinceStart : 2191.5171649456024
Agent1_Critic_Loss : 1.4205906391143799
Agent1_Actor_Loss : -0.9826823472976685
Agent1_Alpha_Loss : 0.7271881103515625
Agent1_Temperature : 0.07672324133367667
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 941 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 942 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 943 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 944 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 945 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 946 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 947 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 948 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 949 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 950 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -30.982446670532227
Agent0_Eval_StdReturn : 25.074058532714844
Agent0_Eval_MaxReturn : -1.8764846324920654
Agent0_Eval_MinReturn : -73.20570373535156
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -22.730167388916016
Agent0_Train_StdReturn : 22.06521224975586
Agent0_Train_MaxReturn : 22.452259063720703
Agent0_Train_MinReturn : -61.41658401489258
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1426500
Agent0_TimeSinceStart : 2212.4194498062134
Agent0_Critic_Loss : 1.316941738128662
Agent0_Actor_Loss : -0.9878000020980835
Agent0_Alpha_Loss : 0.7289561629295349
Agent0_Temperature : 0.07646221336246664
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -13.755589485168457
Agent1_Eval_StdReturn : 19.435253143310547
Agent1_Eval_MaxReturn : 13.119126319885254
Agent1_Eval_MinReturn : -49.970191955566406
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -26.492595672607422
Agent1_Train_StdReturn : 10.11664867401123
Agent1_Train_MaxReturn : -8.475244522094727
Agent1_Train_MinReturn : -41.261329650878906
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1426500
Agent1_TimeSinceStart : 2214.5037093162537
Agent1_Critic_Loss : 1.5576419830322266
Agent1_Actor_Loss : -0.9887363910675049
Agent1_Alpha_Loss : 0.7250492572784424
Agent1_Temperature : 0.07650879768480372
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 951 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 952 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 953 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 954 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 955 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 956 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 957 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 958 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 959 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 960 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -14.824989318847656
Agent0_Eval_StdReturn : 17.66851234436035
Agent0_Eval_MaxReturn : 17.334352493286133
Agent0_Eval_MinReturn : -48.56932830810547
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -12.96753978729248
Agent0_Train_StdReturn : 20.041309356689453
Agent0_Train_MaxReturn : 27.654935836791992
Agent0_Train_MinReturn : -53.27199935913086
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1441500
Agent0_TimeSinceStart : 2235.4510595798492
Agent0_Critic_Loss : 1.493804693222046
Agent0_Actor_Loss : -1.111204981803894
Agent0_Alpha_Loss : 0.7362891435623169
Agent0_Temperature : 0.07624773486091942
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -10.556106567382812
Agent1_Eval_StdReturn : 14.002869606018066
Agent1_Eval_MaxReturn : 19.165973663330078
Agent1_Eval_MinReturn : -29.745826721191406
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -7.584477424621582
Agent1_Train_StdReturn : 15.317058563232422
Agent1_Train_MaxReturn : 19.086811065673828
Agent1_Train_MinReturn : -40.68598556518555
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1441500
Agent1_TimeSinceStart : 2237.541357755661
Agent1_Critic_Loss : 1.4874004125595093
Agent1_Actor_Loss : -0.8533893823623657
Agent1_Alpha_Loss : 0.7323910593986511
Agent1_Temperature : 0.07629476799341185
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 961 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 962 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 963 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 964 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 965 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 966 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 967 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 968 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 969 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 970 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -13.332586288452148
Agent0_Eval_StdReturn : 22.58428955078125
Agent0_Eval_MaxReturn : 16.69947052001953
Agent0_Eval_MinReturn : -45.73582458496094
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -24.869619369506836
Agent0_Train_StdReturn : 22.56700897216797
Agent0_Train_MaxReturn : 7.877784252166748
Agent0_Train_MinReturn : -54.532596588134766
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1456500
Agent0_TimeSinceStart : 2258.503131389618
Agent0_Critic_Loss : 1.4573776721954346
Agent0_Actor_Loss : -1.1746960878372192
Agent0_Alpha_Loss : 0.7268126010894775
Agent0_Temperature : 0.07603403052503438
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -14.525854110717773
Agent1_Eval_StdReturn : 18.762664794921875
Agent1_Eval_MaxReturn : 6.700176239013672
Agent1_Eval_MinReturn : -53.42975616455078
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -15.002105712890625
Agent1_Train_StdReturn : 18.516693115234375
Agent1_Train_MaxReturn : 12.749534606933594
Agent1_Train_MinReturn : -52.21295166015625
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1456500
Agent1_TimeSinceStart : 2260.5931446552277
Agent1_Critic_Loss : 1.2434121370315552
Agent1_Actor_Loss : -1.0376551151275635
Agent1_Alpha_Loss : 0.7279102802276611
Agent1_Temperature : 0.07608044996681103
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 971 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 972 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 973 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 974 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 975 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 976 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 977 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 978 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 979 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 980 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -8.078264236450195
Agent0_Eval_StdReturn : 16.90233612060547
Agent0_Eval_MaxReturn : 16.758432388305664
Agent0_Eval_MinReturn : -37.78252029418945
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -11.910024642944336
Agent0_Train_StdReturn : 10.982834815979004
Agent0_Train_MaxReturn : 8.534441947937012
Agent0_Train_MinReturn : -32.334632873535156
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1471500
Agent0_TimeSinceStart : 2281.649798631668
Agent0_Critic_Loss : 1.7464836835861206
Agent0_Actor_Loss : -0.931617021560669
Agent0_Alpha_Loss : 0.7123337984085083
Agent0_Temperature : 0.07582159866316185
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -7.543713569641113
Agent1_Eval_StdReturn : 7.766400337219238
Agent1_Eval_MaxReturn : 5.689845085144043
Agent1_Eval_MinReturn : -19.369163513183594
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -7.840401649475098
Agent1_Train_StdReturn : 13.282013893127441
Agent1_Train_MaxReturn : 11.285798072814941
Agent1_Train_MinReturn : -32.120269775390625
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1471500
Agent1_TimeSinceStart : 2283.738891363144
Agent1_Critic_Loss : 1.416022539138794
Agent1_Actor_Loss : -0.9919862151145935
Agent1_Alpha_Loss : 0.7268154621124268
Agent1_Temperature : 0.07586772003988805
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 981 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 982 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 983 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 984 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 985 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 986 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 987 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 988 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 989 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 990 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -6.035455703735352
Agent0_Eval_StdReturn : 21.89693260192871
Agent0_Eval_MaxReturn : 31.99154281616211
Agent0_Eval_MinReturn : -54.338443756103516
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -10.859064102172852
Agent0_Train_StdReturn : 17.664201736450195
Agent0_Train_MaxReturn : 16.9580135345459
Agent0_Train_MinReturn : -36.6263313293457
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1486500
Agent0_TimeSinceStart : 2304.8137958049774
Agent0_Critic_Loss : 1.4621871709823608
Agent0_Actor_Loss : -1.1198499202728271
Agent0_Alpha_Loss : 0.7112252712249756
Agent0_Temperature : 0.0756113839991518
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -13.046841621398926
Agent1_Eval_StdReturn : 13.579036712646484
Agent1_Eval_MaxReturn : 3.594757556915283
Agent1_Eval_MinReturn : -42.2644157409668
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -9.60282039642334
Agent1_Train_StdReturn : 9.598381996154785
Agent1_Train_MaxReturn : -0.24756813049316406
Agent1_Train_MinReturn : -31.62193489074707
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1486500
Agent1_TimeSinceStart : 2306.9229435920715
Agent1_Critic_Loss : 1.1443405151367188
Agent1_Actor_Loss : -1.185337781906128
Agent1_Alpha_Loss : 0.7234877943992615
Agent1_Temperature : 0.0756568693001542
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 991 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 992 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 993 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training.../home/harvey/anaconda3/envs/285final/lib/python3.7/site-packages/gym/core.py:318: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  "Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future."
/home/harvey/anaconda3/envs/285final/lib/python3.7/site-packages/gym/wrappers/step_api_compatibility.py:40: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  "Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future."
/home/harvey/anaconda3/envs/285final/lib/python3.7/site-packages/gym/core.py:257: DeprecationWarning: [33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.[0m
  "Function `env.seed(seed)` is marked as deprecated and will be removed in the future. "


Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 994 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 995 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 996 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 997 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 998 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 999 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...
./peersacv2_2ndrun.sh: 58: --seed: not found
