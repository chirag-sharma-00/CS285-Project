


LOGGING TO:  /home/harvey/Documents/cs285/CS285-Project/cs285/scripts/../../data/peersac_v2_2agents_HalfCheetah-v4_12-12-2022_02-33-51 



########################
logging outputs to  /home/harvey/Documents/cs285/CS285-Project/cs285/scripts/../../data/peersac_v2_2agents_HalfCheetah-v4_12-12-2022_02-33-51
########################
Using GPU id 0


********** Iteration 0 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -32.58100509643555
Agent0_Eval_StdReturn : 38.008583068847656
Agent0_Eval_MaxReturn : 18.935745239257812
Agent0_Eval_MinReturn : -95.31880187988281
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -68.51490020751953
Agent0_Train_StdReturn : 35.8519172668457
Agent0_Train_MaxReturn : 10.17027473449707
Agent0_Train_MinReturn : -109.59283447265625
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1500
Agent0_TimeSinceStart : 1.896939992904663
Agent0_Critic_Loss : 1.7086536884307861
Agent0_Actor_Loss : -0.34447938203811646
Agent0_Alpha_Loss : 0.9863041639328003
Agent0_Temperature : 0.09997000449985415
Agent0_Initial_DataCollection_AverageReturn : -68.51490020751953
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -51.067047119140625
Agent1_Eval_StdReturn : 36.643306732177734
Agent1_Eval_MaxReturn : 5.4539031982421875
Agent1_Eval_MinReturn : -123.81517028808594
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -41.37040710449219
Agent1_Train_StdReturn : 23.476428985595703
Agent1_Train_MaxReturn : -3.7883758544921875
Agent1_Train_MinReturn : -74.03202819824219
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1500
Agent1_TimeSinceStart : 3.7069098949432373
Agent1_Critic_Loss : 0.9912823438644409
Agent1_Actor_Loss : -0.4837449789047241
Agent1_Alpha_Loss : 0.9798400402069092
Agent1_Temperature : 0.09997000449985614
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 1 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 2 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 3 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 4 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 5 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 6 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 7 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 8 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 9 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 10 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -46.618980407714844
Agent0_Eval_StdReturn : 34.360862731933594
Agent0_Eval_MaxReturn : 4.177082061767578
Agent0_Eval_MinReturn : -101.20817565917969
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -47.71162033081055
Agent0_Train_StdReturn : 16.91861343383789
Agent0_Train_MaxReturn : -16.964988708496094
Agent0_Train_MinReturn : -70.50853729248047
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 16500
Agent0_TimeSinceStart : 22.524166107177734
Agent0_Critic_Loss : 0.8942358493804932
Agent0_Actor_Loss : -0.45209968090057373
Agent0_Alpha_Loss : 0.9856557846069336
Agent0_Temperature : 0.09967050744945741
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -23.17498016357422
Agent1_Eval_StdReturn : 35.43242645263672
Agent1_Eval_MaxReturn : 30.243358612060547
Agent1_Eval_MinReturn : -104.72036743164062
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -49.53214645385742
Agent1_Train_StdReturn : 23.37198829650879
Agent1_Train_MaxReturn : -17.918338775634766
Agent1_Train_MinReturn : -91.98331451416016
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 16500
Agent1_TimeSinceStart : 24.44415259361267
Agent1_Critic_Loss : 1.0224330425262451
Agent1_Actor_Loss : -0.5217679738998413
Agent1_Alpha_Loss : 0.9854030013084412
Agent1_Temperature : 0.09967044117277171
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 11 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 12 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 13 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 14 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 15 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 16 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 17 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 18 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 19 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 20 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -46.330047607421875
Agent0_Eval_StdReturn : 49.37164306640625
Agent0_Eval_MaxReturn : 24.719141006469727
Agent0_Eval_MinReturn : -123.84056091308594
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -19.812902450561523
Agent0_Train_StdReturn : 29.254955291748047
Agent0_Train_MaxReturn : 34.5399055480957
Agent0_Train_MinReturn : -71.24075317382812
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 31500
Agent0_TimeSinceStart : 44.18755125999451
Agent0_Critic_Loss : 0.8943381309509277
Agent0_Actor_Loss : -0.4953515827655792
Agent0_Alpha_Loss : 0.9938284158706665
Agent0_Temperature : 0.09937202970545943
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -47.99956512451172
Agent1_Eval_StdReturn : 25.836910247802734
Agent1_Eval_MaxReturn : 6.322393417358398
Agent1_Eval_MinReturn : -81.1266098022461
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -47.09725570678711
Agent1_Train_StdReturn : 28.182693481445312
Agent1_Train_MaxReturn : -5.158754825592041
Agent1_Train_MinReturn : -86.24165344238281
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 31500
Agent1_TimeSinceStart : 46.17431092262268
Agent1_Critic_Loss : 0.739264965057373
Agent1_Actor_Loss : -0.5862676501274109
Agent1_Alpha_Loss : 0.9884578585624695
Agent1_Temperature : 0.09937173561606101
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 21 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 22 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 23 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 24 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 25 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 26 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 27 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 28 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 29 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 30 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -25.192249298095703
Agent0_Eval_StdReturn : 25.30379295349121
Agent0_Eval_MaxReturn : 3.0973892211914062
Agent0_Eval_MinReturn : -60.547706604003906
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -37.913211822509766
Agent0_Train_StdReturn : 32.80707931518555
Agent0_Train_MaxReturn : 1.5589098930358887
Agent0_Train_MinReturn : -105.21112060546875
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 46500
Agent0_TimeSinceStart : 66.32616877555847
Agent0_Critic_Loss : 0.8887016773223877
Agent0_Actor_Loss : -0.4369214177131653
Agent0_Alpha_Loss : 0.988058865070343
Agent0_Temperature : 0.09907434019726678
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -51.427154541015625
Agent1_Eval_StdReturn : 21.33152198791504
Agent1_Eval_MaxReturn : -16.6425724029541
Agent1_Eval_MinReturn : -91.05067443847656
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -52.567970275878906
Agent1_Train_StdReturn : 36.218318939208984
Agent1_Train_MaxReturn : 14.909168243408203
Agent1_Train_MinReturn : -131.29782104492188
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 46500
Agent1_TimeSinceStart : 68.35580825805664
Agent1_Critic_Loss : 0.758634090423584
Agent1_Actor_Loss : -0.567564845085144
Agent1_Alpha_Loss : 0.9845913648605347
Agent1_Temperature : 0.09907393494136207
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 31 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 32 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 33 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 34 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 35 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 36 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 37 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 38 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 39 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 40 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -51.81474685668945
Agent0_Eval_StdReturn : 25.792320251464844
Agent0_Eval_MaxReturn : -2.598421096801758
Agent0_Eval_MinReturn : -97.19104766845703
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -50.26304626464844
Agent0_Train_StdReturn : 36.14711380004883
Agent0_Train_MaxReturn : -3.343472480773926
Agent0_Train_MinReturn : -111.74008178710938
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 61500
Agent0_TimeSinceStart : 88.86975049972534
Agent0_Critic_Loss : 0.85677570104599
Agent0_Actor_Loss : -0.4834839701652527
Agent0_Alpha_Loss : 0.9817242622375488
Agent0_Temperature : 0.09877806434367238
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -48.24110794067383
Agent1_Eval_StdReturn : 43.748985290527344
Agent1_Eval_MaxReturn : 10.693902015686035
Agent1_Eval_MinReturn : -126.4328842163086
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -35.22085189819336
Agent1_Train_StdReturn : 30.384601593017578
Agent1_Train_MaxReturn : 11.832371711730957
Agent1_Train_MinReturn : -92.32306671142578
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 61500
Agent1_TimeSinceStart : 90.91772556304932
Agent1_Critic_Loss : 0.7632298469543457
Agent1_Actor_Loss : -0.5450243353843689
Agent1_Alpha_Loss : 0.9787603616714478
Agent1_Temperature : 0.09877750537214858
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 41 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 42 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 43 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 44 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 45 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 46 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 47 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 48 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 49 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 50 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -47.231201171875
Agent0_Eval_StdReturn : 31.12499237060547
Agent0_Eval_MaxReturn : 18.758352279663086
Agent0_Eval_MinReturn : -88.896240234375
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -37.9083251953125
Agent0_Train_StdReturn : 26.463823318481445
Agent0_Train_MaxReturn : 1.205824613571167
Agent0_Train_MinReturn : -83.82466888427734
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 76500
Agent0_TimeSinceStart : 111.53261852264404
Agent0_Critic_Loss : 0.702551007270813
Agent0_Actor_Loss : -0.4979085326194763
Agent0_Alpha_Loss : 0.9726197719573975
Agent0_Temperature : 0.09848341178896498
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -41.91449737548828
Agent1_Eval_StdReturn : 38.189754486083984
Agent1_Eval_MaxReturn : 20.076635360717773
Agent1_Eval_MinReturn : -104.0946044921875
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -39.73896789550781
Agent1_Train_StdReturn : 43.03814697265625
Agent1_Train_MaxReturn : 33.95060348510742
Agent1_Train_MinReturn : -100.48456573486328
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 76500
Agent1_TimeSinceStart : 113.60160231590271
Agent1_Critic_Loss : 0.7645267844200134
Agent1_Actor_Loss : -0.5161893367767334
Agent1_Alpha_Loss : 0.9827108979225159
Agent1_Temperature : 0.09848265155672024
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 51 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 52 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 53 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 54 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 55 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 56 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 57 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 58 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 59 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 60 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -23.058563232421875
Agent0_Eval_StdReturn : 24.89092254638672
Agent0_Eval_MaxReturn : 34.60225296020508
Agent0_Eval_MinReturn : -51.01687240600586
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -47.699371337890625
Agent0_Train_StdReturn : 34.96453094482422
Agent0_Train_MaxReturn : 36.56296157836914
Agent0_Train_MinReturn : -93.66365051269531
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 91500
Agent0_TimeSinceStart : 134.3746633529663
Agent0_Critic_Loss : 0.6643715500831604
Agent0_Actor_Loss : -0.5324295163154602
Agent0_Alpha_Loss : 0.9678753614425659
Agent0_Temperature : 0.09819020510403086
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -41.831787109375
Agent1_Eval_StdReturn : 19.8931827545166
Agent1_Eval_MaxReturn : -17.821029663085938
Agent1_Eval_MinReturn : -88.01695251464844
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -42.75724792480469
Agent1_Train_StdReturn : 32.87258529663086
Agent1_Train_MaxReturn : 3.8843421936035156
Agent1_Train_MinReturn : -104.14067077636719
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 91500
Agent1_TimeSinceStart : 136.45236206054688
Agent1_Critic_Loss : 0.6939704418182373
Agent1_Actor_Loss : -0.5409138202667236
Agent1_Alpha_Loss : 0.9693310856819153
Agent1_Temperature : 0.09818908928501255
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 61 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 62 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 63 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 64 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 65 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 66 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 67 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 68 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 69 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 70 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -38.8419075012207
Agent0_Eval_StdReturn : 29.566526412963867
Agent0_Eval_MaxReturn : -3.729405164718628
Agent0_Eval_MinReturn : -113.11373901367188
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -52.9005241394043
Agent0_Train_StdReturn : 40.080482482910156
Agent0_Train_MaxReturn : 1.0143446922302246
Agent0_Train_MinReturn : -107.70153045654297
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 106500
Agent0_TimeSinceStart : 157.2657127380371
Agent0_Critic_Loss : 0.7037286758422852
Agent0_Actor_Loss : -0.4647260308265686
Agent0_Alpha_Loss : 0.9602019786834717
Agent0_Temperature : 0.09789869714272686
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -30.252145767211914
Agent1_Eval_StdReturn : 28.29826545715332
Agent1_Eval_MaxReturn : 16.39629554748535
Agent1_Eval_MinReturn : -75.33551788330078
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -25.83236312866211
Agent1_Train_StdReturn : 29.567489624023438
Agent1_Train_MaxReturn : 26.50406265258789
Agent1_Train_MinReturn : -65.26861572265625
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 106500
Agent1_TimeSinceStart : 159.33737754821777
Agent1_Critic_Loss : 0.5866408348083496
Agent1_Actor_Loss : -0.6239601373672485
Agent1_Alpha_Loss : 0.9610376358032227
Agent1_Temperature : 0.09789759600044688
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 71 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 72 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 73 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 74 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 75 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 76 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 77 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 78 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 79 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 80 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -32.57512664794922
Agent0_Eval_StdReturn : 27.380290985107422
Agent0_Eval_MaxReturn : 9.714351654052734
Agent0_Eval_MinReturn : -82.47639465332031
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -48.643165588378906
Agent0_Train_StdReturn : 21.835474014282227
Agent0_Train_MaxReturn : -13.810791969299316
Agent0_Train_MinReturn : -86.53678131103516
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 121500
Agent0_TimeSinceStart : 180.18854427337646
Agent0_Critic_Loss : 0.5861657857894897
Agent0_Actor_Loss : -0.5243018865585327
Agent0_Alpha_Loss : 0.9481593370437622
Agent0_Temperature : 0.09760997633682657
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -28.237812042236328
Agent1_Eval_StdReturn : 39.9020881652832
Agent1_Eval_MaxReturn : 18.770275115966797
Agent1_Eval_MinReturn : -108.76464080810547
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -31.456554412841797
Agent1_Train_StdReturn : 23.307397842407227
Agent1_Train_MaxReturn : -7.219683647155762
Agent1_Train_MinReturn : -87.21615600585938
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 121500
Agent1_TimeSinceStart : 182.25934195518494
Agent1_Critic_Loss : 0.4728608727455139
Agent1_Actor_Loss : -0.6072537899017334
Agent1_Alpha_Loss : 0.943848192691803
Agent1_Temperature : 0.09760899984253193
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 81 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 82 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 83 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 84 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 85 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 86 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 87 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 88 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 89 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 90 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -17.857620239257812
Agent0_Eval_StdReturn : 29.711423873901367
Agent0_Eval_MaxReturn : 39.58865737915039
Agent0_Eval_MinReturn : -53.58030319213867
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -10.79987907409668
Agent0_Train_StdReturn : 21.534536361694336
Agent0_Train_MaxReturn : 26.618576049804688
Agent0_Train_MinReturn : -48.618534088134766
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 136500
Agent0_TimeSinceStart : 203.16461277008057
Agent0_Critic_Loss : 0.4966686964035034
Agent0_Actor_Loss : -0.5530083179473877
Agent0_Alpha_Loss : 0.9283055067062378
Agent0_Temperature : 0.09732510135183746
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -22.70708465576172
Agent1_Eval_StdReturn : 28.623443603515625
Agent1_Eval_MaxReturn : 41.20599365234375
Agent1_Eval_MinReturn : -65.87571716308594
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -29.3641300201416
Agent1_Train_StdReturn : 18.432497024536133
Agent1_Train_MaxReturn : 7.412674427032471
Agent1_Train_MinReturn : -63.426666259765625
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 136500
Agent1_TimeSinceStart : 205.25839567184448
Agent1_Critic_Loss : 0.5023685693740845
Agent1_Actor_Loss : -0.6076624989509583
Agent1_Alpha_Loss : 0.9397616982460022
Agent1_Temperature : 0.0973242661772684
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 91 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 92 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 93 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 94 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 95 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 96 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 97 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 98 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 99 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 100 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -37.80340576171875
Agent0_Eval_StdReturn : 20.51852035522461
Agent0_Eval_MaxReturn : -8.982361793518066
Agent0_Eval_MinReturn : -69.56307983398438
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -13.584561347961426
Agent0_Train_StdReturn : 29.4119873046875
Agent0_Train_MaxReturn : 39.010250091552734
Agent0_Train_MinReturn : -50.01905059814453
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 151500
Agent0_TimeSinceStart : 226.28529477119446
Agent0_Critic_Loss : 0.4442911446094513
Agent0_Actor_Loss : -0.5299762487411499
Agent0_Alpha_Loss : 0.8924819231033325
Agent0_Temperature : 0.09704567997417912
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -26.93208885192871
Agent1_Eval_StdReturn : 15.997502326965332
Agent1_Eval_MaxReturn : -3.8266448974609375
Agent1_Eval_MinReturn : -59.922542572021484
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -28.49300193786621
Agent1_Train_StdReturn : 23.280410766601562
Agent1_Train_MaxReturn : 2.7106361389160156
Agent1_Train_MinReturn : -77.24320983886719
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 151500
Agent1_TimeSinceStart : 228.37332916259766
Agent1_Critic_Loss : 0.5145032405853271
Agent1_Actor_Loss : -0.7386530637741089
Agent1_Alpha_Loss : 0.8874350786209106
Agent1_Temperature : 0.09704388809122931
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 101 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 102 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 103 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 104 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 105 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 106 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 107 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 108 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 109 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 110 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -26.71738052368164
Agent0_Eval_StdReturn : 9.157398223876953
Agent0_Eval_MaxReturn : -13.375016212463379
Agent0_Eval_MinReturn : -42.88822937011719
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -19.410362243652344
Agent0_Train_StdReturn : 7.425318241119385
Agent0_Train_MaxReturn : -8.613565444946289
Agent0_Train_MinReturn : -30.00765037536621
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 166500
Agent0_TimeSinceStart : 249.38815116882324
Agent0_Critic_Loss : 0.4051252603530884
Agent0_Actor_Loss : -0.5468058586120605
Agent0_Alpha_Loss : 0.8308137655258179
Agent0_Temperature : 0.09677476231533662
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -29.879653930664062
Agent1_Eval_StdReturn : 10.994625091552734
Agent1_Eval_MaxReturn : -4.192960739135742
Agent1_Eval_MinReturn : -39.91998291015625
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -21.70599365234375
Agent1_Train_StdReturn : 8.793038368225098
Agent1_Train_MaxReturn : -6.571042060852051
Agent1_Train_MinReturn : -37.95457458496094
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 166500
Agent1_TimeSinceStart : 251.48544049263
Agent1_Critic_Loss : 0.4581545293331146
Agent1_Actor_Loss : -0.6983570456504822
Agent1_Alpha_Loss : 0.8447428345680237
Agent1_Temperature : 0.09677138948908492
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 111 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 112 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 113 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 114 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 115 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 116 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 117 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 118 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 119 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 120 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -24.482786178588867
Agent0_Eval_StdReturn : 14.492881774902344
Agent0_Eval_MaxReturn : 3.942654609680176
Agent0_Eval_MinReturn : -49.24791717529297
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -19.76818084716797
Agent0_Train_StdReturn : 14.692700386047363
Agent0_Train_MaxReturn : 8.915509223937988
Agent0_Train_MinReturn : -44.430538177490234
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 181500
Agent0_TimeSinceStart : 272.5621917247772
Agent0_Critic_Loss : 0.4409399926662445
Agent0_Actor_Loss : -0.5370804667472839
Agent0_Alpha_Loss : 0.7897802591323853
Agent0_Temperature : 0.09651470315587865
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -29.733917236328125
Agent1_Eval_StdReturn : 14.06531047821045
Agent1_Eval_MaxReturn : -3.601330041885376
Agent1_Eval_MinReturn : -60.80698013305664
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -24.933208465576172
Agent1_Train_StdReturn : 16.737770080566406
Agent1_Train_MaxReturn : -7.081881999969482
Agent1_Train_MinReturn : -65.99290466308594
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 181500
Agent1_TimeSinceStart : 274.6524968147278
Agent1_Critic_Loss : 0.39527273178100586
Agent1_Actor_Loss : -0.6849207878112793
Agent1_Alpha_Loss : 0.7959141135215759
Agent1_Temperature : 0.0965084619101353
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 121 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 122 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 123 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 124 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 125 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 126 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 127 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 128 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 129 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 130 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -30.72934341430664
Agent0_Eval_StdReturn : 7.28204345703125
Agent0_Eval_MaxReturn : -21.046300888061523
Agent0_Eval_MinReturn : -44.18566131591797
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -33.520572662353516
Agent0_Train_StdReturn : 14.600418090820312
Agent0_Train_MaxReturn : -14.512083053588867
Agent0_Train_MinReturn : -68.73931121826172
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 196500
Agent0_TimeSinceStart : 295.79438495635986
Agent0_Critic_Loss : 0.4850107431411743
Agent0_Actor_Loss : -0.4656216502189636
Agent0_Alpha_Loss : 0.7841089367866516
Agent0_Temperature : 0.09626522147069992
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -34.47418212890625
Agent1_Eval_StdReturn : 12.714120864868164
Agent1_Eval_MaxReturn : -17.067184448242188
Agent1_Eval_MinReturn : -63.6812744140625
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -35.14310073852539
Agent1_Train_StdReturn : 14.900437355041504
Agent1_Train_MaxReturn : -18.32403564453125
Agent1_Train_MinReturn : -75.90545654296875
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 196500
Agent1_TimeSinceStart : 297.8895070552826
Agent1_Critic_Loss : 0.3992483615875244
Agent1_Actor_Loss : -0.6165434122085571
Agent1_Alpha_Loss : 0.7931673526763916
Agent1_Temperature : 0.0962551694498973
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 131 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 132 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 133 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 134 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 135 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 136 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 137 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 138 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 139 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 140 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -25.436416625976562
Agent0_Eval_StdReturn : 10.668664932250977
Agent0_Eval_MaxReturn : -5.131865501403809
Agent0_Eval_MinReturn : -41.88395690917969
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -32.71979904174805
Agent0_Train_StdReturn : 6.228855133056641
Agent0_Train_MaxReturn : -22.526844024658203
Agent0_Train_MinReturn : -42.00605010986328
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 211500
Agent0_TimeSinceStart : 319.06502962112427
Agent0_Critic_Loss : 0.39317232370376587
Agent0_Actor_Loss : -0.5013166666030884
Agent0_Alpha_Loss : 0.7903857231140137
Agent0_Temperature : 0.0960199839826443
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -18.286291122436523
Agent1_Eval_StdReturn : 16.946006774902344
Agent1_Eval_MaxReturn : 0.406219482421875
Agent1_Eval_MinReturn : -58.388404846191406
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -31.03554916381836
Agent1_Train_StdReturn : 19.03114891052246
Agent1_Train_MaxReturn : -3.648172378540039
Agent1_Train_MinReturn : -65.96772766113281
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 211500
Agent1_TimeSinceStart : 321.1599028110504
Agent1_Critic_Loss : 0.37308788299560547
Agent1_Actor_Loss : -0.6019374132156372
Agent1_Alpha_Loss : 0.8196832537651062
Agent1_Temperature : 0.09600565036244861
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 141 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 142 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 143 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 144 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 145 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 146 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 147 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 148 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 149 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 150 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -31.892099380493164
Agent0_Eval_StdReturn : 12.439228057861328
Agent0_Eval_MaxReturn : -12.451138496398926
Agent0_Eval_MinReturn : -51.76466369628906
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -27.9456729888916
Agent0_Train_StdReturn : 10.288050651550293
Agent0_Train_MaxReturn : -12.234962463378906
Agent0_Train_MinReturn : -48.911224365234375
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 226500
Agent0_TimeSinceStart : 342.250789642334
Agent0_Critic_Loss : 0.38597971200942993
Agent0_Actor_Loss : -0.5260317325592041
Agent0_Alpha_Loss : 0.8047704100608826
Agent0_Temperature : 0.0957727699576644
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -26.361913681030273
Agent1_Eval_StdReturn : 16.365890502929688
Agent1_Eval_MaxReturn : 5.785409927368164
Agent1_Eval_MinReturn : -57.972164154052734
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -21.194849014282227
Agent1_Train_StdReturn : 10.356460571289062
Agent1_Train_MaxReturn : -1.4959745407104492
Agent1_Train_MinReturn : -33.84349822998047
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 226500
Agent1_TimeSinceStart : 344.3516969680786
Agent1_Critic_Loss : 0.36958667635917664
Agent1_Actor_Loss : -0.539533257484436
Agent1_Alpha_Loss : 0.8046441674232483
Agent1_Temperature : 0.09575486746138635
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 151 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 152 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 153 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 154 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 155 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 156 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 157 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 158 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 159 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 160 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -28.369461059570312
Agent0_Eval_StdReturn : 15.800494194030762
Agent0_Eval_MaxReturn : -6.013942718505859
Agent0_Eval_MinReturn : -50.84025573730469
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -17.05450439453125
Agent0_Train_StdReturn : 22.834875106811523
Agent0_Train_MaxReturn : 17.602853775024414
Agent0_Train_MinReturn : -56.72097396850586
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 241500
Agent0_TimeSinceStart : 365.3783280849457
Agent0_Critic_Loss : 0.39450690150260925
Agent0_Actor_Loss : -0.4640153646469116
Agent0_Alpha_Loss : 0.8255113959312439
Agent0_Temperature : 0.09552109655257941
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -25.255813598632812
Agent1_Eval_StdReturn : 6.8625874519348145
Agent1_Eval_MaxReturn : -14.703727722167969
Agent1_Eval_MinReturn : -36.29902648925781
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -20.357406616210938
Agent1_Train_StdReturn : 11.571333885192871
Agent1_Train_MaxReturn : 3.507589340209961
Agent1_Train_MinReturn : -36.570167541503906
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 241500
Agent1_TimeSinceStart : 367.4651436805725
Agent1_Critic_Loss : 0.2832237482070923
Agent1_Actor_Loss : -0.6322349309921265
Agent1_Alpha_Loss : 0.8384940028190613
Agent1_Temperature : 0.09550122755746757
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 161 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 162 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 163 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 164 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 165 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 166 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 167 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 168 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 169 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 170 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -21.955142974853516
Agent0_Eval_StdReturn : 14.017755508422852
Agent0_Eval_MaxReturn : -3.4731693267822266
Agent0_Eval_MinReturn : -58.09199905395508
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -17.145771026611328
Agent0_Train_StdReturn : 11.94571304321289
Agent0_Train_MaxReturn : 5.7421698570251465
Agent0_Train_MinReturn : -38.180389404296875
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 256500
Agent0_TimeSinceStart : 388.5220217704773
Agent0_Critic_Loss : 0.30586960911750793
Agent0_Actor_Loss : -0.32850509881973267
Agent0_Alpha_Loss : 0.8147903680801392
Agent0_Temperature : 0.09526527187051673
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -28.28069496154785
Agent1_Eval_StdReturn : 25.534046173095703
Agent1_Eval_MaxReturn : -3.7594070434570312
Agent1_Eval_MinReturn : -93.77108764648438
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -25.064228057861328
Agent1_Train_StdReturn : 17.75586700439453
Agent1_Train_MaxReturn : 1.773763656616211
Agent1_Train_MinReturn : -55.343414306640625
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 256500
Agent1_TimeSinceStart : 390.61465549468994
Agent1_Critic_Loss : 0.3038290739059448
Agent1_Actor_Loss : -0.5801087617874146
Agent1_Alpha_Loss : 0.8144093751907349
Agent1_Temperature : 0.09524513003155671
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 171 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 172 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 173 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 174 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 175 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 176 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 177 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 178 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 179 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 180 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -27.076618194580078
Agent0_Eval_StdReturn : 15.346336364746094
Agent0_Eval_MaxReturn : -4.051137924194336
Agent0_Eval_MinReturn : -60.678123474121094
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -17.712825775146484
Agent0_Train_StdReturn : 13.926739692687988
Agent0_Train_MaxReturn : 10.59235954284668
Agent0_Train_MinReturn : -37.77747344970703
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 271500
Agent0_TimeSinceStart : 411.6728343963623
Agent0_Critic_Loss : 0.318859338760376
Agent0_Actor_Loss : -0.48374971747398376
Agent0_Alpha_Loss : 0.8070443868637085
Agent0_Temperature : 0.09500847950734942
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -14.019808769226074
Agent1_Eval_StdReturn : 4.695367336273193
Agent1_Eval_MaxReturn : -6.574995517730713
Agent1_Eval_MinReturn : -22.182910919189453
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -19.994857788085938
Agent1_Train_StdReturn : 17.90374183654785
Agent1_Train_MaxReturn : 10.091588020324707
Agent1_Train_MinReturn : -43.324684143066406
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 271500
Agent1_TimeSinceStart : 413.76292181015015
Agent1_Critic_Loss : 0.3104366660118103
Agent1_Actor_Loss : -0.5791971683502197
Agent1_Alpha_Loss : 0.8123703002929688
Agent1_Temperature : 0.0949880875299392
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 181 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 182 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 183 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 184 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 185 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 186 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 187 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 188 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 189 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 190 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -21.80546760559082
Agent0_Eval_StdReturn : 16.769208908081055
Agent0_Eval_MaxReturn : 6.622250556945801
Agent0_Eval_MinReturn : -49.69880294799805
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -16.967369079589844
Agent0_Train_StdReturn : 10.091402053833008
Agent0_Train_MaxReturn : -4.692663192749023
Agent0_Train_MinReturn : -36.403682708740234
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 286500
Agent0_TimeSinceStart : 434.8546562194824
Agent0_Critic_Loss : 0.30364954471588135
Agent0_Actor_Loss : -0.4403717517852783
Agent0_Alpha_Loss : 0.796306312084198
Agent0_Temperature : 0.09475282935455145
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -22.501718521118164
Agent1_Eval_StdReturn : 9.146004676818848
Agent1_Eval_MaxReturn : -9.557808876037598
Agent1_Eval_MinReturn : -34.794677734375
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -20.40598487854004
Agent1_Train_StdReturn : 12.294474601745605
Agent1_Train_MaxReturn : -7.418977737426758
Agent1_Train_MinReturn : -45.753150939941406
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 286500
Agent1_TimeSinceStart : 436.95348286628723
Agent1_Critic_Loss : 0.26685407757759094
Agent1_Actor_Loss : -0.5384045839309692
Agent1_Alpha_Loss : 0.8114606738090515
Agent1_Temperature : 0.09473029919771728
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 191 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 192 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 193 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 194 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 195 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 196 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 197 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 198 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 199 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 200 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -25.69723129272461
Agent0_Eval_StdReturn : 20.455692291259766
Agent0_Eval_MaxReturn : 10.974164962768555
Agent0_Eval_MinReturn : -51.000919342041016
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -20.289236068725586
Agent0_Train_StdReturn : 17.39792251586914
Agent0_Train_MaxReturn : 0.43537425994873047
Agent0_Train_MinReturn : -65.25035858154297
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 301500
Agent0_TimeSinceStart : 458.0271553993225
Agent0_Critic_Loss : 0.2412942796945572
Agent0_Actor_Loss : -0.3400561213493347
Agent0_Alpha_Loss : 0.7977859377861023
Agent0_Temperature : 0.09449895330535356
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -20.21791648864746
Agent1_Eval_StdReturn : 11.459834098815918
Agent1_Eval_MaxReturn : 3.1967945098876953
Agent1_Eval_MinReturn : -35.55563735961914
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -25.8229923248291
Agent1_Train_StdReturn : 10.7367582321167
Agent1_Train_MaxReturn : -4.19175910949707
Agent1_Train_MinReturn : -41.7381706237793
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 301500
Agent1_TimeSinceStart : 460.11892318725586
Agent1_Critic_Loss : 0.329375684261322
Agent1_Actor_Loss : -0.5519530177116394
Agent1_Alpha_Loss : 0.8178637027740479
Agent1_Temperature : 0.09447224516686203
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 201 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 202 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 203 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 204 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 205 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 206 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 207 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 208 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 209 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 210 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -21.8115291595459
Agent0_Eval_StdReturn : 13.657686233520508
Agent0_Eval_MaxReturn : -2.757404327392578
Agent0_Eval_MinReturn : -48.650047302246094
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -14.39471435546875
Agent0_Train_StdReturn : 16.347627639770508
Agent0_Train_MaxReturn : 14.92820930480957
Agent0_Train_MinReturn : -34.654483795166016
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 316500
Agent0_TimeSinceStart : 481.2462406158447
Agent0_Critic_Loss : 0.27737730741500854
Agent0_Actor_Loss : -0.41797274351119995
Agent0_Alpha_Loss : 0.7780022025108337
Agent0_Temperature : 0.09424531666721062
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -22.183481216430664
Agent1_Eval_StdReturn : 12.680124282836914
Agent1_Eval_MaxReturn : -5.597496032714844
Agent1_Eval_MinReturn : -41.762596130371094
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -16.213851928710938
Agent1_Train_StdReturn : 18.73265838623047
Agent1_Train_MaxReturn : 12.309500694274902
Agent1_Train_MinReturn : -50.59186935424805
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 316500
Agent1_TimeSinceStart : 483.3436484336853
Agent1_Critic_Loss : 0.26005643606185913
Agent1_Actor_Loss : -0.4757649302482605
Agent1_Alpha_Loss : 0.8048917651176453
Agent1_Temperature : 0.09421393358537866
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 211 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 212 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 213 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 214 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 215 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 216 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 217 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 218 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 219 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 220 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -13.577470779418945
Agent0_Eval_StdReturn : 16.09775161743164
Agent0_Eval_MaxReturn : 13.942264556884766
Agent0_Eval_MinReturn : -37.72106170654297
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -10.577577590942383
Agent0_Train_StdReturn : 17.933340072631836
Agent0_Train_MaxReturn : 13.795208930969238
Agent0_Train_MinReturn : -42.75967025756836
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 331500
Agent0_TimeSinceStart : 504.4476523399353
Agent0_Critic_Loss : 0.2705122232437134
Agent0_Actor_Loss : -0.3920987546443939
Agent0_Alpha_Loss : 0.7923597097396851
Agent0_Temperature : 0.09399066654138319
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -24.284931182861328
Agent1_Eval_StdReturn : 18.248394012451172
Agent1_Eval_MaxReturn : 1.9455909729003906
Agent1_Eval_MinReturn : -64.74829864501953
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -17.958498001098633
Agent1_Train_StdReturn : 16.714183807373047
Agent1_Train_MaxReturn : 7.660728454589844
Agent1_Train_MinReturn : -46.426483154296875
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 331500
Agent1_TimeSinceStart : 506.5507709980011
Agent1_Critic_Loss : 0.2633100748062134
Agent1_Actor_Loss : -0.48805761337280273
Agent1_Alpha_Loss : 0.7811381816864014
Agent1_Temperature : 0.09395560785892178
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 221 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 222 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 223 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 224 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 225 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 226 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 227 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 228 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 229 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 230 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -18.710599899291992
Agent0_Eval_StdReturn : 15.809965133666992
Agent0_Eval_MaxReturn : 2.2870659828186035
Agent0_Eval_MinReturn : -44.86009216308594
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -19.17093276977539
Agent0_Train_StdReturn : 13.501765251159668
Agent0_Train_MaxReturn : 0.7054409384727478
Agent0_Train_MinReturn : -39.32066345214844
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 346500
Agent0_TimeSinceStart : 527.6640090942383
Agent0_Critic_Loss : 0.22688761353492737
Agent0_Actor_Loss : -0.3476746678352356
Agent0_Alpha_Loss : 0.7892990112304688
Agent0_Temperature : 0.09373451595001299
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -23.829654693603516
Agent1_Eval_StdReturn : 16.401927947998047
Agent1_Eval_MaxReturn : -4.864241123199463
Agent1_Eval_MinReturn : -53.475162506103516
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -21.34646987915039
Agent1_Train_StdReturn : 16.41570472717285
Agent1_Train_MaxReturn : 14.388132095336914
Agent1_Train_MinReturn : -40.5125732421875
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 346500
Agent1_TimeSinceStart : 529.7507622241974
Agent1_Critic_Loss : 0.2123662829399109
Agent1_Actor_Loss : -0.47763341665267944
Agent1_Alpha_Loss : 0.8241918683052063
Agent1_Temperature : 0.09369781734922288
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 231 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 232 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 233 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 234 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 235 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 236 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 237 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 238 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 239 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 240 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -17.333988189697266
Agent0_Eval_StdReturn : 22.86820411682129
Agent0_Eval_MaxReturn : 3.0578129291534424
Agent0_Eval_MinReturn : -78.88383483886719
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -20.085369110107422
Agent0_Train_StdReturn : 9.355685234069824
Agent0_Train_MaxReturn : 0.6124482154846191
Agent0_Train_MinReturn : -33.810489654541016
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 361500
Agent0_TimeSinceStart : 550.7585577964783
Agent0_Critic_Loss : 0.22649532556533813
Agent0_Actor_Loss : -0.4314124584197998
Agent0_Alpha_Loss : 0.8179545998573303
Agent0_Temperature : 0.09347691437687203
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -18.3162899017334
Agent1_Eval_StdReturn : 17.166223526000977
Agent1_Eval_MaxReturn : 1.881246566772461
Agent1_Eval_MinReturn : -51.84557342529297
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -34.039085388183594
Agent1_Train_StdReturn : 13.983345031738281
Agent1_Train_MaxReturn : -18.71865463256836
Agent1_Train_MinReturn : -56.42881774902344
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 361500
Agent1_TimeSinceStart : 552.8524107933044
Agent1_Critic_Loss : 0.23187902569770813
Agent1_Actor_Loss : -0.46610862016677856
Agent1_Alpha_Loss : 0.818598747253418
Agent1_Temperature : 0.09343862549918217
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 241 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 242 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 243 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 244 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 245 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 246 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 247 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 248 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 249 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 250 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -28.273305892944336
Agent0_Eval_StdReturn : 20.605722427368164
Agent0_Eval_MaxReturn : 3.391468048095703
Agent0_Eval_MinReturn : -61.47727966308594
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -22.134458541870117
Agent0_Train_StdReturn : 25.50248146057129
Agent0_Train_MaxReturn : 0.7803969383239746
Agent0_Train_MinReturn : -94.14483642578125
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 376500
Agent0_TimeSinceStart : 573.8869931697845
Agent0_Critic_Loss : 0.3047303557395935
Agent0_Actor_Loss : -0.4328756034374237
Agent0_Alpha_Loss : 0.8132928013801575
Agent0_Temperature : 0.09321761287041025
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -19.992265701293945
Agent1_Eval_StdReturn : 10.623624801635742
Agent1_Eval_MaxReturn : -2.776881694793701
Agent1_Eval_MinReturn : -35.5587043762207
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -10.000242233276367
Agent1_Train_StdReturn : 11.439395904541016
Agent1_Train_MaxReturn : 4.235828399658203
Agent1_Train_MinReturn : -32.62958908081055
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 376500
Agent1_TimeSinceStart : 575.9761629104614
Agent1_Critic_Loss : 0.2005358785390854
Agent1_Actor_Loss : -0.4687945246696472
Agent1_Alpha_Loss : 0.8252982497215271
Agent1_Temperature : 0.09317791669596483
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 251 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 252 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 253 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 254 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 255 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 256 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 257 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 258 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 259 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 260 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -21.173725128173828
Agent0_Eval_StdReturn : 22.272939682006836
Agent0_Eval_MaxReturn : 7.241703510284424
Agent0_Eval_MinReturn : -63.53387451171875
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -22.807300567626953
Agent0_Train_StdReturn : 16.27992057800293
Agent0_Train_MaxReturn : 1.8352727890014648
Agent0_Train_MinReturn : -44.94645690917969
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 391500
Agent0_TimeSinceStart : 597.013368844986
Agent0_Critic_Loss : 0.24238094687461853
Agent0_Actor_Loss : -0.3988884687423706
Agent0_Alpha_Loss : 0.8145051598548889
Agent0_Temperature : 0.09295810211711002
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -22.740795135498047
Agent1_Eval_StdReturn : 17.84267807006836
Agent1_Eval_MaxReturn : -0.16417014598846436
Agent1_Eval_MinReturn : -68.10855102539062
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -18.616830825805664
Agent1_Train_StdReturn : 12.847663879394531
Agent1_Train_MaxReturn : 6.060478687286377
Agent1_Train_MinReturn : -45.211875915527344
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 391500
Agent1_TimeSinceStart : 599.1001842021942
Agent1_Critic_Loss : 0.2865895628929138
Agent1_Actor_Loss : -0.5141335725784302
Agent1_Alpha_Loss : 0.8191352486610413
Agent1_Temperature : 0.09291674372453547
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 261 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 262 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 263 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 264 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 265 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 266 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 267 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 268 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 269 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 270 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -10.512846946716309
Agent0_Eval_StdReturn : 13.774767875671387
Agent0_Eval_MaxReturn : 11.582235336303711
Agent0_Eval_MinReturn : -32.29518508911133
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -13.4161376953125
Agent0_Train_StdReturn : 23.522686004638672
Agent0_Train_MaxReturn : 23.2353515625
Agent0_Train_MinReturn : -55.13616180419922
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 406500
Agent0_TimeSinceStart : 620.1311957836151
Agent0_Critic_Loss : 0.3442981243133545
Agent0_Actor_Loss : -0.40543293952941895
Agent0_Alpha_Loss : 0.8171842098236084
Agent0_Temperature : 0.09269592974801372
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -9.648462295532227
Agent1_Eval_StdReturn : 22.913223266601562
Agent1_Eval_MaxReturn : 26.497390747070312
Agent1_Eval_MinReturn : -54.01353454589844
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -33.79578399658203
Agent1_Train_StdReturn : 15.738564491271973
Agent1_Train_MaxReturn : -1.1309329271316528
Agent1_Train_MinReturn : -54.414337158203125
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 406500
Agent1_TimeSinceStart : 622.2181451320648
Agent1_Critic_Loss : 0.26162654161453247
Agent1_Actor_Loss : -0.5619012117385864
Agent1_Alpha_Loss : 0.8127342462539673
Agent1_Temperature : 0.09265593987875001
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 271 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 272 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 273 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 274 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 275 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 276 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 277 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 278 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 279 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 280 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -30.283252716064453
Agent0_Eval_StdReturn : 25.37603759765625
Agent0_Eval_MaxReturn : 12.135286331176758
Agent0_Eval_MinReturn : -77.88578796386719
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -23.479312896728516
Agent0_Train_StdReturn : 18.681013107299805
Agent0_Train_MaxReturn : -0.013998985290527344
Agent0_Train_MinReturn : -59.95723342895508
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 421500
Agent0_TimeSinceStart : 643.2262237071991
Agent0_Critic_Loss : 0.36272817850112915
Agent0_Actor_Loss : -0.49390438199043274
Agent0_Alpha_Loss : 0.8066123723983765
Agent0_Temperature : 0.09243355152872568
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -18.736736297607422
Agent1_Eval_StdReturn : 17.764461517333984
Agent1_Eval_MaxReturn : 7.280604362487793
Agent1_Eval_MinReturn : -51.28277587890625
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -21.252260208129883
Agent1_Train_StdReturn : 16.68300437927246
Agent1_Train_MaxReturn : 18.72759437561035
Agent1_Train_MinReturn : -40.4295654296875
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 421500
Agent1_TimeSinceStart : 645.3189613819122
Agent1_Critic_Loss : 0.2777755856513977
Agent1_Actor_Loss : -0.4685590863227844
Agent1_Alpha_Loss : 0.8310694694519043
Agent1_Temperature : 0.09239528086008178
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 281 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 282 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 283 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 284 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 285 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 286 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 287 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 288 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 289 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 290 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -23.595516204833984
Agent0_Eval_StdReturn : 20.059581756591797
Agent0_Eval_MaxReturn : 10.174663543701172
Agent0_Eval_MinReturn : -55.899757385253906
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -32.25330352783203
Agent0_Train_StdReturn : 26.456214904785156
Agent0_Train_MaxReturn : 28.51021385192871
Agent0_Train_MinReturn : -62.81499481201172
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 436500
Agent0_TimeSinceStart : 666.3299264907837
Agent0_Critic_Loss : 0.3397170305252075
Agent0_Actor_Loss : -0.4539000391960144
Agent0_Alpha_Loss : 0.8094656467437744
Agent0_Temperature : 0.09217217773772532
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -26.199859619140625
Agent1_Eval_StdReturn : 30.655960083007812
Agent1_Eval_MaxReturn : 19.09996223449707
Agent1_Eval_MinReturn : -85.20821380615234
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -20.576250076293945
Agent1_Train_StdReturn : 23.522932052612305
Agent1_Train_MaxReturn : 16.836807250976562
Agent1_Train_MinReturn : -63.4809684753418
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 436500
Agent1_TimeSinceStart : 668.4177305698395
Agent1_Critic_Loss : 0.3389924168586731
Agent1_Actor_Loss : -0.5380591154098511
Agent1_Alpha_Loss : 0.8115537166595459
Agent1_Temperature : 0.09213540255554403
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 291 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 292 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 293 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 294 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 295 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 296 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 297 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 298 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 299 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 300 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -19.194705963134766
Agent0_Eval_StdReturn : 20.533872604370117
Agent0_Eval_MaxReturn : 11.376367568969727
Agent0_Eval_MinReturn : -66.9398193359375
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -30.98599624633789
Agent0_Train_StdReturn : 27.600034713745117
Agent0_Train_MaxReturn : 11.761993408203125
Agent0_Train_MinReturn : -71.42707061767578
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 451500
Agent0_TimeSinceStart : 689.412743806839
Agent0_Critic_Loss : 0.32151931524276733
Agent0_Actor_Loss : -0.4429622292518616
Agent0_Alpha_Loss : 0.8083616495132446
Agent0_Temperature : 0.09191241202806633
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -20.708343505859375
Agent1_Eval_StdReturn : 16.63187599182129
Agent1_Eval_MaxReturn : 6.875889778137207
Agent1_Eval_MinReturn : -49.585262298583984
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -23.951841354370117
Agent1_Train_StdReturn : 19.38088607788086
Agent1_Train_MaxReturn : 13.88760757446289
Agent1_Train_MinReturn : -53.550289154052734
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 451500
Agent1_TimeSinceStart : 691.4961867332458
Agent1_Critic_Loss : 0.3512432277202606
Agent1_Actor_Loss : -0.7054246068000793
Agent1_Alpha_Loss : 0.8117501735687256
Agent1_Temperature : 0.09187611557410194
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 301 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 302 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 303 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 304 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 305 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 306 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 307 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 308 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 309 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 310 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -25.286510467529297
Agent0_Eval_StdReturn : 20.459747314453125
Agent0_Eval_MaxReturn : 6.085593223571777
Agent0_Eval_MinReturn : -57.886348724365234
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -21.134723663330078
Agent0_Train_StdReturn : 31.16391944885254
Agent0_Train_MaxReturn : 27.580158233642578
Agent0_Train_MinReturn : -85.47311401367188
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 466500
Agent0_TimeSinceStart : 712.4906272888184
Agent0_Critic_Loss : 0.398018479347229
Agent0_Actor_Loss : -0.3958684802055359
Agent0_Alpha_Loss : 0.8079240322113037
Agent0_Temperature : 0.0916534327516035
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -26.192956924438477
Agent1_Eval_StdReturn : 11.477371215820312
Agent1_Eval_MaxReturn : -12.226518630981445
Agent1_Eval_MinReturn : -49.11680603027344
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -24.602725982666016
Agent1_Train_StdReturn : 15.936698913574219
Agent1_Train_MaxReturn : 4.593789100646973
Agent1_Train_MinReturn : -47.22639465332031
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 466500
Agent1_TimeSinceStart : 714.5699183940887
Agent1_Critic_Loss : 0.332567423582077
Agent1_Actor_Loss : -0.5542720556259155
Agent1_Alpha_Loss : 0.8019198775291443
Agent1_Temperature : 0.09161719579519823
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 311 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 312 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 313 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 314 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 315 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 316 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 317 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 318 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 319 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 320 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -24.705801010131836
Agent0_Eval_StdReturn : 19.075075149536133
Agent0_Eval_MaxReturn : 2.4338719844818115
Agent0_Eval_MinReturn : -54.608985900878906
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -22.203445434570312
Agent0_Train_StdReturn : 13.708393096923828
Agent0_Train_MaxReturn : 2.7937564849853516
Agent0_Train_MinReturn : -41.12067413330078
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 481500
Agent0_TimeSinceStart : 735.569173336029
Agent0_Critic_Loss : 0.33031201362609863
Agent0_Actor_Loss : -0.5101511478424072
Agent0_Alpha_Loss : 0.821237325668335
Agent0_Temperature : 0.09139412485821331
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -13.947354316711426
Agent1_Eval_StdReturn : 18.0933780670166
Agent1_Eval_MaxReturn : 10.643583297729492
Agent1_Eval_MinReturn : -39.726749420166016
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -17.595245361328125
Agent1_Train_StdReturn : 14.696773529052734
Agent1_Train_MaxReturn : 8.018087387084961
Agent1_Train_MinReturn : -50.69114303588867
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 481500
Agent1_TimeSinceStart : 737.6613373756409
Agent1_Critic_Loss : 0.3165989816188812
Agent1_Actor_Loss : -0.5600560903549194
Agent1_Alpha_Loss : 0.8025144338607788
Agent1_Temperature : 0.09136068700596023
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 321 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 322 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 323 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 324 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 325 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 326 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 327 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 328 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 329 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 330 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -12.092443466186523
Agent0_Eval_StdReturn : 13.87833023071289
Agent0_Eval_MaxReturn : 16.807514190673828
Agent0_Eval_MinReturn : -26.641738891601562
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -15.428210258483887
Agent0_Train_StdReturn : 10.815107345581055
Agent0_Train_MaxReturn : 0.35452842712402344
Agent0_Train_MinReturn : -35.20900344848633
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 496500
Agent0_TimeSinceStart : 758.6790680885315
Agent0_Critic_Loss : 0.30838149785995483
Agent0_Actor_Loss : -0.4863130748271942
Agent0_Alpha_Loss : 0.8117921352386475
Agent0_Temperature : 0.09113487731211635
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -32.02956771850586
Agent1_Eval_StdReturn : 19.849437713623047
Agent1_Eval_MaxReturn : -4.152190208435059
Agent1_Eval_MinReturn : -60.177974700927734
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -18.467260360717773
Agent1_Train_StdReturn : 18.557706832885742
Agent1_Train_MaxReturn : -0.14077472686767578
Agent1_Train_MinReturn : -51.77149963378906
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 496500
Agent1_TimeSinceStart : 760.7641954421997
Agent1_Critic_Loss : 0.40743908286094666
Agent1_Actor_Loss : -0.6035406589508057
Agent1_Alpha_Loss : 0.7834727168083191
Agent1_Temperature : 0.09110506259273615
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 331 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 332 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 333 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 334 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 335 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 336 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 337 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 338 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 339 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 340 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -26.694995880126953
Agent0_Eval_StdReturn : 18.066043853759766
Agent0_Eval_MaxReturn : 11.272394180297852
Agent0_Eval_MinReturn : -52.916011810302734
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -9.274656295776367
Agent0_Train_StdReturn : 14.302080154418945
Agent0_Train_MaxReturn : 11.882001876831055
Agent0_Train_MinReturn : -31.93508529663086
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 511500
Agent0_TimeSinceStart : 781.7787408828735
Agent0_Critic_Loss : 0.3211015462875366
Agent0_Actor_Loss : -0.47457432746887207
Agent0_Alpha_Loss : 0.811062216758728
Agent0_Temperature : 0.09087606895171785
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -22.26936149597168
Agent1_Eval_StdReturn : 19.707082748413086
Agent1_Eval_MaxReturn : 11.060861587524414
Agent1_Eval_MinReturn : -61.7706184387207
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -22.84769058227539
Agent1_Train_StdReturn : 17.299850463867188
Agent1_Train_MaxReturn : 10.799400329589844
Agent1_Train_MinReturn : -45.96625518798828
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 511500
Agent1_TimeSinceStart : 783.871776342392
Agent1_Critic_Loss : 0.35649803280830383
Agent1_Actor_Loss : -0.5406082272529602
Agent1_Alpha_Loss : 0.7848169207572937
Agent1_Temperature : 0.09085122267444683
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 341 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 342 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 343 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 344 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 345 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 346 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 347 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 348 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 349 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 350 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -9.7374267578125
Agent0_Eval_StdReturn : 15.898818969726562
Agent0_Eval_MaxReturn : 11.414478302001953
Agent0_Eval_MinReturn : -47.168540954589844
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -20.6744327545166
Agent0_Train_StdReturn : 13.608880996704102
Agent0_Train_MaxReturn : 1.1516590118408203
Agent0_Train_MinReturn : -42.95416259765625
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 526500
Agent0_TimeSinceStart : 804.913890838623
Agent0_Critic_Loss : 0.3436412215232849
Agent0_Actor_Loss : -0.5985157489776611
Agent0_Alpha_Loss : 0.8002958297729492
Agent0_Temperature : 0.09061838429933841
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -19.112735748291016
Agent1_Eval_StdReturn : 15.32368278503418
Agent1_Eval_MaxReturn : -1.2861032485961914
Agent1_Eval_MinReturn : -55.6138916015625
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -12.882573127746582
Agent1_Train_StdReturn : 16.83832550048828
Agent1_Train_MaxReturn : 15.277576446533203
Agent1_Train_MinReturn : -49.259132385253906
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 526500
Agent1_TimeSinceStart : 807.0056834220886
Agent1_Critic_Loss : 0.31648749113082886
Agent1_Actor_Loss : -0.6032606363296509
Agent1_Alpha_Loss : 0.7741221785545349
Agent1_Temperature : 0.0905990092702799
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 351 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 352 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 353 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 354 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 355 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 356 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 357 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 358 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 359 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 360 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -18.15387725830078
Agent0_Eval_StdReturn : 15.39348316192627
Agent0_Eval_MaxReturn : 12.493901252746582
Agent0_Eval_MinReturn : -40.753517150878906
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -22.97520637512207
Agent0_Train_StdReturn : 26.14950942993164
Agent0_Train_MaxReturn : 20.838565826416016
Agent0_Train_MinReturn : -69.32353973388672
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 541500
Agent0_TimeSinceStart : 828.1168088912964
Agent0_Critic_Loss : 0.48618483543395996
Agent0_Actor_Loss : -0.46394944190979004
Agent0_Alpha_Loss : 0.7875508069992065
Agent0_Temperature : 0.09036260891732288
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -26.226613998413086
Agent1_Eval_StdReturn : 17.123353958129883
Agent1_Eval_MaxReturn : -3.7045233249664307
Agent1_Eval_MinReturn : -61.8442497253418
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -16.9221248626709
Agent1_Train_StdReturn : 18.236705780029297
Agent1_Train_MaxReturn : 11.117691993713379
Agent1_Train_MinReturn : -53.55839538574219
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 541500
Agent1_TimeSinceStart : 830.209753036499
Agent1_Critic_Loss : 0.3456694185733795
Agent1_Actor_Loss : -0.6444045305252075
Agent1_Alpha_Loss : 0.7947706580162048
Agent1_Temperature : 0.09034838989953234
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 361 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 362 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 363 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 364 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 365 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 366 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 367 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 368 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 369 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 370 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -18.107250213623047
Agent0_Eval_StdReturn : 10.899334907531738
Agent0_Eval_MaxReturn : 4.725037574768066
Agent0_Eval_MinReturn : -34.189884185791016
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -12.650533676147461
Agent0_Train_StdReturn : 15.09224796295166
Agent0_Train_MaxReturn : 12.208056449890137
Agent0_Train_MinReturn : -41.97841262817383
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 556500
Agent0_TimeSinceStart : 851.2887291908264
Agent0_Critic_Loss : 0.3925657868385315
Agent0_Actor_Loss : -0.5470947027206421
Agent0_Alpha_Loss : 0.7964504957199097
Agent0_Temperature : 0.09010747707300207
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -15.982856750488281
Agent1_Eval_StdReturn : 11.797380447387695
Agent1_Eval_MaxReturn : -2.0168519020080566
Agent1_Eval_MinReturn : -39.419490814208984
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -16.218523025512695
Agent1_Train_StdReturn : 17.079496383666992
Agent1_Train_MaxReturn : 6.706143856048584
Agent1_Train_MinReturn : -49.2998161315918
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 556500
Agent1_TimeSinceStart : 853.3952989578247
Agent1_Critic_Loss : 0.3383156359195709
Agent1_Actor_Loss : -0.6574286222457886
Agent1_Alpha_Loss : 0.781275749206543
Agent1_Temperature : 0.09009796296643147
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 371 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 372 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 373 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 374 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 375 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 376 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 377 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 378 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 379 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 380 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -11.832112312316895
Agent0_Eval_StdReturn : 11.276193618774414
Agent0_Eval_MaxReturn : 2.628052234649658
Agent0_Eval_MinReturn : -32.549957275390625
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -23.425827026367188
Agent0_Train_StdReturn : 19.849689483642578
Agent0_Train_MaxReturn : 4.7365827560424805
Agent0_Train_MinReturn : -54.607154846191406
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 571500
Agent0_TimeSinceStart : 874.5052857398987
Agent0_Critic_Loss : 0.31302982568740845
Agent0_Actor_Loss : -0.46345093846321106
Agent0_Alpha_Loss : 0.7906743288040161
Agent0_Temperature : 0.08985391727659968
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -20.37346839904785
Agent1_Eval_StdReturn : 11.32889175415039
Agent1_Eval_MaxReturn : 3.78753662109375
Agent1_Eval_MinReturn : -38.21631622314453
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -16.713153839111328
Agent1_Train_StdReturn : 12.173930168151855
Agent1_Train_MaxReturn : -1.034379005432129
Agent1_Train_MinReturn : -38.78723907470703
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 571500
Agent1_TimeSinceStart : 876.6414134502411
Agent1_Critic_Loss : 0.28599822521209717
Agent1_Actor_Loss : -0.5683072805404663
Agent1_Alpha_Loss : 0.7852461338043213
Agent1_Temperature : 0.08984780687990195
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 381 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 382 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 383 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 384 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 385 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 386 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 387 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 388 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 389 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 390 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -25.997268676757812
Agent0_Eval_StdReturn : 10.575004577636719
Agent0_Eval_MaxReturn : -10.781713485717773
Agent0_Eval_MinReturn : -44.731956481933594
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -13.210467338562012
Agent0_Train_StdReturn : 8.28680419921875
Agent0_Train_MaxReturn : -0.17941761016845703
Agent0_Train_MinReturn : -26.807971954345703
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 586500
Agent0_TimeSinceStart : 898.1534287929535
Agent0_Critic_Loss : 0.40279829502105713
Agent0_Actor_Loss : -0.4834907352924347
Agent0_Alpha_Loss : 0.808134138584137
Agent0_Temperature : 0.08960221398008991
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -15.147132873535156
Agent1_Eval_StdReturn : 13.502035140991211
Agent1_Eval_MaxReturn : 2.2788445949554443
Agent1_Eval_MinReturn : -43.87636184692383
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -17.501720428466797
Agent1_Train_StdReturn : 14.089155197143555
Agent1_Train_MaxReturn : 3.5124454498291016
Agent1_Train_MinReturn : -50.221431732177734
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 586500
Agent1_TimeSinceStart : 900.2887501716614
Agent1_Critic_Loss : 0.4392952620983124
Agent1_Actor_Loss : -0.5180997252464294
Agent1_Alpha_Loss : 0.7640551328659058
Agent1_Temperature : 0.08959916800692995
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 391 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 392 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 393 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 394 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 395 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 396 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 397 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 398 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 399 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 400 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -22.444549560546875
Agent0_Eval_StdReturn : 11.149872779846191
Agent0_Eval_MaxReturn : -5.827047348022461
Agent0_Eval_MinReturn : -44.41047668457031
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -12.501476287841797
Agent0_Train_StdReturn : 13.870780944824219
Agent0_Train_MaxReturn : 11.38357162475586
Agent0_Train_MinReturn : -33.03313064575195
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 601500
Agent0_TimeSinceStart : 921.7866766452789
Agent0_Critic_Loss : 0.37248072028160095
Agent0_Actor_Loss : -0.4326912462711334
Agent0_Alpha_Loss : 0.7808903455734253
Agent0_Temperature : 0.08935138800448657
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -22.994487762451172
Agent1_Eval_StdReturn : 10.64844799041748
Agent1_Eval_MaxReturn : -6.120430946350098
Agent1_Eval_MinReturn : -39.420143127441406
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -17.722867965698242
Agent1_Train_StdReturn : 6.0130934715271
Agent1_Train_MaxReturn : -9.915961265563965
Agent1_Train_MinReturn : -28.782270431518555
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 601500
Agent1_TimeSinceStart : 923.9193079471588
Agent1_Critic_Loss : 0.3385634124279022
Agent1_Actor_Loss : -0.5979757308959961
Agent1_Alpha_Loss : 0.7597662210464478
Agent1_Temperature : 0.08935195025783985
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 401 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 402 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 403 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 404 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 405 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 406 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 407 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 408 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 409 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 410 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -10.20018196105957
Agent0_Eval_StdReturn : 11.715714454650879
Agent0_Eval_MaxReturn : 13.723154067993164
Agent0_Eval_MinReturn : -27.522520065307617
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -17.33185386657715
Agent0_Train_StdReturn : 15.995111465454102
Agent0_Train_MaxReturn : 15.997194290161133
Agent0_Train_MinReturn : -47.17620849609375
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 616500
Agent0_TimeSinceStart : 945.3635816574097
Agent0_Critic_Loss : 0.3779869079589844
Agent0_Actor_Loss : -0.39740389585494995
Agent0_Alpha_Loss : 0.8043760061264038
Agent0_Temperature : 0.0891018371798401
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -18.689796447753906
Agent1_Eval_StdReturn : 13.26981258392334
Agent1_Eval_MaxReturn : 8.217309951782227
Agent1_Eval_MinReturn : -47.49790954589844
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -11.210206985473633
Agent1_Train_StdReturn : 14.216797828674316
Agent1_Train_MaxReturn : 13.718526840209961
Agent1_Train_MinReturn : -38.88214874267578
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 616500
Agent1_TimeSinceStart : 947.5085332393646
Agent1_Critic_Loss : 0.4036501348018646
Agent1_Actor_Loss : -0.6397807598114014
Agent1_Alpha_Loss : 0.7610278725624084
Agent1_Temperature : 0.08910630198173848
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 411 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 412 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 413 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 414 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 415 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 416 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 417 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 418 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 419 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 420 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -17.163341522216797
Agent0_Eval_StdReturn : 14.15212631225586
Agent0_Eval_MaxReturn : 3.1051535606384277
Agent0_Eval_MinReturn : -41.406639099121094
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -16.336748123168945
Agent0_Train_StdReturn : 20.081872940063477
Agent0_Train_MaxReturn : 31.21438217163086
Agent0_Train_MinReturn : -42.0771598815918
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 631500
Agent0_TimeSinceStart : 968.8989043235779
Agent0_Critic_Loss : 0.35685354471206665
Agent0_Actor_Loss : -0.4378851056098938
Agent0_Alpha_Loss : 0.7840607166290283
Agent0_Temperature : 0.0888509574546071
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -18.997669219970703
Agent1_Eval_StdReturn : 17.856204986572266
Agent1_Eval_MaxReturn : 17.324085235595703
Agent1_Eval_MinReturn : -42.302520751953125
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -11.85605525970459
Agent1_Train_StdReturn : 15.134965896606445
Agent1_Train_MaxReturn : 17.719812393188477
Agent1_Train_MinReturn : -39.80769348144531
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 631500
Agent1_TimeSinceStart : 971.0206816196442
Agent1_Critic_Loss : 0.3824191093444824
Agent1_Actor_Loss : -0.5684844255447388
Agent1_Alpha_Loss : 0.7877401113510132
Agent1_Temperature : 0.08886057218476848
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 421 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 422 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 423 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 424 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 425 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 426 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 427 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 428 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 429 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 430 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -9.720501899719238
Agent0_Eval_StdReturn : 17.581661224365234
Agent0_Eval_MaxReturn : 24.73849868774414
Agent0_Eval_MinReturn : -42.77692413330078
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -15.639472961425781
Agent0_Train_StdReturn : 9.1926851272583
Agent0_Train_MaxReturn : 2.408247709274292
Agent0_Train_MinReturn : -24.685691833496094
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 646500
Agent0_TimeSinceStart : 992.3293759822845
Agent0_Critic_Loss : 0.359536349773407
Agent0_Actor_Loss : -0.5480346083641052
Agent0_Alpha_Loss : 0.794967770576477
Agent0_Temperature : 0.08859926605026648
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -17.985666275024414
Agent1_Eval_StdReturn : 15.211503982543945
Agent1_Eval_MaxReturn : 15.384761810302734
Agent1_Eval_MinReturn : -35.63591384887695
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -15.754678726196289
Agent1_Train_StdReturn : 14.444207191467285
Agent1_Train_MaxReturn : 14.761960983276367
Agent1_Train_MinReturn : -29.58713150024414
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 646500
Agent1_TimeSinceStart : 994.4532468318939
Agent1_Critic_Loss : 0.4060973823070526
Agent1_Actor_Loss : -0.6632694602012634
Agent1_Alpha_Loss : 0.7819362878799438
Agent1_Temperature : 0.08861416865644443
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 431 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 432 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 433 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 434 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 435 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 436 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 437 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 438 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 439 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 440 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -16.15285301208496
Agent0_Eval_StdReturn : 14.945289611816406
Agent0_Eval_MaxReturn : 10.669755935668945
Agent0_Eval_MinReturn : -41.33992385864258
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -10.093859672546387
Agent0_Train_StdReturn : 12.055289268493652
Agent0_Train_MaxReturn : 4.1100263595581055
Agent0_Train_MinReturn : -33.594051361083984
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 661500
Agent0_TimeSinceStart : 1015.7805199623108
Agent0_Critic_Loss : 0.33811354637145996
Agent0_Actor_Loss : -0.6700525879859924
Agent0_Alpha_Loss : 0.8040476441383362
Agent0_Temperature : 0.08834801943339068
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -16.688291549682617
Agent1_Eval_StdReturn : 14.360786437988281
Agent1_Eval_MaxReturn : -0.09733033180236816
Agent1_Eval_MinReturn : -42.66958236694336
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -19.734081268310547
Agent1_Train_StdReturn : 16.484752655029297
Agent1_Train_MaxReturn : 2.9459357261657715
Agent1_Train_MinReturn : -51.64549255371094
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 661500
Agent1_TimeSinceStart : 1017.8925933837891
Agent1_Critic_Loss : 0.38777655363082886
Agent1_Actor_Loss : -0.4490404725074768
Agent1_Alpha_Loss : 0.7958188056945801
Agent1_Temperature : 0.08836603041050695
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 441 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 442 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 443 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 444 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 445 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 446 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 447 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 448 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 449 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 450 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -18.71817398071289
Agent0_Eval_StdReturn : 24.98949432373047
Agent0_Eval_MaxReturn : 27.206693649291992
Agent0_Eval_MinReturn : -65.95061492919922
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -8.136739730834961
Agent0_Train_StdReturn : 11.899829864501953
Agent0_Train_MaxReturn : 17.932201385498047
Agent0_Train_MinReturn : -26.16686248779297
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 676500
Agent0_TimeSinceStart : 1039.1847231388092
Agent0_Critic_Loss : 0.3658323585987091
Agent0_Actor_Loss : -0.5716757774353027
Agent0_Alpha_Loss : 0.7851812839508057
Agent0_Temperature : 0.08809778417335273
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -16.235851287841797
Agent1_Eval_StdReturn : 11.545921325683594
Agent1_Eval_MaxReturn : 3.9270429611206055
Agent1_Eval_MinReturn : -37.83555603027344
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -10.45598030090332
Agent1_Train_StdReturn : 17.569700241088867
Agent1_Train_MaxReturn : 11.94528579711914
Agent1_Train_MinReturn : -34.97099685668945
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 676500
Agent1_TimeSinceStart : 1041.3006007671356
Agent1_Critic_Loss : 0.32870355248451233
Agent1_Actor_Loss : -0.5762958526611328
Agent1_Alpha_Loss : 0.7899541258811951
Agent1_Temperature : 0.08811774313569137
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 451 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 452 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 453 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 454 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 455 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 456 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 457 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 458 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 459 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 460 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -17.89453125
Agent0_Eval_StdReturn : 18.630647659301758
Agent0_Eval_MaxReturn : 6.804923057556152
Agent0_Eval_MinReturn : -51.59268569946289
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -17.469364166259766
Agent0_Train_StdReturn : 16.761272430419922
Agent0_Train_MaxReturn : -0.7047944068908691
Agent0_Train_MinReturn : -59.493621826171875
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 691500
Agent0_TimeSinceStart : 1062.5590245723724
Agent0_Critic_Loss : 0.3418712913990021
Agent0_Actor_Loss : -0.5254909992218018
Agent0_Alpha_Loss : 0.7915223240852356
Agent0_Temperature : 0.08784778217283508
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -14.494775772094727
Agent1_Eval_StdReturn : 17.285531997680664
Agent1_Eval_MaxReturn : 13.237944602966309
Agent1_Eval_MinReturn : -45.240142822265625
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -8.967280387878418
Agent1_Train_StdReturn : 19.96124267578125
Agent1_Train_MaxReturn : 14.671859741210938
Agent1_Train_MinReturn : -53.49006652832031
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 691500
Agent1_TimeSinceStart : 1064.6769976615906
Agent1_Critic_Loss : 0.48649871349334717
Agent1_Actor_Loss : -0.6212393641471863
Agent1_Alpha_Loss : 0.7896752953529358
Agent1_Temperature : 0.08787011680335544
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 461 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 462 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 463 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 464 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 465 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 466 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 467 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 468 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 469 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 470 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -8.332423210144043
Agent0_Eval_StdReturn : 18.985857009887695
Agent0_Eval_MaxReturn : 8.785791397094727
Agent0_Eval_MinReturn : -59.463783264160156
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -20.649295806884766
Agent0_Train_StdReturn : 16.6437931060791
Agent0_Train_MaxReturn : 0.15791276097297668
Agent0_Train_MinReturn : -53.54070281982422
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 706500
Agent0_TimeSinceStart : 1085.917979478836
Agent0_Critic_Loss : 0.3997959494590759
Agent0_Actor_Loss : -0.6031081080436707
Agent0_Alpha_Loss : 0.7880992889404297
Agent0_Temperature : 0.08759820014441139
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -13.312332153320312
Agent1_Eval_StdReturn : 13.615640640258789
Agent1_Eval_MaxReturn : 6.56608772277832
Agent1_Eval_MinReturn : -39.286293029785156
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -13.835952758789062
Agent1_Train_StdReturn : 15.374527931213379
Agent1_Train_MaxReturn : 8.768317222595215
Agent1_Train_MinReturn : -51.09318923950195
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 706500
Agent1_TimeSinceStart : 1088.029095172882
Agent1_Critic_Loss : 0.337207555770874
Agent1_Actor_Loss : -0.5628470182418823
Agent1_Alpha_Loss : 0.7806682586669922
Agent1_Temperature : 0.08762316815399772
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 471 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 472 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 473 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 474 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 475 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 476 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 477 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 478 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 479 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 480 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -20.296253204345703
Agent0_Eval_StdReturn : 14.150328636169434
Agent0_Eval_MaxReturn : -0.7684059143066406
Agent0_Eval_MinReturn : -39.143184661865234
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -8.19139575958252
Agent0_Train_StdReturn : 14.571707725524902
Agent0_Train_MaxReturn : 16.20867156982422
Agent0_Train_MinReturn : -36.50791931152344
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 721500
Agent0_TimeSinceStart : 1109.308887720108
Agent0_Critic_Loss : 0.3565486669540405
Agent0_Actor_Loss : -0.5714972019195557
Agent0_Alpha_Loss : 0.7806117534637451
Agent0_Temperature : 0.0873494509041133
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -10.293214797973633
Agent1_Eval_StdReturn : 13.14430046081543
Agent1_Eval_MaxReturn : 13.31221866607666
Agent1_Eval_MinReturn : -41.096954345703125
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -24.558040618896484
Agent1_Train_StdReturn : 17.867481231689453
Agent1_Train_MaxReturn : -6.132192611694336
Agent1_Train_MinReturn : -71.5452880859375
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 721500
Agent1_TimeSinceStart : 1111.4193267822266
Agent1_Critic_Loss : 0.36133092641830444
Agent1_Actor_Loss : -0.53892982006073
Agent1_Alpha_Loss : 0.7825480699539185
Agent1_Temperature : 0.08737545261181455
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 481 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 482 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 483 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 484 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 485 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 486 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 487 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 488 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 489 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 490 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -26.9721736907959
Agent0_Eval_StdReturn : 27.22003936767578
Agent0_Eval_MaxReturn : 2.529693603515625
Agent0_Eval_MinReturn : -98.80030059814453
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -18.960947036743164
Agent0_Train_StdReturn : 19.746057510375977
Agent0_Train_MaxReturn : 13.651792526245117
Agent0_Train_MinReturn : -52.16978454589844
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 736500
Agent0_TimeSinceStart : 1132.8046214580536
Agent0_Critic_Loss : 0.34584298729896545
Agent0_Actor_Loss : -0.502711832523346
Agent0_Alpha_Loss : 0.7994934320449829
Agent0_Temperature : 0.08710066859367586
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -13.786158561706543
Agent1_Eval_StdReturn : 13.104702949523926
Agent1_Eval_MaxReturn : 6.125530242919922
Agent1_Eval_MinReturn : -44.78725051879883
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -19.735368728637695
Agent1_Train_StdReturn : 22.433713912963867
Agent1_Train_MaxReturn : 6.066374778747559
Agent1_Train_MinReturn : -65.20808410644531
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 736500
Agent1_TimeSinceStart : 1134.9196825027466
Agent1_Critic_Loss : 0.3232502043247223
Agent1_Actor_Loss : -0.7856799960136414
Agent1_Alpha_Loss : 0.7912164926528931
Agent1_Temperature : 0.0871269977234004
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 491 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 492 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 493 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 494 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 495 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 496 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 497 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 498 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 499 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 500 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -15.237652778625488
Agent0_Eval_StdReturn : 16.94461441040039
Agent0_Eval_MaxReturn : 10.275437355041504
Agent0_Eval_MinReturn : -49.24978256225586
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -6.125749588012695
Agent0_Train_StdReturn : 16.5716552734375
Agent0_Train_MaxReturn : 16.16585922241211
Agent0_Train_MinReturn : -39.582618713378906
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 751500
Agent0_TimeSinceStart : 1156.1782803535461
Agent0_Critic_Loss : 0.43660685420036316
Agent0_Actor_Loss : -0.4757356345653534
Agent0_Alpha_Loss : 0.7857452630996704
Agent0_Temperature : 0.08685114255339085
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -13.65434741973877
Agent1_Eval_StdReturn : 15.43779468536377
Agent1_Eval_MaxReturn : 7.170194625854492
Agent1_Eval_MinReturn : -47.518028259277344
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -13.110410690307617
Agent1_Train_StdReturn : 12.572164535522461
Agent1_Train_MaxReturn : 6.817826271057129
Agent1_Train_MinReturn : -33.68421173095703
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 751500
Agent1_TimeSinceStart : 1158.2994470596313
Agent1_Critic_Loss : 0.4470776319503784
Agent1_Actor_Loss : -0.6786742210388184
Agent1_Alpha_Loss : 0.799828052520752
Agent1_Temperature : 0.08687912338074963
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 501 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 502 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 503 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 504 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 505 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 506 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 507 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 508 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 509 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 510 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -15.971814155578613
Agent0_Eval_StdReturn : 16.757652282714844
Agent0_Eval_MaxReturn : 7.365053653717041
Agent0_Eval_MinReturn : -59.27269744873047
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -9.207478523254395
Agent0_Train_StdReturn : 16.403488159179688
Agent0_Train_MaxReturn : 31.375375747680664
Agent0_Train_MinReturn : -27.958858489990234
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 766500
Agent0_TimeSinceStart : 1179.567528963089
Agent0_Critic_Loss : 0.443951815366745
Agent0_Actor_Loss : -0.5360262393951416
Agent0_Alpha_Loss : 0.7922095656394958
Agent0_Temperature : 0.08660275211411024
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -35.503074645996094
Agent1_Eval_StdReturn : 18.144161224365234
Agent1_Eval_MaxReturn : -7.983528137207031
Agent1_Eval_MinReturn : -67.4659423828125
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -15.020672798156738
Agent1_Train_StdReturn : 19.735261917114258
Agent1_Train_MaxReturn : 2.6154518127441406
Agent1_Train_MinReturn : -67.12481689453125
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 766500
Agent1_TimeSinceStart : 1181.6838448047638
Agent1_Critic_Loss : 0.38621336221694946
Agent1_Actor_Loss : -0.5560240149497986
Agent1_Alpha_Loss : 0.7960377931594849
Agent1_Temperature : 0.0866306791394106
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 511 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 512 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 513 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 514 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 515 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 516 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 517 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 518 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 519 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 520 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -22.96804428100586
Agent0_Eval_StdReturn : 14.381937980651855
Agent0_Eval_MaxReturn : 6.5777106285095215
Agent0_Eval_MinReturn : -38.15611267089844
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -11.321078300476074
Agent0_Train_StdReturn : 11.139625549316406
Agent0_Train_MaxReturn : 2.998292922973633
Agent0_Train_MinReturn : -37.68669128417969
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 781500
Agent0_TimeSinceStart : 1202.922039270401
Agent0_Critic_Loss : 0.4701997637748718
Agent0_Actor_Loss : -0.6182149052619934
Agent0_Alpha_Loss : 0.7915887832641602
Agent0_Temperature : 0.08635463000561747
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -25.703866958618164
Agent1_Eval_StdReturn : 19.106704711914062
Agent1_Eval_MaxReturn : -8.119465827941895
Agent1_Eval_MinReturn : -74.39430236816406
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -33.107261657714844
Agent1_Train_StdReturn : 27.664600372314453
Agent1_Train_MaxReturn : 8.06783390045166
Agent1_Train_MinReturn : -72.48590087890625
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 781500
Agent1_TimeSinceStart : 1205.0256197452545
Agent1_Critic_Loss : 0.41506752371788025
Agent1_Actor_Loss : -0.590158224105835
Agent1_Alpha_Loss : 0.7954953908920288
Agent1_Temperature : 0.08638205687349108
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 521 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 522 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 523 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 524 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 525 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 526 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 527 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 528 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 529 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 530 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -15.064974784851074
Agent0_Eval_StdReturn : 11.127603530883789
Agent0_Eval_MaxReturn : 0.8607931137084961
Agent0_Eval_MinReturn : -33.805442810058594
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -13.828910827636719
Agent0_Train_StdReturn : 15.999634742736816
Agent0_Train_MaxReturn : 6.829071044921875
Agent0_Train_MinReturn : -46.15393829345703
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 796500
Agent0_TimeSinceStart : 1226.2719087600708
Agent0_Critic_Loss : 0.39476877450942993
Agent0_Actor_Loss : -0.646602988243103
Agent0_Alpha_Loss : 0.7922431230545044
Agent0_Temperature : 0.08610756498225813
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -16.59089469909668
Agent1_Eval_StdReturn : 14.643315315246582
Agent1_Eval_MaxReturn : 11.577012062072754
Agent1_Eval_MinReturn : -44.96072769165039
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -17.317636489868164
Agent1_Train_StdReturn : 25.941194534301758
Agent1_Train_MaxReturn : 21.707683563232422
Agent1_Train_MinReturn : -56.0850715637207
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 796500
Agent1_TimeSinceStart : 1228.3816900253296
Agent1_Critic_Loss : 0.44597703218460083
Agent1_Actor_Loss : -0.5065741539001465
Agent1_Alpha_Loss : 0.7901157736778259
Agent1_Temperature : 0.08613407384343053
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 531 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 532 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 533 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 534 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 535 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 536 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 537 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 538 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 539 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 540 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -25.620025634765625
Agent0_Eval_StdReturn : 25.27305793762207
Agent0_Eval_MaxReturn : 22.678247451782227
Agent0_Eval_MinReturn : -62.2039680480957
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -2.378209352493286
Agent0_Train_StdReturn : 12.554793357849121
Agent0_Train_MaxReturn : 16.686830520629883
Agent0_Train_MinReturn : -19.258464813232422
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 811500
Agent0_TimeSinceStart : 1249.6628708839417
Agent0_Critic_Loss : 0.4086218476295471
Agent0_Actor_Loss : -0.5688501596450806
Agent0_Alpha_Loss : 0.7978488206863403
Agent0_Temperature : 0.08586161554483784
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -20.781299591064453
Agent1_Eval_StdReturn : 9.207722663879395
Agent1_Eval_MaxReturn : -3.632359504699707
Agent1_Eval_MinReturn : -36.68057632446289
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -35.42045593261719
Agent1_Train_StdReturn : 18.135961532592773
Agent1_Train_MaxReturn : 3.2440085411071777
Agent1_Train_MinReturn : -60.14325714111328
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 811500
Agent1_TimeSinceStart : 1251.7812886238098
Agent1_Critic_Loss : 0.6915026903152466
Agent1_Actor_Loss : -0.6919418573379517
Agent1_Alpha_Loss : 0.787150502204895
Agent1_Temperature : 0.08588686836562825
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 541 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 542 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 543 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 544 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 545 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 546 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 547 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 548 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 549 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 550 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -32.34202194213867
Agent0_Eval_StdReturn : 22.101709365844727
Agent0_Eval_MaxReturn : 7.059003829956055
Agent0_Eval_MinReturn : -62.01729965209961
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -12.287359237670898
Agent0_Train_StdReturn : 18.83169174194336
Agent0_Train_MaxReturn : 14.231830596923828
Agent0_Train_MinReturn : -46.80339050292969
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 826500
Agent0_TimeSinceStart : 1273.062807559967
Agent0_Critic_Loss : 0.42024892568588257
Agent0_Actor_Loss : -0.5597076416015625
Agent0_Alpha_Loss : 0.7963374257087708
Agent0_Temperature : 0.0856151337962625
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -25.848724365234375
Agent1_Eval_StdReturn : 20.928709030151367
Agent1_Eval_MaxReturn : 10.280214309692383
Agent1_Eval_MinReturn : -60.84492492675781
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -14.39128303527832
Agent1_Train_StdReturn : 13.61208438873291
Agent1_Train_MaxReturn : 7.050969123840332
Agent1_Train_MinReturn : -31.83637237548828
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 826500
Agent1_TimeSinceStart : 1275.1707298755646
Agent1_Critic_Loss : 0.529310941696167
Agent1_Actor_Loss : -0.6276315450668335
Agent1_Alpha_Loss : 0.7816053628921509
Agent1_Temperature : 0.08564209162945499
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 551 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 552 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 553 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 554 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 555 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 556 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 557 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 558 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 559 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 560 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -12.484884262084961
Agent0_Eval_StdReturn : 21.396221160888672
Agent0_Eval_MaxReturn : 24.040904998779297
Agent0_Eval_MinReturn : -42.83885192871094
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -13.527908325195312
Agent0_Train_StdReturn : 9.398762702941895
Agent0_Train_MaxReturn : -0.8634824752807617
Agent0_Train_MinReturn : -34.20330047607422
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 841500
Agent0_TimeSinceStart : 1296.4972803592682
Agent0_Critic_Loss : 0.5253984928131104
Agent0_Actor_Loss : -0.5028151273727417
Agent0_Alpha_Loss : 0.7963211536407471
Agent0_Temperature : 0.08536950015580727
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -29.271503448486328
Agent1_Eval_StdReturn : 15.711421012878418
Agent1_Eval_MaxReturn : 1.366750717163086
Agent1_Eval_MinReturn : -52.86723327636719
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -11.593932151794434
Agent1_Train_StdReturn : 11.63668155670166
Agent1_Train_MaxReturn : 12.093856811523438
Agent1_Train_MinReturn : -23.85800552368164
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 841500
Agent1_TimeSinceStart : 1298.6185162067413
Agent1_Critic_Loss : 0.4778120517730713
Agent1_Actor_Loss : -0.7811667323112488
Agent1_Alpha_Loss : 0.7839361429214478
Agent1_Temperature : 0.08539901096532972
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 561 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 562 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 563 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 564 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 565 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 566 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 567 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 568 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 569 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 570 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -2.8857905864715576
Agent0_Eval_StdReturn : 16.45833396911621
Agent0_Eval_MaxReturn : 23.10932731628418
Agent0_Eval_MinReturn : -25.10063934326172
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -7.851675987243652
Agent0_Train_StdReturn : 20.186731338500977
Agent0_Train_MaxReturn : 21.374069213867188
Agent0_Train_MinReturn : -38.509490966796875
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 856500
Agent0_TimeSinceStart : 1319.899765253067
Agent0_Critic_Loss : 0.5747071504592896
Agent0_Actor_Loss : -0.5751829147338867
Agent0_Alpha_Loss : 0.7993736267089844
Agent0_Temperature : 0.08512352634156915
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -15.264880180358887
Agent1_Eval_StdReturn : 14.097529411315918
Agent1_Eval_MaxReturn : 7.58270263671875
Agent1_Eval_MinReturn : -41.956512451171875
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -13.663989067077637
Agent1_Train_StdReturn : 12.466405868530273
Agent1_Train_MaxReturn : 7.0241241455078125
Agent1_Train_MinReturn : -30.879980087280273
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 856500
Agent1_TimeSinceStart : 1322.0279095172882
Agent1_Critic_Loss : 0.44440239667892456
Agent1_Actor_Loss : -0.6271694898605347
Agent1_Alpha_Loss : 0.7543730735778809
Agent1_Temperature : 0.08515836487789404
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 571 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 572 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 573 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 574 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 575 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 576 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 577 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 578 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 579 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 580 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -22.789154052734375
Agent0_Eval_StdReturn : 12.962625503540039
Agent0_Eval_MaxReturn : -4.278965950012207
Agent0_Eval_MinReturn : -43.74451446533203
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -10.081528663635254
Agent0_Train_StdReturn : 13.350142478942871
Agent0_Train_MaxReturn : 10.904486656188965
Agent0_Train_MinReturn : -32.05449676513672
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 871500
Agent0_TimeSinceStart : 1343.3374390602112
Agent0_Critic_Loss : 0.4891481101512909
Agent0_Actor_Loss : -0.783216118812561
Agent0_Alpha_Loss : 0.7976452112197876
Agent0_Temperature : 0.08487682255726565
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -16.96377944946289
Agent1_Eval_StdReturn : 15.702855110168457
Agent1_Eval_MaxReturn : 7.968247890472412
Agent1_Eval_MinReturn : -49.332130432128906
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -17.262659072875977
Agent1_Train_StdReturn : 15.688736915588379
Agent1_Train_MaxReturn : 4.465647220611572
Agent1_Train_MinReturn : -49.25847625732422
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 871500
Agent1_TimeSinceStart : 1345.4642584323883
Agent1_Critic_Loss : 0.517041802406311
Agent1_Actor_Loss : -0.5118658542633057
Agent1_Alpha_Loss : 0.7394821643829346
Agent1_Temperature : 0.08492143247900079
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 581 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 582 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 583 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 584 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 585 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 586 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 587 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 588 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 589 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 590 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -16.216327667236328
Agent0_Eval_StdReturn : 15.452786445617676
Agent0_Eval_MaxReturn : 0.07794523239135742
Agent0_Eval_MinReturn : -42.26994705200195
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -14.482833862304688
Agent0_Train_StdReturn : 17.254880905151367
Agent0_Train_MaxReturn : 6.645758628845215
Agent0_Train_MinReturn : -43.56011199951172
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 886500
Agent0_TimeSinceStart : 1366.8099055290222
Agent0_Critic_Loss : 0.5983138680458069
Agent0_Actor_Loss : -0.6843633651733398
Agent0_Alpha_Loss : 0.797383189201355
Agent0_Temperature : 0.08463133014518291
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -18.36930274963379
Agent1_Eval_StdReturn : 10.780479431152344
Agent1_Eval_MaxReturn : 2.9481630325317383
Agent1_Eval_MinReturn : -36.35014724731445
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -11.44288444519043
Agent1_Train_StdReturn : 8.07148265838623
Agent1_Train_MaxReturn : 1.1829633712768555
Agent1_Train_MinReturn : -26.394916534423828
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 886500
Agent1_TimeSinceStart : 1368.9478583335876
Agent1_Critic_Loss : 0.634239137172699
Agent1_Actor_Loss : -0.7740403413772583
Agent1_Alpha_Loss : 0.7513232827186584
Agent1_Temperature : 0.08468704497907163
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 591 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 592 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 593 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 594 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 595 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 596 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 597 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 598 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 599 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 600 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -7.841470241546631
Agent0_Eval_StdReturn : 16.461633682250977
Agent0_Eval_MaxReturn : 26.994646072387695
Agent0_Eval_MinReturn : -38.02934265136719
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -15.901098251342773
Agent0_Train_StdReturn : 26.141551971435547
Agent0_Train_MaxReturn : 16.94432830810547
Agent0_Train_MinReturn : -77.76029968261719
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 901500
Agent0_TimeSinceStart : 1390.4827971458435
Agent0_Critic_Loss : 0.5191825032234192
Agent0_Actor_Loss : -0.579664945602417
Agent0_Alpha_Loss : 0.7867361307144165
Agent0_Temperature : 0.08438709398318747
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -16.972314834594727
Agent1_Eval_StdReturn : 15.550799369812012
Agent1_Eval_MaxReturn : 14.737915992736816
Agent1_Eval_MinReturn : -42.6563720703125
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -22.832073211669922
Agent1_Train_StdReturn : 15.602899551391602
Agent1_Train_MaxReturn : -0.35248279571533203
Agent1_Train_MinReturn : -45.577667236328125
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 901500
Agent1_TimeSinceStart : 1392.618215084076
Agent1_Critic_Loss : 0.4447370767593384
Agent1_Actor_Loss : -0.6374155282974243
Agent1_Alpha_Loss : 0.7465195655822754
Agent1_Temperature : 0.08445460239151484
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 601 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 602 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 603 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 604 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 605 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 606 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 607 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 608 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 609 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 610 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -8.66118049621582
Agent0_Eval_StdReturn : 14.430651664733887
Agent0_Eval_MaxReturn : 7.831181526184082
Agent0_Eval_MinReturn : -39.9301872253418
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -5.690924167633057
Agent0_Train_StdReturn : 13.138993263244629
Agent0_Train_MaxReturn : 17.262332916259766
Agent0_Train_MinReturn : -30.117115020751953
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 916500
Agent0_TimeSinceStart : 1414.0204560756683
Agent0_Critic_Loss : 0.4393913149833679
Agent0_Actor_Loss : -0.7124022841453552
Agent0_Alpha_Loss : 0.7909284234046936
Agent0_Temperature : 0.08414404102029696
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -18.9953670501709
Agent1_Eval_StdReturn : 14.244745254516602
Agent1_Eval_MaxReturn : 14.675501823425293
Agent1_Eval_MinReturn : -37.88825225830078
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -12.522345542907715
Agent1_Train_StdReturn : 9.072115898132324
Agent1_Train_MaxReturn : 2.069550037384033
Agent1_Train_MinReturn : -28.636262893676758
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 916500
Agent1_TimeSinceStart : 1416.1479094028473
Agent1_Critic_Loss : 0.43216055631637573
Agent1_Actor_Loss : -0.6610205173492432
Agent1_Alpha_Loss : 0.7432957887649536
Agent1_Temperature : 0.08422374998571135
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 611 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 612 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 613 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 614 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 615 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 616 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 617 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 618 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 619 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 620 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -10.84858512878418
Agent0_Eval_StdReturn : 18.26580047607422
Agent0_Eval_MaxReturn : 27.31088638305664
Agent0_Eval_MinReturn : -34.639892578125
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -14.317453384399414
Agent0_Train_StdReturn : 14.396919250488281
Agent0_Train_MaxReturn : 9.48522663116455
Agent0_Train_MinReturn : -40.00347900390625
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 931500
Agent0_TimeSinceStart : 1437.5712575912476
Agent0_Critic_Loss : 0.5058703422546387
Agent0_Actor_Loss : -0.7368254661560059
Agent0_Alpha_Loss : 0.7747635841369629
Agent0_Temperature : 0.08390229872266647
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -16.750455856323242
Agent1_Eval_StdReturn : 14.340750694274902
Agent1_Eval_MaxReturn : 0.25082921981811523
Agent1_Eval_MinReturn : -45.74446105957031
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -20.05385971069336
Agent1_Train_StdReturn : 12.090439796447754
Agent1_Train_MaxReturn : 0.11142539978027344
Agent1_Train_MinReturn : -34.519683837890625
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 931500
Agent1_TimeSinceStart : 1439.6957042217255
Agent1_Critic_Loss : 0.46012094616889954
Agent1_Actor_Loss : -0.6188565492630005
Agent1_Alpha_Loss : 0.7351322174072266
Agent1_Temperature : 0.08399309447351105
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 621 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 622 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 623 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 624 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 625 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 626 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 627 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 628 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 629 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 630 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -23.33216094970703
Agent0_Eval_StdReturn : 15.606898307800293
Agent0_Eval_MaxReturn : -1.0865821838378906
Agent0_Eval_MinReturn : -53.7294921875
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -25.525836944580078
Agent0_Train_StdReturn : 17.956605911254883
Agent0_Train_MaxReturn : 0.06566810607910156
Agent0_Train_MinReturn : -59.50785827636719
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 946500
Agent0_TimeSinceStart : 1461.0729928016663
Agent0_Critic_Loss : 0.5099753737449646
Agent0_Actor_Loss : -0.7467824816703796
Agent0_Alpha_Loss : 0.768416166305542
Agent0_Temperature : 0.08366179205383778
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -15.571965217590332
Agent1_Eval_StdReturn : 9.067418098449707
Agent1_Eval_MaxReturn : -0.8077211380004883
Agent1_Eval_MinReturn : -28.41400718688965
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -22.141109466552734
Agent1_Train_StdReturn : 19.667924880981445
Agent1_Train_MaxReturn : 6.9920454025268555
Agent1_Train_MinReturn : -60.79118347167969
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 946500
Agent1_TimeSinceStart : 1463.1989579200745
Agent1_Critic_Loss : 0.5699690580368042
Agent1_Actor_Loss : -0.5850486755371094
Agent1_Alpha_Loss : 0.7488493323326111
Agent1_Temperature : 0.08376250182574266
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 631 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 632 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 633 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 634 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 635 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 636 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 637 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 638 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 639 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 640 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -13.34253215789795
Agent0_Eval_StdReturn : 18.457189559936523
Agent0_Eval_MaxReturn : 12.473712921142578
Agent0_Eval_MinReturn : -60.345890045166016
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -21.086694717407227
Agent0_Train_StdReturn : 13.880529403686523
Agent0_Train_MaxReturn : 2.33331298828125
Agent0_Train_MinReturn : -35.09620666503906
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 961500
Agent0_TimeSinceStart : 1484.5206997394562
Agent0_Critic_Loss : 0.4103240370750427
Agent0_Actor_Loss : -0.7221051454544067
Agent0_Alpha_Loss : 0.7833635807037354
Agent0_Temperature : 0.0834224687387432
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -12.580370903015137
Agent1_Eval_StdReturn : 15.10409164428711
Agent1_Eval_MaxReturn : 9.802249908447266
Agent1_Eval_MinReturn : -47.24549865722656
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -11.917354583740234
Agent1_Train_StdReturn : 14.205092430114746
Agent1_Train_MaxReturn : 22.6897029876709
Agent1_Train_MinReturn : -28.367076873779297
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 961500
Agent1_TimeSinceStart : 1486.647428035736
Agent1_Critic_Loss : 0.6208828687667847
Agent1_Actor_Loss : -0.5897115468978882
Agent1_Alpha_Loss : 0.7505300045013428
Agent1_Temperature : 0.08353200658605536
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 641 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 642 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 643 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 644 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 645 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 646 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 647 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 648 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 649 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 650 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -11.19360065460205
Agent0_Eval_StdReturn : 15.930548667907715
Agent0_Eval_MaxReturn : 13.723873138427734
Agent0_Eval_MinReturn : -35.62041473388672
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -19.5264892578125
Agent0_Train_StdReturn : 17.455280303955078
Agent0_Train_MaxReturn : 2.058140277862549
Agent0_Train_MinReturn : -56.74843978881836
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 976500
Agent0_TimeSinceStart : 1508.0115756988525
Agent0_Critic_Loss : 0.4802672863006592
Agent0_Actor_Loss : -0.6871686577796936
Agent0_Alpha_Loss : 0.7703127861022949
Agent0_Temperature : 0.08318447068293738
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -7.6240386962890625
Agent1_Eval_StdReturn : 15.554420471191406
Agent1_Eval_MaxReturn : 29.366817474365234
Agent1_Eval_MinReturn : -27.886714935302734
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -20.110431671142578
Agent1_Train_StdReturn : 17.263334274291992
Agent1_Train_MaxReturn : 5.89833927154541
Agent1_Train_MinReturn : -49.49818420410156
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 976500
Agent1_TimeSinceStart : 1510.1334319114685
Agent1_Critic_Loss : 0.44936877489089966
Agent1_Actor_Loss : -0.6949562430381775
Agent1_Alpha_Loss : 0.758205771446228
Agent1_Temperature : 0.08330103317387855
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 651 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 652 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 653 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 654 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 655 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 656 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 657 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 658 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 659 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 660 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -10.791821479797363
Agent0_Eval_StdReturn : 17.50000762939453
Agent0_Eval_MaxReturn : 23.00190544128418
Agent0_Eval_MinReturn : -41.81275177001953
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -6.205528259277344
Agent0_Train_StdReturn : 23.84868812561035
Agent0_Train_MaxReturn : 48.6168212890625
Agent0_Train_MinReturn : -47.221893310546875
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 991500
Agent0_TimeSinceStart : 1531.4879143238068
Agent0_Critic_Loss : 0.5220114588737488
Agent0_Actor_Loss : -0.6477996110916138
Agent0_Alpha_Loss : 0.7802212238311768
Agent0_Temperature : 0.08294775631163959
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -15.202618598937988
Agent1_Eval_StdReturn : 12.215559959411621
Agent1_Eval_MaxReturn : 2.8898701667785645
Agent1_Eval_MinReturn : -42.357967376708984
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -24.966373443603516
Agent1_Train_StdReturn : 20.161170959472656
Agent1_Train_MaxReturn : 8.279767036437988
Agent1_Train_MinReturn : -53.268497467041016
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 991500
Agent1_TimeSinceStart : 1533.6024208068848
Agent1_Critic_Loss : 0.4853271245956421
Agent1_Actor_Loss : -0.7608102560043335
Agent1_Alpha_Loss : 0.7608060240745544
Agent1_Temperature : 0.08306877151913679
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 661 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 662 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 663 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 664 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 665 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 666 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 667 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 668 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 669 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 670 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -6.440576076507568
Agent0_Eval_StdReturn : 12.22825813293457
Agent0_Eval_MaxReturn : 16.609663009643555
Agent0_Eval_MinReturn : -25.39291000366211
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -11.498576164245605
Agent0_Train_StdReturn : 13.528006553649902
Agent0_Train_MaxReturn : 11.869964599609375
Agent0_Train_MinReturn : -36.52655792236328
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1006500
Agent0_TimeSinceStart : 1554.9389612674713
Agent0_Critic_Loss : 0.6629723310470581
Agent0_Actor_Loss : -0.5861366987228394
Agent0_Alpha_Loss : 0.7695485353469849
Agent0_Temperature : 0.08271300643536018
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -15.16392993927002
Agent1_Eval_StdReturn : 29.6558837890625
Agent1_Eval_MaxReturn : 9.937274932861328
Agent1_Eval_MinReturn : -87.18919372558594
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -11.049468994140625
Agent1_Train_StdReturn : 16.489337921142578
Agent1_Train_MaxReturn : 12.732585906982422
Agent1_Train_MinReturn : -40.86761474609375
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1006500
Agent1_TimeSinceStart : 1557.0592052936554
Agent1_Critic_Loss : 0.4095708429813385
Agent1_Actor_Loss : -0.7162833213806152
Agent1_Alpha_Loss : 0.7713409066200256
Agent1_Temperature : 0.08283469989273193
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 671 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 672 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 673 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 674 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 675 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 676 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 677 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 678 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 679 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 680 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -8.467641830444336
Agent0_Eval_StdReturn : 9.336271286010742
Agent0_Eval_MaxReturn : 6.4219183921813965
Agent0_Eval_MinReturn : -20.414770126342773
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -17.885425567626953
Agent0_Train_StdReturn : 13.642309188842773
Agent0_Train_MaxReturn : -6.731997489929199
Agent0_Train_MinReturn : -45.19118118286133
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1021500
Agent0_TimeSinceStart : 1578.440022468567
Agent0_Critic_Loss : 0.6375986337661743
Agent0_Actor_Loss : -0.7273605465888977
Agent0_Alpha_Loss : 0.7622085809707642
Agent0_Temperature : 0.08248035154370366
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -19.423831939697266
Agent1_Eval_StdReturn : 13.841111183166504
Agent1_Eval_MaxReturn : 0.7421624660491943
Agent1_Eval_MinReturn : -48.530189514160156
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -17.369417190551758
Agent1_Train_StdReturn : 16.91293716430664
Agent1_Train_MaxReturn : 5.244499206542969
Agent1_Train_MinReturn : -50.23974609375
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1021500
Agent1_TimeSinceStart : 1580.5551009178162
Agent1_Critic_Loss : 0.4827311635017395
Agent1_Actor_Loss : -0.7122905254364014
Agent1_Alpha_Loss : 0.781387448310852
Agent1_Temperature : 0.08259882817714016
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 681 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 682 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 683 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 684 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 685 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 686 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 687 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 688 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 689 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 690 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -12.538536071777344
Agent0_Eval_StdReturn : 14.833117485046387
Agent0_Eval_MaxReturn : 10.969046592712402
Agent0_Eval_MinReturn : -37.62710189819336
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -10.322945594787598
Agent0_Train_StdReturn : 14.480172157287598
Agent0_Train_MaxReturn : 23.946306228637695
Agent0_Train_MinReturn : -32.31199645996094
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1036500
Agent0_TimeSinceStart : 1601.922523021698
Agent0_Critic_Loss : 0.5178655385971069
Agent0_Actor_Loss : -0.6749753355979919
Agent0_Alpha_Loss : 0.759323239326477
Agent0_Temperature : 0.08224901038621463
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -6.122828483581543
Agent1_Eval_StdReturn : 21.350025177001953
Agent1_Eval_MaxReturn : 40.747161865234375
Agent1_Eval_MinReturn : -35.504722595214844
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -17.561124801635742
Agent1_Train_StdReturn : 25.036561965942383
Agent1_Train_MaxReturn : 23.646427154541016
Agent1_Train_MinReturn : -52.61623764038086
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1036500
Agent1_TimeSinceStart : 1604.0449655056
Agent1_Critic_Loss : 0.5222713351249695
Agent1_Actor_Loss : -0.7123814225196838
Agent1_Alpha_Loss : 0.7791756987571716
Agent1_Temperature : 0.08236278311574836
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 691 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 692 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 693 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 694 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 695 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 696 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 697 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 698 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 699 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 700 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -18.122779846191406
Agent0_Eval_StdReturn : 13.538463592529297
Agent0_Eval_MaxReturn : -3.647662878036499
Agent0_Eval_MinReturn : -43.501564025878906
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -15.775967597961426
Agent0_Train_StdReturn : 14.939800262451172
Agent0_Train_MaxReturn : 3.1044840812683105
Agent0_Train_MinReturn : -43.880287170410156
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1051500
Agent0_TimeSinceStart : 1625.3370661735535
Agent0_Critic_Loss : 0.5614727735519409
Agent0_Actor_Loss : -0.644767165184021
Agent0_Alpha_Loss : 0.7634012699127197
Agent0_Temperature : 0.08201838399906515
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -17.339765548706055
Agent1_Eval_StdReturn : 24.685762405395508
Agent1_Eval_MaxReturn : 15.891656875610352
Agent1_Eval_MinReturn : -53.52412796020508
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -10.879220962524414
Agent1_Train_StdReturn : 19.84909439086914
Agent1_Train_MaxReturn : 17.77328109741211
Agent1_Train_MinReturn : -42.7299919128418
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1051500
Agent1_TimeSinceStart : 1627.451131105423
Agent1_Critic_Loss : 0.4366590678691864
Agent1_Actor_Loss : -0.6171002984046936
Agent1_Alpha_Loss : 0.7776542901992798
Agent1_Temperature : 0.08212703080048003
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 701 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 702 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 703 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 704 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 705 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 706 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 707 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 708 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 709 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 710 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -21.996746063232422
Agent0_Eval_StdReturn : 17.606260299682617
Agent0_Eval_MaxReturn : 4.394181251525879
Agent0_Eval_MinReturn : -58.89968490600586
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -11.727747917175293
Agent0_Train_StdReturn : 14.81747817993164
Agent0_Train_MaxReturn : 2.769383192062378
Agent0_Train_MinReturn : -48.72863006591797
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1066500
Agent0_TimeSinceStart : 1648.7283947467804
Agent0_Critic_Loss : 0.45605170726776123
Agent0_Actor_Loss : -0.6465818285942078
Agent0_Alpha_Loss : 0.7511382102966309
Agent0_Temperature : 0.08178741589883698
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -23.849285125732422
Agent1_Eval_StdReturn : 19.116065979003906
Agent1_Eval_MaxReturn : 6.322566986083984
Agent1_Eval_MinReturn : -46.122554779052734
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -18.930782318115234
Agent1_Train_StdReturn : 16.592266082763672
Agent1_Train_MaxReturn : 2.8231899738311768
Agent1_Train_MinReturn : -53.88099670410156
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1066500
Agent1_TimeSinceStart : 1650.8410713672638
Agent1_Critic_Loss : 0.45628565549850464
Agent1_Actor_Loss : -0.6274500489234924
Agent1_Alpha_Loss : 0.7683842182159424
Agent1_Temperature : 0.08189149432154486
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 711 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 712 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 713 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 714 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 715 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 716 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 717 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 718 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 719 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 720 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -15.169512748718262
Agent0_Eval_StdReturn : 17.50234031677246
Agent0_Eval_MaxReturn : 13.708824157714844
Agent0_Eval_MinReturn : -53.427268981933594
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -9.282407760620117
Agent0_Train_StdReturn : 15.226466178894043
Agent0_Train_MaxReturn : 17.392513275146484
Agent0_Train_MinReturn : -37.06302261352539
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1081500
Agent0_TimeSinceStart : 1672.0943038463593
Agent0_Critic_Loss : 0.4544791877269745
Agent0_Actor_Loss : -0.7064581513404846
Agent0_Alpha_Loss : 0.7532625794410706
Agent0_Temperature : 0.08155714266712087
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -27.198461532592773
Agent1_Eval_StdReturn : 36.372901916503906
Agent1_Eval_MaxReturn : 14.726040840148926
Agent1_Eval_MinReturn : -99.70405578613281
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -12.23108959197998
Agent1_Train_StdReturn : 15.866654396057129
Agent1_Train_MaxReturn : 14.472549438476562
Agent1_Train_MinReturn : -41.048072814941406
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1081500
Agent1_TimeSinceStart : 1674.2022433280945
Agent1_Critic_Loss : 0.5384163856506348
Agent1_Actor_Loss : -0.8484556674957275
Agent1_Alpha_Loss : 0.7560931444168091
Agent1_Temperature : 0.08165607234690493
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 721 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 722 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 723 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 724 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 725 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 726 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 727 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 728 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 729 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 730 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -15.539300918579102
Agent0_Eval_StdReturn : 11.405712127685547
Agent0_Eval_MaxReturn : 1.298479437828064
Agent0_Eval_MinReturn : -43.455814361572266
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -0.16568851470947266
Agent0_Train_StdReturn : 15.55759334564209
Agent0_Train_MaxReturn : 29.954158782958984
Agent0_Train_MinReturn : -29.248046875
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1096500
Agent0_TimeSinceStart : 1695.533046722412
Agent0_Critic_Loss : 0.48350057005882263
Agent0_Actor_Loss : -0.6789775490760803
Agent0_Alpha_Loss : 0.7518587708473206
Agent0_Temperature : 0.08132780111835694
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -16.420854568481445
Agent1_Eval_StdReturn : 21.304719924926758
Agent1_Eval_MaxReturn : 17.08386993408203
Agent1_Eval_MinReturn : -63.01170349121094
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -19.00188636779785
Agent1_Train_StdReturn : 15.743940353393555
Agent1_Train_MaxReturn : 4.015966415405273
Agent1_Train_MinReturn : -49.17552947998047
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1096500
Agent1_TimeSinceStart : 1697.6413552761078
Agent1_Critic_Loss : 0.633712649345398
Agent1_Actor_Loss : -0.8166463375091553
Agent1_Alpha_Loss : 0.7636439800262451
Agent1_Temperature : 0.08142149217115693
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 731 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 732 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 733 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 734 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 735 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 736 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 737 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 738 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 739 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 740 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -16.8717041015625
Agent0_Eval_StdReturn : 12.620537757873535
Agent0_Eval_MaxReturn : 4.564884185791016
Agent0_Eval_MinReturn : -32.783042907714844
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -6.631211757659912
Agent0_Train_StdReturn : 13.224653244018555
Agent0_Train_MaxReturn : 14.947166442871094
Agent0_Train_MinReturn : -29.921405792236328
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1111500
Agent0_TimeSinceStart : 1718.8740329742432
Agent0_Critic_Loss : 0.5901875495910645
Agent0_Actor_Loss : -0.655962347984314
Agent0_Alpha_Loss : 0.7561516761779785
Agent0_Temperature : 0.08109928420499973
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -11.436797142028809
Agent1_Eval_StdReturn : 23.029836654663086
Agent1_Eval_MaxReturn : 28.07135581970215
Agent1_Eval_MinReturn : -63.412105560302734
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -13.451135635375977
Agent1_Train_StdReturn : 20.65577507019043
Agent1_Train_MaxReturn : 24.24252700805664
Agent1_Train_MinReturn : -50.63579559326172
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1111500
Agent1_TimeSinceStart : 1720.9784581661224
Agent1_Critic_Loss : 0.49121585488319397
Agent1_Actor_Loss : -0.8017423152923584
Agent1_Alpha_Loss : 0.7733007669448853
Agent1_Temperature : 0.08118713198401298
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 741 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 742 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 743 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 744 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 745 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 746 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 747 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 748 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 749 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 750 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -8.42000675201416
Agent0_Eval_StdReturn : 12.426454544067383
Agent0_Eval_MaxReturn : 10.963292121887207
Agent0_Eval_MinReturn : -24.230464935302734
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -16.443866729736328
Agent0_Train_StdReturn : 10.264244079589844
Agent0_Train_MaxReturn : 2.9169671535491943
Agent0_Train_MinReturn : -35.63247299194336
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1126500
Agent0_TimeSinceStart : 1742.2636406421661
Agent0_Critic_Loss : 0.5134709477424622
Agent0_Actor_Loss : -0.7467735409736633
Agent0_Alpha_Loss : 0.7539827823638916
Agent0_Temperature : 0.08087149731162638
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -18.37026596069336
Agent1_Eval_StdReturn : 23.65644645690918
Agent1_Eval_MaxReturn : 10.99044132232666
Agent1_Eval_MinReturn : -54.62868118286133
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -18.623126983642578
Agent1_Train_StdReturn : 15.848087310791016
Agent1_Train_MaxReturn : 10.82720947265625
Agent1_Train_MinReturn : -51.15226364135742
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1126500
Agent1_TimeSinceStart : 1744.3700876235962
Agent1_Critic_Loss : 0.7656859755516052
Agent1_Actor_Loss : -0.7474914789199829
Agent1_Alpha_Loss : 0.7772432565689087
Agent1_Temperature : 0.08095361556062222
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 751 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 752 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 753 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 754 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 755 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 756 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 757 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 758 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 759 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 760 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -12.863726615905762
Agent0_Eval_StdReturn : 12.948776245117188
Agent0_Eval_MaxReturn : 13.196874618530273
Agent0_Eval_MinReturn : -34.39454650878906
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -15.092915534973145
Agent0_Train_StdReturn : 21.76633644104004
Agent0_Train_MaxReturn : 12.508588790893555
Agent0_Train_MinReturn : -57.921226501464844
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1141500
Agent0_TimeSinceStart : 1765.7042939662933
Agent0_Critic_Loss : 0.5318242311477661
Agent0_Actor_Loss : -0.7804426550865173
Agent0_Alpha_Loss : 0.7723991870880127
Agent0_Temperature : 0.08064460383354705
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -7.017946720123291
Agent1_Eval_StdReturn : 19.26467514038086
Agent1_Eval_MaxReturn : 39.01436233520508
Agent1_Eval_MinReturn : -30.414785385131836
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -36.614566802978516
Agent1_Train_StdReturn : 21.317546844482422
Agent1_Train_MaxReturn : -4.540079116821289
Agent1_Train_MinReturn : -74.05452728271484
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1141500
Agent1_TimeSinceStart : 1767.8160135746002
Agent1_Critic_Loss : 0.9315478801727295
Agent1_Actor_Loss : -0.7414970993995667
Agent1_Alpha_Loss : 0.7642977237701416
Agent1_Temperature : 0.0807207532129493
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 761 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 762 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 763 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 764 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 765 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 766 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 767 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 768 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 769 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 770 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -13.89140510559082
Agent0_Eval_StdReturn : 13.882332801818848
Agent0_Eval_MaxReturn : 3.9478845596313477
Agent0_Eval_MinReturn : -33.96921920776367
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -14.457748413085938
Agent0_Train_StdReturn : 21.440752029418945
Agent0_Train_MaxReturn : 17.793041229248047
Agent0_Train_MinReturn : -51.39524841308594
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1156500
Agent0_TimeSinceStart : 1789.1679606437683
Agent0_Critic_Loss : 0.4828040897846222
Agent0_Actor_Loss : -0.6857547760009766
Agent0_Alpha_Loss : 0.7618672847747803
Agent0_Temperature : 0.08041730498105427
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -8.450464248657227
Agent1_Eval_StdReturn : 22.540552139282227
Agent1_Eval_MaxReturn : 27.514631271362305
Agent1_Eval_MinReturn : -57.33772659301758
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -17.640186309814453
Agent1_Train_StdReturn : 15.155695915222168
Agent1_Train_MaxReturn : 2.525188446044922
Agent1_Train_MinReturn : -41.57296371459961
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1156500
Agent1_TimeSinceStart : 1791.2909893989563
Agent1_Critic_Loss : 1.1117162704467773
Agent1_Actor_Loss : -0.6393736600875854
Agent1_Alpha_Loss : 0.762566089630127
Agent1_Temperature : 0.08048969497298482
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 771 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 772 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 773 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 774 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 775 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 776 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 777 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 778 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 779 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 780 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -2.053454637527466
Agent0_Eval_StdReturn : 21.4679012298584
Agent0_Eval_MaxReturn : 40.36792755126953
Agent0_Eval_MinReturn : -30.164941787719727
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -11.338749885559082
Agent0_Train_StdReturn : 11.115272521972656
Agent0_Train_MaxReturn : 13.643491744995117
Agent0_Train_MinReturn : -33.60273742675781
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1171500
Agent0_TimeSinceStart : 1812.6604821681976
Agent0_Critic_Loss : 0.5063446164131165
Agent0_Actor_Loss : -0.6124482154846191
Agent0_Alpha_Loss : 0.7552692890167236
Agent0_Temperature : 0.08018995810276162
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -13.91026782989502
Agent1_Eval_StdReturn : 15.3272123336792
Agent1_Eval_MaxReturn : 10.97376823425293
Agent1_Eval_MinReturn : -42.120025634765625
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -14.865432739257812
Agent1_Train_StdReturn : 14.872917175292969
Agent1_Train_MaxReturn : 3.602250099182129
Agent1_Train_MinReturn : -47.951820373535156
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1171500
Agent1_TimeSinceStart : 1814.7895941734314
Agent1_Critic_Loss : 0.608254075050354
Agent1_Actor_Loss : -0.6139170527458191
Agent1_Alpha_Loss : 0.7495406270027161
Agent1_Temperature : 0.08026071187957456
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 781 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 782 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 783 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 784 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 785 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 786 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 787 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 788 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 789 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 790 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -19.582420349121094
Agent0_Eval_StdReturn : 37.10621643066406
Agent0_Eval_MaxReturn : 32.39827346801758
Agent0_Eval_MinReturn : -103.69652557373047
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -11.863649368286133
Agent0_Train_StdReturn : 22.827238082885742
Agent0_Train_MaxReturn : 20.797515869140625
Agent0_Train_MinReturn : -47.504844665527344
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1186500
Agent0_TimeSinceStart : 1836.1131327152252
Agent0_Critic_Loss : 0.5630289912223816
Agent0_Actor_Loss : -0.7343184351921082
Agent0_Alpha_Loss : 0.7600172758102417
Agent0_Temperature : 0.07996308982202621
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -7.43402099609375
Agent1_Eval_StdReturn : 13.052010536193848
Agent1_Eval_MaxReturn : 15.851608276367188
Agent1_Eval_MinReturn : -23.976049423217773
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -13.447372436523438
Agent1_Train_StdReturn : 13.690320014953613
Agent1_Train_MaxReturn : 4.85615348815918
Agent1_Train_MinReturn : -44.96314239501953
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1186500
Agent1_TimeSinceStart : 1838.24493932724
Agent1_Critic_Loss : 0.9639801383018494
Agent1_Actor_Loss : -0.7372862100601196
Agent1_Alpha_Loss : 0.7362161874771118
Agent1_Temperature : 0.08003450581165326
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 791 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 792 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 793 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 794 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 795 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 796 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 797 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 798 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 799 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 800 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -22.413223266601562
Agent0_Eval_StdReturn : 17.73639678955078
Agent0_Eval_MaxReturn : 4.131196975708008
Agent0_Eval_MinReturn : -51.9211311340332
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -17.390621185302734
Agent0_Train_StdReturn : 11.509300231933594
Agent0_Train_MaxReturn : 3.1821422576904297
Agent0_Train_MinReturn : -32.8302001953125
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1201500
Agent0_TimeSinceStart : 1859.6564598083496
Agent0_Critic_Loss : 0.5408133268356323
Agent0_Actor_Loss : -0.8986081480979919
Agent0_Alpha_Loss : 0.7634145021438599
Agent0_Temperature : 0.07973552851788937
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -13.362462997436523
Agent1_Eval_StdReturn : 7.948846340179443
Agent1_Eval_MaxReturn : -0.7863948345184326
Agent1_Eval_MinReturn : -28.62525177001953
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -15.24463176727295
Agent1_Train_StdReturn : 10.684562683105469
Agent1_Train_MaxReturn : 3.909749984741211
Agent1_Train_MinReturn : -32.07044982910156
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1201500
Agent1_TimeSinceStart : 1861.7863948345184
Agent1_Critic_Loss : 0.9294147491455078
Agent1_Actor_Loss : -0.7910563349723816
Agent1_Alpha_Loss : 0.7262438535690308
Agent1_Temperature : 0.07981292606407368
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 801 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 802 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 803 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 804 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 805 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 806 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 807 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 808 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 809 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 810 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -21.89670181274414
Agent0_Eval_StdReturn : 20.660154342651367
Agent0_Eval_MaxReturn : 8.37087345123291
Agent0_Eval_MinReturn : -49.28630065917969
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -43.77967071533203
Agent0_Train_StdReturn : 33.040122985839844
Agent0_Train_MaxReturn : -1.7674102783203125
Agent0_Train_MinReturn : -100.50584411621094
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1216500
Agent0_TimeSinceStart : 1882.3437459468842
Agent0_Critic_Loss : 0.6817288398742676
Agent0_Actor_Loss : -0.8572887182235718
Agent0_Alpha_Loss : 0.771665096282959
Agent0_Temperature : 0.07950823878040782
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -11.876036643981934
Agent1_Eval_StdReturn : 10.979077339172363
Agent1_Eval_MaxReturn : 4.196592330932617
Agent1_Eval_MinReturn : -25.456222534179688
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -10.07821273803711
Agent1_Train_StdReturn : 14.645079612731934
Agent1_Train_MaxReturn : 8.44273567199707
Agent1_Train_MinReturn : -43.0304069519043
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1216500
Agent1_TimeSinceStart : 1884.4086573123932
Agent1_Critic_Loss : 0.6633087396621704
Agent1_Actor_Loss : -0.8011385202407837
Agent1_Alpha_Loss : 0.7157536745071411
Agent1_Temperature : 0.0795945396794552
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 811 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 812 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 813 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 814 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 815 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 816 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 817 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 818 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 819 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 820 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -22.95198631286621
Agent0_Eval_StdReturn : 24.44071388244629
Agent0_Eval_MaxReturn : 17.153072357177734
Agent0_Eval_MinReturn : -59.25103759765625
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -19.70718002319336
Agent0_Train_StdReturn : 19.456506729125977
Agent0_Train_MaxReturn : 14.126317024230957
Agent0_Train_MinReturn : -50.79753112792969
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1231500
Agent0_TimeSinceStart : 1905.2229568958282
Agent0_Critic_Loss : 0.7174925804138184
Agent0_Actor_Loss : -0.7637374997138977
Agent0_Alpha_Loss : 0.7519702315330505
Agent0_Temperature : 0.07928187590252242
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -14.201301574707031
Agent1_Eval_StdReturn : 9.269737243652344
Agent1_Eval_MaxReturn : -1.8379817008972168
Agent1_Eval_MinReturn : -29.734127044677734
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -13.075239181518555
Agent1_Train_StdReturn : 14.017549514770508
Agent1_Train_MaxReturn : 6.817705154418945
Agent1_Train_MinReturn : -37.11793899536133
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1231500
Agent1_TimeSinceStart : 1907.3113598823547
Agent1_Critic_Loss : 0.6516234874725342
Agent1_Actor_Loss : -0.7581926584243774
Agent1_Alpha_Loss : 0.7162759304046631
Agent1_Temperature : 0.07937868125315976
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 821 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 822 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 823 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 824 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 825 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 826 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 827 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 828 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 829 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 830 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -28.871906280517578
Agent0_Eval_StdReturn : 22.20890998840332
Agent0_Eval_MaxReturn : -1.1863101720809937
Agent0_Eval_MinReturn : -71.3106689453125
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -27.68563461303711
Agent0_Train_StdReturn : 24.220970153808594
Agent0_Train_MaxReturn : 7.410549640655518
Agent0_Train_MinReturn : -69.63038635253906
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1246500
Agent0_TimeSinceStart : 1928.2350614070892
Agent0_Critic_Loss : 0.705058217048645
Agent0_Actor_Loss : -0.6563958525657654
Agent0_Alpha_Loss : 0.7526540756225586
Agent0_Temperature : 0.07905739257319037
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -21.022693634033203
Agent1_Eval_StdReturn : 11.359203338623047
Agent1_Eval_MaxReturn : -4.273465156555176
Agent1_Eval_MinReturn : -40.22064971923828
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -12.626550674438477
Agent1_Train_StdReturn : 9.846952438354492
Agent1_Train_MaxReturn : -1.5515565872192383
Agent1_Train_MinReturn : -37.19441223144531
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1246500
Agent1_TimeSinceStart : 1930.330721616745
Agent1_Critic_Loss : 1.0208983421325684
Agent1_Actor_Loss : -0.78515625
Agent1_Alpha_Loss : 0.7294063568115234
Agent1_Temperature : 0.07916429486524766
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 831 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 832 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 833 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 834 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 835 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 836 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 837 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 838 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 839 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 840 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -15.255935668945312
Agent0_Eval_StdReturn : 17.310894012451172
Agent0_Eval_MaxReturn : 2.1391029357910156
Agent0_Eval_MinReturn : -49.076332092285156
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -14.664892196655273
Agent0_Train_StdReturn : 25.9791202545166
Agent0_Train_MaxReturn : 29.993560791015625
Agent0_Train_MinReturn : -55.711421966552734
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1261500
Agent0_TimeSinceStart : 1951.315392255783
Agent0_Critic_Loss : 0.6541227698326111
Agent0_Actor_Loss : -0.6910560727119446
Agent0_Alpha_Loss : 0.7540789246559143
Agent0_Temperature : 0.07883345402059053
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -19.597856521606445
Agent1_Eval_StdReturn : 21.59762954711914
Agent1_Eval_MaxReturn : 10.730167388916016
Agent1_Eval_MinReturn : -70.13639068603516
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -9.749100685119629
Agent1_Train_StdReturn : 8.591999053955078
Agent1_Train_MaxReturn : 11.4096040725708
Agent1_Train_MinReturn : -21.25857925415039
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1261500
Agent1_TimeSinceStart : 1953.4109942913055
Agent1_Critic_Loss : 0.6911858320236206
Agent1_Actor_Loss : -0.7842354774475098
Agent1_Alpha_Loss : 0.7257938385009766
Agent1_Temperature : 0.07894936279747196
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 841 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 842 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 843 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 844 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 845 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 846 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 847 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 848 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 849 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 850 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -12.778448104858398
Agent0_Eval_StdReturn : 19.153085708618164
Agent0_Eval_MaxReturn : 18.219465255737305
Agent0_Eval_MinReturn : -47.79154968261719
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -4.171023368835449
Agent0_Train_StdReturn : 18.46993637084961
Agent0_Train_MaxReturn : 23.293394088745117
Agent0_Train_MinReturn : -32.87272644042969
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1276500
Agent0_TimeSinceStart : 1974.4372131824493
Agent0_Critic_Loss : 0.5601798295974731
Agent0_Actor_Loss : -0.7968685626983643
Agent0_Alpha_Loss : 0.7434315085411072
Agent0_Temperature : 0.07861063305724961
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -7.95693826675415
Agent1_Eval_StdReturn : 6.994320392608643
Agent1_Eval_MaxReturn : 3.7353696823120117
Agent1_Eval_MinReturn : -22.719411849975586
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -19.532432556152344
Agent1_Train_StdReturn : 16.371614456176758
Agent1_Train_MaxReturn : 1.5289192199707031
Agent1_Train_MinReturn : -59.9133186340332
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1276500
Agent1_TimeSinceStart : 1976.5331754684448
Agent1_Critic_Loss : 0.7906107306480408
Agent1_Actor_Loss : -0.8594580888748169
Agent1_Alpha_Loss : 0.7247709631919861
Agent1_Temperature : 0.078733801211164
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 851 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 852 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 853 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 854 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 855 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 856 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 857 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 858 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 859 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 860 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -8.261159896850586
Agent0_Eval_StdReturn : 22.02651596069336
Agent0_Eval_MaxReturn : 31.287269592285156
Agent0_Eval_MinReturn : -37.490196228027344
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -18.020740509033203
Agent0_Train_StdReturn : 18.533061981201172
Agent0_Train_MaxReturn : 1.6223230361938477
Agent0_Train_MinReturn : -59.17204284667969
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1291500
Agent0_TimeSinceStart : 1997.5365002155304
Agent0_Critic_Loss : 0.7394950985908508
Agent0_Actor_Loss : -0.8001711368560791
Agent0_Alpha_Loss : 0.7429209351539612
Agent0_Temperature : 0.07838985579961134
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -16.333160400390625
Agent1_Eval_StdReturn : 11.038554191589355
Agent1_Eval_MaxReturn : 3.2646918296813965
Agent1_Eval_MinReturn : -36.37223815917969
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -14.308810234069824
Agent1_Train_StdReturn : 15.4580717086792
Agent1_Train_MaxReturn : 9.099908828735352
Agent1_Train_MinReturn : -39.212646484375
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1291500
Agent1_TimeSinceStart : 1999.626225233078
Agent1_Critic_Loss : 0.5315920114517212
Agent1_Actor_Loss : -0.8146176934242249
Agent1_Alpha_Loss : 0.7268352508544922
Agent1_Temperature : 0.0785186963774229
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 861 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 862 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 863 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 864 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 865 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 866 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 867 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 868 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 869 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 870 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -16.223194122314453
Agent0_Eval_StdReturn : 17.003414154052734
Agent0_Eval_MaxReturn : 9.36388111114502
Agent0_Eval_MinReturn : -54.211917877197266
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -10.48302936553955
Agent0_Train_StdReturn : 11.850190162658691
Agent0_Train_MaxReturn : 4.251366138458252
Agent0_Train_MinReturn : -32.71227264404297
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1306500
Agent0_TimeSinceStart : 2020.70760679245
Agent0_Critic_Loss : 0.8312960863113403
Agent0_Actor_Loss : -0.8533698916435242
Agent0_Alpha_Loss : 0.7376953363418579
Agent0_Temperature : 0.07817087398821924
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -21.917377471923828
Agent1_Eval_StdReturn : 14.541678428649902
Agent1_Eval_MaxReturn : -0.20843029022216797
Agent1_Eval_MinReturn : -50.10948181152344
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -14.207612991333008
Agent1_Train_StdReturn : 11.540014266967773
Agent1_Train_MaxReturn : 2.9410829544067383
Agent1_Train_MinReturn : -37.690975189208984
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1306500
Agent1_TimeSinceStart : 2022.8047001361847
Agent1_Critic_Loss : 0.5910598039627075
Agent1_Actor_Loss : -0.7508796453475952
Agent1_Alpha_Loss : 0.7299805879592896
Agent1_Temperature : 0.07830260769181252
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 871 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 872 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 873 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 874 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 875 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 876 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 877 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 878 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 879 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 880 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -9.031476974487305
Agent0_Eval_StdReturn : 11.910674095153809
Agent0_Eval_MaxReturn : 8.928253173828125
Agent0_Eval_MinReturn : -34.32345199584961
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -11.598559379577637
Agent0_Train_StdReturn : 15.266921043395996
Agent0_Train_MaxReturn : 10.646381378173828
Agent0_Train_MinReturn : -35.1094856262207
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1321500
Agent0_TimeSinceStart : 2043.9598169326782
Agent0_Critic_Loss : 0.8781977295875549
Agent0_Actor_Loss : -0.816606879234314
Agent0_Alpha_Loss : 0.7312049269676208
Agent0_Temperature : 0.07795350183826427
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -14.932034492492676
Agent1_Eval_StdReturn : 16.762025833129883
Agent1_Eval_MaxReturn : 17.964981079101562
Agent1_Eval_MinReturn : -41.25978088378906
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -14.005086898803711
Agent1_Train_StdReturn : 11.242856979370117
Agent1_Train_MaxReturn : 4.555875778198242
Agent1_Train_MinReturn : -31.211305618286133
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1321500
Agent1_TimeSinceStart : 2046.0635900497437
Agent1_Critic_Loss : 0.7119113802909851
Agent1_Actor_Loss : -0.8810054659843445
Agent1_Alpha_Loss : 0.7365108728408813
Agent1_Temperature : 0.07808683494381578
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 881 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 882 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 883 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 884 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 885 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 886 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 887 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 888 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 889 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 890 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -13.2225923538208
Agent0_Eval_StdReturn : 7.899472236633301
Agent0_Eval_MaxReturn : 4.302783012390137
Agent0_Eval_MinReturn : -27.277782440185547
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -4.0362701416015625
Agent0_Train_StdReturn : 18.847942352294922
Agent0_Train_MaxReturn : 28.889877319335938
Agent0_Train_MinReturn : -36.75605010986328
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1336500
Agent0_TimeSinceStart : 2067.254232645035
Agent0_Critic_Loss : 0.866920530796051
Agent0_Actor_Loss : -0.8391628861427307
Agent0_Alpha_Loss : 0.7215343713760376
Agent0_Temperature : 0.07773865148406639
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -19.24504280090332
Agent1_Eval_StdReturn : 13.9314546585083
Agent1_Eval_MaxReturn : 1.608540654182434
Agent1_Eval_MinReturn : -47.066471099853516
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -8.567230224609375
Agent1_Train_StdReturn : 15.663131713867188
Agent1_Train_MaxReturn : 21.40172004699707
Agent1_Train_MinReturn : -43.05994415283203
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1336500
Agent1_TimeSinceStart : 2069.348824739456
Agent1_Critic_Loss : 0.5879424810409546
Agent1_Actor_Loss : -0.8346368074417114
Agent1_Alpha_Loss : 0.743725061416626
Agent1_Temperature : 0.07787047569322936
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 891 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 892 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 893 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 894 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 895 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 896 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 897 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 898 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 899 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 900 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -21.015153884887695
Agent0_Eval_StdReturn : 17.640209197998047
Agent0_Eval_MaxReturn : 10.872051239013672
Agent0_Eval_MinReturn : -65.81245422363281
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -1.9832031726837158
Agent0_Train_StdReturn : 10.200069427490234
Agent0_Train_MaxReturn : 20.913667678833008
Agent0_Train_MinReturn : -18.848270416259766
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1351500
Agent0_TimeSinceStart : 2090.4077920913696
Agent0_Critic_Loss : 0.8364413976669312
Agent0_Actor_Loss : -0.7321898341178894
Agent0_Alpha_Loss : 0.7272231578826904
Agent0_Temperature : 0.0775257767521391
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -18.602176666259766
Agent1_Eval_StdReturn : 19.76792335510254
Agent1_Eval_MaxReturn : 10.16269302368164
Agent1_Eval_MinReturn : -45.63542938232422
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -9.061631202697754
Agent1_Train_StdReturn : 13.64448356628418
Agent1_Train_MaxReturn : 13.893156051635742
Agent1_Train_MinReturn : -34.85884094238281
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1351500
Agent1_TimeSinceStart : 2092.50000500679
Agent1_Critic_Loss : 0.5423764586448669
Agent1_Actor_Loss : -0.9666440486907959
Agent1_Alpha_Loss : 0.7547261714935303
Agent1_Temperature : 0.07765370296086856
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 901 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 902 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 903 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 904 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 905 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 906 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 907 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 908 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 909 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 910 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -8.163424491882324
Agent0_Eval_StdReturn : 15.623340606689453
Agent0_Eval_MaxReturn : 25.43826675415039
Agent0_Eval_MinReturn : -37.825096130371094
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -16.9205265045166
Agent0_Train_StdReturn : 13.787992477416992
Agent0_Train_MaxReturn : -0.8210601806640625
Agent0_Train_MinReturn : -37.947265625
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1366500
Agent0_TimeSinceStart : 2113.5909190177917
Agent0_Critic_Loss : 0.7076895236968994
Agent0_Actor_Loss : -0.6963627934455872
Agent0_Alpha_Loss : 0.7370032072067261
Agent0_Temperature : 0.07731358410281441
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -7.804219722747803
Agent1_Eval_StdReturn : 14.622791290283203
Agent1_Eval_MaxReturn : 17.671350479125977
Agent1_Eval_MinReturn : -32.19041061401367
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -14.33128833770752
Agent1_Train_StdReturn : 23.433460235595703
Agent1_Train_MaxReturn : 21.006567001342773
Agent1_Train_MinReturn : -69.18721008300781
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1366500
Agent1_TimeSinceStart : 2115.6863493919373
Agent1_Critic_Loss : 0.5217598080635071
Agent1_Actor_Loss : -0.9251367449760437
Agent1_Alpha_Loss : 0.7386234998703003
Agent1_Temperature : 0.07743550346111519
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 911 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 912 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 913 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 914 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 915 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 916 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 917 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 918 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 919 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 920 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -20.536972045898438
Agent0_Eval_StdReturn : 17.00377082824707
Agent0_Eval_MaxReturn : 3.957456588745117
Agent0_Eval_MinReturn : -51.400306701660156
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -14.154095649719238
Agent0_Train_StdReturn : 21.11654281616211
Agent0_Train_MaxReturn : 5.93084716796875
Agent0_Train_MinReturn : -68.85381317138672
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1381500
Agent0_TimeSinceStart : 2136.7945261001587
Agent0_Critic_Loss : 0.8030083179473877
Agent0_Actor_Loss : -0.8289045095443726
Agent0_Alpha_Loss : 0.7281752824783325
Agent0_Temperature : 0.07710163264223868
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -12.935137748718262
Agent1_Eval_StdReturn : 20.951059341430664
Agent1_Eval_MaxReturn : 10.564168930053711
Agent1_Eval_MinReturn : -57.228782653808594
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -5.542840480804443
Agent1_Train_StdReturn : 17.720491409301758
Agent1_Train_MaxReturn : 20.942018508911133
Agent1_Train_MinReturn : -38.871368408203125
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1381500
Agent1_TimeSinceStart : 2138.888794898987
Agent1_Critic_Loss : 0.7549366354942322
Agent1_Actor_Loss : -0.8303861021995544
Agent1_Alpha_Loss : 0.7416497468948364
Agent1_Temperature : 0.07721657445359134
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 921 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 922 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 923 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 924 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 925 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 926 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 927 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 928 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 929 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 930 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -10.457531929016113
Agent0_Eval_StdReturn : 14.855162620544434
Agent0_Eval_MaxReturn : 5.312955856323242
Agent0_Eval_MinReturn : -37.27194595336914
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -9.81082820892334
Agent0_Train_StdReturn : 8.330985069274902
Agent0_Train_MaxReturn : 7.900588035583496
Agent0_Train_MinReturn : -24.611230850219727
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1396500
Agent0_TimeSinceStart : 2159.9894573688507
Agent0_Critic_Loss : 0.6404407024383545
Agent0_Actor_Loss : -0.8150357007980347
Agent0_Alpha_Loss : 0.7245379686355591
Agent0_Temperature : 0.07689023404691307
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -40.05531692504883
Agent1_Eval_StdReturn : 18.28441047668457
Agent1_Eval_MaxReturn : -16.557302474975586
Agent1_Eval_MinReturn : -75.12823486328125
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -24.735721588134766
Agent1_Train_StdReturn : 17.753026962280273
Agent1_Train_MaxReturn : 5.838751316070557
Agent1_Train_MinReturn : -46.500732421875
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1396500
Agent1_TimeSinceStart : 2162.0718734264374
Agent1_Critic_Loss : 0.7408277988433838
Agent1_Actor_Loss : -0.9620357751846313
Agent1_Alpha_Loss : 0.7368197441101074
Agent1_Temperature : 0.07699873988671412
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 931 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 932 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 933 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 934 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 935 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 936 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 937 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 938 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 939 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 940 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -12.08072566986084
Agent0_Eval_StdReturn : 12.293183326721191
Agent0_Eval_MaxReturn : -2.2154204845428467
Agent0_Eval_MinReturn : -44.6818733215332
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -15.423535346984863
Agent0_Train_StdReturn : 13.214570045471191
Agent0_Train_MaxReturn : 11.283377647399902
Agent0_Train_MinReturn : -43.02207946777344
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1411500
Agent0_TimeSinceStart : 2183.1278235912323
Agent0_Critic_Loss : 0.7846618890762329
Agent0_Actor_Loss : -0.8037799000740051
Agent0_Alpha_Loss : 0.712094783782959
Agent0_Temperature : 0.0766799462446349
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -15.585871696472168
Agent1_Eval_StdReturn : 32.85227966308594
Agent1_Eval_MaxReturn : 37.16623306274414
Agent1_Eval_MinReturn : -77.39348602294922
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -29.479244232177734
Agent1_Train_StdReturn : 19.03998565673828
Agent1_Train_MaxReturn : 13.959148406982422
Agent1_Train_MinReturn : -64.99068450927734
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1411500
Agent1_TimeSinceStart : 2185.220977306366
Agent1_Critic_Loss : 0.6220201849937439
Agent1_Actor_Loss : -0.9867813587188721
Agent1_Alpha_Loss : 0.7306963205337524
Agent1_Temperature : 0.0767819209405779
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 941 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 942 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 943 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 944 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 945 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 946 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 947 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 948 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 949 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 950 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -9.674771308898926
Agent0_Eval_StdReturn : 11.025941848754883
Agent0_Eval_MaxReturn : 2.7394275665283203
Agent0_Eval_MinReturn : -33.17115783691406
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -7.906301021575928
Agent0_Train_StdReturn : 11.892627716064453
Agent0_Train_MaxReturn : 14.230194091796875
Agent0_Train_MinReturn : -27.29912567138672
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1426500
Agent0_TimeSinceStart : 2206.329260110855
Agent0_Critic_Loss : 0.6634587049484253
Agent0_Actor_Loss : -0.8824299573898315
Agent0_Alpha_Loss : 0.7077593207359314
Agent0_Temperature : 0.07647124926355679
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -17.56426239013672
Agent1_Eval_StdReturn : 22.311670303344727
Agent1_Eval_MaxReturn : 9.208208084106445
Agent1_Eval_MinReturn : -57.695411682128906
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -27.772287368774414
Agent1_Train_StdReturn : 22.198610305786133
Agent1_Train_MaxReturn : 10.660511016845703
Agent1_Train_MinReturn : -59.34058380126953
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1426500
Agent1_TimeSinceStart : 2208.4119522571564
Agent1_Critic_Loss : 0.8522234559059143
Agent1_Actor_Loss : -0.8694875836372375
Agent1_Alpha_Loss : 0.7267639636993408
Agent1_Temperature : 0.07656610355667728
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 951 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 952 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 953 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 954 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 955 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 956 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 957 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 958 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 959 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 960 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -11.483150482177734
Agent0_Eval_StdReturn : 17.211870193481445
Agent0_Eval_MaxReturn : 20.382051467895508
Agent0_Eval_MinReturn : -30.823204040527344
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -11.586820602416992
Agent0_Train_StdReturn : 11.134270668029785
Agent0_Train_MaxReturn : 9.531128883361816
Agent0_Train_MinReturn : -26.107919692993164
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1441500
Agent0_TimeSinceStart : 2229.49622797966
Agent0_Critic_Loss : 0.6770725250244141
Agent0_Actor_Loss : -0.8546434640884399
Agent0_Alpha_Loss : 0.7046211957931519
Agent0_Temperature : 0.07626408473648315
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -20.223724365234375
Agent1_Eval_StdReturn : 20.384613037109375
Agent1_Eval_MaxReturn : 8.660011291503906
Agent1_Eval_MinReturn : -44.99341583251953
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -27.547882080078125
Agent1_Train_StdReturn : 21.68562126159668
Agent1_Train_MaxReturn : -0.1376047134399414
Agent1_Train_MinReturn : -73.9770736694336
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1441500
Agent1_TimeSinceStart : 2231.5777213573456
Agent1_Critic_Loss : 0.7913976311683655
Agent1_Actor_Loss : -0.9218299984931946
Agent1_Alpha_Loss : 0.7244064807891846
Agent1_Temperature : 0.07635130797039034
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 961 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 962 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 963 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 964 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 965 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 966 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 967 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 968 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 969 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 970 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : 3.145343065261841
Agent0_Eval_StdReturn : 14.072893142700195
Agent0_Eval_MaxReturn : 26.725942611694336
Agent0_Eval_MinReturn : -19.357934951782227
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -9.264749526977539
Agent0_Train_StdReturn : 11.481945037841797
Agent0_Train_MaxReturn : 11.694328308105469
Agent0_Train_MinReturn : -28.15854263305664
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1456500
Agent0_TimeSinceStart : 2252.6638498306274
Agent0_Critic_Loss : 0.665631115436554
Agent0_Actor_Loss : -0.8270963430404663
Agent0_Alpha_Loss : 0.7322870492935181
Agent0_Temperature : 0.07605724567570692
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -19.15384292602539
Agent1_Eval_StdReturn : 16.790706634521484
Agent1_Eval_MaxReturn : 2.45166015625
Agent1_Eval_MinReturn : -56.41191482543945
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -32.82868194580078
Agent1_Train_StdReturn : 22.27954864501953
Agent1_Train_MaxReturn : -1.813734769821167
Agent1_Train_MinReturn : -77.46883392333984
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1456500
Agent1_TimeSinceStart : 2254.752119541168
Agent1_Critic_Loss : 0.8623886108398438
Agent1_Actor_Loss : -0.7808836698532104
Agent1_Alpha_Loss : 0.7264251112937927
Agent1_Temperature : 0.07613689364004741
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 971 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 972 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 973 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 974 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 975 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 976 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 977 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 978 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 979 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 980 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -13.105108261108398
Agent0_Eval_StdReturn : 22.795373916625977
Agent0_Eval_MaxReturn : 10.846830368041992
Agent0_Eval_MinReturn : -59.86211013793945
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -5.773351192474365
Agent0_Train_StdReturn : 14.313027381896973
Agent0_Train_MaxReturn : 20.203311920166016
Agent0_Train_MinReturn : -27.264623641967773
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1471500
Agent0_TimeSinceStart : 2275.858950614929
Agent0_Critic_Loss : 0.7179741859436035
Agent0_Actor_Loss : -0.7886296510696411
Agent0_Alpha_Loss : 0.7197920083999634
Agent0_Temperature : 0.07584940387439458
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -17.894447326660156
Agent1_Eval_StdReturn : 18.89568328857422
Agent1_Eval_MaxReturn : 10.782584190368652
Agent1_Eval_MinReturn : -53.71235656738281
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -11.372687339782715
Agent1_Train_StdReturn : 11.18143367767334
Agent1_Train_MaxReturn : 5.0858473777771
Agent1_Train_MinReturn : -27.282875061035156
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1471500
Agent1_TimeSinceStart : 2277.951450109482
Agent1_Critic_Loss : 0.7311053276062012
Agent1_Actor_Loss : -0.8644039630889893
Agent1_Alpha_Loss : 0.7334622144699097
Agent1_Temperature : 0.0759235797415027
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 981 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 982 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 983 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 984 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 985 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 986 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 987 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 988 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 989 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 990 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -11.639371871948242
Agent0_Eval_StdReturn : 21.25242042541504
Agent0_Eval_MaxReturn : 16.963361740112305
Agent0_Eval_MinReturn : -56.34259796142578
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -21.286405563354492
Agent0_Train_StdReturn : 23.5972957611084
Agent0_Train_MaxReturn : 12.399872779846191
Agent0_Train_MinReturn : -84.64105987548828
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1486500
Agent0_TimeSinceStart : 2299.0473046302795
Agent0_Critic_Loss : 0.6368573904037476
Agent0_Actor_Loss : -0.9025330543518066
Agent0_Alpha_Loss : 0.7217196226119995
Agent0_Temperature : 0.07564115579304308
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -17.463979721069336
Agent1_Eval_StdReturn : 12.877161979675293
Agent1_Eval_MaxReturn : -3.99495792388916
Agent1_Eval_MinReturn : -45.88735580444336
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -6.883005619049072
Agent1_Train_StdReturn : 16.338050842285156
Agent1_Train_MaxReturn : 16.594886779785156
Agent1_Train_MinReturn : -41.70326232910156
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1486500
Agent1_TimeSinceStart : 2301.151962041855
Agent1_Critic_Loss : 1.0573607683181763
Agent1_Actor_Loss : -0.9531529545783997
Agent1_Alpha_Loss : 0.7306195497512817
Agent1_Temperature : 0.07571122438295208
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 991 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 992 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 993 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 994 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer.../home/harvey/anaconda3/envs/285final/lib/python3.7/site-packages/gym/core.py:318: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  "Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future."
/home/harvey/anaconda3/envs/285final/lib/python3.7/site-packages/gym/wrappers/step_api_compatibility.py:40: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  "Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future."
/home/harvey/anaconda3/envs/285final/lib/python3.7/site-packages/gym/core.py:257: DeprecationWarning: [33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.[0m
  "Function `env.seed(seed)` is marked as deprecated and will be removed in the future. "


Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 995 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 996 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 997 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 998 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 999 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...
./peersacv2.sh: 8: --seed: not found



LOGGING TO:  /home/harvey/Documents/cs285/CS285-Project/cs285/scripts/../../data/peersac_v2_3agents_HalfCheetah-v4_12-12-2022_03-12-34 



########################
logging outputs to  /home/harvey/Documents/cs285/CS285-Project/cs285/scripts/../../data/peersac_v2_3agents_HalfCheetah-v4_12-12-2022_03-12-34
########################
Using GPU id 0


********** Iteration 0 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -32.58100509643555
Agent0_Eval_StdReturn : 38.008583068847656
Agent0_Eval_MaxReturn : 18.935745239257812
Agent0_Eval_MinReturn : -95.31880187988281
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -68.51490020751953
Agent0_Train_StdReturn : 35.8519172668457
Agent0_Train_MaxReturn : 10.17027473449707
Agent0_Train_MinReturn : -109.59283447265625
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1500
Agent0_TimeSinceStart : 2.219771385192871
Agent0_Critic_Loss : 1.7086536884307861
Agent0_Actor_Loss : -0.34447938203811646
Agent0_Alpha_Loss : 0.9863041639328003
Agent0_Temperature : 0.09997000449985415
Agent0_Initial_DataCollection_AverageReturn : -68.51490020751953
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -51.067047119140625
Agent1_Eval_StdReturn : 36.643306732177734
Agent1_Eval_MaxReturn : 5.4539031982421875
Agent1_Eval_MinReturn : -123.81517028808594
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -41.37040710449219
Agent1_Train_StdReturn : 23.476428985595703
Agent1_Train_MaxReturn : -3.7883758544921875
Agent1_Train_MinReturn : -74.03202819824219
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1500
Agent1_TimeSinceStart : 4.303806781768799
Agent1_Critic_Loss : 0.9912823438644409
Agent1_Actor_Loss : -0.4837449789047241
Agent1_Alpha_Loss : 0.9798400402069092
Agent1_Temperature : 0.09997000449985614
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 1 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 2 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 3 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 4 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 5 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 6 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 7 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 8 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 9 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 10 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -46.618980407714844
Agent0_Eval_StdReturn : 34.360862731933594
Agent0_Eval_MaxReturn : 4.177082061767578
Agent0_Eval_MinReturn : -101.20817565917969
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -47.71162033081055
Agent0_Train_StdReturn : 16.91861343383789
Agent0_Train_MaxReturn : -16.964988708496094
Agent0_Train_MinReturn : -70.50853729248047
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 16500
Agent0_TimeSinceStart : 25.26017713546753
Agent0_Critic_Loss : 0.8942358493804932
Agent0_Actor_Loss : -0.45209968090057373
Agent0_Alpha_Loss : 0.9856557846069336
Agent0_Temperature : 0.09967050744945741
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -23.17498016357422
Agent1_Eval_StdReturn : 35.43242645263672
Agent1_Eval_MaxReturn : 30.243358612060547
Agent1_Eval_MinReturn : -104.72036743164062
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -49.53214645385742
Agent1_Train_StdReturn : 23.37198829650879
Agent1_Train_MaxReturn : -17.918338775634766
Agent1_Train_MinReturn : -91.98331451416016
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 16500
Agent1_TimeSinceStart : 27.36055898666382
Agent1_Critic_Loss : 1.0224330425262451
Agent1_Actor_Loss : -0.5217679738998413
Agent1_Alpha_Loss : 0.9854030013084412
Agent1_Temperature : 0.09967044117277171
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 11 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 12 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 13 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 14 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 15 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 16 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 17 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 18 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 19 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 20 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -46.330047607421875
Agent0_Eval_StdReturn : 49.37164306640625
Agent0_Eval_MaxReturn : 24.719141006469727
Agent0_Eval_MinReturn : -123.84056091308594
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -19.812902450561523
Agent0_Train_StdReturn : 29.254955291748047
Agent0_Train_MaxReturn : 34.5399055480957
Agent0_Train_MinReturn : -71.24075317382812
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 31500
Agent0_TimeSinceStart : 48.483657121658325
Agent0_Critic_Loss : 0.8943381309509277
Agent0_Actor_Loss : -0.4953515827655792
Agent0_Alpha_Loss : 0.9938284158706665
Agent0_Temperature : 0.09937202970545943
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -47.99956512451172
Agent1_Eval_StdReturn : 25.836910247802734
Agent1_Eval_MaxReturn : 6.322393417358398
Agent1_Eval_MinReturn : -81.1266098022461
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -47.09725570678711
Agent1_Train_StdReturn : 28.182693481445312
Agent1_Train_MaxReturn : -5.158754825592041
Agent1_Train_MinReturn : -86.24165344238281
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 31500
Agent1_TimeSinceStart : 50.65969395637512
Agent1_Critic_Loss : 0.739264965057373
Agent1_Actor_Loss : -0.5862676501274109
Agent1_Alpha_Loss : 0.9884578585624695
Agent1_Temperature : 0.09937173561606101
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 21 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 22 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 23 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 24 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 25 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 26 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 27 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 28 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 29 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 30 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -25.192249298095703
Agent0_Eval_StdReturn : 25.30379295349121
Agent0_Eval_MaxReturn : 3.0973892211914062
Agent0_Eval_MinReturn : -60.547706604003906
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -37.913211822509766
Agent0_Train_StdReturn : 32.80707931518555
Agent0_Train_MaxReturn : 1.5589098930358887
Agent0_Train_MinReturn : -105.21112060546875
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 46500
Agent0_TimeSinceStart : 72.4294421672821
Agent0_Critic_Loss : 0.8887016773223877
Agent0_Actor_Loss : -0.4369214177131653
Agent0_Alpha_Loss : 0.988058865070343
Agent0_Temperature : 0.09907434019726678
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -51.427154541015625
Agent1_Eval_StdReturn : 21.33152198791504
Agent1_Eval_MaxReturn : -16.6425724029541
Agent1_Eval_MinReturn : -91.05067443847656
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -52.567970275878906
Agent1_Train_StdReturn : 36.218318939208984
Agent1_Train_MaxReturn : 14.909168243408203
Agent1_Train_MinReturn : -131.29782104492188
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 46500
Agent1_TimeSinceStart : 74.59218406677246
Agent1_Critic_Loss : 0.758634090423584
Agent1_Actor_Loss : -0.567564845085144
Agent1_Alpha_Loss : 0.9845913648605347
Agent1_Temperature : 0.09907393494136207
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 31 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 32 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 33 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 34 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 35 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 36 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 37 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 38 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 39 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 40 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -51.81474685668945
Agent0_Eval_StdReturn : 25.792320251464844
Agent0_Eval_MaxReturn : -2.598421096801758
Agent0_Eval_MinReturn : -97.19104766845703
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -50.26304626464844
Agent0_Train_StdReturn : 36.14711380004883
Agent0_Train_MaxReturn : -3.343472480773926
Agent0_Train_MinReturn : -111.74008178710938
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 61500
Agent0_TimeSinceStart : 96.30354738235474
Agent0_Critic_Loss : 0.85677570104599
Agent0_Actor_Loss : -0.4834839701652527
Agent0_Alpha_Loss : 0.9817242622375488
Agent0_Temperature : 0.09877806434367238
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -48.24110794067383
Agent1_Eval_StdReturn : 43.748985290527344
Agent1_Eval_MaxReturn : 10.693902015686035
Agent1_Eval_MinReturn : -126.4328842163086
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -35.22085189819336
Agent1_Train_StdReturn : 30.384601593017578
Agent1_Train_MaxReturn : 11.832371711730957
Agent1_Train_MinReturn : -92.32306671142578
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 61500
Agent1_TimeSinceStart : 98.46515893936157
Agent1_Critic_Loss : 0.7632298469543457
Agent1_Actor_Loss : -0.5450243353843689
Agent1_Alpha_Loss : 0.9787603616714478
Agent1_Temperature : 0.09877750537214858
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 41 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 42 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 43 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 44 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 45 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 46 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 47 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 48 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 49 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 50 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -47.231201171875
Agent0_Eval_StdReturn : 31.12499237060547
Agent0_Eval_MaxReturn : 18.758352279663086
Agent0_Eval_MinReturn : -88.896240234375
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -37.9083251953125
Agent0_Train_StdReturn : 26.463823318481445
Agent0_Train_MaxReturn : 1.205824613571167
Agent0_Train_MinReturn : -83.82466888427734
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 76500
Agent0_TimeSinceStart : 120.13201951980591
Agent0_Critic_Loss : 0.702551007270813
Agent0_Actor_Loss : -0.4979085326194763
Agent0_Alpha_Loss : 0.9726197719573975
Agent0_Temperature : 0.09848341178896498
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -41.91449737548828
Agent1_Eval_StdReturn : 38.189754486083984
Agent1_Eval_MaxReturn : 20.076635360717773
Agent1_Eval_MinReturn : -104.0946044921875
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -39.73896789550781
Agent1_Train_StdReturn : 43.03814697265625
Agent1_Train_MaxReturn : 33.95060348510742
Agent1_Train_MinReturn : -100.48456573486328
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 76500
Agent1_TimeSinceStart : 122.29249620437622
Agent1_Critic_Loss : 0.7645267844200134
Agent1_Actor_Loss : -0.5161893367767334
Agent1_Alpha_Loss : 0.9827108979225159
Agent1_Temperature : 0.09848265155672024
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 51 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 52 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 53 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 54 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 55 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 56 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 57 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 58 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 59 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 60 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -23.058563232421875
Agent0_Eval_StdReturn : 24.89092254638672
Agent0_Eval_MaxReturn : 34.60225296020508
Agent0_Eval_MinReturn : -51.01687240600586
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -47.699371337890625
Agent0_Train_StdReturn : 34.96453094482422
Agent0_Train_MaxReturn : 36.56296157836914
Agent0_Train_MinReturn : -93.66365051269531
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 91500
Agent0_TimeSinceStart : 143.96408462524414
Agent0_Critic_Loss : 0.6643715500831604
Agent0_Actor_Loss : -0.5324295163154602
Agent0_Alpha_Loss : 0.9678753614425659
Agent0_Temperature : 0.09819020510403086
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -41.831787109375
Agent1_Eval_StdReturn : 19.8931827545166
Agent1_Eval_MaxReturn : -17.821029663085938
Agent1_Eval_MinReturn : -88.01695251464844
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -42.75724792480469
Agent1_Train_StdReturn : 32.87258529663086
Agent1_Train_MaxReturn : 3.8843421936035156
Agent1_Train_MinReturn : -104.14067077636719
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 91500
Agent1_TimeSinceStart : 146.12348675727844
Agent1_Critic_Loss : 0.6939704418182373
Agent1_Actor_Loss : -0.5409138202667236
Agent1_Alpha_Loss : 0.9693310856819153
Agent1_Temperature : 0.09818908928501255
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 61 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 62 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 63 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 64 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 65 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 66 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 67 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 68 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 69 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 70 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -38.8419075012207
Agent0_Eval_StdReturn : 29.566526412963867
Agent0_Eval_MaxReturn : -3.729405164718628
Agent0_Eval_MinReturn : -113.11373901367188
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -52.9005241394043
Agent0_Train_StdReturn : 40.080482482910156
Agent0_Train_MaxReturn : 1.0143446922302246
Agent0_Train_MinReturn : -107.70153045654297
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 106500
Agent0_TimeSinceStart : 167.77954816818237
Agent0_Critic_Loss : 0.7037286758422852
Agent0_Actor_Loss : -0.4647260308265686
Agent0_Alpha_Loss : 0.9602019786834717
Agent0_Temperature : 0.09789869714272686
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -30.252145767211914
Agent1_Eval_StdReturn : 28.29826545715332
Agent1_Eval_MaxReturn : 16.39629554748535
Agent1_Eval_MinReturn : -75.33551788330078
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -25.83236312866211
Agent1_Train_StdReturn : 29.567489624023438
Agent1_Train_MaxReturn : 26.50406265258789
Agent1_Train_MinReturn : -65.26861572265625
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 106500
Agent1_TimeSinceStart : 169.93310546875
Agent1_Critic_Loss : 0.5866408348083496
Agent1_Actor_Loss : -0.6239601373672485
Agent1_Alpha_Loss : 0.9610376358032227
Agent1_Temperature : 0.09789759600044688
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 71 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 72 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 73 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 74 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 75 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 76 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 77 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 78 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 79 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 80 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -32.57512664794922
Agent0_Eval_StdReturn : 27.380290985107422
Agent0_Eval_MaxReturn : 9.714351654052734
Agent0_Eval_MinReturn : -82.47639465332031
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -48.643165588378906
Agent0_Train_StdReturn : 21.835474014282227
Agent0_Train_MaxReturn : -13.810791969299316
Agent0_Train_MinReturn : -86.53678131103516
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 121500
Agent0_TimeSinceStart : 191.49115133285522
Agent0_Critic_Loss : 0.5861657857894897
Agent0_Actor_Loss : -0.5243018865585327
Agent0_Alpha_Loss : 0.9481593370437622
Agent0_Temperature : 0.09760997633682657
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -28.237812042236328
Agent1_Eval_StdReturn : 39.9020881652832
Agent1_Eval_MaxReturn : 18.770275115966797
Agent1_Eval_MinReturn : -108.76464080810547
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -31.456554412841797
Agent1_Train_StdReturn : 23.307397842407227
Agent1_Train_MaxReturn : -7.219683647155762
Agent1_Train_MinReturn : -87.21615600585938
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 121500
Agent1_TimeSinceStart : 193.63412761688232
Agent1_Critic_Loss : 0.4728608727455139
Agent1_Actor_Loss : -0.6072537899017334
Agent1_Alpha_Loss : 0.943848192691803
Agent1_Temperature : 0.09760899984253193
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 81 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 82 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 83 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 84 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 85 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 86 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 87 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 88 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 89 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 90 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -17.857620239257812
Agent0_Eval_StdReturn : 29.711423873901367
Agent0_Eval_MaxReturn : 39.58865737915039
Agent0_Eval_MinReturn : -53.58030319213867
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -10.79987907409668
Agent0_Train_StdReturn : 21.534536361694336
Agent0_Train_MaxReturn : 26.618576049804688
Agent0_Train_MinReturn : -48.618534088134766
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 136500
Agent0_TimeSinceStart : 215.2264232635498
Agent0_Critic_Loss : 0.4966686964035034
Agent0_Actor_Loss : -0.5530083179473877
Agent0_Alpha_Loss : 0.9283055067062378
Agent0_Temperature : 0.09732510135183746
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -22.70708465576172
Agent1_Eval_StdReturn : 28.623443603515625
Agent1_Eval_MaxReturn : 41.20599365234375
Agent1_Eval_MinReturn : -65.87571716308594
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -29.3641300201416
Agent1_Train_StdReturn : 18.432497024536133
Agent1_Train_MaxReturn : 7.412674427032471
Agent1_Train_MinReturn : -63.426666259765625
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 136500
Agent1_TimeSinceStart : 217.37429809570312
Agent1_Critic_Loss : 0.5023685693740845
Agent1_Actor_Loss : -0.6076624989509583
Agent1_Alpha_Loss : 0.9397616982460022
Agent1_Temperature : 0.0973242661772684
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 91 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 92 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 93 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 94 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 95 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 96 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 97 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 98 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 99 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 100 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -37.80340576171875
Agent0_Eval_StdReturn : 20.51852035522461
Agent0_Eval_MaxReturn : -8.982361793518066
Agent0_Eval_MinReturn : -69.56307983398438
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -13.584561347961426
Agent0_Train_StdReturn : 29.4119873046875
Agent0_Train_MaxReturn : 39.010250091552734
Agent0_Train_MinReturn : -50.01905059814453
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 151500
Agent0_TimeSinceStart : 238.96962308883667
Agent0_Critic_Loss : 0.4442911446094513
Agent0_Actor_Loss : -0.5299762487411499
Agent0_Alpha_Loss : 0.8924819231033325
Agent0_Temperature : 0.09704567997417912
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -26.93208885192871
Agent1_Eval_StdReturn : 15.997502326965332
Agent1_Eval_MaxReturn : -3.8266448974609375
Agent1_Eval_MinReturn : -59.922542572021484
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -28.49300193786621
Agent1_Train_StdReturn : 23.280410766601562
Agent1_Train_MaxReturn : 2.7106361389160156
Agent1_Train_MinReturn : -77.24320983886719
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 151500
Agent1_TimeSinceStart : 241.13148498535156
Agent1_Critic_Loss : 0.5145032405853271
Agent1_Actor_Loss : -0.7386530637741089
Agent1_Alpha_Loss : 0.8874350786209106
Agent1_Temperature : 0.09704388809122931
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 101 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 102 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 103 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 104 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 105 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 106 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 107 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 108 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 109 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 110 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -26.71738052368164
Agent0_Eval_StdReturn : 9.157398223876953
Agent0_Eval_MaxReturn : -13.375016212463379
Agent0_Eval_MinReturn : -42.88822937011719
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -19.410362243652344
Agent0_Train_StdReturn : 7.425318241119385
Agent0_Train_MaxReturn : -8.613565444946289
Agent0_Train_MinReturn : -30.00765037536621
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 166500
Agent0_TimeSinceStart : 262.84959506988525
Agent0_Critic_Loss : 0.4051252603530884
Agent0_Actor_Loss : -0.5468058586120605
Agent0_Alpha_Loss : 0.8308137655258179
Agent0_Temperature : 0.09677476231533662
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -29.879653930664062
Agent1_Eval_StdReturn : 10.994625091552734
Agent1_Eval_MaxReturn : -4.192960739135742
Agent1_Eval_MinReturn : -39.91998291015625
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -21.70599365234375
Agent1_Train_StdReturn : 8.793038368225098
Agent1_Train_MaxReturn : -6.571042060852051
Agent1_Train_MinReturn : -37.95457458496094
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 166500
Agent1_TimeSinceStart : 265.02021956443787
Agent1_Critic_Loss : 0.4581545293331146
Agent1_Actor_Loss : -0.6983570456504822
Agent1_Alpha_Loss : 0.8447428345680237
Agent1_Temperature : 0.09677138948908492
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 111 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 112 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 113 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 114 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 115 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 116 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 117 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 118 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 119 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 120 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -24.482786178588867
Agent0_Eval_StdReturn : 14.492881774902344
Agent0_Eval_MaxReturn : 3.942654609680176
Agent0_Eval_MinReturn : -49.24791717529297
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -19.76818084716797
Agent0_Train_StdReturn : 14.692700386047363
Agent0_Train_MaxReturn : 8.915509223937988
Agent0_Train_MinReturn : -44.430538177490234
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 181500
Agent0_TimeSinceStart : 286.81898832321167
Agent0_Critic_Loss : 0.4409399926662445
Agent0_Actor_Loss : -0.5370804667472839
Agent0_Alpha_Loss : 0.7897802591323853
Agent0_Temperature : 0.09651470315587865
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -29.733917236328125
Agent1_Eval_StdReturn : 14.06531047821045
Agent1_Eval_MaxReturn : -3.601330041885376
Agent1_Eval_MinReturn : -60.80698013305664
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -24.933208465576172
Agent1_Train_StdReturn : 16.737770080566406
Agent1_Train_MaxReturn : -7.081881999969482
Agent1_Train_MinReturn : -65.99290466308594
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 181500
Agent1_TimeSinceStart : 288.9791188240051
Agent1_Critic_Loss : 0.39527273178100586
Agent1_Actor_Loss : -0.6849207878112793
Agent1_Alpha_Loss : 0.7959141135215759
Agent1_Temperature : 0.0965084619101353
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 121 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 122 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 123 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 124 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 125 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 126 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 127 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 128 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 129 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 130 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -30.72934341430664
Agent0_Eval_StdReturn : 7.28204345703125
Agent0_Eval_MaxReturn : -21.046300888061523
Agent0_Eval_MinReturn : -44.18566131591797
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -33.520572662353516
Agent0_Train_StdReturn : 14.600418090820312
Agent0_Train_MaxReturn : -14.512083053588867
Agent0_Train_MinReturn : -68.73931121826172
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 196500
Agent0_TimeSinceStart : 310.86010479927063
Agent0_Critic_Loss : 0.4850107431411743
Agent0_Actor_Loss : -0.4656216502189636
Agent0_Alpha_Loss : 0.7841089367866516
Agent0_Temperature : 0.09626522147069992
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -34.47418212890625
Agent1_Eval_StdReturn : 12.714120864868164
Agent1_Eval_MaxReturn : -17.067184448242188
Agent1_Eval_MinReturn : -63.6812744140625
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -35.14310073852539
Agent1_Train_StdReturn : 14.900437355041504
Agent1_Train_MaxReturn : -18.32403564453125
Agent1_Train_MinReturn : -75.90545654296875
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 196500
Agent1_TimeSinceStart : 313.0215663909912
Agent1_Critic_Loss : 0.3992483615875244
Agent1_Actor_Loss : -0.6165434122085571
Agent1_Alpha_Loss : 0.7931673526763916
Agent1_Temperature : 0.0962551694498973
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 131 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 132 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 133 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 134 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 135 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 136 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 137 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 138 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 139 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 140 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -25.436416625976562
Agent0_Eval_StdReturn : 10.668664932250977
Agent0_Eval_MaxReturn : -5.131865501403809
Agent0_Eval_MinReturn : -41.88395690917969
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -32.71979904174805
Agent0_Train_StdReturn : 6.228855133056641
Agent0_Train_MaxReturn : -22.526844024658203
Agent0_Train_MinReturn : -42.00605010986328
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 211500
Agent0_TimeSinceStart : 334.86484694480896
Agent0_Critic_Loss : 0.39317232370376587
Agent0_Actor_Loss : -0.5013166666030884
Agent0_Alpha_Loss : 0.7903857231140137
Agent0_Temperature : 0.0960199839826443
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -18.286291122436523
Agent1_Eval_StdReturn : 16.946006774902344
Agent1_Eval_MaxReturn : 0.406219482421875
Agent1_Eval_MinReturn : -58.388404846191406
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -31.03554916381836
Agent1_Train_StdReturn : 19.03114891052246
Agent1_Train_MaxReturn : -3.648172378540039
Agent1_Train_MinReturn : -65.96772766113281
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 211500
Agent1_TimeSinceStart : 337.03908801078796
Agent1_Critic_Loss : 0.37308788299560547
Agent1_Actor_Loss : -0.6019374132156372
Agent1_Alpha_Loss : 0.8196832537651062
Agent1_Temperature : 0.09600565036244861
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 141 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 142 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 143 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 144 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 145 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 146 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 147 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 148 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 149 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 150 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -31.892099380493164
Agent0_Eval_StdReturn : 12.439228057861328
Agent0_Eval_MaxReturn : -12.451138496398926
Agent0_Eval_MinReturn : -51.76466369628906
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -27.9456729888916
Agent0_Train_StdReturn : 10.288050651550293
Agent0_Train_MaxReturn : -12.234962463378906
Agent0_Train_MinReturn : -48.911224365234375
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 226500
Agent0_TimeSinceStart : 358.9063787460327
Agent0_Critic_Loss : 0.38597971200942993
Agent0_Actor_Loss : -0.5260317325592041
Agent0_Alpha_Loss : 0.8047704100608826
Agent0_Temperature : 0.0957727699576644
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -26.361913681030273
Agent1_Eval_StdReturn : 16.365890502929688
Agent1_Eval_MaxReturn : 5.785409927368164
Agent1_Eval_MinReturn : -57.972164154052734
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -21.194849014282227
Agent1_Train_StdReturn : 10.356460571289062
Agent1_Train_MaxReturn : -1.4959745407104492
Agent1_Train_MinReturn : -33.84349822998047
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 226500
Agent1_TimeSinceStart : 361.0722653865814
Agent1_Critic_Loss : 0.36958667635917664
Agent1_Actor_Loss : -0.539533257484436
Agent1_Alpha_Loss : 0.8046441674232483
Agent1_Temperature : 0.09575486746138635
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 151 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 152 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 153 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 154 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 155 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 156 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 157 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 158 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 159 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 160 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -28.369461059570312
Agent0_Eval_StdReturn : 15.800494194030762
Agent0_Eval_MaxReturn : -6.013942718505859
Agent0_Eval_MinReturn : -50.84025573730469
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -17.05450439453125
Agent0_Train_StdReturn : 22.834875106811523
Agent0_Train_MaxReturn : 17.602853775024414
Agent0_Train_MinReturn : -56.72097396850586
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 241500
Agent0_TimeSinceStart : 382.7822074890137
Agent0_Critic_Loss : 0.39450690150260925
Agent0_Actor_Loss : -0.4640153646469116
Agent0_Alpha_Loss : 0.8255113959312439
Agent0_Temperature : 0.09552109655257941
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -25.255813598632812
Agent1_Eval_StdReturn : 6.8625874519348145
Agent1_Eval_MaxReturn : -14.703727722167969
Agent1_Eval_MinReturn : -36.29902648925781
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -20.357406616210938
Agent1_Train_StdReturn : 11.571333885192871
Agent1_Train_MaxReturn : 3.507589340209961
Agent1_Train_MinReturn : -36.570167541503906
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 241500
Agent1_TimeSinceStart : 384.9262447357178
Agent1_Critic_Loss : 0.2832237482070923
Agent1_Actor_Loss : -0.6322349309921265
Agent1_Alpha_Loss : 0.8384940028190613
Agent1_Temperature : 0.09550122755746757
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 161 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 162 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 163 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 164 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 165 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 166 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 167 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 168 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 169 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 170 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -21.955142974853516
Agent0_Eval_StdReturn : 14.017755508422852
Agent0_Eval_MaxReturn : -3.4731693267822266
Agent0_Eval_MinReturn : -58.09199905395508
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -17.145771026611328
Agent0_Train_StdReturn : 11.94571304321289
Agent0_Train_MaxReturn : 5.7421698570251465
Agent0_Train_MinReturn : -38.180389404296875
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 256500
Agent0_TimeSinceStart : 406.53795623779297
Agent0_Critic_Loss : 0.30586960911750793
Agent0_Actor_Loss : -0.32850509881973267
Agent0_Alpha_Loss : 0.8147903680801392
Agent0_Temperature : 0.09526527187051673
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -28.28069496154785
Agent1_Eval_StdReturn : 25.534046173095703
Agent1_Eval_MaxReturn : -3.7594070434570312
Agent1_Eval_MinReturn : -93.77108764648438
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -25.064228057861328
Agent1_Train_StdReturn : 17.75586700439453
Agent1_Train_MaxReturn : 1.773763656616211
Agent1_Train_MinReturn : -55.343414306640625
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 256500
Agent1_TimeSinceStart : 408.6952905654907
Agent1_Critic_Loss : 0.3038290739059448
Agent1_Actor_Loss : -0.5801087617874146
Agent1_Alpha_Loss : 0.8144093751907349
Agent1_Temperature : 0.09524513003155671
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 171 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 172 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 173 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 174 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 175 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 176 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 177 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 178 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 179 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 180 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -27.076618194580078
Agent0_Eval_StdReturn : 15.346336364746094
Agent0_Eval_MaxReturn : -4.051137924194336
Agent0_Eval_MinReturn : -60.678123474121094
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -17.712825775146484
Agent0_Train_StdReturn : 13.926739692687988
Agent0_Train_MaxReturn : 10.59235954284668
Agent0_Train_MinReturn : -37.77747344970703
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 271500
Agent0_TimeSinceStart : 430.41046500205994
Agent0_Critic_Loss : 0.318859338760376
Agent0_Actor_Loss : -0.48374971747398376
Agent0_Alpha_Loss : 0.8070443868637085
Agent0_Temperature : 0.09500847950734942
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -14.019808769226074
Agent1_Eval_StdReturn : 4.695367336273193
Agent1_Eval_MaxReturn : -6.574995517730713
Agent1_Eval_MinReturn : -22.182910919189453
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -19.994857788085938
Agent1_Train_StdReturn : 17.90374183654785
Agent1_Train_MaxReturn : 10.091588020324707
Agent1_Train_MinReturn : -43.324684143066406
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 271500
Agent1_TimeSinceStart : 432.5665338039398
Agent1_Critic_Loss : 0.3104366660118103
Agent1_Actor_Loss : -0.5791971683502197
Agent1_Alpha_Loss : 0.8123703002929688
Agent1_Temperature : 0.0949880875299392
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 181 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 182 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 183 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 184 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 185 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 186 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 187 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 188 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 189 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 190 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -21.80546760559082
Agent0_Eval_StdReturn : 16.769208908081055
Agent0_Eval_MaxReturn : 6.622250556945801
Agent0_Eval_MinReturn : -49.69880294799805
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -16.967369079589844
Agent0_Train_StdReturn : 10.091402053833008
Agent0_Train_MaxReturn : -4.692663192749023
Agent0_Train_MinReturn : -36.403682708740234
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 286500
Agent0_TimeSinceStart : 454.2132706642151
Agent0_Critic_Loss : 0.30364954471588135
Agent0_Actor_Loss : -0.4403717517852783
Agent0_Alpha_Loss : 0.796306312084198
Agent0_Temperature : 0.09475282935455145
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -22.501718521118164
Agent1_Eval_StdReturn : 9.146004676818848
Agent1_Eval_MaxReturn : -9.557808876037598
Agent1_Eval_MinReturn : -34.794677734375
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -20.40598487854004
Agent1_Train_StdReturn : 12.294474601745605
Agent1_Train_MaxReturn : -7.418977737426758
Agent1_Train_MinReturn : -45.753150939941406
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 286500
Agent1_TimeSinceStart : 456.3663532733917
Agent1_Critic_Loss : 0.26685407757759094
Agent1_Actor_Loss : -0.5384045839309692
Agent1_Alpha_Loss : 0.8114606738090515
Agent1_Temperature : 0.09473029919771728
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 191 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 192 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 193 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 194 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 195 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 196 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 197 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 198 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 199 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 200 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -25.69723129272461
Agent0_Eval_StdReturn : 20.455692291259766
Agent0_Eval_MaxReturn : 10.974164962768555
Agent0_Eval_MinReturn : -51.000919342041016
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -20.289236068725586
Agent0_Train_StdReturn : 17.39792251586914
Agent0_Train_MaxReturn : 0.43537425994873047
Agent0_Train_MinReturn : -65.25035858154297
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 301500
Agent0_TimeSinceStart : 478.0461530685425
Agent0_Critic_Loss : 0.2412942796945572
Agent0_Actor_Loss : -0.3400561213493347
Agent0_Alpha_Loss : 0.7977859377861023
Agent0_Temperature : 0.09449895330535356
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -20.21791648864746
Agent1_Eval_StdReturn : 11.459834098815918
Agent1_Eval_MaxReturn : 3.1967945098876953
Agent1_Eval_MinReturn : -35.55563735961914
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -25.8229923248291
Agent1_Train_StdReturn : 10.7367582321167
Agent1_Train_MaxReturn : -4.19175910949707
Agent1_Train_MinReturn : -41.7381706237793
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 301500
Agent1_TimeSinceStart : 480.19863986968994
Agent1_Critic_Loss : 0.329375684261322
Agent1_Actor_Loss : -0.5519530177116394
Agent1_Alpha_Loss : 0.8178637027740479
Agent1_Temperature : 0.09447224516686203
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 201 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 202 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 203 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 204 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 205 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 206 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 207 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 208 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 209 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 210 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -21.8115291595459
Agent0_Eval_StdReturn : 13.657686233520508
Agent0_Eval_MaxReturn : -2.757404327392578
Agent0_Eval_MinReturn : -48.650047302246094
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -14.39471435546875
Agent0_Train_StdReturn : 16.347627639770508
Agent0_Train_MaxReturn : 14.92820930480957
Agent0_Train_MinReturn : -34.654483795166016
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 316500
Agent0_TimeSinceStart : 501.8390464782715
Agent0_Critic_Loss : 0.27737730741500854
Agent0_Actor_Loss : -0.41797274351119995
Agent0_Alpha_Loss : 0.7780022025108337
Agent0_Temperature : 0.09424531666721062
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -22.183481216430664
Agent1_Eval_StdReturn : 12.680124282836914
Agent1_Eval_MaxReturn : -5.597496032714844
Agent1_Eval_MinReturn : -41.762596130371094
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -16.213851928710938
Agent1_Train_StdReturn : 18.73265838623047
Agent1_Train_MaxReturn : 12.309500694274902
Agent1_Train_MinReturn : -50.59186935424805
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 316500
Agent1_TimeSinceStart : 503.9952058792114
Agent1_Critic_Loss : 0.26005643606185913
Agent1_Actor_Loss : -0.4757649302482605
Agent1_Alpha_Loss : 0.8048917651176453
Agent1_Temperature : 0.09421393358537866
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 211 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 212 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 213 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 214 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 215 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 216 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 217 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 218 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 219 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 220 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -13.577470779418945
Agent0_Eval_StdReturn : 16.09775161743164
Agent0_Eval_MaxReturn : 13.942264556884766
Agent0_Eval_MinReturn : -37.72106170654297
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -10.577577590942383
Agent0_Train_StdReturn : 17.933340072631836
Agent0_Train_MaxReturn : 13.795208930969238
Agent0_Train_MinReturn : -42.75967025756836
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 331500
Agent0_TimeSinceStart : 525.7201964855194
Agent0_Critic_Loss : 0.2705122232437134
Agent0_Actor_Loss : -0.3920987546443939
Agent0_Alpha_Loss : 0.7923597097396851
Agent0_Temperature : 0.09399066654138319
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -24.284931182861328
Agent1_Eval_StdReturn : 18.248394012451172
Agent1_Eval_MaxReturn : 1.9455909729003906
Agent1_Eval_MinReturn : -64.74829864501953
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -17.958498001098633
Agent1_Train_StdReturn : 16.714183807373047
Agent1_Train_MaxReturn : 7.660728454589844
Agent1_Train_MinReturn : -46.426483154296875
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 331500
Agent1_TimeSinceStart : 527.8695950508118
Agent1_Critic_Loss : 0.2633100748062134
Agent1_Actor_Loss : -0.48805761337280273
Agent1_Alpha_Loss : 0.7811381816864014
Agent1_Temperature : 0.09395560785892178
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 221 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 222 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 223 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 224 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 225 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 226 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 227 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 228 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 229 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 230 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -18.710599899291992
Agent0_Eval_StdReturn : 15.809965133666992
Agent0_Eval_MaxReturn : 2.2870659828186035
Agent0_Eval_MinReturn : -44.86009216308594
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -19.17093276977539
Agent0_Train_StdReturn : 13.501765251159668
Agent0_Train_MaxReturn : 0.7054409384727478
Agent0_Train_MinReturn : -39.32066345214844
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 346500
Agent0_TimeSinceStart : 549.4594321250916
Agent0_Critic_Loss : 0.22688761353492737
Agent0_Actor_Loss : -0.3476746678352356
Agent0_Alpha_Loss : 0.7892990112304688
Agent0_Temperature : 0.09373451595001299
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -23.829654693603516
Agent1_Eval_StdReturn : 16.401927947998047
Agent1_Eval_MaxReturn : -4.864241123199463
Agent1_Eval_MinReturn : -53.475162506103516
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -21.34646987915039
Agent1_Train_StdReturn : 16.41570472717285
Agent1_Train_MaxReturn : 14.388132095336914
Agent1_Train_MinReturn : -40.5125732421875
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 346500
Agent1_TimeSinceStart : 551.6051435470581
Agent1_Critic_Loss : 0.2123662829399109
Agent1_Actor_Loss : -0.47763341665267944
Agent1_Alpha_Loss : 0.8241918683052063
Agent1_Temperature : 0.09369781734922288
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 231 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 232 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 233 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 234 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 235 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 236 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 237 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 238 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 239 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 240 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -17.333988189697266
Agent0_Eval_StdReturn : 22.86820411682129
Agent0_Eval_MaxReturn : 3.0578129291534424
Agent0_Eval_MinReturn : -78.88383483886719
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -20.085369110107422
Agent0_Train_StdReturn : 9.355685234069824
Agent0_Train_MaxReturn : 0.6124482154846191
Agent0_Train_MinReturn : -33.810489654541016
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 361500
Agent0_TimeSinceStart : 573.1726160049438
Agent0_Critic_Loss : 0.22649532556533813
Agent0_Actor_Loss : -0.4314124584197998
Agent0_Alpha_Loss : 0.8179545998573303
Agent0_Temperature : 0.09347691437687203
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -18.3162899017334
Agent1_Eval_StdReturn : 17.166223526000977
Agent1_Eval_MaxReturn : 1.881246566772461
Agent1_Eval_MinReturn : -51.84557342529297
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -34.039085388183594
Agent1_Train_StdReturn : 13.983345031738281
Agent1_Train_MaxReturn : -18.71865463256836
Agent1_Train_MinReturn : -56.42881774902344
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 361500
Agent1_TimeSinceStart : 575.3094766139984
Agent1_Critic_Loss : 0.23187902569770813
Agent1_Actor_Loss : -0.46610862016677856
Agent1_Alpha_Loss : 0.818598747253418
Agent1_Temperature : 0.09343862549918217
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 241 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 242 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 243 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 244 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 245 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 246 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 247 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 248 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 249 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 250 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -28.273305892944336
Agent0_Eval_StdReturn : 20.605722427368164
Agent0_Eval_MaxReturn : 3.391468048095703
Agent0_Eval_MinReturn : -61.47727966308594
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -22.134458541870117
Agent0_Train_StdReturn : 25.50248146057129
Agent0_Train_MaxReturn : 0.7803969383239746
Agent0_Train_MinReturn : -94.14483642578125
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 376500
Agent0_TimeSinceStart : 596.884584903717
Agent0_Critic_Loss : 0.3047303557395935
Agent0_Actor_Loss : -0.4328756034374237
Agent0_Alpha_Loss : 0.8132928013801575
Agent0_Temperature : 0.09321761287041025
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -19.992265701293945
Agent1_Eval_StdReturn : 10.623624801635742
Agent1_Eval_MaxReturn : -2.776881694793701
Agent1_Eval_MinReturn : -35.5587043762207
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -10.000242233276367
Agent1_Train_StdReturn : 11.439395904541016
Agent1_Train_MaxReturn : 4.235828399658203
Agent1_Train_MinReturn : -32.62958908081055
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 376500
Agent1_TimeSinceStart : 599.0285522937775
Agent1_Critic_Loss : 0.2005358785390854
Agent1_Actor_Loss : -0.4687945246696472
Agent1_Alpha_Loss : 0.8252982497215271
Agent1_Temperature : 0.09317791669596483
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 251 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 252 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 253 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 254 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 255 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 256 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 257 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 258 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 259 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 260 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -21.173725128173828
Agent0_Eval_StdReturn : 22.272939682006836
Agent0_Eval_MaxReturn : 7.241703510284424
Agent0_Eval_MinReturn : -63.53387451171875
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -22.807300567626953
Agent0_Train_StdReturn : 16.27992057800293
Agent0_Train_MaxReturn : 1.8352727890014648
Agent0_Train_MinReturn : -44.94645690917969
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 391500
Agent0_TimeSinceStart : 620.5498960018158
Agent0_Critic_Loss : 0.24238094687461853
Agent0_Actor_Loss : -0.3988884687423706
Agent0_Alpha_Loss : 0.8145051598548889
Agent0_Temperature : 0.09295810211711002
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -22.740795135498047
Agent1_Eval_StdReturn : 17.84267807006836
Agent1_Eval_MaxReturn : -0.16417014598846436
Agent1_Eval_MinReturn : -68.10855102539062
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -18.616830825805664
Agent1_Train_StdReturn : 12.847663879394531
Agent1_Train_MaxReturn : 6.060478687286377
Agent1_Train_MinReturn : -45.211875915527344
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 391500
Agent1_TimeSinceStart : 622.6899473667145
Agent1_Critic_Loss : 0.2865895628929138
Agent1_Actor_Loss : -0.5141335725784302
Agent1_Alpha_Loss : 0.8191352486610413
Agent1_Temperature : 0.09291674372453547
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 261 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 262 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 263 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 264 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 265 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 266 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 267 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 268 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 269 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 270 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -10.512846946716309
Agent0_Eval_StdReturn : 13.774767875671387
Agent0_Eval_MaxReturn : 11.582235336303711
Agent0_Eval_MinReturn : -32.29518508911133
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -13.4161376953125
Agent0_Train_StdReturn : 23.522686004638672
Agent0_Train_MaxReturn : 23.2353515625
Agent0_Train_MinReturn : -55.13616180419922
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 406500
Agent0_TimeSinceStart : 643.7284872531891
Agent0_Critic_Loss : 0.3442981243133545
Agent0_Actor_Loss : -0.40543293952941895
Agent0_Alpha_Loss : 0.8171842098236084
Agent0_Temperature : 0.09269592974801372
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -9.648462295532227
Agent1_Eval_StdReturn : 22.913223266601562
Agent1_Eval_MaxReturn : 26.497390747070312
Agent1_Eval_MinReturn : -54.01353454589844
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -33.79578399658203
Agent1_Train_StdReturn : 15.738564491271973
Agent1_Train_MaxReturn : -1.1309329271316528
Agent1_Train_MinReturn : -54.414337158203125
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 406500
Agent1_TimeSinceStart : 645.7960550785065
Agent1_Critic_Loss : 0.26162654161453247
Agent1_Actor_Loss : -0.5619012117385864
Agent1_Alpha_Loss : 0.8127342462539673
Agent1_Temperature : 0.09265593987875001
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 271 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 272 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 273 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 274 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 275 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 276 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 277 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 278 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 279 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 280 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -30.283252716064453
Agent0_Eval_StdReturn : 25.37603759765625
Agent0_Eval_MaxReturn : 12.135286331176758
Agent0_Eval_MinReturn : -77.88578796386719
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -23.479312896728516
Agent0_Train_StdReturn : 18.681013107299805
Agent0_Train_MaxReturn : -0.013998985290527344
Agent0_Train_MinReturn : -59.95723342895508
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 421500
Agent0_TimeSinceStart : 666.3413953781128
Agent0_Critic_Loss : 0.36272817850112915
Agent0_Actor_Loss : -0.49390438199043274
Agent0_Alpha_Loss : 0.8066123723983765
Agent0_Temperature : 0.09243355152872568
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -18.736736297607422
Agent1_Eval_StdReturn : 17.764461517333984
Agent1_Eval_MaxReturn : 7.280604362487793
Agent1_Eval_MinReturn : -51.28277587890625
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -21.252260208129883
Agent1_Train_StdReturn : 16.68300437927246
Agent1_Train_MaxReturn : 18.72759437561035
Agent1_Train_MinReturn : -40.4295654296875
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 421500
Agent1_TimeSinceStart : 668.3991756439209
Agent1_Critic_Loss : 0.2777755856513977
Agent1_Actor_Loss : -0.4685590863227844
Agent1_Alpha_Loss : 0.8310694694519043
Agent1_Temperature : 0.09239528086008178
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 281 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 282 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 283 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 284 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 285 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 286 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 287 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 288 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 289 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 290 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -23.595516204833984
Agent0_Eval_StdReturn : 20.059581756591797
Agent0_Eval_MaxReturn : 10.174663543701172
Agent0_Eval_MinReturn : -55.899757385253906
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -32.25330352783203
Agent0_Train_StdReturn : 26.456214904785156
Agent0_Train_MaxReturn : 28.51021385192871
Agent0_Train_MinReturn : -62.81499481201172
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 436500
Agent0_TimeSinceStart : 689.1544787883759
Agent0_Critic_Loss : 0.3397170305252075
Agent0_Actor_Loss : -0.4539000391960144
Agent0_Alpha_Loss : 0.8094656467437744
Agent0_Temperature : 0.09217217773772532
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -26.199859619140625
Agent1_Eval_StdReturn : 30.655960083007812
Agent1_Eval_MaxReturn : 19.09996223449707
Agent1_Eval_MinReturn : -85.20821380615234
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -20.576250076293945
Agent1_Train_StdReturn : 23.522932052612305
Agent1_Train_MaxReturn : 16.836807250976562
Agent1_Train_MinReturn : -63.4809684753418
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 436500
Agent1_TimeSinceStart : 691.2135298252106
Agent1_Critic_Loss : 0.3389924168586731
Agent1_Actor_Loss : -0.5380591154098511
Agent1_Alpha_Loss : 0.8115537166595459
Agent1_Temperature : 0.09213540255554403
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 291 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 292 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 293 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 294 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 295 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 296 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 297 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 298 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 299 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 300 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -19.194705963134766
Agent0_Eval_StdReturn : 20.533872604370117
Agent0_Eval_MaxReturn : 11.376367568969727
Agent0_Eval_MinReturn : -66.9398193359375
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -30.98599624633789
Agent0_Train_StdReturn : 27.600034713745117
Agent0_Train_MaxReturn : 11.761993408203125
Agent0_Train_MinReturn : -71.42707061767578
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 451500
Agent0_TimeSinceStart : 712.0817394256592
Agent0_Critic_Loss : 0.32151931524276733
Agent0_Actor_Loss : -0.4429622292518616
Agent0_Alpha_Loss : 0.8083616495132446
Agent0_Temperature : 0.09191241202806633
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -20.708343505859375
Agent1_Eval_StdReturn : 16.63187599182129
Agent1_Eval_MaxReturn : 6.875889778137207
Agent1_Eval_MinReturn : -49.585262298583984
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -23.951841354370117
Agent1_Train_StdReturn : 19.38088607788086
Agent1_Train_MaxReturn : 13.88760757446289
Agent1_Train_MinReturn : -53.550289154052734
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 451500
Agent1_TimeSinceStart : 714.1578571796417
Agent1_Critic_Loss : 0.3512432277202606
Agent1_Actor_Loss : -0.7054246068000793
Agent1_Alpha_Loss : 0.8117501735687256
Agent1_Temperature : 0.09187611557410194
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 301 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 302 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 303 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 304 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 305 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 306 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 307 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 308 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 309 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 310 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -25.286510467529297
Agent0_Eval_StdReturn : 20.459747314453125
Agent0_Eval_MaxReturn : 6.085593223571777
Agent0_Eval_MinReturn : -57.886348724365234
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -21.134723663330078
Agent0_Train_StdReturn : 31.16391944885254
Agent0_Train_MaxReturn : 27.580158233642578
Agent0_Train_MinReturn : -85.47311401367188
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 466500
Agent0_TimeSinceStart : 735.0952401161194
Agent0_Critic_Loss : 0.398018479347229
Agent0_Actor_Loss : -0.3958684802055359
Agent0_Alpha_Loss : 0.8079240322113037
Agent0_Temperature : 0.0916534327516035
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -26.192956924438477
Agent1_Eval_StdReturn : 11.477371215820312
Agent1_Eval_MaxReturn : -12.226518630981445
Agent1_Eval_MinReturn : -49.11680603027344
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -24.602725982666016
Agent1_Train_StdReturn : 15.936698913574219
Agent1_Train_MaxReturn : 4.593789100646973
Agent1_Train_MinReturn : -47.22639465332031
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 466500
Agent1_TimeSinceStart : 737.1812431812286
Agent1_Critic_Loss : 0.332567423582077
Agent1_Actor_Loss : -0.5542720556259155
Agent1_Alpha_Loss : 0.8019198775291443
Agent1_Temperature : 0.09161719579519823
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 311 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 312 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 313 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 314 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 315 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 316 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 317 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 318 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 319 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 320 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -24.705801010131836
Agent0_Eval_StdReturn : 19.075075149536133
Agent0_Eval_MaxReturn : 2.4338719844818115
Agent0_Eval_MinReturn : -54.608985900878906
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -22.203445434570312
Agent0_Train_StdReturn : 13.708393096923828
Agent0_Train_MaxReturn : 2.7937564849853516
Agent0_Train_MinReturn : -41.12067413330078
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 481500
Agent0_TimeSinceStart : 758.1830451488495
Agent0_Critic_Loss : 0.33031201362609863
Agent0_Actor_Loss : -0.5101511478424072
Agent0_Alpha_Loss : 0.821237325668335
Agent0_Temperature : 0.09139412485821331
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -13.947354316711426
Agent1_Eval_StdReturn : 18.0933780670166
Agent1_Eval_MaxReturn : 10.643583297729492
Agent1_Eval_MinReturn : -39.726749420166016
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -17.595245361328125
Agent1_Train_StdReturn : 14.696773529052734
Agent1_Train_MaxReturn : 8.018087387084961
Agent1_Train_MinReturn : -50.69114303588867
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 481500
Agent1_TimeSinceStart : 760.2728986740112
Agent1_Critic_Loss : 0.3165989816188812
Agent1_Actor_Loss : -0.5600560903549194
Agent1_Alpha_Loss : 0.8025144338607788
Agent1_Temperature : 0.09136068700596023
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 321 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 322 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 323 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 324 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 325 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 326 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 327 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 328 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 329 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 330 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -12.092443466186523
Agent0_Eval_StdReturn : 13.87833023071289
Agent0_Eval_MaxReturn : 16.807514190673828
Agent0_Eval_MinReturn : -26.641738891601562
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -15.428210258483887
Agent0_Train_StdReturn : 10.815107345581055
Agent0_Train_MaxReturn : 0.35452842712402344
Agent0_Train_MinReturn : -35.20900344848633
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 496500
Agent0_TimeSinceStart : 781.239821434021
Agent0_Critic_Loss : 0.30838149785995483
Agent0_Actor_Loss : -0.4863130748271942
Agent0_Alpha_Loss : 0.8117921352386475
Agent0_Temperature : 0.09113487731211635
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -32.02956771850586
Agent1_Eval_StdReturn : 19.849437713623047
Agent1_Eval_MaxReturn : -4.152190208435059
Agent1_Eval_MinReturn : -60.177974700927734
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -18.467260360717773
Agent1_Train_StdReturn : 18.557706832885742
Agent1_Train_MaxReturn : -0.14077472686767578
Agent1_Train_MinReturn : -51.77149963378906
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 496500
Agent1_TimeSinceStart : 783.3320097923279
Agent1_Critic_Loss : 0.40743908286094666
Agent1_Actor_Loss : -0.6035406589508057
Agent1_Alpha_Loss : 0.7834727168083191
Agent1_Temperature : 0.09110506259273615
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 331 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 332 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 333 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 334 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 335 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 336 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 337 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 338 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 339 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 340 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -26.694995880126953
Agent0_Eval_StdReturn : 18.066043853759766
Agent0_Eval_MaxReturn : 11.272394180297852
Agent0_Eval_MinReturn : -52.916011810302734
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -9.274656295776367
Agent0_Train_StdReturn : 14.302080154418945
Agent0_Train_MaxReturn : 11.882001876831055
Agent0_Train_MinReturn : -31.93508529663086
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 511500
Agent0_TimeSinceStart : 804.3394358158112
Agent0_Critic_Loss : 0.3211015462875366
Agent0_Actor_Loss : -0.47457432746887207
Agent0_Alpha_Loss : 0.811062216758728
Agent0_Temperature : 0.09087606895171785
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -22.26936149597168
Agent1_Eval_StdReturn : 19.707082748413086
Agent1_Eval_MaxReturn : 11.060861587524414
Agent1_Eval_MinReturn : -61.7706184387207
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -22.84769058227539
Agent1_Train_StdReturn : 17.299850463867188
Agent1_Train_MaxReturn : 10.799400329589844
Agent1_Train_MinReturn : -45.96625518798828
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 511500
Agent1_TimeSinceStart : 806.4315392971039
Agent1_Critic_Loss : 0.35649803280830383
Agent1_Actor_Loss : -0.5406082272529602
Agent1_Alpha_Loss : 0.7848169207572937
Agent1_Temperature : 0.09085122267444683
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 341 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 342 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 343 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 344 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 345 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 346 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 347 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 348 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 349 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 350 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -9.7374267578125
Agent0_Eval_StdReturn : 15.898818969726562
Agent0_Eval_MaxReturn : 11.414478302001953
Agent0_Eval_MinReturn : -47.168540954589844
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -20.6744327545166
Agent0_Train_StdReturn : 13.608880996704102
Agent0_Train_MaxReturn : 1.1516590118408203
Agent0_Train_MinReturn : -42.95416259765625
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 526500
Agent0_TimeSinceStart : 827.4455783367157
Agent0_Critic_Loss : 0.3436412215232849
Agent0_Actor_Loss : -0.5985157489776611
Agent0_Alpha_Loss : 0.8002958297729492
Agent0_Temperature : 0.09061838429933841
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -19.112735748291016
Agent1_Eval_StdReturn : 15.32368278503418
Agent1_Eval_MaxReturn : -1.2861032485961914
Agent1_Eval_MinReturn : -55.6138916015625
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -12.882573127746582
Agent1_Train_StdReturn : 16.83832550048828
Agent1_Train_MaxReturn : 15.277576446533203
Agent1_Train_MinReturn : -49.259132385253906
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 526500
Agent1_TimeSinceStart : 829.5372533798218
Agent1_Critic_Loss : 0.31648749113082886
Agent1_Actor_Loss : -0.6032606363296509
Agent1_Alpha_Loss : 0.7741221785545349
Agent1_Temperature : 0.0905990092702799
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 351 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 352 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 353 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 354 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 355 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 356 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 357 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 358 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 359 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 360 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -18.15387725830078
Agent0_Eval_StdReturn : 15.39348316192627
Agent0_Eval_MaxReturn : 12.493901252746582
Agent0_Eval_MinReturn : -40.753517150878906
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -22.97520637512207
Agent0_Train_StdReturn : 26.14950942993164
Agent0_Train_MaxReturn : 20.838565826416016
Agent0_Train_MinReturn : -69.32353973388672
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 541500
Agent0_TimeSinceStart : 850.5801239013672
Agent0_Critic_Loss : 0.48618483543395996
Agent0_Actor_Loss : -0.46394944190979004
Agent0_Alpha_Loss : 0.7875508069992065
Agent0_Temperature : 0.09036260891732288
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -26.226613998413086
Agent1_Eval_StdReturn : 17.123353958129883
Agent1_Eval_MaxReturn : -3.7045233249664307
Agent1_Eval_MinReturn : -61.8442497253418
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -16.9221248626709
Agent1_Train_StdReturn : 18.236705780029297
Agent1_Train_MaxReturn : 11.117691993713379
Agent1_Train_MinReturn : -53.55839538574219
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 541500
Agent1_TimeSinceStart : 852.6754024028778
Agent1_Critic_Loss : 0.3456694185733795
Agent1_Actor_Loss : -0.6444045305252075
Agent1_Alpha_Loss : 0.7947706580162048
Agent1_Temperature : 0.09034838989953234
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 361 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 362 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 363 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 364 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 365 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 366 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 367 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 368 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 369 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 370 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -18.107250213623047
Agent0_Eval_StdReturn : 10.899334907531738
Agent0_Eval_MaxReturn : 4.725037574768066
Agent0_Eval_MinReturn : -34.189884185791016
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -12.650533676147461
Agent0_Train_StdReturn : 15.09224796295166
Agent0_Train_MaxReturn : 12.208056449890137
Agent0_Train_MinReturn : -41.97841262817383
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 556500
Agent0_TimeSinceStart : 873.735437631607
Agent0_Critic_Loss : 0.3925657868385315
Agent0_Actor_Loss : -0.5470947027206421
Agent0_Alpha_Loss : 0.7964504957199097
Agent0_Temperature : 0.09010747707300207
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -15.982856750488281
Agent1_Eval_StdReturn : 11.797380447387695
Agent1_Eval_MaxReturn : -2.0168519020080566
Agent1_Eval_MinReturn : -39.419490814208984
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -16.218523025512695
Agent1_Train_StdReturn : 17.079496383666992
Agent1_Train_MaxReturn : 6.706143856048584
Agent1_Train_MinReturn : -49.2998161315918
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 556500
Agent1_TimeSinceStart : 875.8316371440887
Agent1_Critic_Loss : 0.3383156359195709
Agent1_Actor_Loss : -0.6574286222457886
Agent1_Alpha_Loss : 0.781275749206543
Agent1_Temperature : 0.09009796296643147
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 371 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 372 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 373 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 374 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 375 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 376 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 377 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 378 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 379 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 380 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -11.832112312316895
Agent0_Eval_StdReturn : 11.276193618774414
Agent0_Eval_MaxReturn : 2.628052234649658
Agent0_Eval_MinReturn : -32.549957275390625
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -23.425827026367188
Agent0_Train_StdReturn : 19.849689483642578
Agent0_Train_MaxReturn : 4.7365827560424805
Agent0_Train_MinReturn : -54.607154846191406
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 571500
Agent0_TimeSinceStart : 896.9369702339172
Agent0_Critic_Loss : 0.31302982568740845
Agent0_Actor_Loss : -0.46345093846321106
Agent0_Alpha_Loss : 0.7906743288040161
Agent0_Temperature : 0.08985391727659968
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -20.37346839904785
Agent1_Eval_StdReturn : 11.32889175415039
Agent1_Eval_MaxReturn : 3.78753662109375
Agent1_Eval_MinReturn : -38.21631622314453
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -16.713153839111328
Agent1_Train_StdReturn : 12.173930168151855
Agent1_Train_MaxReturn : -1.034379005432129
Agent1_Train_MinReturn : -38.78723907470703
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 571500
Agent1_TimeSinceStart : 899.0424463748932
Agent1_Critic_Loss : 0.28599822521209717
Agent1_Actor_Loss : -0.5683072805404663
Agent1_Alpha_Loss : 0.7852461338043213
Agent1_Temperature : 0.08984780687990195
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 381 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 382 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 383 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 384 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 385 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 386 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 387 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 388 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 389 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 390 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -25.997268676757812
Agent0_Eval_StdReturn : 10.575004577636719
Agent0_Eval_MaxReturn : -10.781713485717773
Agent0_Eval_MinReturn : -44.731956481933594
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -13.210467338562012
Agent0_Train_StdReturn : 8.28680419921875
Agent0_Train_MaxReturn : -0.17941761016845703
Agent0_Train_MinReturn : -26.807971954345703
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 586500
Agent0_TimeSinceStart : 920.1749277114868
Agent0_Critic_Loss : 0.40279829502105713
Agent0_Actor_Loss : -0.4834907352924347
Agent0_Alpha_Loss : 0.808134138584137
Agent0_Temperature : 0.08960221398008991
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -15.147132873535156
Agent1_Eval_StdReturn : 13.502035140991211
Agent1_Eval_MaxReturn : 2.2788445949554443
Agent1_Eval_MinReturn : -43.87636184692383
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -17.501720428466797
Agent1_Train_StdReturn : 14.089155197143555
Agent1_Train_MaxReturn : 3.5124454498291016
Agent1_Train_MinReturn : -50.221431732177734
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 586500
Agent1_TimeSinceStart : 922.2825510501862
Agent1_Critic_Loss : 0.4392952620983124
Agent1_Actor_Loss : -0.5180997252464294
Agent1_Alpha_Loss : 0.7640551328659058
Agent1_Temperature : 0.08959916800692995
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 391 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 392 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 393 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 394 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 395 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 396 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 397 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 398 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 399 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 400 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -22.444549560546875
Agent0_Eval_StdReturn : 11.149872779846191
Agent0_Eval_MaxReturn : -5.827047348022461
Agent0_Eval_MinReturn : -44.41047668457031
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -12.501476287841797
Agent0_Train_StdReturn : 13.870780944824219
Agent0_Train_MaxReturn : 11.38357162475586
Agent0_Train_MinReturn : -33.03313064575195
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 601500
Agent0_TimeSinceStart : 943.4200482368469
Agent0_Critic_Loss : 0.37248072028160095
Agent0_Actor_Loss : -0.4326912462711334
Agent0_Alpha_Loss : 0.7808903455734253
Agent0_Temperature : 0.08935138800448657
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -22.994487762451172
Agent1_Eval_StdReturn : 10.64844799041748
Agent1_Eval_MaxReturn : -6.120430946350098
Agent1_Eval_MinReturn : -39.420143127441406
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -17.722867965698242
Agent1_Train_StdReturn : 6.0130934715271
Agent1_Train_MaxReturn : -9.915961265563965
Agent1_Train_MinReturn : -28.782270431518555
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 601500
Agent1_TimeSinceStart : 945.5203902721405
Agent1_Critic_Loss : 0.3385634124279022
Agent1_Actor_Loss : -0.5979757308959961
Agent1_Alpha_Loss : 0.7597662210464478
Agent1_Temperature : 0.08935195025783985
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 401 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 402 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 403 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 404 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 405 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 406 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 407 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 408 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 409 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 410 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -10.20018196105957
Agent0_Eval_StdReturn : 11.715714454650879
Agent0_Eval_MaxReturn : 13.723154067993164
Agent0_Eval_MinReturn : -27.522520065307617
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -17.33185386657715
Agent0_Train_StdReturn : 15.995111465454102
Agent0_Train_MaxReturn : 15.997194290161133
Agent0_Train_MinReturn : -47.17620849609375
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 616500
Agent0_TimeSinceStart : 966.6898112297058
Agent0_Critic_Loss : 0.3779869079589844
Agent0_Actor_Loss : -0.39740389585494995
Agent0_Alpha_Loss : 0.8043760061264038
Agent0_Temperature : 0.0891018371798401
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -18.689796447753906
Agent1_Eval_StdReturn : 13.26981258392334
Agent1_Eval_MaxReturn : 8.217309951782227
Agent1_Eval_MinReturn : -47.49790954589844
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -11.210206985473633
Agent1_Train_StdReturn : 14.216797828674316
Agent1_Train_MaxReturn : 13.718526840209961
Agent1_Train_MinReturn : -38.88214874267578
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 616500
Agent1_TimeSinceStart : 968.793618440628
Agent1_Critic_Loss : 0.4036501348018646
Agent1_Actor_Loss : -0.6397807598114014
Agent1_Alpha_Loss : 0.7610278725624084
Agent1_Temperature : 0.08910630198173848
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 411 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 412 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 413 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 414 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 415 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 416 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 417 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 418 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 419 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 420 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -17.163341522216797
Agent0_Eval_StdReturn : 14.15212631225586
Agent0_Eval_MaxReturn : 3.1051535606384277
Agent0_Eval_MinReturn : -41.406639099121094
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -16.336748123168945
Agent0_Train_StdReturn : 20.081872940063477
Agent0_Train_MaxReturn : 31.21438217163086
Agent0_Train_MinReturn : -42.0771598815918
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 631500
Agent0_TimeSinceStart : 989.9534254074097
Agent0_Critic_Loss : 0.35685354471206665
Agent0_Actor_Loss : -0.4378851056098938
Agent0_Alpha_Loss : 0.7840607166290283
Agent0_Temperature : 0.0888509574546071
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -18.997669219970703
Agent1_Eval_StdReturn : 17.856204986572266
Agent1_Eval_MaxReturn : 17.324085235595703
Agent1_Eval_MinReturn : -42.302520751953125
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -11.85605525970459
Agent1_Train_StdReturn : 15.134965896606445
Agent1_Train_MaxReturn : 17.719812393188477
Agent1_Train_MinReturn : -39.80769348144531
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 631500
Agent1_TimeSinceStart : 992.0592906475067
Agent1_Critic_Loss : 0.3824191093444824
Agent1_Actor_Loss : -0.5684844255447388
Agent1_Alpha_Loss : 0.7877401113510132
Agent1_Temperature : 0.08886057218476848
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 421 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 422 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 423 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 424 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 425 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 426 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 427 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 428 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 429 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 430 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -9.720501899719238
Agent0_Eval_StdReturn : 17.581661224365234
Agent0_Eval_MaxReturn : 24.73849868774414
Agent0_Eval_MinReturn : -42.77692413330078
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -15.639472961425781
Agent0_Train_StdReturn : 9.1926851272583
Agent0_Train_MaxReturn : 2.408247709274292
Agent0_Train_MinReturn : -24.685691833496094
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 646500
Agent0_TimeSinceStart : 1013.2403211593628
Agent0_Critic_Loss : 0.359536349773407
Agent0_Actor_Loss : -0.5480346083641052
Agent0_Alpha_Loss : 0.794967770576477
Agent0_Temperature : 0.08859926605026648
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -17.985666275024414
Agent1_Eval_StdReturn : 15.211503982543945
Agent1_Eval_MaxReturn : 15.384761810302734
Agent1_Eval_MinReturn : -35.63591384887695
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -15.754678726196289
Agent1_Train_StdReturn : 14.444207191467285
Agent1_Train_MaxReturn : 14.761960983276367
Agent1_Train_MinReturn : -29.58713150024414
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 646500
Agent1_TimeSinceStart : 1015.3491938114166
Agent1_Critic_Loss : 0.4060973823070526
Agent1_Actor_Loss : -0.6632694602012634
Agent1_Alpha_Loss : 0.7819362878799438
Agent1_Temperature : 0.08861416865644443
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 431 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 432 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 433 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 434 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 435 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 436 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 437 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 438 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 439 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 440 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -16.15285301208496
Agent0_Eval_StdReturn : 14.945289611816406
Agent0_Eval_MaxReturn : 10.669755935668945
Agent0_Eval_MinReturn : -41.33992385864258
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -10.093859672546387
Agent0_Train_StdReturn : 12.055289268493652
Agent0_Train_MaxReturn : 4.1100263595581055
Agent0_Train_MinReturn : -33.594051361083984
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 661500
Agent0_TimeSinceStart : 1036.4789571762085
Agent0_Critic_Loss : 0.33811354637145996
Agent0_Actor_Loss : -0.6700525879859924
Agent0_Alpha_Loss : 0.8040476441383362
Agent0_Temperature : 0.08834801943339068
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -16.688291549682617
Agent1_Eval_StdReturn : 14.360786437988281
Agent1_Eval_MaxReturn : -0.09733033180236816
Agent1_Eval_MinReturn : -42.66958236694336
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -19.734081268310547
Agent1_Train_StdReturn : 16.484752655029297
Agent1_Train_MaxReturn : 2.9459357261657715
Agent1_Train_MinReturn : -51.64549255371094
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 661500
Agent1_TimeSinceStart : 1038.5786154270172
Agent1_Critic_Loss : 0.38777655363082886
Agent1_Actor_Loss : -0.4490404725074768
Agent1_Alpha_Loss : 0.7958188056945801
Agent1_Temperature : 0.08836603041050695
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 441 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 442 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 443 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 444 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 445 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 446 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 447 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 448 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 449 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 450 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -18.71817398071289
Agent0_Eval_StdReturn : 24.98949432373047
Agent0_Eval_MaxReturn : 27.206693649291992
Agent0_Eval_MinReturn : -65.95061492919922
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -8.136739730834961
Agent0_Train_StdReturn : 11.899829864501953
Agent0_Train_MaxReturn : 17.932201385498047
Agent0_Train_MinReturn : -26.16686248779297
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 676500
Agent0_TimeSinceStart : 1059.7539377212524
Agent0_Critic_Loss : 0.3658323585987091
Agent0_Actor_Loss : -0.5716757774353027
Agent0_Alpha_Loss : 0.7851812839508057
Agent0_Temperature : 0.08809778417335273
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -16.235851287841797
Agent1_Eval_StdReturn : 11.545921325683594
Agent1_Eval_MaxReturn : 3.9270429611206055
Agent1_Eval_MinReturn : -37.83555603027344
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -10.45598030090332
Agent1_Train_StdReturn : 17.569700241088867
Agent1_Train_MaxReturn : 11.94528579711914
Agent1_Train_MinReturn : -34.97099685668945
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 676500
Agent1_TimeSinceStart : 1061.8863756656647
Agent1_Critic_Loss : 0.32870355248451233
Agent1_Actor_Loss : -0.5762958526611328
Agent1_Alpha_Loss : 0.7899541258811951
Agent1_Temperature : 0.08811774313569137
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 451 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 452 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 453 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 454 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 455 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 456 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 457 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 458 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 459 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 460 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -17.89453125
Agent0_Eval_StdReturn : 18.630647659301758
Agent0_Eval_MaxReturn : 6.804923057556152
Agent0_Eval_MinReturn : -51.59268569946289
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -17.469364166259766
Agent0_Train_StdReturn : 16.761272430419922
Agent0_Train_MaxReturn : -0.7047944068908691
Agent0_Train_MinReturn : -59.493621826171875
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 691500
Agent0_TimeSinceStart : 1083.092113018036
Agent0_Critic_Loss : 0.3418712913990021
Agent0_Actor_Loss : -0.5254909992218018
Agent0_Alpha_Loss : 0.7915223240852356
Agent0_Temperature : 0.08784778217283508
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -14.494775772094727
Agent1_Eval_StdReturn : 17.285531997680664
Agent1_Eval_MaxReturn : 13.237944602966309
Agent1_Eval_MinReturn : -45.240142822265625
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -8.967280387878418
Agent1_Train_StdReturn : 19.96124267578125
Agent1_Train_MaxReturn : 14.671859741210938
Agent1_Train_MinReturn : -53.49006652832031
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 691500
Agent1_TimeSinceStart : 1085.1964383125305
Agent1_Critic_Loss : 0.48649871349334717
Agent1_Actor_Loss : -0.6212393641471863
Agent1_Alpha_Loss : 0.7896752953529358
Agent1_Temperature : 0.08787011680335544
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 461 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 462 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 463 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 464 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 465 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 466 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 467 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 468 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 469 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 470 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -8.332423210144043
Agent0_Eval_StdReturn : 18.985857009887695
Agent0_Eval_MaxReturn : 8.785791397094727
Agent0_Eval_MinReturn : -59.463783264160156
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -20.649295806884766
Agent0_Train_StdReturn : 16.6437931060791
Agent0_Train_MaxReturn : 0.15791276097297668
Agent0_Train_MinReturn : -53.54070281982422
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 706500
Agent0_TimeSinceStart : 1106.342360496521
Agent0_Critic_Loss : 0.3997959494590759
Agent0_Actor_Loss : -0.6031081080436707
Agent0_Alpha_Loss : 0.7880992889404297
Agent0_Temperature : 0.08759820014441139
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -13.312332153320312
Agent1_Eval_StdReturn : 13.615640640258789
Agent1_Eval_MaxReturn : 6.56608772277832
Agent1_Eval_MinReturn : -39.286293029785156
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -13.835952758789062
Agent1_Train_StdReturn : 15.374527931213379
Agent1_Train_MaxReturn : 8.768317222595215
Agent1_Train_MinReturn : -51.09318923950195
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 706500
Agent1_TimeSinceStart : 1108.4399936199188
Agent1_Critic_Loss : 0.337207555770874
Agent1_Actor_Loss : -0.5628470182418823
Agent1_Alpha_Loss : 0.7806682586669922
Agent1_Temperature : 0.08762316815399772
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 471 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 472 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 473 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 474 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 475 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 476 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 477 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 478 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 479 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 480 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -20.296253204345703
Agent0_Eval_StdReturn : 14.150328636169434
Agent0_Eval_MaxReturn : -0.7684059143066406
Agent0_Eval_MinReturn : -39.143184661865234
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -8.19139575958252
Agent0_Train_StdReturn : 14.571707725524902
Agent0_Train_MaxReturn : 16.20867156982422
Agent0_Train_MinReturn : -36.50791931152344
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 721500
Agent0_TimeSinceStart : 1129.5857138633728
Agent0_Critic_Loss : 0.3565486669540405
Agent0_Actor_Loss : -0.5714972019195557
Agent0_Alpha_Loss : 0.7806117534637451
Agent0_Temperature : 0.0873494509041133
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -10.293214797973633
Agent1_Eval_StdReturn : 13.14430046081543
Agent1_Eval_MaxReturn : 13.31221866607666
Agent1_Eval_MinReturn : -41.096954345703125
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -24.558040618896484
Agent1_Train_StdReturn : 17.867481231689453
Agent1_Train_MaxReturn : -6.132192611694336
Agent1_Train_MinReturn : -71.5452880859375
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 721500
Agent1_TimeSinceStart : 1131.688040971756
Agent1_Critic_Loss : 0.36133092641830444
Agent1_Actor_Loss : -0.53892982006073
Agent1_Alpha_Loss : 0.7825480699539185
Agent1_Temperature : 0.08737545261181455
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 481 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 482 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 483 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 484 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 485 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 486 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 487 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 488 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 489 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 490 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -26.9721736907959
Agent0_Eval_StdReturn : 27.22003936767578
Agent0_Eval_MaxReturn : 2.529693603515625
Agent0_Eval_MinReturn : -98.80030059814453
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -18.960947036743164
Agent0_Train_StdReturn : 19.746057510375977
Agent0_Train_MaxReturn : 13.651792526245117
Agent0_Train_MinReturn : -52.16978454589844
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 736500
Agent0_TimeSinceStart : 1152.7931175231934
Agent0_Critic_Loss : 0.34584298729896545
Agent0_Actor_Loss : -0.502711832523346
Agent0_Alpha_Loss : 0.7994934320449829
Agent0_Temperature : 0.08710066859367586
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -13.786158561706543
Agent1_Eval_StdReturn : 13.104702949523926
Agent1_Eval_MaxReturn : 6.125530242919922
Agent1_Eval_MinReturn : -44.78725051879883
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -19.735368728637695
Agent1_Train_StdReturn : 22.433713912963867
Agent1_Train_MaxReturn : 6.066374778747559
Agent1_Train_MinReturn : -65.20808410644531
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 736500
Agent1_TimeSinceStart : 1154.8896207809448
Agent1_Critic_Loss : 0.3232502043247223
Agent1_Actor_Loss : -0.7856799960136414
Agent1_Alpha_Loss : 0.7912164926528931
Agent1_Temperature : 0.0871269977234004
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 491 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 492 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 493 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 494 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 495 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 496 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 497 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 498 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 499 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 500 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -15.237652778625488
Agent0_Eval_StdReturn : 16.94461441040039
Agent0_Eval_MaxReturn : 10.275437355041504
Agent0_Eval_MinReturn : -49.24978256225586
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -6.125749588012695
Agent0_Train_StdReturn : 16.5716552734375
Agent0_Train_MaxReturn : 16.16585922241211
Agent0_Train_MinReturn : -39.582618713378906
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 751500
Agent0_TimeSinceStart : 1176.0013694763184
Agent0_Critic_Loss : 0.43660685420036316
Agent0_Actor_Loss : -0.4757356345653534
Agent0_Alpha_Loss : 0.7857452630996704
Agent0_Temperature : 0.08685114255339085
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -13.65434741973877
Agent1_Eval_StdReturn : 15.43779468536377
Agent1_Eval_MaxReturn : 7.170194625854492
Agent1_Eval_MinReturn : -47.518028259277344
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -13.110410690307617
Agent1_Train_StdReturn : 12.572164535522461
Agent1_Train_MaxReturn : 6.817826271057129
Agent1_Train_MinReturn : -33.68421173095703
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 751500
Agent1_TimeSinceStart : 1178.101301908493
Agent1_Critic_Loss : 0.4470776319503784
Agent1_Actor_Loss : -0.6786742210388184
Agent1_Alpha_Loss : 0.799828052520752
Agent1_Temperature : 0.08687912338074963
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 501 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 502 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 503 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 504 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 505 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 506 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 507 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 508 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 509 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 510 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -15.971814155578613
Agent0_Eval_StdReturn : 16.757652282714844
Agent0_Eval_MaxReturn : 7.365053653717041
Agent0_Eval_MinReturn : -59.27269744873047
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -9.207478523254395
Agent0_Train_StdReturn : 16.403488159179688
Agent0_Train_MaxReturn : 31.375375747680664
Agent0_Train_MinReturn : -27.958858489990234
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 766500
Agent0_TimeSinceStart : 1199.187070608139
Agent0_Critic_Loss : 0.443951815366745
Agent0_Actor_Loss : -0.5360262393951416
Agent0_Alpha_Loss : 0.7922095656394958
Agent0_Temperature : 0.08660275211411024
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -35.503074645996094
Agent1_Eval_StdReturn : 18.144161224365234
Agent1_Eval_MaxReturn : -7.983528137207031
Agent1_Eval_MinReturn : -67.4659423828125
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -15.020672798156738
Agent1_Train_StdReturn : 19.735261917114258
Agent1_Train_MaxReturn : 2.6154518127441406
Agent1_Train_MinReturn : -67.12481689453125
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 766500
Agent1_TimeSinceStart : 1201.2803990840912
Agent1_Critic_Loss : 0.38621336221694946
Agent1_Actor_Loss : -0.5560240149497986
Agent1_Alpha_Loss : 0.7960377931594849
Agent1_Temperature : 0.0866306791394106
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 511 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 512 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 513 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 514 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 515 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 516 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 517 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 518 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 519 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 520 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -22.96804428100586
Agent0_Eval_StdReturn : 14.381937980651855
Agent0_Eval_MaxReturn : 6.5777106285095215
Agent0_Eval_MinReturn : -38.15611267089844
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -11.321078300476074
Agent0_Train_StdReturn : 11.139625549316406
Agent0_Train_MaxReturn : 2.998292922973633
Agent0_Train_MinReturn : -37.68669128417969
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 781500
Agent0_TimeSinceStart : 1222.4131844043732
Agent0_Critic_Loss : 0.4701997637748718
Agent0_Actor_Loss : -0.6182149052619934
Agent0_Alpha_Loss : 0.7915887832641602
Agent0_Temperature : 0.08635463000561747
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -25.703866958618164
Agent1_Eval_StdReturn : 19.106704711914062
Agent1_Eval_MaxReturn : -8.119465827941895
Agent1_Eval_MinReturn : -74.39430236816406
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -33.107261657714844
Agent1_Train_StdReturn : 27.664600372314453
Agent1_Train_MaxReturn : 8.06783390045166
Agent1_Train_MinReturn : -72.48590087890625
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 781500
Agent1_TimeSinceStart : 1224.5046393871307
Agent1_Critic_Loss : 0.41506752371788025
Agent1_Actor_Loss : -0.590158224105835
Agent1_Alpha_Loss : 0.7954953908920288
Agent1_Temperature : 0.08638205687349108
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 521 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 522 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 523 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 524 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 525 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 526 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 527 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 528 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 529 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 530 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -15.064974784851074
Agent0_Eval_StdReturn : 11.127603530883789
Agent0_Eval_MaxReturn : 0.8607931137084961
Agent0_Eval_MinReturn : -33.805442810058594
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -13.828910827636719
Agent0_Train_StdReturn : 15.999634742736816
Agent0_Train_MaxReturn : 6.829071044921875
Agent0_Train_MinReturn : -46.15393829345703
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 796500
Agent0_TimeSinceStart : 1246.4647648334503
Agent0_Critic_Loss : 0.39476877450942993
Agent0_Actor_Loss : -0.646602988243103
Agent0_Alpha_Loss : 0.7922431230545044
Agent0_Temperature : 0.08610756498225813
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -16.59089469909668
Agent1_Eval_StdReturn : 14.643315315246582
Agent1_Eval_MaxReturn : 11.577012062072754
Agent1_Eval_MinReturn : -44.96072769165039
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -17.317636489868164
Agent1_Train_StdReturn : 25.941194534301758
Agent1_Train_MaxReturn : 21.707683563232422
Agent1_Train_MinReturn : -56.0850715637207
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 796500
Agent1_TimeSinceStart : 1248.6339497566223
Agent1_Critic_Loss : 0.44597703218460083
Agent1_Actor_Loss : -0.5065741539001465
Agent1_Alpha_Loss : 0.7901157736778259
Agent1_Temperature : 0.08613407384343053
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 531 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 532 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 533 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 534 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 535 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 536 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 537 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 538 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 539 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 540 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -25.620025634765625
Agent0_Eval_StdReturn : 25.27305793762207
Agent0_Eval_MaxReturn : 22.678247451782227
Agent0_Eval_MinReturn : -62.2039680480957
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -2.378209352493286
Agent0_Train_StdReturn : 12.554793357849121
Agent0_Train_MaxReturn : 16.686830520629883
Agent0_Train_MinReturn : -19.258464813232422
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 811500
Agent0_TimeSinceStart : 1270.5051839351654
Agent0_Critic_Loss : 0.4086218476295471
Agent0_Actor_Loss : -0.5688501596450806
Agent0_Alpha_Loss : 0.7978488206863403
Agent0_Temperature : 0.08586161554483784
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -20.781299591064453
Agent1_Eval_StdReturn : 9.207722663879395
Agent1_Eval_MaxReturn : -3.632359504699707
Agent1_Eval_MinReturn : -36.68057632446289
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -35.42045593261719
Agent1_Train_StdReturn : 18.135961532592773
Agent1_Train_MaxReturn : 3.2440085411071777
Agent1_Train_MinReturn : -60.14325714111328
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 811500
Agent1_TimeSinceStart : 1272.6721601486206
Agent1_Critic_Loss : 0.6915026903152466
Agent1_Actor_Loss : -0.6919418573379517
Agent1_Alpha_Loss : 0.787150502204895
Agent1_Temperature : 0.08588686836562825
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 541 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 542 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 543 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 544 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 545 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 546 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 547 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 548 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 549 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 550 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -32.34202194213867
Agent0_Eval_StdReturn : 22.101709365844727
Agent0_Eval_MaxReturn : 7.059003829956055
Agent0_Eval_MinReturn : -62.01729965209961
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -12.287359237670898
Agent0_Train_StdReturn : 18.83169174194336
Agent0_Train_MaxReturn : 14.231830596923828
Agent0_Train_MinReturn : -46.80339050292969
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 826500
Agent0_TimeSinceStart : 1294.4174106121063
Agent0_Critic_Loss : 0.42024892568588257
Agent0_Actor_Loss : -0.5597076416015625
Agent0_Alpha_Loss : 0.7963374257087708
Agent0_Temperature : 0.0856151337962625
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -25.848724365234375
Agent1_Eval_StdReturn : 20.928709030151367
Agent1_Eval_MaxReturn : 10.280214309692383
Agent1_Eval_MinReturn : -60.84492492675781
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -14.39128303527832
Agent1_Train_StdReturn : 13.61208438873291
Agent1_Train_MaxReturn : 7.050969123840332
Agent1_Train_MinReturn : -31.83637237548828
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 826500
Agent1_TimeSinceStart : 1296.5746321678162
Agent1_Critic_Loss : 0.529310941696167
Agent1_Actor_Loss : -0.6276315450668335
Agent1_Alpha_Loss : 0.7816053628921509
Agent1_Temperature : 0.08564209162945499
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 551 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 552 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 553 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 554 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 555 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 556 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 557 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 558 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 559 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 560 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -12.484884262084961
Agent0_Eval_StdReturn : 21.396221160888672
Agent0_Eval_MaxReturn : 24.040904998779297
Agent0_Eval_MinReturn : -42.83885192871094
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -13.527908325195312
Agent0_Train_StdReturn : 9.398762702941895
Agent0_Train_MaxReturn : -0.8634824752807617
Agent0_Train_MinReturn : -34.20330047607422
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 841500
Agent0_TimeSinceStart : 1318.2533712387085
Agent0_Critic_Loss : 0.5253984928131104
Agent0_Actor_Loss : -0.5028151273727417
Agent0_Alpha_Loss : 0.7963211536407471
Agent0_Temperature : 0.08536950015580727
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -29.271503448486328
Agent1_Eval_StdReturn : 15.711421012878418
Agent1_Eval_MaxReturn : 1.366750717163086
Agent1_Eval_MinReturn : -52.86723327636719
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -11.593932151794434
Agent1_Train_StdReturn : 11.63668155670166
Agent1_Train_MaxReturn : 12.093856811523438
Agent1_Train_MinReturn : -23.85800552368164
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 841500
Agent1_TimeSinceStart : 1320.4182007312775
Agent1_Critic_Loss : 0.4778120517730713
Agent1_Actor_Loss : -0.7811667323112488
Agent1_Alpha_Loss : 0.7839361429214478
Agent1_Temperature : 0.08539901096532972
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 561 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 562 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 563 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 564 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 565 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 566 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 567 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 568 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 569 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 570 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -2.8857905864715576
Agent0_Eval_StdReturn : 16.45833396911621
Agent0_Eval_MaxReturn : 23.10932731628418
Agent0_Eval_MinReturn : -25.10063934326172
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -7.851675987243652
Agent0_Train_StdReturn : 20.186731338500977
Agent0_Train_MaxReturn : 21.374069213867188
Agent0_Train_MinReturn : -38.509490966796875
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 856500
Agent0_TimeSinceStart : 1342.1093904972076
Agent0_Critic_Loss : 0.5747071504592896
Agent0_Actor_Loss : -0.5751829147338867
Agent0_Alpha_Loss : 0.7993736267089844
Agent0_Temperature : 0.08512352634156915
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -15.264880180358887
Agent1_Eval_StdReturn : 14.097529411315918
Agent1_Eval_MaxReturn : 7.58270263671875
Agent1_Eval_MinReturn : -41.956512451171875
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -13.663989067077637
Agent1_Train_StdReturn : 12.466405868530273
Agent1_Train_MaxReturn : 7.0241241455078125
Agent1_Train_MinReturn : -30.879980087280273
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 856500
Agent1_TimeSinceStart : 1344.2753472328186
Agent1_Critic_Loss : 0.44440239667892456
Agent1_Actor_Loss : -0.6271694898605347
Agent1_Alpha_Loss : 0.7543730735778809
Agent1_Temperature : 0.08515836487789404
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 571 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 572 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 573 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 574 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 575 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 576 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 577 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 578 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 579 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 580 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -22.789154052734375
Agent0_Eval_StdReturn : 12.962625503540039
Agent0_Eval_MaxReturn : -4.278965950012207
Agent0_Eval_MinReturn : -43.74451446533203
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -10.081528663635254
Agent0_Train_StdReturn : 13.350142478942871
Agent0_Train_MaxReturn : 10.904486656188965
Agent0_Train_MinReturn : -32.05449676513672
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 871500
Agent0_TimeSinceStart : 1365.9918329715729
Agent0_Critic_Loss : 0.4891481101512909
Agent0_Actor_Loss : -0.783216118812561
Agent0_Alpha_Loss : 0.7976452112197876
Agent0_Temperature : 0.08487682255726565
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -16.96377944946289
Agent1_Eval_StdReturn : 15.702855110168457
Agent1_Eval_MaxReturn : 7.968247890472412
Agent1_Eval_MinReturn : -49.332130432128906
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -17.262659072875977
Agent1_Train_StdReturn : 15.688736915588379
Agent1_Train_MaxReturn : 4.465647220611572
Agent1_Train_MinReturn : -49.25847625732422
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 871500
Agent1_TimeSinceStart : 1368.1592671871185
Agent1_Critic_Loss : 0.517041802406311
Agent1_Actor_Loss : -0.5118658542633057
Agent1_Alpha_Loss : 0.7394821643829346
Agent1_Temperature : 0.08492143247900079
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 581 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 582 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 583 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 584 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 585 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 586 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 587 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 588 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 589 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 590 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -16.216327667236328
Agent0_Eval_StdReturn : 15.452786445617676
Agent0_Eval_MaxReturn : 0.07794523239135742
Agent0_Eval_MinReturn : -42.26994705200195
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -14.482833862304688
Agent0_Train_StdReturn : 17.254880905151367
Agent0_Train_MaxReturn : 6.645758628845215
Agent0_Train_MinReturn : -43.56011199951172
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 886500
Agent0_TimeSinceStart : 1389.809190750122
Agent0_Critic_Loss : 0.5983138680458069
Agent0_Actor_Loss : -0.6843633651733398
Agent0_Alpha_Loss : 0.797383189201355
Agent0_Temperature : 0.08463133014518291
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -18.36930274963379
Agent1_Eval_StdReturn : 10.780479431152344
Agent1_Eval_MaxReturn : 2.9481630325317383
Agent1_Eval_MinReturn : -36.35014724731445
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -11.44288444519043
Agent1_Train_StdReturn : 8.07148265838623
Agent1_Train_MaxReturn : 1.1829633712768555
Agent1_Train_MinReturn : -26.394916534423828
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 886500
Agent1_TimeSinceStart : 1391.9653735160828
Agent1_Critic_Loss : 0.634239137172699
Agent1_Actor_Loss : -0.7740403413772583
Agent1_Alpha_Loss : 0.7513232827186584
Agent1_Temperature : 0.08468704497907163
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 591 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 592 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 593 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 594 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 595 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 596 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 597 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 598 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 599 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 600 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -7.841470241546631
Agent0_Eval_StdReturn : 16.461633682250977
Agent0_Eval_MaxReturn : 26.994646072387695
Agent0_Eval_MinReturn : -38.02934265136719
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -15.901098251342773
Agent0_Train_StdReturn : 26.141551971435547
Agent0_Train_MaxReturn : 16.94432830810547
Agent0_Train_MinReturn : -77.76029968261719
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 901500
Agent0_TimeSinceStart : 1413.6378314495087
Agent0_Critic_Loss : 0.5191825032234192
Agent0_Actor_Loss : -0.579664945602417
Agent0_Alpha_Loss : 0.7867361307144165
Agent0_Temperature : 0.08438709398318747
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -16.972314834594727
Agent1_Eval_StdReturn : 15.550799369812012
Agent1_Eval_MaxReturn : 14.737915992736816
Agent1_Eval_MinReturn : -42.6563720703125
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -22.832073211669922
Agent1_Train_StdReturn : 15.602899551391602
Agent1_Train_MaxReturn : -0.35248279571533203
Agent1_Train_MinReturn : -45.577667236328125
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 901500
Agent1_TimeSinceStart : 1415.8092186450958
Agent1_Critic_Loss : 0.4447370767593384
Agent1_Actor_Loss : -0.6374155282974243
Agent1_Alpha_Loss : 0.7465195655822754
Agent1_Temperature : 0.08445460239151484
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 601 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 602 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 603 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 604 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 605 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 606 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 607 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 608 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 609 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 610 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -8.66118049621582
Agent0_Eval_StdReturn : 14.430651664733887
Agent0_Eval_MaxReturn : 7.831181526184082
Agent0_Eval_MinReturn : -39.9301872253418
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -5.690924167633057
Agent0_Train_StdReturn : 13.138993263244629
Agent0_Train_MaxReturn : 17.262332916259766
Agent0_Train_MinReturn : -30.117115020751953
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 916500
Agent0_TimeSinceStart : 1437.5156319141388
Agent0_Critic_Loss : 0.4393913149833679
Agent0_Actor_Loss : -0.7124022841453552
Agent0_Alpha_Loss : 0.7909284234046936
Agent0_Temperature : 0.08414404102029696
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -18.9953670501709
Agent1_Eval_StdReturn : 14.244745254516602
Agent1_Eval_MaxReturn : 14.675501823425293
Agent1_Eval_MinReturn : -37.88825225830078
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -12.522345542907715
Agent1_Train_StdReturn : 9.072115898132324
Agent1_Train_MaxReturn : 2.069550037384033
Agent1_Train_MinReturn : -28.636262893676758
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 916500
Agent1_TimeSinceStart : 1439.6629858016968
Agent1_Critic_Loss : 0.43216055631637573
Agent1_Actor_Loss : -0.6610205173492432
Agent1_Alpha_Loss : 0.7432957887649536
Agent1_Temperature : 0.08422374998571135
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 611 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 612 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 613 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 614 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 615 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 616 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 617 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 618 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 619 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 620 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -10.84858512878418
Agent0_Eval_StdReturn : 18.26580047607422
Agent0_Eval_MaxReturn : 27.31088638305664
Agent0_Eval_MinReturn : -34.639892578125
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -14.317453384399414
Agent0_Train_StdReturn : 14.396919250488281
Agent0_Train_MaxReturn : 9.48522663116455
Agent0_Train_MinReturn : -40.00347900390625
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 931500
Agent0_TimeSinceStart : 1461.3070425987244
Agent0_Critic_Loss : 0.5058703422546387
Agent0_Actor_Loss : -0.7368254661560059
Agent0_Alpha_Loss : 0.7747635841369629
Agent0_Temperature : 0.08390229872266647
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -16.750455856323242
Agent1_Eval_StdReturn : 14.340750694274902
Agent1_Eval_MaxReturn : 0.25082921981811523
Agent1_Eval_MinReturn : -45.74446105957031
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -20.05385971069336
Agent1_Train_StdReturn : 12.090439796447754
Agent1_Train_MaxReturn : 0.11142539978027344
Agent1_Train_MinReturn : -34.519683837890625
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 931500
Agent1_TimeSinceStart : 1463.4563970565796
Agent1_Critic_Loss : 0.46012094616889954
Agent1_Actor_Loss : -0.6188565492630005
Agent1_Alpha_Loss : 0.7351322174072266
Agent1_Temperature : 0.08399309447351105
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 621 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 622 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 623 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 624 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 625 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 626 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 627 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 628 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 629 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 630 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -23.33216094970703
Agent0_Eval_StdReturn : 15.606898307800293
Agent0_Eval_MaxReturn : -1.0865821838378906
Agent0_Eval_MinReturn : -53.7294921875
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -25.525836944580078
Agent0_Train_StdReturn : 17.956605911254883
Agent0_Train_MaxReturn : 0.06566810607910156
Agent0_Train_MinReturn : -59.50785827636719
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 946500
Agent0_TimeSinceStart : 1485.0638387203217
Agent0_Critic_Loss : 0.5099753737449646
Agent0_Actor_Loss : -0.7467824816703796
Agent0_Alpha_Loss : 0.768416166305542
Agent0_Temperature : 0.08366179205383778
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -15.571965217590332
Agent1_Eval_StdReturn : 9.067418098449707
Agent1_Eval_MaxReturn : -0.8077211380004883
Agent1_Eval_MinReturn : -28.41400718688965
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -22.141109466552734
Agent1_Train_StdReturn : 19.667924880981445
Agent1_Train_MaxReturn : 6.9920454025268555
Agent1_Train_MinReturn : -60.79118347167969
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 946500
Agent1_TimeSinceStart : 1487.2086915969849
Agent1_Critic_Loss : 0.5699690580368042
Agent1_Actor_Loss : -0.5850486755371094
Agent1_Alpha_Loss : 0.7488493323326111
Agent1_Temperature : 0.08376250182574266
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 631 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 632 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 633 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 634 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 635 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 636 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 637 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 638 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 639 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 640 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -13.34253215789795
Agent0_Eval_StdReturn : 18.457189559936523
Agent0_Eval_MaxReturn : 12.473712921142578
Agent0_Eval_MinReturn : -60.345890045166016
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -21.086694717407227
Agent0_Train_StdReturn : 13.880529403686523
Agent0_Train_MaxReturn : 2.33331298828125
Agent0_Train_MinReturn : -35.09620666503906
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 961500
Agent0_TimeSinceStart : 1508.7354338169098
Agent0_Critic_Loss : 0.4103240370750427
Agent0_Actor_Loss : -0.7221051454544067
Agent0_Alpha_Loss : 0.7833635807037354
Agent0_Temperature : 0.0834224687387432
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -12.580370903015137
Agent1_Eval_StdReturn : 15.10409164428711
Agent1_Eval_MaxReturn : 9.802249908447266
Agent1_Eval_MinReturn : -47.24549865722656
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -11.917354583740234
Agent1_Train_StdReturn : 14.205092430114746
Agent1_Train_MaxReturn : 22.6897029876709
Agent1_Train_MinReturn : -28.367076873779297
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 961500
Agent1_TimeSinceStart : 1510.8863804340363
Agent1_Critic_Loss : 0.6208828687667847
Agent1_Actor_Loss : -0.5897115468978882
Agent1_Alpha_Loss : 0.7505300045013428
Agent1_Temperature : 0.08353200658605536
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 641 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 642 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 643 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 644 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 645 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 646 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 647 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 648 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 649 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 650 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -11.19360065460205
Agent0_Eval_StdReturn : 15.930548667907715
Agent0_Eval_MaxReturn : 13.723873138427734
Agent0_Eval_MinReturn : -35.62041473388672
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -19.5264892578125
Agent0_Train_StdReturn : 17.455280303955078
Agent0_Train_MaxReturn : 2.058140277862549
Agent0_Train_MinReturn : -56.74843978881836
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 976500
Agent0_TimeSinceStart : 1532.480284690857
Agent0_Critic_Loss : 0.4802672863006592
Agent0_Actor_Loss : -0.6871686577796936
Agent0_Alpha_Loss : 0.7703127861022949
Agent0_Temperature : 0.08318447068293738
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -7.6240386962890625
Agent1_Eval_StdReturn : 15.554420471191406
Agent1_Eval_MaxReturn : 29.366817474365234
Agent1_Eval_MinReturn : -27.886714935302734
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -20.110431671142578
Agent1_Train_StdReturn : 17.263334274291992
Agent1_Train_MaxReturn : 5.89833927154541
Agent1_Train_MinReturn : -49.49818420410156
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 976500
Agent1_TimeSinceStart : 1534.6164696216583
Agent1_Critic_Loss : 0.44936877489089966
Agent1_Actor_Loss : -0.6949562430381775
Agent1_Alpha_Loss : 0.758205771446228
Agent1_Temperature : 0.08330103317387855
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 651 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 652 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 653 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 654 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 655 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 656 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 657 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 658 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 659 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 660 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -10.791821479797363
Agent0_Eval_StdReturn : 17.50000762939453
Agent0_Eval_MaxReturn : 23.00190544128418
Agent0_Eval_MinReturn : -41.81275177001953
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -6.205528259277344
Agent0_Train_StdReturn : 23.84868812561035
Agent0_Train_MaxReturn : 48.6168212890625
Agent0_Train_MinReturn : -47.221893310546875
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 991500
Agent0_TimeSinceStart : 1556.244074344635
Agent0_Critic_Loss : 0.5220114588737488
Agent0_Actor_Loss : -0.6477996110916138
Agent0_Alpha_Loss : 0.7802212238311768
Agent0_Temperature : 0.08294775631163959
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -15.202618598937988
Agent1_Eval_StdReturn : 12.215559959411621
Agent1_Eval_MaxReturn : 2.8898701667785645
Agent1_Eval_MinReturn : -42.357967376708984
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -24.966373443603516
Agent1_Train_StdReturn : 20.161170959472656
Agent1_Train_MaxReturn : 8.279767036437988
Agent1_Train_MinReturn : -53.268497467041016
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 991500
Agent1_TimeSinceStart : 1558.3893604278564
Agent1_Critic_Loss : 0.4853271245956421
Agent1_Actor_Loss : -0.7608102560043335
Agent1_Alpha_Loss : 0.7608060240745544
Agent1_Temperature : 0.08306877151913679
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 661 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 662 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 663 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 664 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 665 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 666 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 667 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 668 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 669 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 670 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -6.440576076507568
Agent0_Eval_StdReturn : 12.22825813293457
Agent0_Eval_MaxReturn : 16.609663009643555
Agent0_Eval_MinReturn : -25.39291000366211
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -11.498576164245605
Agent0_Train_StdReturn : 13.528006553649902
Agent0_Train_MaxReturn : 11.869964599609375
Agent0_Train_MinReturn : -36.52655792236328
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1006500
Agent0_TimeSinceStart : 1580.1434118747711
Agent0_Critic_Loss : 0.6629723310470581
Agent0_Actor_Loss : -0.5861366987228394
Agent0_Alpha_Loss : 0.7695485353469849
Agent0_Temperature : 0.08271300643536018
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -15.16392993927002
Agent1_Eval_StdReturn : 29.6558837890625
Agent1_Eval_MaxReturn : 9.937274932861328
Agent1_Eval_MinReturn : -87.18919372558594
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -11.049468994140625
Agent1_Train_StdReturn : 16.489337921142578
Agent1_Train_MaxReturn : 12.732585906982422
Agent1_Train_MinReturn : -40.86761474609375
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1006500
Agent1_TimeSinceStart : 1582.295855998993
Agent1_Critic_Loss : 0.4095708429813385
Agent1_Actor_Loss : -0.7162833213806152
Agent1_Alpha_Loss : 0.7713409066200256
Agent1_Temperature : 0.08283469989273193
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 671 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 672 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 673 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 674 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 675 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 676 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 677 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 678 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 679 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 680 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -8.467641830444336
Agent0_Eval_StdReturn : 9.336271286010742
Agent0_Eval_MaxReturn : 6.4219183921813965
Agent0_Eval_MinReturn : -20.414770126342773
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -17.885425567626953
Agent0_Train_StdReturn : 13.642309188842773
Agent0_Train_MaxReturn : -6.731997489929199
Agent0_Train_MinReturn : -45.19118118286133
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1021500
Agent0_TimeSinceStart : 1603.938271522522
Agent0_Critic_Loss : 0.6375986337661743
Agent0_Actor_Loss : -0.7273605465888977
Agent0_Alpha_Loss : 0.7622085809707642
Agent0_Temperature : 0.08248035154370366
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -19.423831939697266
Agent1_Eval_StdReturn : 13.841111183166504
Agent1_Eval_MaxReturn : 0.7421624660491943
Agent1_Eval_MinReturn : -48.530189514160156
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -17.369417190551758
Agent1_Train_StdReturn : 16.91293716430664
Agent1_Train_MaxReturn : 5.244499206542969
Agent1_Train_MinReturn : -50.23974609375
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1021500
Agent1_TimeSinceStart : 1606.094493150711
Agent1_Critic_Loss : 0.4827311635017395
Agent1_Actor_Loss : -0.7122905254364014
Agent1_Alpha_Loss : 0.781387448310852
Agent1_Temperature : 0.08259882817714016
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 681 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 682 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 683 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 684 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 685 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 686 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 687 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 688 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 689 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 690 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -12.538536071777344
Agent0_Eval_StdReturn : 14.833117485046387
Agent0_Eval_MaxReturn : 10.969046592712402
Agent0_Eval_MinReturn : -37.62710189819336
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -10.322945594787598
Agent0_Train_StdReturn : 14.480172157287598
Agent0_Train_MaxReturn : 23.946306228637695
Agent0_Train_MinReturn : -32.31199645996094
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1036500
Agent0_TimeSinceStart : 1627.7399628162384
Agent0_Critic_Loss : 0.5178655385971069
Agent0_Actor_Loss : -0.6749753355979919
Agent0_Alpha_Loss : 0.759323239326477
Agent0_Temperature : 0.08224901038621463
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -6.122828483581543
Agent1_Eval_StdReturn : 21.350025177001953
Agent1_Eval_MaxReturn : 40.747161865234375
Agent1_Eval_MinReturn : -35.504722595214844
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -17.561124801635742
Agent1_Train_StdReturn : 25.036561965942383
Agent1_Train_MaxReturn : 23.646427154541016
Agent1_Train_MinReturn : -52.61623764038086
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1036500
Agent1_TimeSinceStart : 1629.8920390605927
Agent1_Critic_Loss : 0.5222713351249695
Agent1_Actor_Loss : -0.7123814225196838
Agent1_Alpha_Loss : 0.7791756987571716
Agent1_Temperature : 0.08236278311574836
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 691 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 692 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 693 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 694 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 695 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 696 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 697 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 698 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 699 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 700 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -18.122779846191406
Agent0_Eval_StdReturn : 13.538463592529297
Agent0_Eval_MaxReturn : -3.647662878036499
Agent0_Eval_MinReturn : -43.501564025878906
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -15.775967597961426
Agent0_Train_StdReturn : 14.939800262451172
Agent0_Train_MaxReturn : 3.1044840812683105
Agent0_Train_MinReturn : -43.880287170410156
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1051500
Agent0_TimeSinceStart : 1651.5118973255157
Agent0_Critic_Loss : 0.5614727735519409
Agent0_Actor_Loss : -0.644767165184021
Agent0_Alpha_Loss : 0.7634012699127197
Agent0_Temperature : 0.08201838399906515
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -17.339765548706055
Agent1_Eval_StdReturn : 24.685762405395508
Agent1_Eval_MaxReturn : 15.891656875610352
Agent1_Eval_MinReturn : -53.52412796020508
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -10.879220962524414
Agent1_Train_StdReturn : 19.84909439086914
Agent1_Train_MaxReturn : 17.77328109741211
Agent1_Train_MinReturn : -42.7299919128418
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1051500
Agent1_TimeSinceStart : 1653.6557033061981
Agent1_Critic_Loss : 0.4366590678691864
Agent1_Actor_Loss : -0.6171002984046936
Agent1_Alpha_Loss : 0.7776542901992798
Agent1_Temperature : 0.08212703080048003
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 701 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 702 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 703 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 704 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 705 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 706 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 707 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 708 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 709 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 710 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -21.996746063232422
Agent0_Eval_StdReturn : 17.606260299682617
Agent0_Eval_MaxReturn : 4.394181251525879
Agent0_Eval_MinReturn : -58.89968490600586
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -11.727747917175293
Agent0_Train_StdReturn : 14.81747817993164
Agent0_Train_MaxReturn : 2.769383192062378
Agent0_Train_MinReturn : -48.72863006591797
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1066500
Agent0_TimeSinceStart : 1675.325898885727
Agent0_Critic_Loss : 0.45605170726776123
Agent0_Actor_Loss : -0.6465818285942078
Agent0_Alpha_Loss : 0.7511382102966309
Agent0_Temperature : 0.08178741589883698
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -23.849285125732422
Agent1_Eval_StdReturn : 19.116065979003906
Agent1_Eval_MaxReturn : 6.322566986083984
Agent1_Eval_MinReturn : -46.122554779052734
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -18.930782318115234
Agent1_Train_StdReturn : 16.592266082763672
Agent1_Train_MaxReturn : 2.8231899738311768
Agent1_Train_MinReturn : -53.88099670410156
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1066500
Agent1_TimeSinceStart : 1677.4635970592499
Agent1_Critic_Loss : 0.45628565549850464
Agent1_Actor_Loss : -0.6274500489234924
Agent1_Alpha_Loss : 0.7683842182159424
Agent1_Temperature : 0.08189149432154486
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 711 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 712 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 713 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 714 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 715 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 716 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 717 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 718 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 719 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 720 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -15.169512748718262
Agent0_Eval_StdReturn : 17.50234031677246
Agent0_Eval_MaxReturn : 13.708824157714844
Agent0_Eval_MinReturn : -53.427268981933594
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -9.282407760620117
Agent0_Train_StdReturn : 15.226466178894043
Agent0_Train_MaxReturn : 17.392513275146484
Agent0_Train_MinReturn : -37.06302261352539
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1081500
Agent0_TimeSinceStart : 1698.987562417984
Agent0_Critic_Loss : 0.4544791877269745
Agent0_Actor_Loss : -0.7064581513404846
Agent0_Alpha_Loss : 0.7532625794410706
Agent0_Temperature : 0.08155714266712087
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -27.198461532592773
Agent1_Eval_StdReturn : 36.372901916503906
Agent1_Eval_MaxReturn : 14.726040840148926
Agent1_Eval_MinReturn : -99.70405578613281
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -12.23108959197998
Agent1_Train_StdReturn : 15.866654396057129
Agent1_Train_MaxReturn : 14.472549438476562
Agent1_Train_MinReturn : -41.048072814941406
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1081500
Agent1_TimeSinceStart : 1701.113972902298
Agent1_Critic_Loss : 0.5384163856506348
Agent1_Actor_Loss : -0.8484556674957275
Agent1_Alpha_Loss : 0.7560931444168091
Agent1_Temperature : 0.08165607234690493
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 721 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 722 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 723 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 724 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 725 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 726 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 727 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 728 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 729 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 730 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -15.539300918579102
Agent0_Eval_StdReturn : 11.405712127685547
Agent0_Eval_MaxReturn : 1.298479437828064
Agent0_Eval_MinReturn : -43.455814361572266
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -0.16568851470947266
Agent0_Train_StdReturn : 15.55759334564209
Agent0_Train_MaxReturn : 29.954158782958984
Agent0_Train_MinReturn : -29.248046875
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1096500
Agent0_TimeSinceStart : 1722.6529695987701
Agent0_Critic_Loss : 0.48350057005882263
Agent0_Actor_Loss : -0.6789775490760803
Agent0_Alpha_Loss : 0.7518587708473206
Agent0_Temperature : 0.08132780111835694
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -16.420854568481445
Agent1_Eval_StdReturn : 21.304719924926758
Agent1_Eval_MaxReturn : 17.08386993408203
Agent1_Eval_MinReturn : -63.01170349121094
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -19.00188636779785
Agent1_Train_StdReturn : 15.743940353393555
Agent1_Train_MaxReturn : 4.015966415405273
Agent1_Train_MinReturn : -49.17552947998047
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1096500
Agent1_TimeSinceStart : 1724.7771439552307
Agent1_Critic_Loss : 0.633712649345398
Agent1_Actor_Loss : -0.8166463375091553
Agent1_Alpha_Loss : 0.7636439800262451
Agent1_Temperature : 0.08142149217115693
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 731 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 732 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 733 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 734 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 735 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 736 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 737 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 738 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 739 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 740 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -16.8717041015625
Agent0_Eval_StdReturn : 12.620537757873535
Agent0_Eval_MaxReturn : 4.564884185791016
Agent0_Eval_MinReturn : -32.783042907714844
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -6.631211757659912
Agent0_Train_StdReturn : 13.224653244018555
Agent0_Train_MaxReturn : 14.947166442871094
Agent0_Train_MinReturn : -29.921405792236328
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1111500
Agent0_TimeSinceStart : 1746.307959318161
Agent0_Critic_Loss : 0.5901875495910645
Agent0_Actor_Loss : -0.655962347984314
Agent0_Alpha_Loss : 0.7561516761779785
Agent0_Temperature : 0.08109928420499973
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -11.436797142028809
Agent1_Eval_StdReturn : 23.029836654663086
Agent1_Eval_MaxReturn : 28.07135581970215
Agent1_Eval_MinReturn : -63.412105560302734
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -13.451135635375977
Agent1_Train_StdReturn : 20.65577507019043
Agent1_Train_MaxReturn : 24.24252700805664
Agent1_Train_MinReturn : -50.63579559326172
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1111500
Agent1_TimeSinceStart : 1748.4362733364105
Agent1_Critic_Loss : 0.49121585488319397
Agent1_Actor_Loss : -0.8017423152923584
Agent1_Alpha_Loss : 0.7733007669448853
Agent1_Temperature : 0.08118713198401298
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 741 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 742 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 743 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 744 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 745 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 746 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 747 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 748 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 749 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 750 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -8.42000675201416
Agent0_Eval_StdReturn : 12.426454544067383
Agent0_Eval_MaxReturn : 10.963292121887207
Agent0_Eval_MinReturn : -24.230464935302734
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -16.443866729736328
Agent0_Train_StdReturn : 10.264244079589844
Agent0_Train_MaxReturn : 2.9169671535491943
Agent0_Train_MinReturn : -35.63247299194336
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1126500
Agent0_TimeSinceStart : 1769.9315848350525
Agent0_Critic_Loss : 0.5134709477424622
Agent0_Actor_Loss : -0.7467735409736633
Agent0_Alpha_Loss : 0.7539827823638916
Agent0_Temperature : 0.08087149731162638
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -18.37026596069336
Agent1_Eval_StdReturn : 23.65644645690918
Agent1_Eval_MaxReturn : 10.99044132232666
Agent1_Eval_MinReturn : -54.62868118286133
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -18.623126983642578
Agent1_Train_StdReturn : 15.848087310791016
Agent1_Train_MaxReturn : 10.82720947265625
Agent1_Train_MinReturn : -51.15226364135742
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1126500
Agent1_TimeSinceStart : 1772.066650390625
Agent1_Critic_Loss : 0.7656859755516052
Agent1_Actor_Loss : -0.7474914789199829
Agent1_Alpha_Loss : 0.7772432565689087
Agent1_Temperature : 0.08095361556062222
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 751 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 752 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 753 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 754 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 755 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 756 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 757 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 758 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 759 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 760 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -12.863726615905762
Agent0_Eval_StdReturn : 12.948776245117188
Agent0_Eval_MaxReturn : 13.196874618530273
Agent0_Eval_MinReturn : -34.39454650878906
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -15.092915534973145
Agent0_Train_StdReturn : 21.76633644104004
Agent0_Train_MaxReturn : 12.508588790893555
Agent0_Train_MinReturn : -57.921226501464844
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1141500
Agent0_TimeSinceStart : 1793.580378293991
Agent0_Critic_Loss : 0.5318242311477661
Agent0_Actor_Loss : -0.7804426550865173
Agent0_Alpha_Loss : 0.7723991870880127
Agent0_Temperature : 0.08064460383354705
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -7.017946720123291
Agent1_Eval_StdReturn : 19.26467514038086
Agent1_Eval_MaxReturn : 39.01436233520508
Agent1_Eval_MinReturn : -30.414785385131836
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -36.614566802978516
Agent1_Train_StdReturn : 21.317546844482422
Agent1_Train_MaxReturn : -4.540079116821289
Agent1_Train_MinReturn : -74.05452728271484
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1141500
Agent1_TimeSinceStart : 1795.7138435840607
Agent1_Critic_Loss : 0.9315478801727295
Agent1_Actor_Loss : -0.7414970993995667
Agent1_Alpha_Loss : 0.7642977237701416
Agent1_Temperature : 0.0807207532129493
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 761 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 762 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 763 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 764 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 765 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 766 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 767 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 768 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 769 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 770 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -13.89140510559082
Agent0_Eval_StdReturn : 13.882332801818848
Agent0_Eval_MaxReturn : 3.9478845596313477
Agent0_Eval_MinReturn : -33.96921920776367
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -14.457748413085938
Agent0_Train_StdReturn : 21.440752029418945
Agent0_Train_MaxReturn : 17.793041229248047
Agent0_Train_MinReturn : -51.39524841308594
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1156500
Agent0_TimeSinceStart : 1817.3134188652039
Agent0_Critic_Loss : 0.4828040897846222
Agent0_Actor_Loss : -0.6857547760009766
Agent0_Alpha_Loss : 0.7618672847747803
Agent0_Temperature : 0.08041730498105427
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -8.450464248657227
Agent1_Eval_StdReturn : 22.540552139282227
Agent1_Eval_MaxReturn : 27.514631271362305
Agent1_Eval_MinReturn : -57.33772659301758
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -17.640186309814453
Agent1_Train_StdReturn : 15.155695915222168
Agent1_Train_MaxReturn : 2.525188446044922
Agent1_Train_MinReturn : -41.57296371459961
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1156500
Agent1_TimeSinceStart : 1819.4534785747528
Agent1_Critic_Loss : 1.1117162704467773
Agent1_Actor_Loss : -0.6393736600875854
Agent1_Alpha_Loss : 0.762566089630127
Agent1_Temperature : 0.08048969497298482
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 771 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 772 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 773 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 774 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 775 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 776 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 777 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 778 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 779 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 780 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -2.053454637527466
Agent0_Eval_StdReturn : 21.4679012298584
Agent0_Eval_MaxReturn : 40.36792755126953
Agent0_Eval_MinReturn : -30.164941787719727
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -11.338749885559082
Agent0_Train_StdReturn : 11.115272521972656
Agent0_Train_MaxReturn : 13.643491744995117
Agent0_Train_MinReturn : -33.60273742675781
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1171500
Agent0_TimeSinceStart : 1841.0528829097748
Agent0_Critic_Loss : 0.5063446164131165
Agent0_Actor_Loss : -0.6124482154846191
Agent0_Alpha_Loss : 0.7552692890167236
Agent0_Temperature : 0.08018995810276162
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -13.91026782989502
Agent1_Eval_StdReturn : 15.3272123336792
Agent1_Eval_MaxReturn : 10.97376823425293
Agent1_Eval_MinReturn : -42.120025634765625
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -14.865432739257812
Agent1_Train_StdReturn : 14.872917175292969
Agent1_Train_MaxReturn : 3.602250099182129
Agent1_Train_MinReturn : -47.951820373535156
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1171500
Agent1_TimeSinceStart : 1843.204023361206
Agent1_Critic_Loss : 0.608254075050354
Agent1_Actor_Loss : -0.6139170527458191
Agent1_Alpha_Loss : 0.7495406270027161
Agent1_Temperature : 0.08026071187957456
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 781 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 782 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 783 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 784 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 785 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 786 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 787 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 788 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 789 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 790 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -19.582420349121094
Agent0_Eval_StdReturn : 37.10621643066406
Agent0_Eval_MaxReturn : 32.39827346801758
Agent0_Eval_MinReturn : -103.69652557373047
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -11.863649368286133
Agent0_Train_StdReturn : 22.827238082885742
Agent0_Train_MaxReturn : 20.797515869140625
Agent0_Train_MinReturn : -47.504844665527344
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1186500
Agent0_TimeSinceStart : 1864.78964304924
Agent0_Critic_Loss : 0.5630289912223816
Agent0_Actor_Loss : -0.7343184351921082
Agent0_Alpha_Loss : 0.7600172758102417
Agent0_Temperature : 0.07996308982202621
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -7.43402099609375
Agent1_Eval_StdReturn : 13.052010536193848
Agent1_Eval_MaxReturn : 15.851608276367188
Agent1_Eval_MinReturn : -23.976049423217773
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -13.447372436523438
Agent1_Train_StdReturn : 13.690320014953613
Agent1_Train_MaxReturn : 4.85615348815918
Agent1_Train_MinReturn : -44.96314239501953
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1186500
Agent1_TimeSinceStart : 1866.9454329013824
Agent1_Critic_Loss : 0.9639801383018494
Agent1_Actor_Loss : -0.7372862100601196
Agent1_Alpha_Loss : 0.7362161874771118
Agent1_Temperature : 0.08003450581165326
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 791 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 792 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 793 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 794 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 795 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 796 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 797 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 798 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 799 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 800 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -22.413223266601562
Agent0_Eval_StdReturn : 17.73639678955078
Agent0_Eval_MaxReturn : 4.131196975708008
Agent0_Eval_MinReturn : -51.9211311340332
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -17.390621185302734
Agent0_Train_StdReturn : 11.509300231933594
Agent0_Train_MaxReturn : 3.1821422576904297
Agent0_Train_MinReturn : -32.8302001953125
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1201500
Agent0_TimeSinceStart : 1888.6204450130463
Agent0_Critic_Loss : 0.5408133268356323
Agent0_Actor_Loss : -0.8986081480979919
Agent0_Alpha_Loss : 0.7634145021438599
Agent0_Temperature : 0.07973552851788937
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -13.362462997436523
Agent1_Eval_StdReturn : 7.948846340179443
Agent1_Eval_MaxReturn : -0.7863948345184326
Agent1_Eval_MinReturn : -28.62525177001953
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -15.24463176727295
Agent1_Train_StdReturn : 10.684562683105469
Agent1_Train_MaxReturn : 3.909749984741211
Agent1_Train_MinReturn : -32.07044982910156
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1201500
Agent1_TimeSinceStart : 1890.7756476402283
Agent1_Critic_Loss : 0.9294147491455078
Agent1_Actor_Loss : -0.7910563349723816
Agent1_Alpha_Loss : 0.7262438535690308
Agent1_Temperature : 0.07981292606407368
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 801 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 802 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 803 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 804 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 805 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 806 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 807 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 808 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 809 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 810 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -21.89670181274414
Agent0_Eval_StdReturn : 20.660154342651367
Agent0_Eval_MaxReturn : 8.37087345123291
Agent0_Eval_MinReturn : -49.28630065917969
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -43.77967071533203
Agent0_Train_StdReturn : 33.040122985839844
Agent0_Train_MaxReturn : -1.7674102783203125
Agent0_Train_MinReturn : -100.50584411621094
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1216500
Agent0_TimeSinceStart : 1912.3608829975128
Agent0_Critic_Loss : 0.6817288398742676
Agent0_Actor_Loss : -0.8572887182235718
Agent0_Alpha_Loss : 0.771665096282959
Agent0_Temperature : 0.07950823878040782
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -11.876036643981934
Agent1_Eval_StdReturn : 10.979077339172363
Agent1_Eval_MaxReturn : 4.196592330932617
Agent1_Eval_MinReturn : -25.456222534179688
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -10.07821273803711
Agent1_Train_StdReturn : 14.645079612731934
Agent1_Train_MaxReturn : 8.44273567199707
Agent1_Train_MinReturn : -43.0304069519043
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1216500
Agent1_TimeSinceStart : 1914.5160593986511
Agent1_Critic_Loss : 0.6633087396621704
Agent1_Actor_Loss : -0.8011385202407837
Agent1_Alpha_Loss : 0.7157536745071411
Agent1_Temperature : 0.0795945396794552
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 811 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 812 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 813 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 814 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 815 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 816 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 817 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 818 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 819 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 820 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -22.95198631286621
Agent0_Eval_StdReturn : 24.44071388244629
Agent0_Eval_MaxReturn : 17.153072357177734
Agent0_Eval_MinReturn : -59.25103759765625
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -19.70718002319336
Agent0_Train_StdReturn : 19.456506729125977
Agent0_Train_MaxReturn : 14.126317024230957
Agent0_Train_MinReturn : -50.79753112792969
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1231500
Agent0_TimeSinceStart : 1936.1749002933502
Agent0_Critic_Loss : 0.7174925804138184
Agent0_Actor_Loss : -0.7637374997138977
Agent0_Alpha_Loss : 0.7519702315330505
Agent0_Temperature : 0.07928187590252242
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -14.201301574707031
Agent1_Eval_StdReturn : 9.269737243652344
Agent1_Eval_MaxReturn : -1.8379817008972168
Agent1_Eval_MinReturn : -29.734127044677734
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -13.075239181518555
Agent1_Train_StdReturn : 14.017549514770508
Agent1_Train_MaxReturn : 6.817705154418945
Agent1_Train_MinReturn : -37.11793899536133
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1231500
Agent1_TimeSinceStart : 1938.3361217975616
Agent1_Critic_Loss : 0.6516234874725342
Agent1_Actor_Loss : -0.7581926584243774
Agent1_Alpha_Loss : 0.7162759304046631
Agent1_Temperature : 0.07937868125315976
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 821 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 822 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 823 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 824 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 825 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 826 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 827 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 828 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 829 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 830 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -28.871906280517578
Agent0_Eval_StdReturn : 22.20890998840332
Agent0_Eval_MaxReturn : -1.1863101720809937
Agent0_Eval_MinReturn : -71.3106689453125
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -27.68563461303711
Agent0_Train_StdReturn : 24.220970153808594
Agent0_Train_MaxReturn : 7.410549640655518
Agent0_Train_MinReturn : -69.63038635253906
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1246500
Agent0_TimeSinceStart : 1959.8932785987854
Agent0_Critic_Loss : 0.705058217048645
Agent0_Actor_Loss : -0.6563958525657654
Agent0_Alpha_Loss : 0.7526540756225586
Agent0_Temperature : 0.07905739257319037
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -21.022693634033203
Agent1_Eval_StdReturn : 11.359203338623047
Agent1_Eval_MaxReturn : -4.273465156555176
Agent1_Eval_MinReturn : -40.22064971923828
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -12.626550674438477
Agent1_Train_StdReturn : 9.846952438354492
Agent1_Train_MaxReturn : -1.5515565872192383
Agent1_Train_MinReturn : -37.19441223144531
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1246500
Agent1_TimeSinceStart : 1962.032631635666
Agent1_Critic_Loss : 1.0208983421325684
Agent1_Actor_Loss : -0.78515625
Agent1_Alpha_Loss : 0.7294063568115234
Agent1_Temperature : 0.07916429486524766
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 831 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 832 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 833 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 834 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 835 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 836 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 837 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 838 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 839 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 840 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -15.255935668945312
Agent0_Eval_StdReturn : 17.310894012451172
Agent0_Eval_MaxReturn : 2.1391029357910156
Agent0_Eval_MinReturn : -49.076332092285156
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -14.664892196655273
Agent0_Train_StdReturn : 25.9791202545166
Agent0_Train_MaxReturn : 29.993560791015625
Agent0_Train_MinReturn : -55.711421966552734
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1261500
Agent0_TimeSinceStart : 1983.532774925232
Agent0_Critic_Loss : 0.6541227698326111
Agent0_Actor_Loss : -0.6910560727119446
Agent0_Alpha_Loss : 0.7540789246559143
Agent0_Temperature : 0.07883345402059053
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -19.597856521606445
Agent1_Eval_StdReturn : 21.59762954711914
Agent1_Eval_MaxReturn : 10.730167388916016
Agent1_Eval_MinReturn : -70.13639068603516
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -9.749100685119629
Agent1_Train_StdReturn : 8.591999053955078
Agent1_Train_MaxReturn : 11.4096040725708
Agent1_Train_MinReturn : -21.25857925415039
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1261500
Agent1_TimeSinceStart : 1985.6743202209473
Agent1_Critic_Loss : 0.6911858320236206
Agent1_Actor_Loss : -0.7842354774475098
Agent1_Alpha_Loss : 0.7257938385009766
Agent1_Temperature : 0.07894936279747196
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 841 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 842 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 843 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 844 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 845 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 846 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 847 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 848 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 849 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 850 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -12.778448104858398
Agent0_Eval_StdReturn : 19.153085708618164
Agent0_Eval_MaxReturn : 18.219465255737305
Agent0_Eval_MinReturn : -47.79154968261719
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -4.171023368835449
Agent0_Train_StdReturn : 18.46993637084961
Agent0_Train_MaxReturn : 23.293394088745117
Agent0_Train_MinReturn : -32.87272644042969
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1276500
Agent0_TimeSinceStart : 2007.1757531166077
Agent0_Critic_Loss : 0.5601798295974731
Agent0_Actor_Loss : -0.7968685626983643
Agent0_Alpha_Loss : 0.7434315085411072
Agent0_Temperature : 0.07861063305724961
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -7.95693826675415
Agent1_Eval_StdReturn : 6.994320392608643
Agent1_Eval_MaxReturn : 3.7353696823120117
Agent1_Eval_MinReturn : -22.719411849975586
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -19.532432556152344
Agent1_Train_StdReturn : 16.371614456176758
Agent1_Train_MaxReturn : 1.5289192199707031
Agent1_Train_MinReturn : -59.9133186340332
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1276500
Agent1_TimeSinceStart : 2009.3316960334778
Agent1_Critic_Loss : 0.7906107306480408
Agent1_Actor_Loss : -0.8594580888748169
Agent1_Alpha_Loss : 0.7247709631919861
Agent1_Temperature : 0.078733801211164
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 851 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 852 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 853 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 854 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 855 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 856 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 857 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 858 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 859 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 860 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -8.261159896850586
Agent0_Eval_StdReturn : 22.02651596069336
Agent0_Eval_MaxReturn : 31.287269592285156
Agent0_Eval_MinReturn : -37.490196228027344
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -18.020740509033203
Agent0_Train_StdReturn : 18.533061981201172
Agent0_Train_MaxReturn : 1.6223230361938477
Agent0_Train_MinReturn : -59.17204284667969
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1291500
Agent0_TimeSinceStart : 2030.928738117218
Agent0_Critic_Loss : 0.7394950985908508
Agent0_Actor_Loss : -0.8001711368560791
Agent0_Alpha_Loss : 0.7429209351539612
Agent0_Temperature : 0.07838985579961134
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -16.333160400390625
Agent1_Eval_StdReturn : 11.038554191589355
Agent1_Eval_MaxReturn : 3.2646918296813965
Agent1_Eval_MinReturn : -36.37223815917969
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -14.308810234069824
Agent1_Train_StdReturn : 15.4580717086792
Agent1_Train_MaxReturn : 9.099908828735352
Agent1_Train_MinReturn : -39.212646484375
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1291500
Agent1_TimeSinceStart : 2033.0751366615295
Agent1_Critic_Loss : 0.5315920114517212
Agent1_Actor_Loss : -0.8146176934242249
Agent1_Alpha_Loss : 0.7268352508544922
Agent1_Temperature : 0.0785186963774229
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 861 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 862 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 863 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 864 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 865 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 866 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 867 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 868 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 869 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 870 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -16.223194122314453
Agent0_Eval_StdReturn : 17.003414154052734
Agent0_Eval_MaxReturn : 9.36388111114502
Agent0_Eval_MinReturn : -54.211917877197266
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -10.48302936553955
Agent0_Train_StdReturn : 11.850190162658691
Agent0_Train_MaxReturn : 4.251366138458252
Agent0_Train_MinReturn : -32.71227264404297
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1306500
Agent0_TimeSinceStart : 2054.665780067444
Agent0_Critic_Loss : 0.8312960863113403
Agent0_Actor_Loss : -0.8533698916435242
Agent0_Alpha_Loss : 0.7376953363418579
Agent0_Temperature : 0.07817087398821924
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -21.917377471923828
Agent1_Eval_StdReturn : 14.541678428649902
Agent1_Eval_MaxReturn : -0.20843029022216797
Agent1_Eval_MinReturn : -50.10948181152344
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -14.207612991333008
Agent1_Train_StdReturn : 11.540014266967773
Agent1_Train_MaxReturn : 2.9410829544067383
Agent1_Train_MinReturn : -37.690975189208984
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1306500
Agent1_TimeSinceStart : 2056.8069558143616
Agent1_Critic_Loss : 0.5910598039627075
Agent1_Actor_Loss : -0.7508796453475952
Agent1_Alpha_Loss : 0.7299805879592896
Agent1_Temperature : 0.07830260769181252
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 871 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 872 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 873 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 874 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 875 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 876 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 877 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 878 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 879 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 880 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -9.031476974487305
Agent0_Eval_StdReturn : 11.910674095153809
Agent0_Eval_MaxReturn : 8.928253173828125
Agent0_Eval_MinReturn : -34.32345199584961
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -11.598559379577637
Agent0_Train_StdReturn : 15.266921043395996
Agent0_Train_MaxReturn : 10.646381378173828
Agent0_Train_MinReturn : -35.1094856262207
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1321500
Agent0_TimeSinceStart : 2078.3823363780975
Agent0_Critic_Loss : 0.8781977295875549
Agent0_Actor_Loss : -0.816606879234314
Agent0_Alpha_Loss : 0.7312049269676208
Agent0_Temperature : 0.07795350183826427
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -14.932034492492676
Agent1_Eval_StdReturn : 16.762025833129883
Agent1_Eval_MaxReturn : 17.964981079101562
Agent1_Eval_MinReturn : -41.25978088378906
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -14.005086898803711
Agent1_Train_StdReturn : 11.242856979370117
Agent1_Train_MaxReturn : 4.555875778198242
Agent1_Train_MinReturn : -31.211305618286133
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1321500
Agent1_TimeSinceStart : 2080.53430891037
Agent1_Critic_Loss : 0.7119113802909851
Agent1_Actor_Loss : -0.8810054659843445
Agent1_Alpha_Loss : 0.7365108728408813
Agent1_Temperature : 0.07808683494381578
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 881 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 882 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 883 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 884 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 885 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 886 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 887 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 888 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 889 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 890 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -13.2225923538208
Agent0_Eval_StdReturn : 7.899472236633301
Agent0_Eval_MaxReturn : 4.302783012390137
Agent0_Eval_MinReturn : -27.277782440185547
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -4.0362701416015625
Agent0_Train_StdReturn : 18.847942352294922
Agent0_Train_MaxReturn : 28.889877319335938
Agent0_Train_MinReturn : -36.75605010986328
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1336500
Agent0_TimeSinceStart : 2102.1477477550507
Agent0_Critic_Loss : 0.866920530796051
Agent0_Actor_Loss : -0.8391628861427307
Agent0_Alpha_Loss : 0.7215343713760376
Agent0_Temperature : 0.07773865148406639
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -19.24504280090332
Agent1_Eval_StdReturn : 13.9314546585083
Agent1_Eval_MaxReturn : 1.608540654182434
Agent1_Eval_MinReturn : -47.066471099853516
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -8.567230224609375
Agent1_Train_StdReturn : 15.663131713867188
Agent1_Train_MaxReturn : 21.40172004699707
Agent1_Train_MinReturn : -43.05994415283203
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1336500
Agent1_TimeSinceStart : 2104.285342693329
Agent1_Critic_Loss : 0.5879424810409546
Agent1_Actor_Loss : -0.8346368074417114
Agent1_Alpha_Loss : 0.743725061416626
Agent1_Temperature : 0.07787047569322936
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 891 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 892 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 893 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 894 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 895 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 896 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 897 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 898 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 899 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 900 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -21.015153884887695
Agent0_Eval_StdReturn : 17.640209197998047
Agent0_Eval_MaxReturn : 10.872051239013672
Agent0_Eval_MinReturn : -65.81245422363281
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -1.9832031726837158
Agent0_Train_StdReturn : 10.200069427490234
Agent0_Train_MaxReturn : 20.913667678833008
Agent0_Train_MinReturn : -18.848270416259766
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1351500
Agent0_TimeSinceStart : 2125.843876838684
Agent0_Critic_Loss : 0.8364413976669312
Agent0_Actor_Loss : -0.7321898341178894
Agent0_Alpha_Loss : 0.7272231578826904
Agent0_Temperature : 0.0775257767521391
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -18.602176666259766
Agent1_Eval_StdReturn : 19.76792335510254
Agent1_Eval_MaxReturn : 10.16269302368164
Agent1_Eval_MinReturn : -45.63542938232422
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -9.061631202697754
Agent1_Train_StdReturn : 13.64448356628418
Agent1_Train_MaxReturn : 13.893156051635742
Agent1_Train_MinReturn : -34.85884094238281
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1351500
Agent1_TimeSinceStart : 2127.9917662143707
Agent1_Critic_Loss : 0.5423764586448669
Agent1_Actor_Loss : -0.9666440486907959
Agent1_Alpha_Loss : 0.7547261714935303
Agent1_Temperature : 0.07765370296086856
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 901 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 902 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 903 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 904 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 905 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 906 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 907 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 908 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 909 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 910 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -8.163424491882324
Agent0_Eval_StdReturn : 15.623340606689453
Agent0_Eval_MaxReturn : 25.43826675415039
Agent0_Eval_MinReturn : -37.825096130371094
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -16.9205265045166
Agent0_Train_StdReturn : 13.787992477416992
Agent0_Train_MaxReturn : -0.8210601806640625
Agent0_Train_MinReturn : -37.947265625
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1366500
Agent0_TimeSinceStart : 2149.558408498764
Agent0_Critic_Loss : 0.7076895236968994
Agent0_Actor_Loss : -0.6963627934455872
Agent0_Alpha_Loss : 0.7370032072067261
Agent0_Temperature : 0.07731358410281441
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -7.804219722747803
Agent1_Eval_StdReturn : 14.622791290283203
Agent1_Eval_MaxReturn : 17.671350479125977
Agent1_Eval_MinReturn : -32.19041061401367
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -14.33128833770752
Agent1_Train_StdReturn : 23.433460235595703
Agent1_Train_MaxReturn : 21.006567001342773
Agent1_Train_MinReturn : -69.18721008300781
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1366500
Agent1_TimeSinceStart : 2151.6895480155945
Agent1_Critic_Loss : 0.5217598080635071
Agent1_Actor_Loss : -0.9251367449760437
Agent1_Alpha_Loss : 0.7386234998703003
Agent1_Temperature : 0.07743550346111519
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 911 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 912 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 913 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 914 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 915 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 916 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 917 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 918 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 919 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 920 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -20.536972045898438
Agent0_Eval_StdReturn : 17.00377082824707
Agent0_Eval_MaxReturn : 3.957456588745117
Agent0_Eval_MinReturn : -51.400306701660156
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -14.154095649719238
Agent0_Train_StdReturn : 21.11654281616211
Agent0_Train_MaxReturn : 5.93084716796875
Agent0_Train_MinReturn : -68.85381317138672
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1381500
Agent0_TimeSinceStart : 2173.155510663986
Agent0_Critic_Loss : 0.8030083179473877
Agent0_Actor_Loss : -0.8289045095443726
Agent0_Alpha_Loss : 0.7281752824783325
Agent0_Temperature : 0.07710163264223868
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -12.935137748718262
Agent1_Eval_StdReturn : 20.951059341430664
Agent1_Eval_MaxReturn : 10.564168930053711
Agent1_Eval_MinReturn : -57.228782653808594
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -5.542840480804443
Agent1_Train_StdReturn : 17.720491409301758
Agent1_Train_MaxReturn : 20.942018508911133
Agent1_Train_MinReturn : -38.871368408203125
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1381500
Agent1_TimeSinceStart : 2175.296100139618
Agent1_Critic_Loss : 0.7549366354942322
Agent1_Actor_Loss : -0.8303861021995544
Agent1_Alpha_Loss : 0.7416497468948364
Agent1_Temperature : 0.07721657445359134
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 921 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 922 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 923 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 924 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 925 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 926 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 927 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 928 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 929 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 930 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -10.457531929016113
Agent0_Eval_StdReturn : 14.855162620544434
Agent0_Eval_MaxReturn : 5.312955856323242
Agent0_Eval_MinReturn : -37.27194595336914
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -9.81082820892334
Agent0_Train_StdReturn : 8.330985069274902
Agent0_Train_MaxReturn : 7.900588035583496
Agent0_Train_MinReturn : -24.611230850219727
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1396500
Agent0_TimeSinceStart : 2196.8168756961823
Agent0_Critic_Loss : 0.6404407024383545
Agent0_Actor_Loss : -0.8150357007980347
Agent0_Alpha_Loss : 0.7245379686355591
Agent0_Temperature : 0.07689023404691307
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -40.05531692504883
Agent1_Eval_StdReturn : 18.28441047668457
Agent1_Eval_MaxReturn : -16.557302474975586
Agent1_Eval_MinReturn : -75.12823486328125
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -24.735721588134766
Agent1_Train_StdReturn : 17.753026962280273
Agent1_Train_MaxReturn : 5.838751316070557
Agent1_Train_MinReturn : -46.500732421875
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1396500
Agent1_TimeSinceStart : 2198.9534657001495
Agent1_Critic_Loss : 0.7408277988433838
Agent1_Actor_Loss : -0.9620357751846313
Agent1_Alpha_Loss : 0.7368197441101074
Agent1_Temperature : 0.07699873988671412
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 931 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 932 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 933 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 934 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 935 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 936 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 937 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 938 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 939 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 940 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -12.08072566986084
Agent0_Eval_StdReturn : 12.293183326721191
Agent0_Eval_MaxReturn : -2.2154204845428467
Agent0_Eval_MinReturn : -44.6818733215332
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -15.423535346984863
Agent0_Train_StdReturn : 13.214570045471191
Agent0_Train_MaxReturn : 11.283377647399902
Agent0_Train_MinReturn : -43.02207946777344
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1411500
Agent0_TimeSinceStart : 2220.410469055176
Agent0_Critic_Loss : 0.7846618890762329
Agent0_Actor_Loss : -0.8037799000740051
Agent0_Alpha_Loss : 0.712094783782959
Agent0_Temperature : 0.0766799462446349
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -15.585871696472168
Agent1_Eval_StdReturn : 32.85227966308594
Agent1_Eval_MaxReturn : 37.16623306274414
Agent1_Eval_MinReturn : -77.39348602294922
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -29.479244232177734
Agent1_Train_StdReturn : 19.03998565673828
Agent1_Train_MaxReturn : 13.959148406982422
Agent1_Train_MinReturn : -64.99068450927734
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1411500
Agent1_TimeSinceStart : 2222.5345754623413
Agent1_Critic_Loss : 0.6220201849937439
Agent1_Actor_Loss : -0.9867813587188721
Agent1_Alpha_Loss : 0.7306963205337524
Agent1_Temperature : 0.0767819209405779
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 941 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 942 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 943 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 944 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 945 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 946 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 947 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 948 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 949 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 950 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -9.674771308898926
Agent0_Eval_StdReturn : 11.025941848754883
Agent0_Eval_MaxReturn : 2.7394275665283203
Agent0_Eval_MinReturn : -33.17115783691406
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -7.906301021575928
Agent0_Train_StdReturn : 11.892627716064453
Agent0_Train_MaxReturn : 14.230194091796875
Agent0_Train_MinReturn : -27.29912567138672
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1426500
Agent0_TimeSinceStart : 2244.036607503891
Agent0_Critic_Loss : 0.6634587049484253
Agent0_Actor_Loss : -0.8824299573898315
Agent0_Alpha_Loss : 0.7077593207359314
Agent0_Temperature : 0.07647124926355679
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -17.56426239013672
Agent1_Eval_StdReturn : 22.311670303344727
Agent1_Eval_MaxReturn : 9.208208084106445
Agent1_Eval_MinReturn : -57.695411682128906
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -27.772287368774414
Agent1_Train_StdReturn : 22.198610305786133
Agent1_Train_MaxReturn : 10.660511016845703
Agent1_Train_MinReturn : -59.34058380126953
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1426500
Agent1_TimeSinceStart : 2246.160013437271
Agent1_Critic_Loss : 0.8522234559059143
Agent1_Actor_Loss : -0.8694875836372375
Agent1_Alpha_Loss : 0.7267639636993408
Agent1_Temperature : 0.07656610355667728
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 951 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 952 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 953 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 954 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 955 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 956 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 957 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 958 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 959 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 960 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -11.483150482177734
Agent0_Eval_StdReturn : 17.211870193481445
Agent0_Eval_MaxReturn : 20.382051467895508
Agent0_Eval_MinReturn : -30.823204040527344
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -11.586820602416992
Agent0_Train_StdReturn : 11.134270668029785
Agent0_Train_MaxReturn : 9.531128883361816
Agent0_Train_MinReturn : -26.107919692993164
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1441500
Agent0_TimeSinceStart : 2267.5961499214172
Agent0_Critic_Loss : 0.6770725250244141
Agent0_Actor_Loss : -0.8546434640884399
Agent0_Alpha_Loss : 0.7046211957931519
Agent0_Temperature : 0.07626408473648315
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -20.223724365234375
Agent1_Eval_StdReturn : 20.384613037109375
Agent1_Eval_MaxReturn : 8.660011291503906
Agent1_Eval_MinReturn : -44.99341583251953
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -27.547882080078125
Agent1_Train_StdReturn : 21.68562126159668
Agent1_Train_MaxReturn : -0.1376047134399414
Agent1_Train_MinReturn : -73.9770736694336
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1441500
Agent1_TimeSinceStart : 2269.7091279029846
Agent1_Critic_Loss : 0.7913976311683655
Agent1_Actor_Loss : -0.9218299984931946
Agent1_Alpha_Loss : 0.7244064807891846
Agent1_Temperature : 0.07635130797039034
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 961 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 962 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 963 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 964 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 965 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 966 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 967 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 968 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 969 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 970 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : 3.145343065261841
Agent0_Eval_StdReturn : 14.072893142700195
Agent0_Eval_MaxReturn : 26.725942611694336
Agent0_Eval_MinReturn : -19.357934951782227
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -9.264749526977539
Agent0_Train_StdReturn : 11.481945037841797
Agent0_Train_MaxReturn : 11.694328308105469
Agent0_Train_MinReturn : -28.15854263305664
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1456500
Agent0_TimeSinceStart : 2291.0986955165863
Agent0_Critic_Loss : 0.665631115436554
Agent0_Actor_Loss : -0.8270963430404663
Agent0_Alpha_Loss : 0.7322870492935181
Agent0_Temperature : 0.07605724567570692
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -19.15384292602539
Agent1_Eval_StdReturn : 16.790706634521484
Agent1_Eval_MaxReturn : 2.45166015625
Agent1_Eval_MinReturn : -56.41191482543945
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -32.82868194580078
Agent1_Train_StdReturn : 22.27954864501953
Agent1_Train_MaxReturn : -1.813734769821167
Agent1_Train_MinReturn : -77.46883392333984
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1456500
Agent1_TimeSinceStart : 2293.2248771190643
Agent1_Critic_Loss : 0.8623886108398438
Agent1_Actor_Loss : -0.7808836698532104
Agent1_Alpha_Loss : 0.7264251112937927
Agent1_Temperature : 0.07613689364004741
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 971 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 972 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 973 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 974 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 975 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 976 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 977 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 978 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 979 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 980 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -13.105108261108398
Agent0_Eval_StdReturn : 22.795373916625977
Agent0_Eval_MaxReturn : 10.846830368041992
Agent0_Eval_MinReturn : -59.86211013793945
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -5.773351192474365
Agent0_Train_StdReturn : 14.313027381896973
Agent0_Train_MaxReturn : 20.203311920166016
Agent0_Train_MinReturn : -27.264623641967773
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1471500
Agent0_TimeSinceStart : 2314.6526062488556
Agent0_Critic_Loss : 0.7179741859436035
Agent0_Actor_Loss : -0.7886296510696411
Agent0_Alpha_Loss : 0.7197920083999634
Agent0_Temperature : 0.07584940387439458
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -17.894447326660156
Agent1_Eval_StdReturn : 18.89568328857422
Agent1_Eval_MaxReturn : 10.782584190368652
Agent1_Eval_MinReturn : -53.71235656738281
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -11.372687339782715
Agent1_Train_StdReturn : 11.18143367767334
Agent1_Train_MaxReturn : 5.0858473777771
Agent1_Train_MinReturn : -27.282875061035156
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1471500
Agent1_TimeSinceStart : 2316.7771422863007
Agent1_Critic_Loss : 0.7311053276062012
Agent1_Actor_Loss : -0.8644039630889893
Agent1_Alpha_Loss : 0.7334622144699097
Agent1_Temperature : 0.0759235797415027
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 981 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 982 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 983 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 984 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 985 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 986 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 987 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 988 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 989 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 990 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -11.639371871948242
Agent0_Eval_StdReturn : 21.25242042541504
Agent0_Eval_MaxReturn : 16.963361740112305
Agent0_Eval_MinReturn : -56.34259796142578
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -21.286405563354492
Agent0_Train_StdReturn : 23.5972957611084
Agent0_Train_MaxReturn : 12.399872779846191
Agent0_Train_MinReturn : -84.64105987548828
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1486500
Agent0_TimeSinceStart : 2338.241994857788
Agent0_Critic_Loss : 0.6368573904037476
Agent0_Actor_Loss : -0.9025330543518066
Agent0_Alpha_Loss : 0.7217196226119995
Agent0_Temperature : 0.07564115579304308
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -17.463979721069336
Agent1_Eval_StdReturn : 12.877161979675293
Agent1_Eval_MaxReturn : -3.99495792388916
Agent1_Eval_MinReturn : -45.88735580444336
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -6.883005619049072
Agent1_Train_StdReturn : 16.338050842285156
Agent1_Train_MaxReturn : 16.594886779785156
Agent1_Train_MinReturn : -41.70326232910156
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1486500
Agent1_TimeSinceStart : 2340.3714847564697
Agent1_Critic_Loss : 1.0573607683181763
Agent1_Actor_Loss : -0.9531529545783997
Agent1_Alpha_Loss : 0.7306195497512817
Agent1_Temperature : 0.07571122438295208
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 991 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 992 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 993 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 994 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer.../home/harvey/anaconda3/envs/285final/lib/python3.7/site-packages/gym/core.py:318: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  "Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future."
/home/harvey/anaconda3/envs/285final/lib/python3.7/site-packages/gym/wrappers/step_api_compatibility.py:40: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  "Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future."
/home/harvey/anaconda3/envs/285final/lib/python3.7/site-packages/gym/core.py:257: DeprecationWarning: [33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.[0m
  "Function `env.seed(seed)` is marked as deprecated and will be removed in the future. "


Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 995 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 996 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 997 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 998 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 999 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...
./peersacv2.sh: 18: --seed: not found



LOGGING TO:  /home/harvey/Documents/cs285/CS285-Project/cs285/scripts/../../data/peersac_v2_5agents_HalfCheetah-v4_12-12-2022_03-51-57 



########################
logging outputs to  /home/harvey/Documents/cs285/CS285-Project/cs285/scripts/../../data/peersac_v2_5agents_HalfCheetah-v4_12-12-2022_03-51-57
########################
Using GPU id 0


********** Iteration 0 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -32.58100509643555
Agent0_Eval_StdReturn : 38.008583068847656
Agent0_Eval_MaxReturn : 18.935745239257812
Agent0_Eval_MinReturn : -95.31880187988281
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -68.51490020751953
Agent0_Train_StdReturn : 35.8519172668457
Agent0_Train_MaxReturn : 10.17027473449707
Agent0_Train_MinReturn : -109.59283447265625
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1500
Agent0_TimeSinceStart : 2.1380558013916016
Agent0_Critic_Loss : 1.7086536884307861
Agent0_Actor_Loss : -0.34447938203811646
Agent0_Alpha_Loss : 0.9863041639328003
Agent0_Temperature : 0.09997000449985415
Agent0_Initial_DataCollection_AverageReturn : -68.51490020751953
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -51.067047119140625
Agent1_Eval_StdReturn : 36.643306732177734
Agent1_Eval_MaxReturn : 5.4539031982421875
Agent1_Eval_MinReturn : -123.81517028808594
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -41.37040710449219
Agent1_Train_StdReturn : 23.476428985595703
Agent1_Train_MaxReturn : -3.7883758544921875
Agent1_Train_MinReturn : -74.03202819824219
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1500
Agent1_TimeSinceStart : 4.16731071472168
Agent1_Critic_Loss : 0.9912823438644409
Agent1_Actor_Loss : -0.4837449789047241
Agent1_Alpha_Loss : 0.9798400402069092
Agent1_Temperature : 0.09997000449985614
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 1 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 2 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 3 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 4 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 5 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 6 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 7 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 8 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 9 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 10 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -46.618980407714844
Agent0_Eval_StdReturn : 34.360862731933594
Agent0_Eval_MaxReturn : 4.177082061767578
Agent0_Eval_MinReturn : -101.20817565917969
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -47.71162033081055
Agent0_Train_StdReturn : 16.91861343383789
Agent0_Train_MaxReturn : -16.964988708496094
Agent0_Train_MinReturn : -70.50853729248047
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 16500
Agent0_TimeSinceStart : 24.743014097213745
Agent0_Critic_Loss : 0.8942358493804932
Agent0_Actor_Loss : -0.45209968090057373
Agent0_Alpha_Loss : 0.9856557846069336
Agent0_Temperature : 0.09967050744945741
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -23.17498016357422
Agent1_Eval_StdReturn : 35.43242645263672
Agent1_Eval_MaxReturn : 30.243358612060547
Agent1_Eval_MinReturn : -104.72036743164062
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -49.53214645385742
Agent1_Train_StdReturn : 23.37198829650879
Agent1_Train_MaxReturn : -17.918338775634766
Agent1_Train_MinReturn : -91.98331451416016
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 16500
Agent1_TimeSinceStart : 26.886576414108276
Agent1_Critic_Loss : 1.0224330425262451
Agent1_Actor_Loss : -0.5217679738998413
Agent1_Alpha_Loss : 0.9854030013084412
Agent1_Temperature : 0.09967044117277171
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 11 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 12 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 13 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 14 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 15 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 16 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 17 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 18 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 19 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 20 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -46.330047607421875
Agent0_Eval_StdReturn : 49.37164306640625
Agent0_Eval_MaxReturn : 24.719141006469727
Agent0_Eval_MinReturn : -123.84056091308594
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -19.812902450561523
Agent0_Train_StdReturn : 29.254955291748047
Agent0_Train_MaxReturn : 34.5399055480957
Agent0_Train_MinReturn : -71.24075317382812
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 31500
Agent0_TimeSinceStart : 48.4534969329834
Agent0_Critic_Loss : 0.8943381309509277
Agent0_Actor_Loss : -0.4953515827655792
Agent0_Alpha_Loss : 0.9938284158706665
Agent0_Temperature : 0.09937202970545943
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -47.99956512451172
Agent1_Eval_StdReturn : 25.836910247802734
Agent1_Eval_MaxReturn : 6.322393417358398
Agent1_Eval_MinReturn : -81.1266098022461
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -47.09725570678711
Agent1_Train_StdReturn : 28.182693481445312
Agent1_Train_MaxReturn : -5.158754825592041
Agent1_Train_MinReturn : -86.24165344238281
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 31500
Agent1_TimeSinceStart : 50.59868383407593
Agent1_Critic_Loss : 0.739264965057373
Agent1_Actor_Loss : -0.5862676501274109
Agent1_Alpha_Loss : 0.9884578585624695
Agent1_Temperature : 0.09937173561606101
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 21 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 22 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 23 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 24 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 25 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 26 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 27 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 28 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 29 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 30 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -25.192249298095703
Agent0_Eval_StdReturn : 25.30379295349121
Agent0_Eval_MaxReturn : 3.0973892211914062
Agent0_Eval_MinReturn : -60.547706604003906
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -37.913211822509766
Agent0_Train_StdReturn : 32.80707931518555
Agent0_Train_MaxReturn : 1.5589098930358887
Agent0_Train_MinReturn : -105.21112060546875
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 46500
Agent0_TimeSinceStart : 72.07559943199158
Agent0_Critic_Loss : 0.8887016773223877
Agent0_Actor_Loss : -0.4369214177131653
Agent0_Alpha_Loss : 0.988058865070343
Agent0_Temperature : 0.09907434019726678
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -51.427154541015625
Agent1_Eval_StdReturn : 21.33152198791504
Agent1_Eval_MaxReturn : -16.6425724029541
Agent1_Eval_MinReturn : -91.05067443847656
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -52.567970275878906
Agent1_Train_StdReturn : 36.218318939208984
Agent1_Train_MaxReturn : 14.909168243408203
Agent1_Train_MinReturn : -131.29782104492188
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 46500
Agent1_TimeSinceStart : 74.22004318237305
Agent1_Critic_Loss : 0.758634090423584
Agent1_Actor_Loss : -0.567564845085144
Agent1_Alpha_Loss : 0.9845913648605347
Agent1_Temperature : 0.09907393494136207
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 31 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 32 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 33 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 34 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 35 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 36 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 37 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 38 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 39 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 40 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -51.81474685668945
Agent0_Eval_StdReturn : 25.792320251464844
Agent0_Eval_MaxReturn : -2.598421096801758
Agent0_Eval_MinReturn : -97.19104766845703
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -50.26304626464844
Agent0_Train_StdReturn : 36.14711380004883
Agent0_Train_MaxReturn : -3.343472480773926
Agent0_Train_MinReturn : -111.74008178710938
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 61500
Agent0_TimeSinceStart : 95.7771384716034
Agent0_Critic_Loss : 0.85677570104599
Agent0_Actor_Loss : -0.4834839701652527
Agent0_Alpha_Loss : 0.9817242622375488
Agent0_Temperature : 0.09877806434367238
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -48.24110794067383
Agent1_Eval_StdReturn : 43.748985290527344
Agent1_Eval_MaxReturn : 10.693902015686035
Agent1_Eval_MinReturn : -126.4328842163086
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -35.22085189819336
Agent1_Train_StdReturn : 30.384601593017578
Agent1_Train_MaxReturn : 11.832371711730957
Agent1_Train_MinReturn : -92.32306671142578
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 61500
Agent1_TimeSinceStart : 97.91944861412048
Agent1_Critic_Loss : 0.7632298469543457
Agent1_Actor_Loss : -0.5450243353843689
Agent1_Alpha_Loss : 0.9787603616714478
Agent1_Temperature : 0.09877750537214858
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 41 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 42 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 43 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 44 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 45 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 46 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 47 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 48 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 49 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 50 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -47.231201171875
Agent0_Eval_StdReturn : 31.12499237060547
Agent0_Eval_MaxReturn : 18.758352279663086
Agent0_Eval_MinReturn : -88.896240234375
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -37.9083251953125
Agent0_Train_StdReturn : 26.463823318481445
Agent0_Train_MaxReturn : 1.205824613571167
Agent0_Train_MinReturn : -83.82466888427734
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 76500
Agent0_TimeSinceStart : 119.51742815971375
Agent0_Critic_Loss : 0.702551007270813
Agent0_Actor_Loss : -0.4979085326194763
Agent0_Alpha_Loss : 0.9726197719573975
Agent0_Temperature : 0.09848341178896498
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -41.91449737548828
Agent1_Eval_StdReturn : 38.189754486083984
Agent1_Eval_MaxReturn : 20.076635360717773
Agent1_Eval_MinReturn : -104.0946044921875
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -39.73896789550781
Agent1_Train_StdReturn : 43.03814697265625
Agent1_Train_MaxReturn : 33.95060348510742
Agent1_Train_MinReturn : -100.48456573486328
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 76500
Agent1_TimeSinceStart : 121.6697838306427
Agent1_Critic_Loss : 0.7645267844200134
Agent1_Actor_Loss : -0.5161893367767334
Agent1_Alpha_Loss : 0.9827108979225159
Agent1_Temperature : 0.09848265155672024
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 51 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 52 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 53 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 54 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 55 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 56 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 57 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 58 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 59 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 60 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -23.058563232421875
Agent0_Eval_StdReturn : 24.89092254638672
Agent0_Eval_MaxReturn : 34.60225296020508
Agent0_Eval_MinReturn : -51.01687240600586
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -47.699371337890625
Agent0_Train_StdReturn : 34.96453094482422
Agent0_Train_MaxReturn : 36.56296157836914
Agent0_Train_MinReturn : -93.66365051269531
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 91500
Agent0_TimeSinceStart : 143.21510481834412
Agent0_Critic_Loss : 0.6643715500831604
Agent0_Actor_Loss : -0.5324295163154602
Agent0_Alpha_Loss : 0.9678753614425659
Agent0_Temperature : 0.09819020510403086
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -41.831787109375
Agent1_Eval_StdReturn : 19.8931827545166
Agent1_Eval_MaxReturn : -17.821029663085938
Agent1_Eval_MinReturn : -88.01695251464844
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -42.75724792480469
Agent1_Train_StdReturn : 32.87258529663086
Agent1_Train_MaxReturn : 3.8843421936035156
Agent1_Train_MinReturn : -104.14067077636719
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 91500
Agent1_TimeSinceStart : 145.36660623550415
Agent1_Critic_Loss : 0.6939704418182373
Agent1_Actor_Loss : -0.5409138202667236
Agent1_Alpha_Loss : 0.9693310856819153
Agent1_Temperature : 0.09818908928501255
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 61 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 62 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 63 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 64 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 65 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 66 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 67 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 68 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 69 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 70 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -38.8419075012207
Agent0_Eval_StdReturn : 29.566526412963867
Agent0_Eval_MaxReturn : -3.729405164718628
Agent0_Eval_MinReturn : -113.11373901367188
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -52.9005241394043
Agent0_Train_StdReturn : 40.080482482910156
Agent0_Train_MaxReturn : 1.0143446922302246
Agent0_Train_MinReturn : -107.70153045654297
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 106500
Agent0_TimeSinceStart : 167.08495020866394
Agent0_Critic_Loss : 0.7037286758422852
Agent0_Actor_Loss : -0.4647260308265686
Agent0_Alpha_Loss : 0.9602019786834717
Agent0_Temperature : 0.09789869714272686
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -30.252145767211914
Agent1_Eval_StdReturn : 28.29826545715332
Agent1_Eval_MaxReturn : 16.39629554748535
Agent1_Eval_MinReturn : -75.33551788330078
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -25.83236312866211
Agent1_Train_StdReturn : 29.567489624023438
Agent1_Train_MaxReturn : 26.50406265258789
Agent1_Train_MinReturn : -65.26861572265625
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 106500
Agent1_TimeSinceStart : 169.2313084602356
Agent1_Critic_Loss : 0.5866408348083496
Agent1_Actor_Loss : -0.6239601373672485
Agent1_Alpha_Loss : 0.9610376358032227
Agent1_Temperature : 0.09789759600044688
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 71 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 72 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 73 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 74 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 75 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 76 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 77 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 78 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 79 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 80 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -32.57512664794922
Agent0_Eval_StdReturn : 27.380290985107422
Agent0_Eval_MaxReturn : 9.714351654052734
Agent0_Eval_MinReturn : -82.47639465332031
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -48.643165588378906
Agent0_Train_StdReturn : 21.835474014282227
Agent0_Train_MaxReturn : -13.810791969299316
Agent0_Train_MinReturn : -86.53678131103516
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 121500
Agent0_TimeSinceStart : 190.76241445541382
Agent0_Critic_Loss : 0.5861657857894897
Agent0_Actor_Loss : -0.5243018865585327
Agent0_Alpha_Loss : 0.9481593370437622
Agent0_Temperature : 0.09760997633682657
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -28.237812042236328
Agent1_Eval_StdReturn : 39.9020881652832
Agent1_Eval_MaxReturn : 18.770275115966797
Agent1_Eval_MinReturn : -108.76464080810547
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -31.456554412841797
Agent1_Train_StdReturn : 23.307397842407227
Agent1_Train_MaxReturn : -7.219683647155762
Agent1_Train_MinReturn : -87.21615600585938
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 121500
Agent1_TimeSinceStart : 192.90228486061096
Agent1_Critic_Loss : 0.4728608727455139
Agent1_Actor_Loss : -0.6072537899017334
Agent1_Alpha_Loss : 0.943848192691803
Agent1_Temperature : 0.09760899984253193
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 81 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 82 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 83 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 84 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 85 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 86 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 87 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 88 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 89 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 90 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -17.857620239257812
Agent0_Eval_StdReturn : 29.711423873901367
Agent0_Eval_MaxReturn : 39.58865737915039
Agent0_Eval_MinReturn : -53.58030319213867
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -10.79987907409668
Agent0_Train_StdReturn : 21.534536361694336
Agent0_Train_MaxReturn : 26.618576049804688
Agent0_Train_MinReturn : -48.618534088134766
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 136500
Agent0_TimeSinceStart : 214.52864122390747
Agent0_Critic_Loss : 0.4966686964035034
Agent0_Actor_Loss : -0.5530083179473877
Agent0_Alpha_Loss : 0.9283055067062378
Agent0_Temperature : 0.09732510135183746
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -22.70708465576172
Agent1_Eval_StdReturn : 28.623443603515625
Agent1_Eval_MaxReturn : 41.20599365234375
Agent1_Eval_MinReturn : -65.87571716308594
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -29.3641300201416
Agent1_Train_StdReturn : 18.432497024536133
Agent1_Train_MaxReturn : 7.412674427032471
Agent1_Train_MinReturn : -63.426666259765625
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 136500
Agent1_TimeSinceStart : 216.68724822998047
Agent1_Critic_Loss : 0.5023685693740845
Agent1_Actor_Loss : -0.6076624989509583
Agent1_Alpha_Loss : 0.9397616982460022
Agent1_Temperature : 0.0973242661772684
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 91 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 92 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 93 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 94 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 95 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 96 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 97 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 98 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 99 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 100 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -37.80340576171875
Agent0_Eval_StdReturn : 20.51852035522461
Agent0_Eval_MaxReturn : -8.982361793518066
Agent0_Eval_MinReturn : -69.56307983398438
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -13.584561347961426
Agent0_Train_StdReturn : 29.4119873046875
Agent0_Train_MaxReturn : 39.010250091552734
Agent0_Train_MinReturn : -50.01905059814453
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 151500
Agent0_TimeSinceStart : 238.24879431724548
Agent0_Critic_Loss : 0.4442911446094513
Agent0_Actor_Loss : -0.5299762487411499
Agent0_Alpha_Loss : 0.8924819231033325
Agent0_Temperature : 0.09704567997417912
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -26.93208885192871
Agent1_Eval_StdReturn : 15.997502326965332
Agent1_Eval_MaxReturn : -3.8266448974609375
Agent1_Eval_MinReturn : -59.922542572021484
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -28.49300193786621
Agent1_Train_StdReturn : 23.280410766601562
Agent1_Train_MaxReturn : 2.7106361389160156
Agent1_Train_MinReturn : -77.24320983886719
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 151500
Agent1_TimeSinceStart : 240.30335783958435
Agent1_Critic_Loss : 0.5145032405853271
Agent1_Actor_Loss : -0.7386530637741089
Agent1_Alpha_Loss : 0.8874350786209106
Agent1_Temperature : 0.09704388809122931
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 101 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 102 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 103 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 104 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 105 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 106 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 107 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 108 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 109 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 110 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -26.71738052368164
Agent0_Eval_StdReturn : 9.157398223876953
Agent0_Eval_MaxReturn : -13.375016212463379
Agent0_Eval_MinReturn : -42.88822937011719
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -19.410362243652344
Agent0_Train_StdReturn : 7.425318241119385
Agent0_Train_MaxReturn : -8.613565444946289
Agent0_Train_MinReturn : -30.00765037536621
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 166500
Agent0_TimeSinceStart : 261.1259984970093
Agent0_Critic_Loss : 0.4051252603530884
Agent0_Actor_Loss : -0.5468058586120605
Agent0_Alpha_Loss : 0.8308137655258179
Agent0_Temperature : 0.09677476231533662
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -29.879653930664062
Agent1_Eval_StdReturn : 10.994625091552734
Agent1_Eval_MaxReturn : -4.192960739135742
Agent1_Eval_MinReturn : -39.91998291015625
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -21.70599365234375
Agent1_Train_StdReturn : 8.793038368225098
Agent1_Train_MaxReturn : -6.571042060852051
Agent1_Train_MinReturn : -37.95457458496094
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 166500
Agent1_TimeSinceStart : 263.2101285457611
Agent1_Critic_Loss : 0.4581545293331146
Agent1_Actor_Loss : -0.6983570456504822
Agent1_Alpha_Loss : 0.8447428345680237
Agent1_Temperature : 0.09677138948908492
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 111 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 112 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 113 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 114 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 115 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 116 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 117 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 118 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 119 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 120 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -24.482786178588867
Agent0_Eval_StdReturn : 14.492881774902344
Agent0_Eval_MaxReturn : 3.942654609680176
Agent0_Eval_MinReturn : -49.24791717529297
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -19.76818084716797
Agent0_Train_StdReturn : 14.692700386047363
Agent0_Train_MaxReturn : 8.915509223937988
Agent0_Train_MinReturn : -44.430538177490234
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 181500
Agent0_TimeSinceStart : 284.251855134964
Agent0_Critic_Loss : 0.4409399926662445
Agent0_Actor_Loss : -0.5370804667472839
Agent0_Alpha_Loss : 0.7897802591323853
Agent0_Temperature : 0.09651470315587865
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -29.733917236328125
Agent1_Eval_StdReturn : 14.06531047821045
Agent1_Eval_MaxReturn : -3.601330041885376
Agent1_Eval_MinReturn : -60.80698013305664
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -24.933208465576172
Agent1_Train_StdReturn : 16.737770080566406
Agent1_Train_MaxReturn : -7.081881999969482
Agent1_Train_MinReturn : -65.99290466308594
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 181500
Agent1_TimeSinceStart : 286.34001064300537
Agent1_Critic_Loss : 0.39527273178100586
Agent1_Actor_Loss : -0.6849207878112793
Agent1_Alpha_Loss : 0.7959141135215759
Agent1_Temperature : 0.0965084619101353
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 121 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 122 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 123 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 124 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 125 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 126 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 127 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 128 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 129 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 130 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -30.72934341430664
Agent0_Eval_StdReturn : 7.28204345703125
Agent0_Eval_MaxReturn : -21.046300888061523
Agent0_Eval_MinReturn : -44.18566131591797
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -33.520572662353516
Agent0_Train_StdReturn : 14.600418090820312
Agent0_Train_MaxReturn : -14.512083053588867
Agent0_Train_MinReturn : -68.73931121826172
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 196500
Agent0_TimeSinceStart : 307.4545090198517
Agent0_Critic_Loss : 0.4850107431411743
Agent0_Actor_Loss : -0.4656216502189636
Agent0_Alpha_Loss : 0.7841089367866516
Agent0_Temperature : 0.09626522147069992
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -34.47418212890625
Agent1_Eval_StdReturn : 12.714120864868164
Agent1_Eval_MaxReturn : -17.067184448242188
Agent1_Eval_MinReturn : -63.6812744140625
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -35.14310073852539
Agent1_Train_StdReturn : 14.900437355041504
Agent1_Train_MaxReturn : -18.32403564453125
Agent1_Train_MinReturn : -75.90545654296875
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 196500
Agent1_TimeSinceStart : 309.5500421524048
Agent1_Critic_Loss : 0.3992483615875244
Agent1_Actor_Loss : -0.6165434122085571
Agent1_Alpha_Loss : 0.7931673526763916
Agent1_Temperature : 0.0962551694498973
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 131 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 132 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 133 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 134 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 135 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 136 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 137 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 138 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 139 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 140 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -25.436416625976562
Agent0_Eval_StdReturn : 10.668664932250977
Agent0_Eval_MaxReturn : -5.131865501403809
Agent0_Eval_MinReturn : -41.88395690917969
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -32.71979904174805
Agent0_Train_StdReturn : 6.228855133056641
Agent0_Train_MaxReturn : -22.526844024658203
Agent0_Train_MinReturn : -42.00605010986328
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 211500
Agent0_TimeSinceStart : 330.72842955589294
Agent0_Critic_Loss : 0.39317232370376587
Agent0_Actor_Loss : -0.5013166666030884
Agent0_Alpha_Loss : 0.7903857231140137
Agent0_Temperature : 0.0960199839826443
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -18.286291122436523
Agent1_Eval_StdReturn : 16.946006774902344
Agent1_Eval_MaxReturn : 0.406219482421875
Agent1_Eval_MinReturn : -58.388404846191406
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -31.03554916381836
Agent1_Train_StdReturn : 19.03114891052246
Agent1_Train_MaxReturn : -3.648172378540039
Agent1_Train_MinReturn : -65.96772766113281
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 211500
Agent1_TimeSinceStart : 332.83781027793884
Agent1_Critic_Loss : 0.37308788299560547
Agent1_Actor_Loss : -0.6019374132156372
Agent1_Alpha_Loss : 0.8196832537651062
Agent1_Temperature : 0.09600565036244861
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 141 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 142 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 143 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 144 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 145 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 146 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 147 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 148 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 149 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 150 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -31.892099380493164
Agent0_Eval_StdReturn : 12.439228057861328
Agent0_Eval_MaxReturn : -12.451138496398926
Agent0_Eval_MinReturn : -51.76466369628906
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -27.9456729888916
Agent0_Train_StdReturn : 10.288050651550293
Agent0_Train_MaxReturn : -12.234962463378906
Agent0_Train_MinReturn : -48.911224365234375
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 226500
Agent0_TimeSinceStart : 354.04147028923035
Agent0_Critic_Loss : 0.38597971200942993
Agent0_Actor_Loss : -0.5260317325592041
Agent0_Alpha_Loss : 0.8047704100608826
Agent0_Temperature : 0.0957727699576644
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -26.361913681030273
Agent1_Eval_StdReturn : 16.365890502929688
Agent1_Eval_MaxReturn : 5.785409927368164
Agent1_Eval_MinReturn : -57.972164154052734
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -21.194849014282227
Agent1_Train_StdReturn : 10.356460571289062
Agent1_Train_MaxReturn : -1.4959745407104492
Agent1_Train_MinReturn : -33.84349822998047
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 226500
Agent1_TimeSinceStart : 356.1612570285797
Agent1_Critic_Loss : 0.36958667635917664
Agent1_Actor_Loss : -0.539533257484436
Agent1_Alpha_Loss : 0.8046441674232483
Agent1_Temperature : 0.09575486746138635
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 151 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 152 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 153 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 154 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 155 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 156 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 157 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 158 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 159 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 160 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -28.369461059570312
Agent0_Eval_StdReturn : 15.800494194030762
Agent0_Eval_MaxReturn : -6.013942718505859
Agent0_Eval_MinReturn : -50.84025573730469
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -17.05450439453125
Agent0_Train_StdReturn : 22.834875106811523
Agent0_Train_MaxReturn : 17.602853775024414
Agent0_Train_MinReturn : -56.72097396850586
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 241500
Agent0_TimeSinceStart : 378.08526277542114
Agent0_Critic_Loss : 0.39450690150260925
Agent0_Actor_Loss : -0.4640153646469116
Agent0_Alpha_Loss : 0.8255113959312439
Agent0_Temperature : 0.09552109655257941
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -25.255813598632812
Agent1_Eval_StdReturn : 6.8625874519348145
Agent1_Eval_MaxReturn : -14.703727722167969
Agent1_Eval_MinReturn : -36.29902648925781
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -20.357406616210938
Agent1_Train_StdReturn : 11.571333885192871
Agent1_Train_MaxReturn : 3.507589340209961
Agent1_Train_MinReturn : -36.570167541503906
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 241500
Agent1_TimeSinceStart : 380.27550649642944
Agent1_Critic_Loss : 0.2832237482070923
Agent1_Actor_Loss : -0.6322349309921265
Agent1_Alpha_Loss : 0.8384940028190613
Agent1_Temperature : 0.09550122755746757
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 161 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 162 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 163 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 164 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 165 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 166 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 167 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 168 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 169 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 170 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -21.955142974853516
Agent0_Eval_StdReturn : 14.017755508422852
Agent0_Eval_MaxReturn : -3.4731693267822266
Agent0_Eval_MinReturn : -58.09199905395508
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -17.145771026611328
Agent0_Train_StdReturn : 11.94571304321289
Agent0_Train_MaxReturn : 5.7421698570251465
Agent0_Train_MinReturn : -38.180389404296875
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 256500
Agent0_TimeSinceStart : 402.20443320274353
Agent0_Critic_Loss : 0.30586960911750793
Agent0_Actor_Loss : -0.32850509881973267
Agent0_Alpha_Loss : 0.8147903680801392
Agent0_Temperature : 0.09526527187051673
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -28.28069496154785
Agent1_Eval_StdReturn : 25.534046173095703
Agent1_Eval_MaxReturn : -3.7594070434570312
Agent1_Eval_MinReturn : -93.77108764648438
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -25.064228057861328
Agent1_Train_StdReturn : 17.75586700439453
Agent1_Train_MaxReturn : 1.773763656616211
Agent1_Train_MinReturn : -55.343414306640625
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 256500
Agent1_TimeSinceStart : 404.3775327205658
Agent1_Critic_Loss : 0.3038290739059448
Agent1_Actor_Loss : -0.5801087617874146
Agent1_Alpha_Loss : 0.8144093751907349
Agent1_Temperature : 0.09524513003155671
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 171 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 172 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 173 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 174 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 175 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 176 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 177 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 178 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 179 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 180 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -27.076618194580078
Agent0_Eval_StdReturn : 15.346336364746094
Agent0_Eval_MaxReturn : -4.051137924194336
Agent0_Eval_MinReturn : -60.678123474121094
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -17.712825775146484
Agent0_Train_StdReturn : 13.926739692687988
Agent0_Train_MaxReturn : 10.59235954284668
Agent0_Train_MinReturn : -37.77747344970703
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 271500
Agent0_TimeSinceStart : 426.1080753803253
Agent0_Critic_Loss : 0.318859338760376
Agent0_Actor_Loss : -0.48374971747398376
Agent0_Alpha_Loss : 0.8070443868637085
Agent0_Temperature : 0.09500847950734942
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -14.019808769226074
Agent1_Eval_StdReturn : 4.695367336273193
Agent1_Eval_MaxReturn : -6.574995517730713
Agent1_Eval_MinReturn : -22.182910919189453
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -19.994857788085938
Agent1_Train_StdReturn : 17.90374183654785
Agent1_Train_MaxReturn : 10.091588020324707
Agent1_Train_MinReturn : -43.324684143066406
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 271500
Agent1_TimeSinceStart : 428.2731342315674
Agent1_Critic_Loss : 0.3104366660118103
Agent1_Actor_Loss : -0.5791971683502197
Agent1_Alpha_Loss : 0.8123703002929688
Agent1_Temperature : 0.0949880875299392
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 181 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 182 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 183 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 184 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 185 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 186 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 187 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 188 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 189 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 190 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -21.80546760559082
Agent0_Eval_StdReturn : 16.769208908081055
Agent0_Eval_MaxReturn : 6.622250556945801
Agent0_Eval_MinReturn : -49.69880294799805
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -16.967369079589844
Agent0_Train_StdReturn : 10.091402053833008
Agent0_Train_MaxReturn : -4.692663192749023
Agent0_Train_MinReturn : -36.403682708740234
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 286500
Agent0_TimeSinceStart : 450.03607726097107
Agent0_Critic_Loss : 0.30364954471588135
Agent0_Actor_Loss : -0.4403717517852783
Agent0_Alpha_Loss : 0.796306312084198
Agent0_Temperature : 0.09475282935455145
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -22.501718521118164
Agent1_Eval_StdReturn : 9.146004676818848
Agent1_Eval_MaxReturn : -9.557808876037598
Agent1_Eval_MinReturn : -34.794677734375
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -20.40598487854004
Agent1_Train_StdReturn : 12.294474601745605
Agent1_Train_MaxReturn : -7.418977737426758
Agent1_Train_MinReturn : -45.753150939941406
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 286500
Agent1_TimeSinceStart : 452.1932182312012
Agent1_Critic_Loss : 0.26685407757759094
Agent1_Actor_Loss : -0.5384045839309692
Agent1_Alpha_Loss : 0.8114606738090515
Agent1_Temperature : 0.09473029919771728
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 191 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 192 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 193 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 194 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 195 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 196 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 197 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 198 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 199 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 200 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -25.69723129272461
Agent0_Eval_StdReturn : 20.455692291259766
Agent0_Eval_MaxReturn : 10.974164962768555
Agent0_Eval_MinReturn : -51.000919342041016
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -20.289236068725586
Agent0_Train_StdReturn : 17.39792251586914
Agent0_Train_MaxReturn : 0.43537425994873047
Agent0_Train_MinReturn : -65.25035858154297
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 301500
Agent0_TimeSinceStart : 473.9722635746002
Agent0_Critic_Loss : 0.2412942796945572
Agent0_Actor_Loss : -0.3400561213493347
Agent0_Alpha_Loss : 0.7977859377861023
Agent0_Temperature : 0.09449895330535356
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -20.21791648864746
Agent1_Eval_StdReturn : 11.459834098815918
Agent1_Eval_MaxReturn : 3.1967945098876953
Agent1_Eval_MinReturn : -35.55563735961914
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -25.8229923248291
Agent1_Train_StdReturn : 10.7367582321167
Agent1_Train_MaxReturn : -4.19175910949707
Agent1_Train_MinReturn : -41.7381706237793
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 301500
Agent1_TimeSinceStart : 476.12339997291565
Agent1_Critic_Loss : 0.329375684261322
Agent1_Actor_Loss : -0.5519530177116394
Agent1_Alpha_Loss : 0.8178637027740479
Agent1_Temperature : 0.09447224516686203
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 201 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 202 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 203 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 204 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 205 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 206 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 207 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 208 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 209 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 210 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -21.8115291595459
Agent0_Eval_StdReturn : 13.657686233520508
Agent0_Eval_MaxReturn : -2.757404327392578
Agent0_Eval_MinReturn : -48.650047302246094
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -14.39471435546875
Agent0_Train_StdReturn : 16.347627639770508
Agent0_Train_MaxReturn : 14.92820930480957
Agent0_Train_MinReturn : -34.654483795166016
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 316500
Agent0_TimeSinceStart : 497.83043456077576
Agent0_Critic_Loss : 0.27737730741500854
Agent0_Actor_Loss : -0.41797274351119995
Agent0_Alpha_Loss : 0.7780022025108337
Agent0_Temperature : 0.09424531666721062
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -22.183481216430664
Agent1_Eval_StdReturn : 12.680124282836914
Agent1_Eval_MaxReturn : -5.597496032714844
Agent1_Eval_MinReturn : -41.762596130371094
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -16.213851928710938
Agent1_Train_StdReturn : 18.73265838623047
Agent1_Train_MaxReturn : 12.309500694274902
Agent1_Train_MinReturn : -50.59186935424805
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 316500
Agent1_TimeSinceStart : 499.98259115219116
Agent1_Critic_Loss : 0.26005643606185913
Agent1_Actor_Loss : -0.4757649302482605
Agent1_Alpha_Loss : 0.8048917651176453
Agent1_Temperature : 0.09421393358537866
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 211 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 212 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 213 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 214 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 215 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 216 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 217 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 218 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 219 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 220 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -13.577470779418945
Agent0_Eval_StdReturn : 16.09775161743164
Agent0_Eval_MaxReturn : 13.942264556884766
Agent0_Eval_MinReturn : -37.72106170654297
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -10.577577590942383
Agent0_Train_StdReturn : 17.933340072631836
Agent0_Train_MaxReturn : 13.795208930969238
Agent0_Train_MinReturn : -42.75967025756836
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 331500
Agent0_TimeSinceStart : 521.6905169487
Agent0_Critic_Loss : 0.2705122232437134
Agent0_Actor_Loss : -0.3920987546443939
Agent0_Alpha_Loss : 0.7923597097396851
Agent0_Temperature : 0.09399066654138319
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -24.284931182861328
Agent1_Eval_StdReturn : 18.248394012451172
Agent1_Eval_MaxReturn : 1.9455909729003906
Agent1_Eval_MinReturn : -64.74829864501953
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -17.958498001098633
Agent1_Train_StdReturn : 16.714183807373047
Agent1_Train_MaxReturn : 7.660728454589844
Agent1_Train_MinReturn : -46.426483154296875
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 331500
Agent1_TimeSinceStart : 523.8493449687958
Agent1_Critic_Loss : 0.2633100748062134
Agent1_Actor_Loss : -0.48805761337280273
Agent1_Alpha_Loss : 0.7811381816864014
Agent1_Temperature : 0.09395560785892178
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 221 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 222 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 223 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 224 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 225 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 226 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 227 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 228 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 229 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 230 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -18.710599899291992
Agent0_Eval_StdReturn : 15.809965133666992
Agent0_Eval_MaxReturn : 2.2870659828186035
Agent0_Eval_MinReturn : -44.86009216308594
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -19.17093276977539
Agent0_Train_StdReturn : 13.501765251159668
Agent0_Train_MaxReturn : 0.7054409384727478
Agent0_Train_MinReturn : -39.32066345214844
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 346500
Agent0_TimeSinceStart : 545.4897043704987
Agent0_Critic_Loss : 0.22688761353492737
Agent0_Actor_Loss : -0.3476746678352356
Agent0_Alpha_Loss : 0.7892990112304688
Agent0_Temperature : 0.09373451595001299
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -23.829654693603516
Agent1_Eval_StdReturn : 16.401927947998047
Agent1_Eval_MaxReturn : -4.864241123199463
Agent1_Eval_MinReturn : -53.475162506103516
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -21.34646987915039
Agent1_Train_StdReturn : 16.41570472717285
Agent1_Train_MaxReturn : 14.388132095336914
Agent1_Train_MinReturn : -40.5125732421875
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 346500
Agent1_TimeSinceStart : 547.6319847106934
Agent1_Critic_Loss : 0.2123662829399109
Agent1_Actor_Loss : -0.47763341665267944
Agent1_Alpha_Loss : 0.8241918683052063
Agent1_Temperature : 0.09369781734922288
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 231 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 232 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 233 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 234 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 235 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 236 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 237 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 238 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 239 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 240 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -17.333988189697266
Agent0_Eval_StdReturn : 22.86820411682129
Agent0_Eval_MaxReturn : 3.0578129291534424
Agent0_Eval_MinReturn : -78.88383483886719
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -20.085369110107422
Agent0_Train_StdReturn : 9.355685234069824
Agent0_Train_MaxReturn : 0.6124482154846191
Agent0_Train_MinReturn : -33.810489654541016
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 361500
Agent0_TimeSinceStart : 569.3372440338135
Agent0_Critic_Loss : 0.22649532556533813
Agent0_Actor_Loss : -0.4314124584197998
Agent0_Alpha_Loss : 0.8179545998573303
Agent0_Temperature : 0.09347691437687203
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -18.3162899017334
Agent1_Eval_StdReturn : 17.166223526000977
Agent1_Eval_MaxReturn : 1.881246566772461
Agent1_Eval_MinReturn : -51.84557342529297
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -34.039085388183594
Agent1_Train_StdReturn : 13.983345031738281
Agent1_Train_MaxReturn : -18.71865463256836
Agent1_Train_MinReturn : -56.42881774902344
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 361500
Agent1_TimeSinceStart : 571.4857888221741
Agent1_Critic_Loss : 0.23187902569770813
Agent1_Actor_Loss : -0.46610862016677856
Agent1_Alpha_Loss : 0.818598747253418
Agent1_Temperature : 0.09343862549918217
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 241 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 242 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 243 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 244 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 245 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 246 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 247 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 248 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 249 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 250 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -28.273305892944336
Agent0_Eval_StdReturn : 20.605722427368164
Agent0_Eval_MaxReturn : 3.391468048095703
Agent0_Eval_MinReturn : -61.47727966308594
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -22.134458541870117
Agent0_Train_StdReturn : 25.50248146057129
Agent0_Train_MaxReturn : 0.7803969383239746
Agent0_Train_MinReturn : -94.14483642578125
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 376500
Agent0_TimeSinceStart : 593.1855442523956
Agent0_Critic_Loss : 0.3047303557395935
Agent0_Actor_Loss : -0.4328756034374237
Agent0_Alpha_Loss : 0.8132928013801575
Agent0_Temperature : 0.09321761287041025
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -19.992265701293945
Agent1_Eval_StdReturn : 10.623624801635742
Agent1_Eval_MaxReturn : -2.776881694793701
Agent1_Eval_MinReturn : -35.5587043762207
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -10.000242233276367
Agent1_Train_StdReturn : 11.439395904541016
Agent1_Train_MaxReturn : 4.235828399658203
Agent1_Train_MinReturn : -32.62958908081055
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 376500
Agent1_TimeSinceStart : 595.3349454402924
Agent1_Critic_Loss : 0.2005358785390854
Agent1_Actor_Loss : -0.4687945246696472
Agent1_Alpha_Loss : 0.8252982497215271
Agent1_Temperature : 0.09317791669596483
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 251 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 252 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 253 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 254 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 255 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 256 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 257 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 258 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 259 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 260 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -21.173725128173828
Agent0_Eval_StdReturn : 22.272939682006836
Agent0_Eval_MaxReturn : 7.241703510284424
Agent0_Eval_MinReturn : -63.53387451171875
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -22.807300567626953
Agent0_Train_StdReturn : 16.27992057800293
Agent0_Train_MaxReturn : 1.8352727890014648
Agent0_Train_MinReturn : -44.94645690917969
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 391500
Agent0_TimeSinceStart : 617.0968654155731
Agent0_Critic_Loss : 0.24238094687461853
Agent0_Actor_Loss : -0.3988884687423706
Agent0_Alpha_Loss : 0.8145051598548889
Agent0_Temperature : 0.09295810211711002
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -22.740795135498047
Agent1_Eval_StdReturn : 17.84267807006836
Agent1_Eval_MaxReturn : -0.16417014598846436
Agent1_Eval_MinReturn : -68.10855102539062
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -18.616830825805664
Agent1_Train_StdReturn : 12.847663879394531
Agent1_Train_MaxReturn : 6.060478687286377
Agent1_Train_MinReturn : -45.211875915527344
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 391500
Agent1_TimeSinceStart : 619.2491433620453
Agent1_Critic_Loss : 0.2865895628929138
Agent1_Actor_Loss : -0.5141335725784302
Agent1_Alpha_Loss : 0.8191352486610413
Agent1_Temperature : 0.09291674372453547
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 261 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 262 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 263 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 264 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 265 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 266 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 267 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 268 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 269 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 270 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -10.512846946716309
Agent0_Eval_StdReturn : 13.774767875671387
Agent0_Eval_MaxReturn : 11.582235336303711
Agent0_Eval_MinReturn : -32.29518508911133
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -13.4161376953125
Agent0_Train_StdReturn : 23.522686004638672
Agent0_Train_MaxReturn : 23.2353515625
Agent0_Train_MinReturn : -55.13616180419922
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 406500
Agent0_TimeSinceStart : 640.9416317939758
Agent0_Critic_Loss : 0.3442981243133545
Agent0_Actor_Loss : -0.40543293952941895
Agent0_Alpha_Loss : 0.8171842098236084
Agent0_Temperature : 0.09269592974801372
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -9.648462295532227
Agent1_Eval_StdReturn : 22.913223266601562
Agent1_Eval_MaxReturn : 26.497390747070312
Agent1_Eval_MinReturn : -54.01353454589844
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -33.79578399658203
Agent1_Train_StdReturn : 15.738564491271973
Agent1_Train_MaxReturn : -1.1309329271316528
Agent1_Train_MinReturn : -54.414337158203125
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 406500
Agent1_TimeSinceStart : 643.0872464179993
Agent1_Critic_Loss : 0.26162654161453247
Agent1_Actor_Loss : -0.5619012117385864
Agent1_Alpha_Loss : 0.8127342462539673
Agent1_Temperature : 0.09265593987875001
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 271 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 272 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 273 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 274 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 275 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 276 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 277 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 278 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 279 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 280 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -30.283252716064453
Agent0_Eval_StdReturn : 25.37603759765625
Agent0_Eval_MaxReturn : 12.135286331176758
Agent0_Eval_MinReturn : -77.88578796386719
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -23.479312896728516
Agent0_Train_StdReturn : 18.681013107299805
Agent0_Train_MaxReturn : -0.013998985290527344
Agent0_Train_MinReturn : -59.95723342895508
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 421500
Agent0_TimeSinceStart : 664.783255815506
Agent0_Critic_Loss : 0.36272817850112915
Agent0_Actor_Loss : -0.49390438199043274
Agent0_Alpha_Loss : 0.8066123723983765
Agent0_Temperature : 0.09243355152872568
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -18.736736297607422
Agent1_Eval_StdReturn : 17.764461517333984
Agent1_Eval_MaxReturn : 7.280604362487793
Agent1_Eval_MinReturn : -51.28277587890625
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -21.252260208129883
Agent1_Train_StdReturn : 16.68300437927246
Agent1_Train_MaxReturn : 18.72759437561035
Agent1_Train_MinReturn : -40.4295654296875
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 421500
Agent1_TimeSinceStart : 666.9400198459625
Agent1_Critic_Loss : 0.2777755856513977
Agent1_Actor_Loss : -0.4685590863227844
Agent1_Alpha_Loss : 0.8310694694519043
Agent1_Temperature : 0.09239528086008178
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 281 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 282 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 283 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 284 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 285 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 286 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 287 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 288 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 289 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 290 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -23.595516204833984
Agent0_Eval_StdReturn : 20.059581756591797
Agent0_Eval_MaxReturn : 10.174663543701172
Agent0_Eval_MinReturn : -55.899757385253906
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -32.25330352783203
Agent0_Train_StdReturn : 26.456214904785156
Agent0_Train_MaxReturn : 28.51021385192871
Agent0_Train_MinReturn : -62.81499481201172
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 436500
Agent0_TimeSinceStart : 688.5843064785004
Agent0_Critic_Loss : 0.3397170305252075
Agent0_Actor_Loss : -0.4539000391960144
Agent0_Alpha_Loss : 0.8094656467437744
Agent0_Temperature : 0.09217217773772532
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -26.199859619140625
Agent1_Eval_StdReturn : 30.655960083007812
Agent1_Eval_MaxReturn : 19.09996223449707
Agent1_Eval_MinReturn : -85.20821380615234
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -20.576250076293945
Agent1_Train_StdReturn : 23.522932052612305
Agent1_Train_MaxReturn : 16.836807250976562
Agent1_Train_MinReturn : -63.4809684753418
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 436500
Agent1_TimeSinceStart : 690.7995011806488
Agent1_Critic_Loss : 0.3389924168586731
Agent1_Actor_Loss : -0.5380591154098511
Agent1_Alpha_Loss : 0.8115537166595459
Agent1_Temperature : 0.09213540255554403
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 291 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 292 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 293 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 294 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 295 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 296 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 297 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 298 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 299 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 300 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -19.194705963134766
Agent0_Eval_StdReturn : 20.533872604370117
Agent0_Eval_MaxReturn : 11.376367568969727
Agent0_Eval_MinReturn : -66.9398193359375
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -30.98599624633789
Agent0_Train_StdReturn : 27.600034713745117
Agent0_Train_MaxReturn : 11.761993408203125
Agent0_Train_MinReturn : -71.42707061767578
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 451500
Agent0_TimeSinceStart : 712.5717418193817
Agent0_Critic_Loss : 0.32151931524276733
Agent0_Actor_Loss : -0.4429622292518616
Agent0_Alpha_Loss : 0.8083616495132446
Agent0_Temperature : 0.09191241202806633
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -20.708343505859375
Agent1_Eval_StdReturn : 16.63187599182129
Agent1_Eval_MaxReturn : 6.875889778137207
Agent1_Eval_MinReturn : -49.585262298583984
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -23.951841354370117
Agent1_Train_StdReturn : 19.38088607788086
Agent1_Train_MaxReturn : 13.88760757446289
Agent1_Train_MinReturn : -53.550289154052734
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 451500
Agent1_TimeSinceStart : 714.7252426147461
Agent1_Critic_Loss : 0.3512432277202606
Agent1_Actor_Loss : -0.7054246068000793
Agent1_Alpha_Loss : 0.8117501735687256
Agent1_Temperature : 0.09187611557410194
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 301 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 302 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 303 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 304 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 305 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 306 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 307 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 308 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 309 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 310 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -25.286510467529297
Agent0_Eval_StdReturn : 20.459747314453125
Agent0_Eval_MaxReturn : 6.085593223571777
Agent0_Eval_MinReturn : -57.886348724365234
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -21.134723663330078
Agent0_Train_StdReturn : 31.16391944885254
Agent0_Train_MaxReturn : 27.580158233642578
Agent0_Train_MinReturn : -85.47311401367188
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 466500
Agent0_TimeSinceStart : 736.3947036266327
Agent0_Critic_Loss : 0.398018479347229
Agent0_Actor_Loss : -0.3958684802055359
Agent0_Alpha_Loss : 0.8079240322113037
Agent0_Temperature : 0.0916534327516035
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -26.192956924438477
Agent1_Eval_StdReturn : 11.477371215820312
Agent1_Eval_MaxReturn : -12.226518630981445
Agent1_Eval_MinReturn : -49.11680603027344
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -24.602725982666016
Agent1_Train_StdReturn : 15.936698913574219
Agent1_Train_MaxReturn : 4.593789100646973
Agent1_Train_MinReturn : -47.22639465332031
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 466500
Agent1_TimeSinceStart : 738.5678281784058
Agent1_Critic_Loss : 0.332567423582077
Agent1_Actor_Loss : -0.5542720556259155
Agent1_Alpha_Loss : 0.8019198775291443
Agent1_Temperature : 0.09161719579519823
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 311 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 312 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 313 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 314 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 315 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 316 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 317 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 318 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 319 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 320 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -24.705801010131836
Agent0_Eval_StdReturn : 19.075075149536133
Agent0_Eval_MaxReturn : 2.4338719844818115
Agent0_Eval_MinReturn : -54.608985900878906
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -22.203445434570312
Agent0_Train_StdReturn : 13.708393096923828
Agent0_Train_MaxReturn : 2.7937564849853516
Agent0_Train_MinReturn : -41.12067413330078
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 481500
Agent0_TimeSinceStart : 760.3227150440216
Agent0_Critic_Loss : 0.33031201362609863
Agent0_Actor_Loss : -0.5101511478424072
Agent0_Alpha_Loss : 0.821237325668335
Agent0_Temperature : 0.09139412485821331
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -13.947354316711426
Agent1_Eval_StdReturn : 18.0933780670166
Agent1_Eval_MaxReturn : 10.643583297729492
Agent1_Eval_MinReturn : -39.726749420166016
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -17.595245361328125
Agent1_Train_StdReturn : 14.696773529052734
Agent1_Train_MaxReturn : 8.018087387084961
Agent1_Train_MinReturn : -50.69114303588867
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 481500
Agent1_TimeSinceStart : 762.4769678115845
Agent1_Critic_Loss : 0.3165989816188812
Agent1_Actor_Loss : -0.5600560903549194
Agent1_Alpha_Loss : 0.8025144338607788
Agent1_Temperature : 0.09136068700596023
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 321 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 322 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 323 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 324 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 325 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 326 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 327 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 328 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 329 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 330 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -12.092443466186523
Agent0_Eval_StdReturn : 13.87833023071289
Agent0_Eval_MaxReturn : 16.807514190673828
Agent0_Eval_MinReturn : -26.641738891601562
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -15.428210258483887
Agent0_Train_StdReturn : 10.815107345581055
Agent0_Train_MaxReturn : 0.35452842712402344
Agent0_Train_MinReturn : -35.20900344848633
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 496500
Agent0_TimeSinceStart : 784.0931625366211
Agent0_Critic_Loss : 0.30838149785995483
Agent0_Actor_Loss : -0.4863130748271942
Agent0_Alpha_Loss : 0.8117921352386475
Agent0_Temperature : 0.09113487731211635
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -32.02956771850586
Agent1_Eval_StdReturn : 19.849437713623047
Agent1_Eval_MaxReturn : -4.152190208435059
Agent1_Eval_MinReturn : -60.177974700927734
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -18.467260360717773
Agent1_Train_StdReturn : 18.557706832885742
Agent1_Train_MaxReturn : -0.14077472686767578
Agent1_Train_MinReturn : -51.77149963378906
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 496500
Agent1_TimeSinceStart : 786.2482903003693
Agent1_Critic_Loss : 0.40743908286094666
Agent1_Actor_Loss : -0.6035406589508057
Agent1_Alpha_Loss : 0.7834727168083191
Agent1_Temperature : 0.09110506259273615
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 331 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 332 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 333 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 334 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 335 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 336 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 337 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 338 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 339 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 340 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -26.694995880126953
Agent0_Eval_StdReturn : 18.066043853759766
Agent0_Eval_MaxReturn : 11.272394180297852
Agent0_Eval_MinReturn : -52.916011810302734
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -9.274656295776367
Agent0_Train_StdReturn : 14.302080154418945
Agent0_Train_MaxReturn : 11.882001876831055
Agent0_Train_MinReturn : -31.93508529663086
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 511500
Agent0_TimeSinceStart : 807.9051089286804
Agent0_Critic_Loss : 0.3211015462875366
Agent0_Actor_Loss : -0.47457432746887207
Agent0_Alpha_Loss : 0.811062216758728
Agent0_Temperature : 0.09087606895171785
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -22.26936149597168
Agent1_Eval_StdReturn : 19.707082748413086
Agent1_Eval_MaxReturn : 11.060861587524414
Agent1_Eval_MinReturn : -61.7706184387207
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -22.84769058227539
Agent1_Train_StdReturn : 17.299850463867188
Agent1_Train_MaxReturn : 10.799400329589844
Agent1_Train_MinReturn : -45.96625518798828
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 511500
Agent1_TimeSinceStart : 810.0602900981903
Agent1_Critic_Loss : 0.35649803280830383
Agent1_Actor_Loss : -0.5406082272529602
Agent1_Alpha_Loss : 0.7848169207572937
Agent1_Temperature : 0.09085122267444683
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 341 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 342 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 343 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 344 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 345 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 346 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 347 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 348 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 349 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 350 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -9.7374267578125
Agent0_Eval_StdReturn : 15.898818969726562
Agent0_Eval_MaxReturn : 11.414478302001953
Agent0_Eval_MinReturn : -47.168540954589844
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -20.6744327545166
Agent0_Train_StdReturn : 13.608880996704102
Agent0_Train_MaxReturn : 1.1516590118408203
Agent0_Train_MinReturn : -42.95416259765625
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 526500
Agent0_TimeSinceStart : 831.7821521759033
Agent0_Critic_Loss : 0.3436412215232849
Agent0_Actor_Loss : -0.5985157489776611
Agent0_Alpha_Loss : 0.8002958297729492
Agent0_Temperature : 0.09061838429933841
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -19.112735748291016
Agent1_Eval_StdReturn : 15.32368278503418
Agent1_Eval_MaxReturn : -1.2861032485961914
Agent1_Eval_MinReturn : -55.6138916015625
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -12.882573127746582
Agent1_Train_StdReturn : 16.83832550048828
Agent1_Train_MaxReturn : 15.277576446533203
Agent1_Train_MinReturn : -49.259132385253906
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 526500
Agent1_TimeSinceStart : 833.9371750354767
Agent1_Critic_Loss : 0.31648749113082886
Agent1_Actor_Loss : -0.6032606363296509
Agent1_Alpha_Loss : 0.7741221785545349
Agent1_Temperature : 0.0905990092702799
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 351 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 352 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 353 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 354 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 355 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 356 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 357 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 358 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 359 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 360 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -18.15387725830078
Agent0_Eval_StdReturn : 15.39348316192627
Agent0_Eval_MaxReturn : 12.493901252746582
Agent0_Eval_MinReturn : -40.753517150878906
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -22.97520637512207
Agent0_Train_StdReturn : 26.14950942993164
Agent0_Train_MaxReturn : 20.838565826416016
Agent0_Train_MinReturn : -69.32353973388672
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 541500
Agent0_TimeSinceStart : 855.5697891712189
Agent0_Critic_Loss : 0.48618483543395996
Agent0_Actor_Loss : -0.46394944190979004
Agent0_Alpha_Loss : 0.7875508069992065
Agent0_Temperature : 0.09036260891732288
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -26.226613998413086
Agent1_Eval_StdReturn : 17.123353958129883
Agent1_Eval_MaxReturn : -3.7045233249664307
Agent1_Eval_MinReturn : -61.8442497253418
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -16.9221248626709
Agent1_Train_StdReturn : 18.236705780029297
Agent1_Train_MaxReturn : 11.117691993713379
Agent1_Train_MinReturn : -53.55839538574219
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 541500
Agent1_TimeSinceStart : 857.7200794219971
Agent1_Critic_Loss : 0.3456694185733795
Agent1_Actor_Loss : -0.6444045305252075
Agent1_Alpha_Loss : 0.7947706580162048
Agent1_Temperature : 0.09034838989953234
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 361 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 362 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 363 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 364 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 365 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 366 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 367 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 368 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 369 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 370 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -18.107250213623047
Agent0_Eval_StdReturn : 10.899334907531738
Agent0_Eval_MaxReturn : 4.725037574768066
Agent0_Eval_MinReturn : -34.189884185791016
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -12.650533676147461
Agent0_Train_StdReturn : 15.09224796295166
Agent0_Train_MaxReturn : 12.208056449890137
Agent0_Train_MinReturn : -41.97841262817383
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 556500
Agent0_TimeSinceStart : 879.3534967899323
Agent0_Critic_Loss : 0.3925657868385315
Agent0_Actor_Loss : -0.5470947027206421
Agent0_Alpha_Loss : 0.7964504957199097
Agent0_Temperature : 0.09010747707300207
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -15.982856750488281
Agent1_Eval_StdReturn : 11.797380447387695
Agent1_Eval_MaxReturn : -2.0168519020080566
Agent1_Eval_MinReturn : -39.419490814208984
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -16.218523025512695
Agent1_Train_StdReturn : 17.079496383666992
Agent1_Train_MaxReturn : 6.706143856048584
Agent1_Train_MinReturn : -49.2998161315918
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 556500
Agent1_TimeSinceStart : 881.5060911178589
Agent1_Critic_Loss : 0.3383156359195709
Agent1_Actor_Loss : -0.6574286222457886
Agent1_Alpha_Loss : 0.781275749206543
Agent1_Temperature : 0.09009796296643147
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 371 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 372 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 373 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 374 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 375 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 376 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 377 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 378 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 379 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 380 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -11.832112312316895
Agent0_Eval_StdReturn : 11.276193618774414
Agent0_Eval_MaxReturn : 2.628052234649658
Agent0_Eval_MinReturn : -32.549957275390625
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -23.425827026367188
Agent0_Train_StdReturn : 19.849689483642578
Agent0_Train_MaxReturn : 4.7365827560424805
Agent0_Train_MinReturn : -54.607154846191406
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 571500
Agent0_TimeSinceStart : 903.1480782032013
Agent0_Critic_Loss : 0.31302982568740845
Agent0_Actor_Loss : -0.46345093846321106
Agent0_Alpha_Loss : 0.7906743288040161
Agent0_Temperature : 0.08985391727659968
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -20.37346839904785
Agent1_Eval_StdReturn : 11.32889175415039
Agent1_Eval_MaxReturn : 3.78753662109375
Agent1_Eval_MinReturn : -38.21631622314453
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -16.713153839111328
Agent1_Train_StdReturn : 12.173930168151855
Agent1_Train_MaxReturn : -1.034379005432129
Agent1_Train_MinReturn : -38.78723907470703
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 571500
Agent1_TimeSinceStart : 905.3098883628845
Agent1_Critic_Loss : 0.28599822521209717
Agent1_Actor_Loss : -0.5683072805404663
Agent1_Alpha_Loss : 0.7852461338043213
Agent1_Temperature : 0.08984780687990195
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 381 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 382 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 383 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 384 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 385 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 386 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 387 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 388 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 389 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 390 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -25.997268676757812
Agent0_Eval_StdReturn : 10.575004577636719
Agent0_Eval_MaxReturn : -10.781713485717773
Agent0_Eval_MinReturn : -44.731956481933594
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -13.210467338562012
Agent0_Train_StdReturn : 8.28680419921875
Agent0_Train_MaxReturn : -0.17941761016845703
Agent0_Train_MinReturn : -26.807971954345703
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 586500
Agent0_TimeSinceStart : 927.0911576747894
Agent0_Critic_Loss : 0.40279829502105713
Agent0_Actor_Loss : -0.4834907352924347
Agent0_Alpha_Loss : 0.808134138584137
Agent0_Temperature : 0.08960221398008991
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -15.147132873535156
Agent1_Eval_StdReturn : 13.502035140991211
Agent1_Eval_MaxReturn : 2.2788445949554443
Agent1_Eval_MinReturn : -43.87636184692383
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -17.501720428466797
Agent1_Train_StdReturn : 14.089155197143555
Agent1_Train_MaxReturn : 3.5124454498291016
Agent1_Train_MinReturn : -50.221431732177734
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 586500
Agent1_TimeSinceStart : 929.2673001289368
Agent1_Critic_Loss : 0.4392952620983124
Agent1_Actor_Loss : -0.5180997252464294
Agent1_Alpha_Loss : 0.7640551328659058
Agent1_Temperature : 0.08959916800692995
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 391 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 392 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 393 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 394 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 395 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 396 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 397 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 398 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 399 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 400 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -22.444549560546875
Agent0_Eval_StdReturn : 11.149872779846191
Agent0_Eval_MaxReturn : -5.827047348022461
Agent0_Eval_MinReturn : -44.41047668457031
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -12.501476287841797
Agent0_Train_StdReturn : 13.870780944824219
Agent0_Train_MaxReturn : 11.38357162475586
Agent0_Train_MinReturn : -33.03313064575195
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 601500
Agent0_TimeSinceStart : 951.0723955631256
Agent0_Critic_Loss : 0.37248072028160095
Agent0_Actor_Loss : -0.4326912462711334
Agent0_Alpha_Loss : 0.7808903455734253
Agent0_Temperature : 0.08935138800448657
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -22.994487762451172
Agent1_Eval_StdReturn : 10.64844799041748
Agent1_Eval_MaxReturn : -6.120430946350098
Agent1_Eval_MinReturn : -39.420143127441406
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -17.722867965698242
Agent1_Train_StdReturn : 6.0130934715271
Agent1_Train_MaxReturn : -9.915961265563965
Agent1_Train_MinReturn : -28.782270431518555
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 601500
Agent1_TimeSinceStart : 953.2439374923706
Agent1_Critic_Loss : 0.3385634124279022
Agent1_Actor_Loss : -0.5979757308959961
Agent1_Alpha_Loss : 0.7597662210464478
Agent1_Temperature : 0.08935195025783985
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 401 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 402 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 403 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 404 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 405 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 406 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 407 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 408 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 409 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 410 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -10.20018196105957
Agent0_Eval_StdReturn : 11.715714454650879
Agent0_Eval_MaxReturn : 13.723154067993164
Agent0_Eval_MinReturn : -27.522520065307617
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -17.33185386657715
Agent0_Train_StdReturn : 15.995111465454102
Agent0_Train_MaxReturn : 15.997194290161133
Agent0_Train_MinReturn : -47.17620849609375
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 616500
Agent0_TimeSinceStart : 974.9731757640839
Agent0_Critic_Loss : 0.3779869079589844
Agent0_Actor_Loss : -0.39740389585494995
Agent0_Alpha_Loss : 0.8043760061264038
Agent0_Temperature : 0.0891018371798401
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -18.689796447753906
Agent1_Eval_StdReturn : 13.26981258392334
Agent1_Eval_MaxReturn : 8.217309951782227
Agent1_Eval_MinReturn : -47.49790954589844
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -11.210206985473633
Agent1_Train_StdReturn : 14.216797828674316
Agent1_Train_MaxReturn : 13.718526840209961
Agent1_Train_MinReturn : -38.88214874267578
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 616500
Agent1_TimeSinceStart : 977.1410727500916
Agent1_Critic_Loss : 0.4036501348018646
Agent1_Actor_Loss : -0.6397807598114014
Agent1_Alpha_Loss : 0.7610278725624084
Agent1_Temperature : 0.08910630198173848
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 411 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 412 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 413 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 414 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 415 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 416 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 417 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 418 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 419 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 420 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -17.163341522216797
Agent0_Eval_StdReturn : 14.15212631225586
Agent0_Eval_MaxReturn : 3.1051535606384277
Agent0_Eval_MinReturn : -41.406639099121094
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -16.336748123168945
Agent0_Train_StdReturn : 20.081872940063477
Agent0_Train_MaxReturn : 31.21438217163086
Agent0_Train_MinReturn : -42.0771598815918
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 631500
Agent0_TimeSinceStart : 998.9410212039948
Agent0_Critic_Loss : 0.35685354471206665
Agent0_Actor_Loss : -0.4378851056098938
Agent0_Alpha_Loss : 0.7840607166290283
Agent0_Temperature : 0.0888509574546071
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -18.997669219970703
Agent1_Eval_StdReturn : 17.856204986572266
Agent1_Eval_MaxReturn : 17.324085235595703
Agent1_Eval_MinReturn : -42.302520751953125
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -11.85605525970459
Agent1_Train_StdReturn : 15.134965896606445
Agent1_Train_MaxReturn : 17.719812393188477
Agent1_Train_MinReturn : -39.80769348144531
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 631500
Agent1_TimeSinceStart : 1001.1032855510712
Agent1_Critic_Loss : 0.3824191093444824
Agent1_Actor_Loss : -0.5684844255447388
Agent1_Alpha_Loss : 0.7877401113510132
Agent1_Temperature : 0.08886057218476848
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 421 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 422 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 423 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 424 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 425 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 426 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 427 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 428 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 429 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 430 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -9.720501899719238
Agent0_Eval_StdReturn : 17.581661224365234
Agent0_Eval_MaxReturn : 24.73849868774414
Agent0_Eval_MinReturn : -42.77692413330078
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -15.639472961425781
Agent0_Train_StdReturn : 9.1926851272583
Agent0_Train_MaxReturn : 2.408247709274292
Agent0_Train_MinReturn : -24.685691833496094
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 646500
Agent0_TimeSinceStart : 1022.9179685115814
Agent0_Critic_Loss : 0.359536349773407
Agent0_Actor_Loss : -0.5480346083641052
Agent0_Alpha_Loss : 0.794967770576477
Agent0_Temperature : 0.08859926605026648
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -17.985666275024414
Agent1_Eval_StdReturn : 15.211503982543945
Agent1_Eval_MaxReturn : 15.384761810302734
Agent1_Eval_MinReturn : -35.63591384887695
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -15.754678726196289
Agent1_Train_StdReturn : 14.444207191467285
Agent1_Train_MaxReturn : 14.761960983276367
Agent1_Train_MinReturn : -29.58713150024414
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 646500
Agent1_TimeSinceStart : 1025.0893387794495
Agent1_Critic_Loss : 0.4060973823070526
Agent1_Actor_Loss : -0.6632694602012634
Agent1_Alpha_Loss : 0.7819362878799438
Agent1_Temperature : 0.08861416865644443
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 431 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 432 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 433 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 434 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 435 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 436 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 437 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 438 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 439 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 440 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -16.15285301208496
Agent0_Eval_StdReturn : 14.945289611816406
Agent0_Eval_MaxReturn : 10.669755935668945
Agent0_Eval_MinReturn : -41.33992385864258
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -10.093859672546387
Agent0_Train_StdReturn : 12.055289268493652
Agent0_Train_MaxReturn : 4.1100263595581055
Agent0_Train_MinReturn : -33.594051361083984
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 661500
Agent0_TimeSinceStart : 1046.8832664489746
Agent0_Critic_Loss : 0.33811354637145996
Agent0_Actor_Loss : -0.6700525879859924
Agent0_Alpha_Loss : 0.8040476441383362
Agent0_Temperature : 0.08834801943339068
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -16.688291549682617
Agent1_Eval_StdReturn : 14.360786437988281
Agent1_Eval_MaxReturn : -0.09733033180236816
Agent1_Eval_MinReturn : -42.66958236694336
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -19.734081268310547
Agent1_Train_StdReturn : 16.484752655029297
Agent1_Train_MaxReturn : 2.9459357261657715
Agent1_Train_MinReturn : -51.64549255371094
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 661500
Agent1_TimeSinceStart : 1049.0620331764221
Agent1_Critic_Loss : 0.38777655363082886
Agent1_Actor_Loss : -0.4490404725074768
Agent1_Alpha_Loss : 0.7958188056945801
Agent1_Temperature : 0.08836603041050695
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 441 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 442 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 443 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 444 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 445 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 446 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 447 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 448 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 449 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 450 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -18.71817398071289
Agent0_Eval_StdReturn : 24.98949432373047
Agent0_Eval_MaxReturn : 27.206693649291992
Agent0_Eval_MinReturn : -65.95061492919922
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -8.136739730834961
Agent0_Train_StdReturn : 11.899829864501953
Agent0_Train_MaxReturn : 17.932201385498047
Agent0_Train_MinReturn : -26.16686248779297
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 676500
Agent0_TimeSinceStart : 1070.962414741516
Agent0_Critic_Loss : 0.3658323585987091
Agent0_Actor_Loss : -0.5716757774353027
Agent0_Alpha_Loss : 0.7851812839508057
Agent0_Temperature : 0.08809778417335273
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -16.235851287841797
Agent1_Eval_StdReturn : 11.545921325683594
Agent1_Eval_MaxReturn : 3.9270429611206055
Agent1_Eval_MinReturn : -37.83555603027344
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -10.45598030090332
Agent1_Train_StdReturn : 17.569700241088867
Agent1_Train_MaxReturn : 11.94528579711914
Agent1_Train_MinReturn : -34.97099685668945
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 676500
Agent1_TimeSinceStart : 1073.13036775589
Agent1_Critic_Loss : 0.32870355248451233
Agent1_Actor_Loss : -0.5762958526611328
Agent1_Alpha_Loss : 0.7899541258811951
Agent1_Temperature : 0.08811774313569137
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 451 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 452 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 453 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 454 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 455 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 456 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 457 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 458 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 459 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 460 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -17.89453125
Agent0_Eval_StdReturn : 18.630647659301758
Agent0_Eval_MaxReturn : 6.804923057556152
Agent0_Eval_MinReturn : -51.59268569946289
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -17.469364166259766
Agent0_Train_StdReturn : 16.761272430419922
Agent0_Train_MaxReturn : -0.7047944068908691
Agent0_Train_MinReturn : -59.493621826171875
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 691500
Agent0_TimeSinceStart : 1094.939037322998
Agent0_Critic_Loss : 0.3418712913990021
Agent0_Actor_Loss : -0.5254909992218018
Agent0_Alpha_Loss : 0.7915223240852356
Agent0_Temperature : 0.08784778217283508
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -14.494775772094727
Agent1_Eval_StdReturn : 17.285531997680664
Agent1_Eval_MaxReturn : 13.237944602966309
Agent1_Eval_MinReturn : -45.240142822265625
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -8.967280387878418
Agent1_Train_StdReturn : 19.96124267578125
Agent1_Train_MaxReturn : 14.671859741210938
Agent1_Train_MinReturn : -53.49006652832031
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 691500
Agent1_TimeSinceStart : 1097.1040227413177
Agent1_Critic_Loss : 0.48649871349334717
Agent1_Actor_Loss : -0.6212393641471863
Agent1_Alpha_Loss : 0.7896752953529358
Agent1_Temperature : 0.08787011680335544
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 461 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 462 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 463 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 464 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 465 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 466 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 467 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 468 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 469 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 470 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -8.332423210144043
Agent0_Eval_StdReturn : 18.985857009887695
Agent0_Eval_MaxReturn : 8.785791397094727
Agent0_Eval_MinReturn : -59.463783264160156
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -20.649295806884766
Agent0_Train_StdReturn : 16.6437931060791
Agent0_Train_MaxReturn : 0.15791276097297668
Agent0_Train_MinReturn : -53.54070281982422
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 706500
Agent0_TimeSinceStart : 1118.8569872379303
Agent0_Critic_Loss : 0.3997959494590759
Agent0_Actor_Loss : -0.6031081080436707
Agent0_Alpha_Loss : 0.7880992889404297
Agent0_Temperature : 0.08759820014441139
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -13.312332153320312
Agent1_Eval_StdReturn : 13.615640640258789
Agent1_Eval_MaxReturn : 6.56608772277832
Agent1_Eval_MinReturn : -39.286293029785156
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -13.835952758789062
Agent1_Train_StdReturn : 15.374527931213379
Agent1_Train_MaxReturn : 8.768317222595215
Agent1_Train_MinReturn : -51.09318923950195
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 706500
Agent1_TimeSinceStart : 1121.0106508731842
Agent1_Critic_Loss : 0.337207555770874
Agent1_Actor_Loss : -0.5628470182418823
Agent1_Alpha_Loss : 0.7806682586669922
Agent1_Temperature : 0.08762316815399772
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 471 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 472 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 473 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 474 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 475 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 476 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 477 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 478 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 479 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 480 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -20.296253204345703
Agent0_Eval_StdReturn : 14.150328636169434
Agent0_Eval_MaxReturn : -0.7684059143066406
Agent0_Eval_MinReturn : -39.143184661865234
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -8.19139575958252
Agent0_Train_StdReturn : 14.571707725524902
Agent0_Train_MaxReturn : 16.20867156982422
Agent0_Train_MinReturn : -36.50791931152344
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 721500
Agent0_TimeSinceStart : 1142.6567778587341
Agent0_Critic_Loss : 0.3565486669540405
Agent0_Actor_Loss : -0.5714972019195557
Agent0_Alpha_Loss : 0.7806117534637451
Agent0_Temperature : 0.0873494509041133
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -10.293214797973633
Agent1_Eval_StdReturn : 13.14430046081543
Agent1_Eval_MaxReturn : 13.31221866607666
Agent1_Eval_MinReturn : -41.096954345703125
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -24.558040618896484
Agent1_Train_StdReturn : 17.867481231689453
Agent1_Train_MaxReturn : -6.132192611694336
Agent1_Train_MinReturn : -71.5452880859375
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 721500
Agent1_TimeSinceStart : 1144.8202877044678
Agent1_Critic_Loss : 0.36133092641830444
Agent1_Actor_Loss : -0.53892982006073
Agent1_Alpha_Loss : 0.7825480699539185
Agent1_Temperature : 0.08737545261181455
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 481 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 482 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 483 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 484 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 485 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 486 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 487 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 488 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 489 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 490 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -26.9721736907959
Agent0_Eval_StdReturn : 27.22003936767578
Agent0_Eval_MaxReturn : 2.529693603515625
Agent0_Eval_MinReturn : -98.80030059814453
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -18.960947036743164
Agent0_Train_StdReturn : 19.746057510375977
Agent0_Train_MaxReturn : 13.651792526245117
Agent0_Train_MinReturn : -52.16978454589844
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 736500
Agent0_TimeSinceStart : 1166.5381307601929
Agent0_Critic_Loss : 0.34584298729896545
Agent0_Actor_Loss : -0.502711832523346
Agent0_Alpha_Loss : 0.7994934320449829
Agent0_Temperature : 0.08710066859367586
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -13.786158561706543
Agent1_Eval_StdReturn : 13.104702949523926
Agent1_Eval_MaxReturn : 6.125530242919922
Agent1_Eval_MinReturn : -44.78725051879883
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -19.735368728637695
Agent1_Train_StdReturn : 22.433713912963867
Agent1_Train_MaxReturn : 6.066374778747559
Agent1_Train_MinReturn : -65.20808410644531
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 736500
Agent1_TimeSinceStart : 1168.7040393352509
Agent1_Critic_Loss : 0.3232502043247223
Agent1_Actor_Loss : -0.7856799960136414
Agent1_Alpha_Loss : 0.7912164926528931
Agent1_Temperature : 0.0871269977234004
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 491 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 492 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 493 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 494 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 495 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 496 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 497 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 498 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 499 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 500 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -15.237652778625488
Agent0_Eval_StdReturn : 16.94461441040039
Agent0_Eval_MaxReturn : 10.275437355041504
Agent0_Eval_MinReturn : -49.24978256225586
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -6.125749588012695
Agent0_Train_StdReturn : 16.5716552734375
Agent0_Train_MaxReturn : 16.16585922241211
Agent0_Train_MinReturn : -39.582618713378906
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 751500
Agent0_TimeSinceStart : 1190.432734966278
Agent0_Critic_Loss : 0.43660685420036316
Agent0_Actor_Loss : -0.4757356345653534
Agent0_Alpha_Loss : 0.7857452630996704
Agent0_Temperature : 0.08685114255339085
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -13.65434741973877
Agent1_Eval_StdReturn : 15.43779468536377
Agent1_Eval_MaxReturn : 7.170194625854492
Agent1_Eval_MinReturn : -47.518028259277344
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -13.110410690307617
Agent1_Train_StdReturn : 12.572164535522461
Agent1_Train_MaxReturn : 6.817826271057129
Agent1_Train_MinReturn : -33.68421173095703
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 751500
Agent1_TimeSinceStart : 1192.5990073680878
Agent1_Critic_Loss : 0.4470776319503784
Agent1_Actor_Loss : -0.6786742210388184
Agent1_Alpha_Loss : 0.799828052520752
Agent1_Temperature : 0.08687912338074963
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 501 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 502 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 503 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 504 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 505 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 506 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 507 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 508 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 509 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 510 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -15.971814155578613
Agent0_Eval_StdReturn : 16.757652282714844
Agent0_Eval_MaxReturn : 7.365053653717041
Agent0_Eval_MinReturn : -59.27269744873047
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -9.207478523254395
Agent0_Train_StdReturn : 16.403488159179688
Agent0_Train_MaxReturn : 31.375375747680664
Agent0_Train_MinReturn : -27.958858489990234
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 766500
Agent0_TimeSinceStart : 1214.2609837055206
Agent0_Critic_Loss : 0.443951815366745
Agent0_Actor_Loss : -0.5360262393951416
Agent0_Alpha_Loss : 0.7922095656394958
Agent0_Temperature : 0.08660275211411024
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -35.503074645996094
Agent1_Eval_StdReturn : 18.144161224365234
Agent1_Eval_MaxReturn : -7.983528137207031
Agent1_Eval_MinReturn : -67.4659423828125
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -15.020672798156738
Agent1_Train_StdReturn : 19.735261917114258
Agent1_Train_MaxReturn : 2.6154518127441406
Agent1_Train_MinReturn : -67.12481689453125
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 766500
Agent1_TimeSinceStart : 1216.4036078453064
Agent1_Critic_Loss : 0.38621336221694946
Agent1_Actor_Loss : -0.5560240149497986
Agent1_Alpha_Loss : 0.7960377931594849
Agent1_Temperature : 0.0866306791394106
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 511 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 512 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 513 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 514 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 515 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 516 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 517 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 518 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 519 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 520 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -22.96804428100586
Agent0_Eval_StdReturn : 14.381937980651855
Agent0_Eval_MaxReturn : 6.5777106285095215
Agent0_Eval_MinReturn : -38.15611267089844
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -11.321078300476074
Agent0_Train_StdReturn : 11.139625549316406
Agent0_Train_MaxReturn : 2.998292922973633
Agent0_Train_MinReturn : -37.68669128417969
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 781500
Agent0_TimeSinceStart : 1238.0684731006622
Agent0_Critic_Loss : 0.4701997637748718
Agent0_Actor_Loss : -0.6182149052619934
Agent0_Alpha_Loss : 0.7915887832641602
Agent0_Temperature : 0.08635463000561747
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -25.703866958618164
Agent1_Eval_StdReturn : 19.106704711914062
Agent1_Eval_MaxReturn : -8.119465827941895
Agent1_Eval_MinReturn : -74.39430236816406
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -33.107261657714844
Agent1_Train_StdReturn : 27.664600372314453
Agent1_Train_MaxReturn : 8.06783390045166
Agent1_Train_MinReturn : -72.48590087890625
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 781500
Agent1_TimeSinceStart : 1240.2141377925873
Agent1_Critic_Loss : 0.41506752371788025
Agent1_Actor_Loss : -0.590158224105835
Agent1_Alpha_Loss : 0.7954953908920288
Agent1_Temperature : 0.08638205687349108
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 521 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 522 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 523 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 524 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 525 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 526 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 527 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 528 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 529 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 530 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -15.064974784851074
Agent0_Eval_StdReturn : 11.127603530883789
Agent0_Eval_MaxReturn : 0.8607931137084961
Agent0_Eval_MinReturn : -33.805442810058594
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -13.828910827636719
Agent0_Train_StdReturn : 15.999634742736816
Agent0_Train_MaxReturn : 6.829071044921875
Agent0_Train_MinReturn : -46.15393829345703
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 796500
Agent0_TimeSinceStart : 1261.7348523139954
Agent0_Critic_Loss : 0.39476877450942993
Agent0_Actor_Loss : -0.646602988243103
Agent0_Alpha_Loss : 0.7922431230545044
Agent0_Temperature : 0.08610756498225813
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -16.59089469909668
Agent1_Eval_StdReturn : 14.643315315246582
Agent1_Eval_MaxReturn : 11.577012062072754
Agent1_Eval_MinReturn : -44.96072769165039
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -17.317636489868164
Agent1_Train_StdReturn : 25.941194534301758
Agent1_Train_MaxReturn : 21.707683563232422
Agent1_Train_MinReturn : -56.0850715637207
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 796500
Agent1_TimeSinceStart : 1263.878278017044
Agent1_Critic_Loss : 0.44597703218460083
Agent1_Actor_Loss : -0.5065741539001465
Agent1_Alpha_Loss : 0.7901157736778259
Agent1_Temperature : 0.08613407384343053
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 531 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 532 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 533 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 534 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 535 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 536 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 537 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 538 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 539 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 540 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -25.620025634765625
Agent0_Eval_StdReturn : 25.27305793762207
Agent0_Eval_MaxReturn : 22.678247451782227
Agent0_Eval_MinReturn : -62.2039680480957
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -2.378209352493286
Agent0_Train_StdReturn : 12.554793357849121
Agent0_Train_MaxReturn : 16.686830520629883
Agent0_Train_MinReturn : -19.258464813232422
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 811500
Agent0_TimeSinceStart : 1285.5637485980988
Agent0_Critic_Loss : 0.4086218476295471
Agent0_Actor_Loss : -0.5688501596450806
Agent0_Alpha_Loss : 0.7978488206863403
Agent0_Temperature : 0.08586161554483784
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -20.781299591064453
Agent1_Eval_StdReturn : 9.207722663879395
Agent1_Eval_MaxReturn : -3.632359504699707
Agent1_Eval_MinReturn : -36.68057632446289
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -35.42045593261719
Agent1_Train_StdReturn : 18.135961532592773
Agent1_Train_MaxReturn : 3.2440085411071777
Agent1_Train_MinReturn : -60.14325714111328
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 811500
Agent1_TimeSinceStart : 1287.7207345962524
Agent1_Critic_Loss : 0.6915026903152466
Agent1_Actor_Loss : -0.6919418573379517
Agent1_Alpha_Loss : 0.787150502204895
Agent1_Temperature : 0.08588686836562825
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 541 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 542 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 543 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 544 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 545 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 546 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 547 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 548 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 549 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 550 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -32.34202194213867
Agent0_Eval_StdReturn : 22.101709365844727
Agent0_Eval_MaxReturn : 7.059003829956055
Agent0_Eval_MinReturn : -62.01729965209961
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -12.287359237670898
Agent0_Train_StdReturn : 18.83169174194336
Agent0_Train_MaxReturn : 14.231830596923828
Agent0_Train_MinReturn : -46.80339050292969
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 826500
Agent0_TimeSinceStart : 1309.4231967926025
Agent0_Critic_Loss : 0.42024892568588257
Agent0_Actor_Loss : -0.5597076416015625
Agent0_Alpha_Loss : 0.7963374257087708
Agent0_Temperature : 0.0856151337962625
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -25.848724365234375
Agent1_Eval_StdReturn : 20.928709030151367
Agent1_Eval_MaxReturn : 10.280214309692383
Agent1_Eval_MinReturn : -60.84492492675781
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -14.39128303527832
Agent1_Train_StdReturn : 13.61208438873291
Agent1_Train_MaxReturn : 7.050969123840332
Agent1_Train_MinReturn : -31.83637237548828
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 826500
Agent1_TimeSinceStart : 1311.590426683426
Agent1_Critic_Loss : 0.529310941696167
Agent1_Actor_Loss : -0.6276315450668335
Agent1_Alpha_Loss : 0.7816053628921509
Agent1_Temperature : 0.08564209162945499
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 551 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 552 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 553 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 554 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 555 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 556 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 557 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 558 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 559 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 560 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -12.484884262084961
Agent0_Eval_StdReturn : 21.396221160888672
Agent0_Eval_MaxReturn : 24.040904998779297
Agent0_Eval_MinReturn : -42.83885192871094
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -13.527908325195312
Agent0_Train_StdReturn : 9.398762702941895
Agent0_Train_MaxReturn : -0.8634824752807617
Agent0_Train_MinReturn : -34.20330047607422
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 841500
Agent0_TimeSinceStart : 1333.3365046977997
Agent0_Critic_Loss : 0.5253984928131104
Agent0_Actor_Loss : -0.5028151273727417
Agent0_Alpha_Loss : 0.7963211536407471
Agent0_Temperature : 0.08536950015580727
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -29.271503448486328
Agent1_Eval_StdReturn : 15.711421012878418
Agent1_Eval_MaxReturn : 1.366750717163086
Agent1_Eval_MinReturn : -52.86723327636719
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -11.593932151794434
Agent1_Train_StdReturn : 11.63668155670166
Agent1_Train_MaxReturn : 12.093856811523438
Agent1_Train_MinReturn : -23.85800552368164
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 841500
Agent1_TimeSinceStart : 1335.4933304786682
Agent1_Critic_Loss : 0.4778120517730713
Agent1_Actor_Loss : -0.7811667323112488
Agent1_Alpha_Loss : 0.7839361429214478
Agent1_Temperature : 0.08539901096532972
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 561 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 562 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 563 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 564 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 565 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 566 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 567 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 568 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 569 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 570 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -2.8857905864715576
Agent0_Eval_StdReturn : 16.45833396911621
Agent0_Eval_MaxReturn : 23.10932731628418
Agent0_Eval_MinReturn : -25.10063934326172
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -7.851675987243652
Agent0_Train_StdReturn : 20.186731338500977
Agent0_Train_MaxReturn : 21.374069213867188
Agent0_Train_MinReturn : -38.509490966796875
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 856500
Agent0_TimeSinceStart : 1357.159940481186
Agent0_Critic_Loss : 0.5747071504592896
Agent0_Actor_Loss : -0.5751829147338867
Agent0_Alpha_Loss : 0.7993736267089844
Agent0_Temperature : 0.08512352634156915
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -15.264880180358887
Agent1_Eval_StdReturn : 14.097529411315918
Agent1_Eval_MaxReturn : 7.58270263671875
Agent1_Eval_MinReturn : -41.956512451171875
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -13.663989067077637
Agent1_Train_StdReturn : 12.466405868530273
Agent1_Train_MaxReturn : 7.0241241455078125
Agent1_Train_MinReturn : -30.879980087280273
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 856500
Agent1_TimeSinceStart : 1359.3104557991028
Agent1_Critic_Loss : 0.44440239667892456
Agent1_Actor_Loss : -0.6271694898605347
Agent1_Alpha_Loss : 0.7543730735778809
Agent1_Temperature : 0.08515836487789404
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 571 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 572 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 573 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 574 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 575 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 576 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 577 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 578 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 579 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 580 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -22.789154052734375
Agent0_Eval_StdReturn : 12.962625503540039
Agent0_Eval_MaxReturn : -4.278965950012207
Agent0_Eval_MinReturn : -43.74451446533203
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -10.081528663635254
Agent0_Train_StdReturn : 13.350142478942871
Agent0_Train_MaxReturn : 10.904486656188965
Agent0_Train_MinReturn : -32.05449676513672
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 871500
Agent0_TimeSinceStart : 1381.009025812149
Agent0_Critic_Loss : 0.4891481101512909
Agent0_Actor_Loss : -0.783216118812561
Agent0_Alpha_Loss : 0.7976452112197876
Agent0_Temperature : 0.08487682255726565
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -16.96377944946289
Agent1_Eval_StdReturn : 15.702855110168457
Agent1_Eval_MaxReturn : 7.968247890472412
Agent1_Eval_MinReturn : -49.332130432128906
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -17.262659072875977
Agent1_Train_StdReturn : 15.688736915588379
Agent1_Train_MaxReturn : 4.465647220611572
Agent1_Train_MinReturn : -49.25847625732422
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 871500
Agent1_TimeSinceStart : 1383.1705298423767
Agent1_Critic_Loss : 0.517041802406311
Agent1_Actor_Loss : -0.5118658542633057
Agent1_Alpha_Loss : 0.7394821643829346
Agent1_Temperature : 0.08492143247900079
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 581 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 582 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 583 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 584 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 585 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 586 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 587 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 588 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 589 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 590 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -16.216327667236328
Agent0_Eval_StdReturn : 15.452786445617676
Agent0_Eval_MaxReturn : 0.07794523239135742
Agent0_Eval_MinReturn : -42.26994705200195
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -14.482833862304688
Agent0_Train_StdReturn : 17.254880905151367
Agent0_Train_MaxReturn : 6.645758628845215
Agent0_Train_MinReturn : -43.56011199951172
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 886500
Agent0_TimeSinceStart : 1404.8828220367432
Agent0_Critic_Loss : 0.5983138680458069
Agent0_Actor_Loss : -0.6843633651733398
Agent0_Alpha_Loss : 0.797383189201355
Agent0_Temperature : 0.08463133014518291
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -18.36930274963379
Agent1_Eval_StdReturn : 10.780479431152344
Agent1_Eval_MaxReturn : 2.9481630325317383
Agent1_Eval_MinReturn : -36.35014724731445
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -11.44288444519043
Agent1_Train_StdReturn : 8.07148265838623
Agent1_Train_MaxReturn : 1.1829633712768555
Agent1_Train_MinReturn : -26.394916534423828
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 886500
Agent1_TimeSinceStart : 1407.0539512634277
Agent1_Critic_Loss : 0.634239137172699
Agent1_Actor_Loss : -0.7740403413772583
Agent1_Alpha_Loss : 0.7513232827186584
Agent1_Temperature : 0.08468704497907163
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 591 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 592 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 593 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 594 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 595 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 596 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 597 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 598 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 599 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 600 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -7.841470241546631
Agent0_Eval_StdReturn : 16.461633682250977
Agent0_Eval_MaxReturn : 26.994646072387695
Agent0_Eval_MinReturn : -38.02934265136719
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -15.901098251342773
Agent0_Train_StdReturn : 26.141551971435547
Agent0_Train_MaxReturn : 16.94432830810547
Agent0_Train_MinReturn : -77.76029968261719
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 901500
Agent0_TimeSinceStart : 1428.8903460502625
Agent0_Critic_Loss : 0.5191825032234192
Agent0_Actor_Loss : -0.579664945602417
Agent0_Alpha_Loss : 0.7867361307144165
Agent0_Temperature : 0.08438709398318747
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -16.972314834594727
Agent1_Eval_StdReturn : 15.550799369812012
Agent1_Eval_MaxReturn : 14.737915992736816
Agent1_Eval_MinReturn : -42.6563720703125
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -22.832073211669922
Agent1_Train_StdReturn : 15.602899551391602
Agent1_Train_MaxReturn : -0.35248279571533203
Agent1_Train_MinReturn : -45.577667236328125
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 901500
Agent1_TimeSinceStart : 1431.0736064910889
Agent1_Critic_Loss : 0.4447370767593384
Agent1_Actor_Loss : -0.6374155282974243
Agent1_Alpha_Loss : 0.7465195655822754
Agent1_Temperature : 0.08445460239151484
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 601 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 602 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 603 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 604 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 605 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 606 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 607 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 608 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 609 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 610 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -8.66118049621582
Agent0_Eval_StdReturn : 14.430651664733887
Agent0_Eval_MaxReturn : 7.831181526184082
Agent0_Eval_MinReturn : -39.9301872253418
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -5.690924167633057
Agent0_Train_StdReturn : 13.138993263244629
Agent0_Train_MaxReturn : 17.262332916259766
Agent0_Train_MinReturn : -30.117115020751953
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 916500
Agent0_TimeSinceStart : 1452.8118612766266
Agent0_Critic_Loss : 0.4393913149833679
Agent0_Actor_Loss : -0.7124022841453552
Agent0_Alpha_Loss : 0.7909284234046936
Agent0_Temperature : 0.08414404102029696
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -18.9953670501709
Agent1_Eval_StdReturn : 14.244745254516602
Agent1_Eval_MaxReturn : 14.675501823425293
Agent1_Eval_MinReturn : -37.88825225830078
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -12.522345542907715
Agent1_Train_StdReturn : 9.072115898132324
Agent1_Train_MaxReturn : 2.069550037384033
Agent1_Train_MinReturn : -28.636262893676758
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 916500
Agent1_TimeSinceStart : 1454.9650428295135
Agent1_Critic_Loss : 0.43216055631637573
Agent1_Actor_Loss : -0.6610205173492432
Agent1_Alpha_Loss : 0.7432957887649536
Agent1_Temperature : 0.08422374998571135
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 611 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 612 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 613 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 614 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 615 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 616 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 617 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 618 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 619 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 620 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -10.84858512878418
Agent0_Eval_StdReturn : 18.26580047607422
Agent0_Eval_MaxReturn : 27.31088638305664
Agent0_Eval_MinReturn : -34.639892578125
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -14.317453384399414
Agent0_Train_StdReturn : 14.396919250488281
Agent0_Train_MaxReturn : 9.48522663116455
Agent0_Train_MinReturn : -40.00347900390625
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 931500
Agent0_TimeSinceStart : 1476.685682296753
Agent0_Critic_Loss : 0.5058703422546387
Agent0_Actor_Loss : -0.7368254661560059
Agent0_Alpha_Loss : 0.7747635841369629
Agent0_Temperature : 0.08390229872266647
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -16.750455856323242
Agent1_Eval_StdReturn : 14.340750694274902
Agent1_Eval_MaxReturn : 0.25082921981811523
Agent1_Eval_MinReturn : -45.74446105957031
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -20.05385971069336
Agent1_Train_StdReturn : 12.090439796447754
Agent1_Train_MaxReturn : 0.11142539978027344
Agent1_Train_MinReturn : -34.519683837890625
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 931500
Agent1_TimeSinceStart : 1478.8478500843048
Agent1_Critic_Loss : 0.46012094616889954
Agent1_Actor_Loss : -0.6188565492630005
Agent1_Alpha_Loss : 0.7351322174072266
Agent1_Temperature : 0.08399309447351105
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 621 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 622 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 623 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 624 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 625 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 626 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 627 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 628 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 629 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 630 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -23.33216094970703
Agent0_Eval_StdReturn : 15.606898307800293
Agent0_Eval_MaxReturn : -1.0865821838378906
Agent0_Eval_MinReturn : -53.7294921875
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -25.525836944580078
Agent0_Train_StdReturn : 17.956605911254883
Agent0_Train_MaxReturn : 0.06566810607910156
Agent0_Train_MinReturn : -59.50785827636719
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 946500
Agent0_TimeSinceStart : 1500.5875852108002
Agent0_Critic_Loss : 0.5099753737449646
Agent0_Actor_Loss : -0.7467824816703796
Agent0_Alpha_Loss : 0.768416166305542
Agent0_Temperature : 0.08366179205383778
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -15.571965217590332
Agent1_Eval_StdReturn : 9.067418098449707
Agent1_Eval_MaxReturn : -0.8077211380004883
Agent1_Eval_MinReturn : -28.41400718688965
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -22.141109466552734
Agent1_Train_StdReturn : 19.667924880981445
Agent1_Train_MaxReturn : 6.9920454025268555
Agent1_Train_MinReturn : -60.79118347167969
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 946500
Agent1_TimeSinceStart : 1502.7585053443909
Agent1_Critic_Loss : 0.5699690580368042
Agent1_Actor_Loss : -0.5850486755371094
Agent1_Alpha_Loss : 0.7488493323326111
Agent1_Temperature : 0.08376250182574266
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 631 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 632 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 633 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 634 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 635 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 636 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 637 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 638 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 639 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 640 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -13.34253215789795
Agent0_Eval_StdReturn : 18.457189559936523
Agent0_Eval_MaxReturn : 12.473712921142578
Agent0_Eval_MinReturn : -60.345890045166016
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -21.086694717407227
Agent0_Train_StdReturn : 13.880529403686523
Agent0_Train_MaxReturn : 2.33331298828125
Agent0_Train_MinReturn : -35.09620666503906
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 961500
Agent0_TimeSinceStart : 1524.4888515472412
Agent0_Critic_Loss : 0.4103240370750427
Agent0_Actor_Loss : -0.7221051454544067
Agent0_Alpha_Loss : 0.7833635807037354
Agent0_Temperature : 0.0834224687387432
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -12.580370903015137
Agent1_Eval_StdReturn : 15.10409164428711
Agent1_Eval_MaxReturn : 9.802249908447266
Agent1_Eval_MinReturn : -47.24549865722656
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -11.917354583740234
Agent1_Train_StdReturn : 14.205092430114746
Agent1_Train_MaxReturn : 22.6897029876709
Agent1_Train_MinReturn : -28.367076873779297
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 961500
Agent1_TimeSinceStart : 1526.6619532108307
Agent1_Critic_Loss : 0.6208828687667847
Agent1_Actor_Loss : -0.5897115468978882
Agent1_Alpha_Loss : 0.7505300045013428
Agent1_Temperature : 0.08353200658605536
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 641 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 642 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 643 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 644 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 645 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 646 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 647 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 648 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 649 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 650 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -11.19360065460205
Agent0_Eval_StdReturn : 15.930548667907715
Agent0_Eval_MaxReturn : 13.723873138427734
Agent0_Eval_MinReturn : -35.62041473388672
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -19.5264892578125
Agent0_Train_StdReturn : 17.455280303955078
Agent0_Train_MaxReturn : 2.058140277862549
Agent0_Train_MinReturn : -56.74843978881836
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 976500
Agent0_TimeSinceStart : 1548.3407781124115
Agent0_Critic_Loss : 0.4802672863006592
Agent0_Actor_Loss : -0.6871686577796936
Agent0_Alpha_Loss : 0.7703127861022949
Agent0_Temperature : 0.08318447068293738
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -7.6240386962890625
Agent1_Eval_StdReturn : 15.554420471191406
Agent1_Eval_MaxReturn : 29.366817474365234
Agent1_Eval_MinReturn : -27.886714935302734
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -20.110431671142578
Agent1_Train_StdReturn : 17.263334274291992
Agent1_Train_MaxReturn : 5.89833927154541
Agent1_Train_MinReturn : -49.49818420410156
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 976500
Agent1_TimeSinceStart : 1550.5047817230225
Agent1_Critic_Loss : 0.44936877489089966
Agent1_Actor_Loss : -0.6949562430381775
Agent1_Alpha_Loss : 0.758205771446228
Agent1_Temperature : 0.08330103317387855
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 651 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 652 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 653 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 654 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 655 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 656 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 657 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 658 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 659 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 660 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -10.791821479797363
Agent0_Eval_StdReturn : 17.50000762939453
Agent0_Eval_MaxReturn : 23.00190544128418
Agent0_Eval_MinReturn : -41.81275177001953
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -6.205528259277344
Agent0_Train_StdReturn : 23.84868812561035
Agent0_Train_MaxReturn : 48.6168212890625
Agent0_Train_MinReturn : -47.221893310546875
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 991500
Agent0_TimeSinceStart : 1572.2370839118958
Agent0_Critic_Loss : 0.5220114588737488
Agent0_Actor_Loss : -0.6477996110916138
Agent0_Alpha_Loss : 0.7802212238311768
Agent0_Temperature : 0.08294775631163959
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -15.202618598937988
Agent1_Eval_StdReturn : 12.215559959411621
Agent1_Eval_MaxReturn : 2.8898701667785645
Agent1_Eval_MinReturn : -42.357967376708984
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -24.966373443603516
Agent1_Train_StdReturn : 20.161170959472656
Agent1_Train_MaxReturn : 8.279767036437988
Agent1_Train_MinReturn : -53.268497467041016
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 991500
Agent1_TimeSinceStart : 1574.394757270813
Agent1_Critic_Loss : 0.4853271245956421
Agent1_Actor_Loss : -0.7608102560043335
Agent1_Alpha_Loss : 0.7608060240745544
Agent1_Temperature : 0.08306877151913679
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 661 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 662 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 663 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 664 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 665 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 666 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 667 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 668 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 669 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 670 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -6.440576076507568
Agent0_Eval_StdReturn : 12.22825813293457
Agent0_Eval_MaxReturn : 16.609663009643555
Agent0_Eval_MinReturn : -25.39291000366211
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -11.498576164245605
Agent0_Train_StdReturn : 13.528006553649902
Agent0_Train_MaxReturn : 11.869964599609375
Agent0_Train_MinReturn : -36.52655792236328
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1006500
Agent0_TimeSinceStart : 1596.1050877571106
Agent0_Critic_Loss : 0.6629723310470581
Agent0_Actor_Loss : -0.5861366987228394
Agent0_Alpha_Loss : 0.7695485353469849
Agent0_Temperature : 0.08271300643536018
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -15.16392993927002
Agent1_Eval_StdReturn : 29.6558837890625
Agent1_Eval_MaxReturn : 9.937274932861328
Agent1_Eval_MinReturn : -87.18919372558594
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -11.049468994140625
Agent1_Train_StdReturn : 16.489337921142578
Agent1_Train_MaxReturn : 12.732585906982422
Agent1_Train_MinReturn : -40.86761474609375
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1006500
Agent1_TimeSinceStart : 1598.2622303962708
Agent1_Critic_Loss : 0.4095708429813385
Agent1_Actor_Loss : -0.7162833213806152
Agent1_Alpha_Loss : 0.7713409066200256
Agent1_Temperature : 0.08283469989273193
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 671 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 672 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 673 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 674 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 675 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 676 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 677 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 678 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 679 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 680 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -8.467641830444336
Agent0_Eval_StdReturn : 9.336271286010742
Agent0_Eval_MaxReturn : 6.4219183921813965
Agent0_Eval_MinReturn : -20.414770126342773
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -17.885425567626953
Agent0_Train_StdReturn : 13.642309188842773
Agent0_Train_MaxReturn : -6.731997489929199
Agent0_Train_MinReturn : -45.19118118286133
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1021500
Agent0_TimeSinceStart : 1619.9862189292908
Agent0_Critic_Loss : 0.6375986337661743
Agent0_Actor_Loss : -0.7273605465888977
Agent0_Alpha_Loss : 0.7622085809707642
Agent0_Temperature : 0.08248035154370366
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -19.423831939697266
Agent1_Eval_StdReturn : 13.841111183166504
Agent1_Eval_MaxReturn : 0.7421624660491943
Agent1_Eval_MinReturn : -48.530189514160156
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -17.369417190551758
Agent1_Train_StdReturn : 16.91293716430664
Agent1_Train_MaxReturn : 5.244499206542969
Agent1_Train_MinReturn : -50.23974609375
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1021500
Agent1_TimeSinceStart : 1622.1385838985443
Agent1_Critic_Loss : 0.4827311635017395
Agent1_Actor_Loss : -0.7122905254364014
Agent1_Alpha_Loss : 0.781387448310852
Agent1_Temperature : 0.08259882817714016
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 681 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 682 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 683 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 684 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 685 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 686 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 687 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 688 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 689 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 690 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -12.538536071777344
Agent0_Eval_StdReturn : 14.833117485046387
Agent0_Eval_MaxReturn : 10.969046592712402
Agent0_Eval_MinReturn : -37.62710189819336
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -10.322945594787598
Agent0_Train_StdReturn : 14.480172157287598
Agent0_Train_MaxReturn : 23.946306228637695
Agent0_Train_MinReturn : -32.31199645996094
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1036500
Agent0_TimeSinceStart : 1643.806327342987
Agent0_Critic_Loss : 0.5178655385971069
Agent0_Actor_Loss : -0.6749753355979919
Agent0_Alpha_Loss : 0.759323239326477
Agent0_Temperature : 0.08224901038621463
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -6.122828483581543
Agent1_Eval_StdReturn : 21.350025177001953
Agent1_Eval_MaxReturn : 40.747161865234375
Agent1_Eval_MinReturn : -35.504722595214844
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -17.561124801635742
Agent1_Train_StdReturn : 25.036561965942383
Agent1_Train_MaxReturn : 23.646427154541016
Agent1_Train_MinReturn : -52.61623764038086
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1036500
Agent1_TimeSinceStart : 1645.9589066505432
Agent1_Critic_Loss : 0.5222713351249695
Agent1_Actor_Loss : -0.7123814225196838
Agent1_Alpha_Loss : 0.7791756987571716
Agent1_Temperature : 0.08236278311574836
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 691 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 692 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 693 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 694 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 695 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 696 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 697 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 698 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 699 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 700 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -18.122779846191406
Agent0_Eval_StdReturn : 13.538463592529297
Agent0_Eval_MaxReturn : -3.647662878036499
Agent0_Eval_MinReturn : -43.501564025878906
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -15.775967597961426
Agent0_Train_StdReturn : 14.939800262451172
Agent0_Train_MaxReturn : 3.1044840812683105
Agent0_Train_MinReturn : -43.880287170410156
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1051500
Agent0_TimeSinceStart : 1667.6952574253082
Agent0_Critic_Loss : 0.5614727735519409
Agent0_Actor_Loss : -0.644767165184021
Agent0_Alpha_Loss : 0.7634012699127197
Agent0_Temperature : 0.08201838399906515
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -17.339765548706055
Agent1_Eval_StdReturn : 24.685762405395508
Agent1_Eval_MaxReturn : 15.891656875610352
Agent1_Eval_MinReturn : -53.52412796020508
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -10.879220962524414
Agent1_Train_StdReturn : 19.84909439086914
Agent1_Train_MaxReturn : 17.77328109741211
Agent1_Train_MinReturn : -42.7299919128418
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1051500
Agent1_TimeSinceStart : 1669.8444318771362
Agent1_Critic_Loss : 0.4366590678691864
Agent1_Actor_Loss : -0.6171002984046936
Agent1_Alpha_Loss : 0.7776542901992798
Agent1_Temperature : 0.08212703080048003
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 701 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 702 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 703 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 704 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 705 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 706 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 707 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 708 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 709 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 710 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -21.996746063232422
Agent0_Eval_StdReturn : 17.606260299682617
Agent0_Eval_MaxReturn : 4.394181251525879
Agent0_Eval_MinReturn : -58.89968490600586
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -11.727747917175293
Agent0_Train_StdReturn : 14.81747817993164
Agent0_Train_MaxReturn : 2.769383192062378
Agent0_Train_MinReturn : -48.72863006591797
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1066500
Agent0_TimeSinceStart : 1691.5528182983398
Agent0_Critic_Loss : 0.45605170726776123
Agent0_Actor_Loss : -0.6465818285942078
Agent0_Alpha_Loss : 0.7511382102966309
Agent0_Temperature : 0.08178741589883698
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -23.849285125732422
Agent1_Eval_StdReturn : 19.116065979003906
Agent1_Eval_MaxReturn : 6.322566986083984
Agent1_Eval_MinReturn : -46.122554779052734
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -18.930782318115234
Agent1_Train_StdReturn : 16.592266082763672
Agent1_Train_MaxReturn : 2.8231899738311768
Agent1_Train_MinReturn : -53.88099670410156
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1066500
Agent1_TimeSinceStart : 1693.7106075286865
Agent1_Critic_Loss : 0.45628565549850464
Agent1_Actor_Loss : -0.6274500489234924
Agent1_Alpha_Loss : 0.7683842182159424
Agent1_Temperature : 0.08189149432154486
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 711 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 712 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 713 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 714 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 715 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 716 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 717 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 718 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 719 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 720 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -15.169512748718262
Agent0_Eval_StdReturn : 17.50234031677246
Agent0_Eval_MaxReturn : 13.708824157714844
Agent0_Eval_MinReturn : -53.427268981933594
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -9.282407760620117
Agent0_Train_StdReturn : 15.226466178894043
Agent0_Train_MaxReturn : 17.392513275146484
Agent0_Train_MinReturn : -37.06302261352539
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1081500
Agent0_TimeSinceStart : 1715.4455053806305
Agent0_Critic_Loss : 0.4544791877269745
Agent0_Actor_Loss : -0.7064581513404846
Agent0_Alpha_Loss : 0.7532625794410706
Agent0_Temperature : 0.08155714266712087
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -27.198461532592773
Agent1_Eval_StdReturn : 36.372901916503906
Agent1_Eval_MaxReturn : 14.726040840148926
Agent1_Eval_MinReturn : -99.70405578613281
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -12.23108959197998
Agent1_Train_StdReturn : 15.866654396057129
Agent1_Train_MaxReturn : 14.472549438476562
Agent1_Train_MinReturn : -41.048072814941406
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1081500
Agent1_TimeSinceStart : 1717.6065039634705
Agent1_Critic_Loss : 0.5384163856506348
Agent1_Actor_Loss : -0.8484556674957275
Agent1_Alpha_Loss : 0.7560931444168091
Agent1_Temperature : 0.08165607234690493
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 721 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 722 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 723 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 724 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 725 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 726 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 727 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 728 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 729 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 730 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -15.539300918579102
Agent0_Eval_StdReturn : 11.405712127685547
Agent0_Eval_MaxReturn : 1.298479437828064
Agent0_Eval_MinReturn : -43.455814361572266
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -0.16568851470947266
Agent0_Train_StdReturn : 15.55759334564209
Agent0_Train_MaxReturn : 29.954158782958984
Agent0_Train_MinReturn : -29.248046875
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1096500
Agent0_TimeSinceStart : 1739.3125298023224
Agent0_Critic_Loss : 0.48350057005882263
Agent0_Actor_Loss : -0.6789775490760803
Agent0_Alpha_Loss : 0.7518587708473206
Agent0_Temperature : 0.08132780111835694
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -16.420854568481445
Agent1_Eval_StdReturn : 21.304719924926758
Agent1_Eval_MaxReturn : 17.08386993408203
Agent1_Eval_MinReturn : -63.01170349121094
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -19.00188636779785
Agent1_Train_StdReturn : 15.743940353393555
Agent1_Train_MaxReturn : 4.015966415405273
Agent1_Train_MinReturn : -49.17552947998047
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1096500
Agent1_TimeSinceStart : 1741.4590198993683
Agent1_Critic_Loss : 0.633712649345398
Agent1_Actor_Loss : -0.8166463375091553
Agent1_Alpha_Loss : 0.7636439800262451
Agent1_Temperature : 0.08142149217115693
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 731 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 732 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 733 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 734 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 735 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 736 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 737 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 738 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 739 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 740 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -16.8717041015625
Agent0_Eval_StdReturn : 12.620537757873535
Agent0_Eval_MaxReturn : 4.564884185791016
Agent0_Eval_MinReturn : -32.783042907714844
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -6.631211757659912
Agent0_Train_StdReturn : 13.224653244018555
Agent0_Train_MaxReturn : 14.947166442871094
Agent0_Train_MinReturn : -29.921405792236328
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1111500
Agent0_TimeSinceStart : 1763.123706817627
Agent0_Critic_Loss : 0.5901875495910645
Agent0_Actor_Loss : -0.655962347984314
Agent0_Alpha_Loss : 0.7561516761779785
Agent0_Temperature : 0.08109928420499973
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -11.436797142028809
Agent1_Eval_StdReturn : 23.029836654663086
Agent1_Eval_MaxReturn : 28.07135581970215
Agent1_Eval_MinReturn : -63.412105560302734
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -13.451135635375977
Agent1_Train_StdReturn : 20.65577507019043
Agent1_Train_MaxReturn : 24.24252700805664
Agent1_Train_MinReturn : -50.63579559326172
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1111500
Agent1_TimeSinceStart : 1765.2800645828247
Agent1_Critic_Loss : 0.49121585488319397
Agent1_Actor_Loss : -0.8017423152923584
Agent1_Alpha_Loss : 0.7733007669448853
Agent1_Temperature : 0.08118713198401298
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 741 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 742 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 743 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 744 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 745 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 746 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 747 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 748 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 749 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 750 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -8.42000675201416
Agent0_Eval_StdReturn : 12.426454544067383
Agent0_Eval_MaxReturn : 10.963292121887207
Agent0_Eval_MinReturn : -24.230464935302734
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -16.443866729736328
Agent0_Train_StdReturn : 10.264244079589844
Agent0_Train_MaxReturn : 2.9169671535491943
Agent0_Train_MinReturn : -35.63247299194336
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1126500
Agent0_TimeSinceStart : 1786.956775188446
Agent0_Critic_Loss : 0.5134709477424622
Agent0_Actor_Loss : -0.7467735409736633
Agent0_Alpha_Loss : 0.7539827823638916
Agent0_Temperature : 0.08087149731162638
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -18.37026596069336
Agent1_Eval_StdReturn : 23.65644645690918
Agent1_Eval_MaxReturn : 10.99044132232666
Agent1_Eval_MinReturn : -54.62868118286133
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -18.623126983642578
Agent1_Train_StdReturn : 15.848087310791016
Agent1_Train_MaxReturn : 10.82720947265625
Agent1_Train_MinReturn : -51.15226364135742
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1126500
Agent1_TimeSinceStart : 1789.0981183052063
Agent1_Critic_Loss : 0.7656859755516052
Agent1_Actor_Loss : -0.7474914789199829
Agent1_Alpha_Loss : 0.7772432565689087
Agent1_Temperature : 0.08095361556062222
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 751 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 752 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 753 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 754 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 755 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 756 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 757 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 758 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 759 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 760 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -12.863726615905762
Agent0_Eval_StdReturn : 12.948776245117188
Agent0_Eval_MaxReturn : 13.196874618530273
Agent0_Eval_MinReturn : -34.39454650878906
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -15.092915534973145
Agent0_Train_StdReturn : 21.76633644104004
Agent0_Train_MaxReturn : 12.508588790893555
Agent0_Train_MinReturn : -57.921226501464844
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1141500
Agent0_TimeSinceStart : 1810.7984771728516
Agent0_Critic_Loss : 0.5318242311477661
Agent0_Actor_Loss : -0.7804426550865173
Agent0_Alpha_Loss : 0.7723991870880127
Agent0_Temperature : 0.08064460383354705
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -7.017946720123291
Agent1_Eval_StdReturn : 19.26467514038086
Agent1_Eval_MaxReturn : 39.01436233520508
Agent1_Eval_MinReturn : -30.414785385131836
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -36.614566802978516
Agent1_Train_StdReturn : 21.317546844482422
Agent1_Train_MaxReturn : -4.540079116821289
Agent1_Train_MinReturn : -74.05452728271484
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1141500
Agent1_TimeSinceStart : 1813.0005240440369
Agent1_Critic_Loss : 0.9315478801727295
Agent1_Actor_Loss : -0.7414970993995667
Agent1_Alpha_Loss : 0.7642977237701416
Agent1_Temperature : 0.0807207532129493
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 761 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 762 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 763 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 764 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 765 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 766 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 767 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 768 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 769 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 770 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -13.89140510559082
Agent0_Eval_StdReturn : 13.882332801818848
Agent0_Eval_MaxReturn : 3.9478845596313477
Agent0_Eval_MinReturn : -33.96921920776367
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -14.457748413085938
Agent0_Train_StdReturn : 21.440752029418945
Agent0_Train_MaxReturn : 17.793041229248047
Agent0_Train_MinReturn : -51.39524841308594
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1156500
Agent0_TimeSinceStart : 1834.790535211563
Agent0_Critic_Loss : 0.4828040897846222
Agent0_Actor_Loss : -0.6857547760009766
Agent0_Alpha_Loss : 0.7618672847747803
Agent0_Temperature : 0.08041730498105427
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -8.450464248657227
Agent1_Eval_StdReturn : 22.540552139282227
Agent1_Eval_MaxReturn : 27.514631271362305
Agent1_Eval_MinReturn : -57.33772659301758
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -17.640186309814453
Agent1_Train_StdReturn : 15.155695915222168
Agent1_Train_MaxReturn : 2.525188446044922
Agent1_Train_MinReturn : -41.57296371459961
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1156500
Agent1_TimeSinceStart : 1836.9506599903107
Agent1_Critic_Loss : 1.1117162704467773
Agent1_Actor_Loss : -0.6393736600875854
Agent1_Alpha_Loss : 0.762566089630127
Agent1_Temperature : 0.08048969497298482
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 771 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 772 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 773 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 774 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 775 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 776 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 777 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 778 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 779 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 780 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -2.053454637527466
Agent0_Eval_StdReturn : 21.4679012298584
Agent0_Eval_MaxReturn : 40.36792755126953
Agent0_Eval_MinReturn : -30.164941787719727
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -11.338749885559082
Agent0_Train_StdReturn : 11.115272521972656
Agent0_Train_MaxReturn : 13.643491744995117
Agent0_Train_MinReturn : -33.60273742675781
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1171500
Agent0_TimeSinceStart : 1858.7101049423218
Agent0_Critic_Loss : 0.5063446164131165
Agent0_Actor_Loss : -0.6124482154846191
Agent0_Alpha_Loss : 0.7552692890167236
Agent0_Temperature : 0.08018995810276162
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -13.91026782989502
Agent1_Eval_StdReturn : 15.3272123336792
Agent1_Eval_MaxReturn : 10.97376823425293
Agent1_Eval_MinReturn : -42.120025634765625
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -14.865432739257812
Agent1_Train_StdReturn : 14.872917175292969
Agent1_Train_MaxReturn : 3.602250099182129
Agent1_Train_MinReturn : -47.951820373535156
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1171500
Agent1_TimeSinceStart : 1860.8689289093018
Agent1_Critic_Loss : 0.608254075050354
Agent1_Actor_Loss : -0.6139170527458191
Agent1_Alpha_Loss : 0.7495406270027161
Agent1_Temperature : 0.08026071187957456
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 781 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 782 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 783 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 784 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 785 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 786 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 787 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 788 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 789 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 790 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -19.582420349121094
Agent0_Eval_StdReturn : 37.10621643066406
Agent0_Eval_MaxReturn : 32.39827346801758
Agent0_Eval_MinReturn : -103.69652557373047
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -11.863649368286133
Agent0_Train_StdReturn : 22.827238082885742
Agent0_Train_MaxReturn : 20.797515869140625
Agent0_Train_MinReturn : -47.504844665527344
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1186500
Agent0_TimeSinceStart : 1882.4770760536194
Agent0_Critic_Loss : 0.5630289912223816
Agent0_Actor_Loss : -0.7343184351921082
Agent0_Alpha_Loss : 0.7600172758102417
Agent0_Temperature : 0.07996308982202621
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -7.43402099609375
Agent1_Eval_StdReturn : 13.052010536193848
Agent1_Eval_MaxReturn : 15.851608276367188
Agent1_Eval_MinReturn : -23.976049423217773
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -13.447372436523438
Agent1_Train_StdReturn : 13.690320014953613
Agent1_Train_MaxReturn : 4.85615348815918
Agent1_Train_MinReturn : -44.96314239501953
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1186500
Agent1_TimeSinceStart : 1884.6397020816803
Agent1_Critic_Loss : 0.9639801383018494
Agent1_Actor_Loss : -0.7372862100601196
Agent1_Alpha_Loss : 0.7362161874771118
Agent1_Temperature : 0.08003450581165326
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 791 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 792 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 793 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 794 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 795 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 796 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 797 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 798 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 799 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 800 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -22.413223266601562
Agent0_Eval_StdReturn : 17.73639678955078
Agent0_Eval_MaxReturn : 4.131196975708008
Agent0_Eval_MinReturn : -51.9211311340332
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -17.390621185302734
Agent0_Train_StdReturn : 11.509300231933594
Agent0_Train_MaxReturn : 3.1821422576904297
Agent0_Train_MinReturn : -32.8302001953125
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1201500
Agent0_TimeSinceStart : 1906.3081197738647
Agent0_Critic_Loss : 0.5408133268356323
Agent0_Actor_Loss : -0.8986081480979919
Agent0_Alpha_Loss : 0.7634145021438599
Agent0_Temperature : 0.07973552851788937
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -13.362462997436523
Agent1_Eval_StdReturn : 7.948846340179443
Agent1_Eval_MaxReturn : -0.7863948345184326
Agent1_Eval_MinReturn : -28.62525177001953
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -15.24463176727295
Agent1_Train_StdReturn : 10.684562683105469
Agent1_Train_MaxReturn : 3.909749984741211
Agent1_Train_MinReturn : -32.07044982910156
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1201500
Agent1_TimeSinceStart : 1908.4793026447296
Agent1_Critic_Loss : 0.9294147491455078
Agent1_Actor_Loss : -0.7910563349723816
Agent1_Alpha_Loss : 0.7262438535690308
Agent1_Temperature : 0.07981292606407368
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 801 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 802 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 803 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 804 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 805 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 806 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 807 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 808 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 809 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 810 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -21.89670181274414
Agent0_Eval_StdReturn : 20.660154342651367
Agent0_Eval_MaxReturn : 8.37087345123291
Agent0_Eval_MinReturn : -49.28630065917969
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -43.77967071533203
Agent0_Train_StdReturn : 33.040122985839844
Agent0_Train_MaxReturn : -1.7674102783203125
Agent0_Train_MinReturn : -100.50584411621094
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1216500
Agent0_TimeSinceStart : 1930.2526407241821
Agent0_Critic_Loss : 0.6817288398742676
Agent0_Actor_Loss : -0.8572887182235718
Agent0_Alpha_Loss : 0.771665096282959
Agent0_Temperature : 0.07950823878040782
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -11.876036643981934
Agent1_Eval_StdReturn : 10.979077339172363
Agent1_Eval_MaxReturn : 4.196592330932617
Agent1_Eval_MinReturn : -25.456222534179688
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -10.07821273803711
Agent1_Train_StdReturn : 14.645079612731934
Agent1_Train_MaxReturn : 8.44273567199707
Agent1_Train_MinReturn : -43.0304069519043
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1216500
Agent1_TimeSinceStart : 1932.4157428741455
Agent1_Critic_Loss : 0.6633087396621704
Agent1_Actor_Loss : -0.8011385202407837
Agent1_Alpha_Loss : 0.7157536745071411
Agent1_Temperature : 0.0795945396794552
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 811 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 812 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 813 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 814 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 815 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 816 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 817 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 818 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 819 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 820 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -22.95198631286621
Agent0_Eval_StdReturn : 24.44071388244629
Agent0_Eval_MaxReturn : 17.153072357177734
Agent0_Eval_MinReturn : -59.25103759765625
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -19.70718002319336
Agent0_Train_StdReturn : 19.456506729125977
Agent0_Train_MaxReturn : 14.126317024230957
Agent0_Train_MinReturn : -50.79753112792969
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1231500
Agent0_TimeSinceStart : 1953.6941187381744
Agent0_Critic_Loss : 0.7174925804138184
Agent0_Actor_Loss : -0.7637374997138977
Agent0_Alpha_Loss : 0.7519702315330505
Agent0_Temperature : 0.07928187590252242
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -14.201301574707031
Agent1_Eval_StdReturn : 9.269737243652344
Agent1_Eval_MaxReturn : -1.8379817008972168
Agent1_Eval_MinReturn : -29.734127044677734
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -13.075239181518555
Agent1_Train_StdReturn : 14.017549514770508
Agent1_Train_MaxReturn : 6.817705154418945
Agent1_Train_MinReturn : -37.11793899536133
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1231500
Agent1_TimeSinceStart : 1955.7605381011963
Agent1_Critic_Loss : 0.6516234874725342
Agent1_Actor_Loss : -0.7581926584243774
Agent1_Alpha_Loss : 0.7162759304046631
Agent1_Temperature : 0.07937868125315976
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 821 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 822 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 823 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 824 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 825 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 826 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 827 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 828 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 829 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 830 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -28.871906280517578
Agent0_Eval_StdReturn : 22.20890998840332
Agent0_Eval_MaxReturn : -1.1863101720809937
Agent0_Eval_MinReturn : -71.3106689453125
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -27.68563461303711
Agent0_Train_StdReturn : 24.220970153808594
Agent0_Train_MaxReturn : 7.410549640655518
Agent0_Train_MinReturn : -69.63038635253906
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1246500
Agent0_TimeSinceStart : 1976.9898488521576
Agent0_Critic_Loss : 0.705058217048645
Agent0_Actor_Loss : -0.6563958525657654
Agent0_Alpha_Loss : 0.7526540756225586
Agent0_Temperature : 0.07905739257319037
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -21.022693634033203
Agent1_Eval_StdReturn : 11.359203338623047
Agent1_Eval_MaxReturn : -4.273465156555176
Agent1_Eval_MinReturn : -40.22064971923828
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -12.626550674438477
Agent1_Train_StdReturn : 9.846952438354492
Agent1_Train_MaxReturn : -1.5515565872192383
Agent1_Train_MinReturn : -37.19441223144531
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1246500
Agent1_TimeSinceStart : 1979.1580374240875
Agent1_Critic_Loss : 1.0208983421325684
Agent1_Actor_Loss : -0.78515625
Agent1_Alpha_Loss : 0.7294063568115234
Agent1_Temperature : 0.07916429486524766
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 831 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 832 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 833 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 834 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 835 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 836 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 837 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 838 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 839 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 840 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -15.255935668945312
Agent0_Eval_StdReturn : 17.310894012451172
Agent0_Eval_MaxReturn : 2.1391029357910156
Agent0_Eval_MinReturn : -49.076332092285156
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -14.664892196655273
Agent0_Train_StdReturn : 25.9791202545166
Agent0_Train_MaxReturn : 29.993560791015625
Agent0_Train_MinReturn : -55.711421966552734
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1261500
Agent0_TimeSinceStart : 2000.8211035728455
Agent0_Critic_Loss : 0.6541227698326111
Agent0_Actor_Loss : -0.6910560727119446
Agent0_Alpha_Loss : 0.7540789246559143
Agent0_Temperature : 0.07883345402059053
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -19.597856521606445
Agent1_Eval_StdReturn : 21.59762954711914
Agent1_Eval_MaxReturn : 10.730167388916016
Agent1_Eval_MinReturn : -70.13639068603516
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -9.749100685119629
Agent1_Train_StdReturn : 8.591999053955078
Agent1_Train_MaxReturn : 11.4096040725708
Agent1_Train_MinReturn : -21.25857925415039
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1261500
Agent1_TimeSinceStart : 2002.9779567718506
Agent1_Critic_Loss : 0.6911858320236206
Agent1_Actor_Loss : -0.7842354774475098
Agent1_Alpha_Loss : 0.7257938385009766
Agent1_Temperature : 0.07894936279747196
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 841 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 842 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 843 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 844 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 845 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 846 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 847 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 848 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 849 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 850 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -12.778448104858398
Agent0_Eval_StdReturn : 19.153085708618164
Agent0_Eval_MaxReturn : 18.219465255737305
Agent0_Eval_MinReturn : -47.79154968261719
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -4.171023368835449
Agent0_Train_StdReturn : 18.46993637084961
Agent0_Train_MaxReturn : 23.293394088745117
Agent0_Train_MinReturn : -32.87272644042969
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1276500
Agent0_TimeSinceStart : 2024.6950800418854
Agent0_Critic_Loss : 0.5601798295974731
Agent0_Actor_Loss : -0.7968685626983643
Agent0_Alpha_Loss : 0.7434315085411072
Agent0_Temperature : 0.07861063305724961
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -7.95693826675415
Agent1_Eval_StdReturn : 6.994320392608643
Agent1_Eval_MaxReturn : 3.7353696823120117
Agent1_Eval_MinReturn : -22.719411849975586
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -19.532432556152344
Agent1_Train_StdReturn : 16.371614456176758
Agent1_Train_MaxReturn : 1.5289192199707031
Agent1_Train_MinReturn : -59.9133186340332
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1276500
Agent1_TimeSinceStart : 2026.866354227066
Agent1_Critic_Loss : 0.7906107306480408
Agent1_Actor_Loss : -0.8594580888748169
Agent1_Alpha_Loss : 0.7247709631919861
Agent1_Temperature : 0.078733801211164
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 851 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 852 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 853 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 854 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 855 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 856 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 857 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 858 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 859 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 860 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -8.261159896850586
Agent0_Eval_StdReturn : 22.02651596069336
Agent0_Eval_MaxReturn : 31.287269592285156
Agent0_Eval_MinReturn : -37.490196228027344
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -18.020740509033203
Agent0_Train_StdReturn : 18.533061981201172
Agent0_Train_MaxReturn : 1.6223230361938477
Agent0_Train_MinReturn : -59.17204284667969
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1291500
Agent0_TimeSinceStart : 2048.6038715839386
Agent0_Critic_Loss : 0.7394950985908508
Agent0_Actor_Loss : -0.8001711368560791
Agent0_Alpha_Loss : 0.7429209351539612
Agent0_Temperature : 0.07838985579961134
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -16.333160400390625
Agent1_Eval_StdReturn : 11.038554191589355
Agent1_Eval_MaxReturn : 3.2646918296813965
Agent1_Eval_MinReturn : -36.37223815917969
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -14.308810234069824
Agent1_Train_StdReturn : 15.4580717086792
Agent1_Train_MaxReturn : 9.099908828735352
Agent1_Train_MinReturn : -39.212646484375
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1291500
Agent1_TimeSinceStart : 2050.780689239502
Agent1_Critic_Loss : 0.5315920114517212
Agent1_Actor_Loss : -0.8146176934242249
Agent1_Alpha_Loss : 0.7268352508544922
Agent1_Temperature : 0.0785186963774229
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 861 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 862 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 863 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 864 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 865 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 866 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 867 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 868 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 869 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 870 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -16.223194122314453
Agent0_Eval_StdReturn : 17.003414154052734
Agent0_Eval_MaxReturn : 9.36388111114502
Agent0_Eval_MinReturn : -54.211917877197266
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -10.48302936553955
Agent0_Train_StdReturn : 11.850190162658691
Agent0_Train_MaxReturn : 4.251366138458252
Agent0_Train_MinReturn : -32.71227264404297
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1306500
Agent0_TimeSinceStart : 2072.53550863266
Agent0_Critic_Loss : 0.8312960863113403
Agent0_Actor_Loss : -0.8533698916435242
Agent0_Alpha_Loss : 0.7376953363418579
Agent0_Temperature : 0.07817087398821924
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -21.917377471923828
Agent1_Eval_StdReturn : 14.541678428649902
Agent1_Eval_MaxReturn : -0.20843029022216797
Agent1_Eval_MinReturn : -50.10948181152344
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -14.207612991333008
Agent1_Train_StdReturn : 11.540014266967773
Agent1_Train_MaxReturn : 2.9410829544067383
Agent1_Train_MinReturn : -37.690975189208984
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1306500
Agent1_TimeSinceStart : 2074.691947221756
Agent1_Critic_Loss : 0.5910598039627075
Agent1_Actor_Loss : -0.7508796453475952
Agent1_Alpha_Loss : 0.7299805879592896
Agent1_Temperature : 0.07830260769181252
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 871 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 872 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 873 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 874 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 875 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 876 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 877 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 878 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 879 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 880 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -9.031476974487305
Agent0_Eval_StdReturn : 11.910674095153809
Agent0_Eval_MaxReturn : 8.928253173828125
Agent0_Eval_MinReturn : -34.32345199584961
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -11.598559379577637
Agent0_Train_StdReturn : 15.266921043395996
Agent0_Train_MaxReturn : 10.646381378173828
Agent0_Train_MinReturn : -35.1094856262207
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1321500
Agent0_TimeSinceStart : 2096.4586219787598
Agent0_Critic_Loss : 0.8781977295875549
Agent0_Actor_Loss : -0.816606879234314
Agent0_Alpha_Loss : 0.7312049269676208
Agent0_Temperature : 0.07795350183826427
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -14.932034492492676
Agent1_Eval_StdReturn : 16.762025833129883
Agent1_Eval_MaxReturn : 17.964981079101562
Agent1_Eval_MinReturn : -41.25978088378906
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -14.005086898803711
Agent1_Train_StdReturn : 11.242856979370117
Agent1_Train_MaxReturn : 4.555875778198242
Agent1_Train_MinReturn : -31.211305618286133
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1321500
Agent1_TimeSinceStart : 2098.6403250694275
Agent1_Critic_Loss : 0.7119113802909851
Agent1_Actor_Loss : -0.8810054659843445
Agent1_Alpha_Loss : 0.7365108728408813
Agent1_Temperature : 0.07808683494381578
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 881 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 882 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 883 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 884 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 885 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 886 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 887 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 888 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 889 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 890 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -13.2225923538208
Agent0_Eval_StdReturn : 7.899472236633301
Agent0_Eval_MaxReturn : 4.302783012390137
Agent0_Eval_MinReturn : -27.277782440185547
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -4.0362701416015625
Agent0_Train_StdReturn : 18.847942352294922
Agent0_Train_MaxReturn : 28.889877319335938
Agent0_Train_MinReturn : -36.75605010986328
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1336500
Agent0_TimeSinceStart : 2120.4882855415344
Agent0_Critic_Loss : 0.866920530796051
Agent0_Actor_Loss : -0.8391628861427307
Agent0_Alpha_Loss : 0.7215343713760376
Agent0_Temperature : 0.07773865148406639
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -19.24504280090332
Agent1_Eval_StdReturn : 13.9314546585083
Agent1_Eval_MaxReturn : 1.608540654182434
Agent1_Eval_MinReturn : -47.066471099853516
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -8.567230224609375
Agent1_Train_StdReturn : 15.663131713867188
Agent1_Train_MaxReturn : 21.40172004699707
Agent1_Train_MinReturn : -43.05994415283203
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1336500
Agent1_TimeSinceStart : 2122.6547973155975
Agent1_Critic_Loss : 0.5879424810409546
Agent1_Actor_Loss : -0.8346368074417114
Agent1_Alpha_Loss : 0.743725061416626
Agent1_Temperature : 0.07787047569322936
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 891 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 892 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 893 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 894 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 895 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 896 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 897 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 898 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 899 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 900 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -21.015153884887695
Agent0_Eval_StdReturn : 17.640209197998047
Agent0_Eval_MaxReturn : 10.872051239013672
Agent0_Eval_MinReturn : -65.81245422363281
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -1.9832031726837158
Agent0_Train_StdReturn : 10.200069427490234
Agent0_Train_MaxReturn : 20.913667678833008
Agent0_Train_MinReturn : -18.848270416259766
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1351500
Agent0_TimeSinceStart : 2144.390182495117
Agent0_Critic_Loss : 0.8364413976669312
Agent0_Actor_Loss : -0.7321898341178894
Agent0_Alpha_Loss : 0.7272231578826904
Agent0_Temperature : 0.0775257767521391
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -18.602176666259766
Agent1_Eval_StdReturn : 19.76792335510254
Agent1_Eval_MaxReturn : 10.16269302368164
Agent1_Eval_MinReturn : -45.63542938232422
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -9.061631202697754
Agent1_Train_StdReturn : 13.64448356628418
Agent1_Train_MaxReturn : 13.893156051635742
Agent1_Train_MinReturn : -34.85884094238281
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1351500
Agent1_TimeSinceStart : 2146.5434653759003
Agent1_Critic_Loss : 0.5423764586448669
Agent1_Actor_Loss : -0.9666440486907959
Agent1_Alpha_Loss : 0.7547261714935303
Agent1_Temperature : 0.07765370296086856
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 901 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 902 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 903 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 904 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 905 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 906 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 907 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 908 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 909 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 910 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -8.163424491882324
Agent0_Eval_StdReturn : 15.623340606689453
Agent0_Eval_MaxReturn : 25.43826675415039
Agent0_Eval_MinReturn : -37.825096130371094
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -16.9205265045166
Agent0_Train_StdReturn : 13.787992477416992
Agent0_Train_MaxReturn : -0.8210601806640625
Agent0_Train_MinReturn : -37.947265625
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1366500
Agent0_TimeSinceStart : 2168.2764914035797
Agent0_Critic_Loss : 0.7076895236968994
Agent0_Actor_Loss : -0.6963627934455872
Agent0_Alpha_Loss : 0.7370032072067261
Agent0_Temperature : 0.07731358410281441
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -7.804219722747803
Agent1_Eval_StdReturn : 14.622791290283203
Agent1_Eval_MaxReturn : 17.671350479125977
Agent1_Eval_MinReturn : -32.19041061401367
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -14.33128833770752
Agent1_Train_StdReturn : 23.433460235595703
Agent1_Train_MaxReturn : 21.006567001342773
Agent1_Train_MinReturn : -69.18721008300781
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1366500
Agent1_TimeSinceStart : 2170.4292097091675
Agent1_Critic_Loss : 0.5217598080635071
Agent1_Actor_Loss : -0.9251367449760437
Agent1_Alpha_Loss : 0.7386234998703003
Agent1_Temperature : 0.07743550346111519
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 911 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 912 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 913 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 914 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 915 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 916 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 917 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 918 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 919 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 920 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -20.536972045898438
Agent0_Eval_StdReturn : 17.00377082824707
Agent0_Eval_MaxReturn : 3.957456588745117
Agent0_Eval_MinReturn : -51.400306701660156
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -14.154095649719238
Agent0_Train_StdReturn : 21.11654281616211
Agent0_Train_MaxReturn : 5.93084716796875
Agent0_Train_MinReturn : -68.85381317138672
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1381500
Agent0_TimeSinceStart : 2192.0780680179596
Agent0_Critic_Loss : 0.8030083179473877
Agent0_Actor_Loss : -0.8289045095443726
Agent0_Alpha_Loss : 0.7281752824783325
Agent0_Temperature : 0.07710163264223868
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -12.935137748718262
Agent1_Eval_StdReturn : 20.951059341430664
Agent1_Eval_MaxReturn : 10.564168930053711
Agent1_Eval_MinReturn : -57.228782653808594
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -5.542840480804443
Agent1_Train_StdReturn : 17.720491409301758
Agent1_Train_MaxReturn : 20.942018508911133
Agent1_Train_MinReturn : -38.871368408203125
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1381500
Agent1_TimeSinceStart : 2194.219950437546
Agent1_Critic_Loss : 0.7549366354942322
Agent1_Actor_Loss : -0.8303861021995544
Agent1_Alpha_Loss : 0.7416497468948364
Agent1_Temperature : 0.07721657445359134
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 921 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 922 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 923 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 924 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 925 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 926 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 927 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 928 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 929 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 930 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -10.457531929016113
Agent0_Eval_StdReturn : 14.855162620544434
Agent0_Eval_MaxReturn : 5.312955856323242
Agent0_Eval_MinReturn : -37.27194595336914
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -9.81082820892334
Agent0_Train_StdReturn : 8.330985069274902
Agent0_Train_MaxReturn : 7.900588035583496
Agent0_Train_MinReturn : -24.611230850219727
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1396500
Agent0_TimeSinceStart : 2215.8799612522125
Agent0_Critic_Loss : 0.6404407024383545
Agent0_Actor_Loss : -0.8150357007980347
Agent0_Alpha_Loss : 0.7245379686355591
Agent0_Temperature : 0.07689023404691307
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -40.05531692504883
Agent1_Eval_StdReturn : 18.28441047668457
Agent1_Eval_MaxReturn : -16.557302474975586
Agent1_Eval_MinReturn : -75.12823486328125
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -24.735721588134766
Agent1_Train_StdReturn : 17.753026962280273
Agent1_Train_MaxReturn : 5.838751316070557
Agent1_Train_MinReturn : -46.500732421875
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1396500
Agent1_TimeSinceStart : 2218.012545824051
Agent1_Critic_Loss : 0.7408277988433838
Agent1_Actor_Loss : -0.9620357751846313
Agent1_Alpha_Loss : 0.7368197441101074
Agent1_Temperature : 0.07699873988671412
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 931 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 932 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 933 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 934 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 935 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 936 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 937 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 938 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 939 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 940 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -12.08072566986084
Agent0_Eval_StdReturn : 12.293183326721191
Agent0_Eval_MaxReturn : -2.2154204845428467
Agent0_Eval_MinReturn : -44.6818733215332
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -15.423535346984863
Agent0_Train_StdReturn : 13.214570045471191
Agent0_Train_MaxReturn : 11.283377647399902
Agent0_Train_MinReturn : -43.02207946777344
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1411500
Agent0_TimeSinceStart : 2239.6763093471527
Agent0_Critic_Loss : 0.7846618890762329
Agent0_Actor_Loss : -0.8037799000740051
Agent0_Alpha_Loss : 0.712094783782959
Agent0_Temperature : 0.0766799462446349
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -15.585871696472168
Agent1_Eval_StdReturn : 32.85227966308594
Agent1_Eval_MaxReturn : 37.16623306274414
Agent1_Eval_MinReturn : -77.39348602294922
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -29.479244232177734
Agent1_Train_StdReturn : 19.03998565673828
Agent1_Train_MaxReturn : 13.959148406982422
Agent1_Train_MinReturn : -64.99068450927734
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1411500
Agent1_TimeSinceStart : 2241.8230860233307
Agent1_Critic_Loss : 0.6220201849937439
Agent1_Actor_Loss : -0.9867813587188721
Agent1_Alpha_Loss : 0.7306963205337524
Agent1_Temperature : 0.0767819209405779
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 941 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 942 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 943 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 944 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 945 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 946 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 947 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 948 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 949 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 950 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -9.674771308898926
Agent0_Eval_StdReturn : 11.025941848754883
Agent0_Eval_MaxReturn : 2.7394275665283203
Agent0_Eval_MinReturn : -33.17115783691406
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -7.906301021575928
Agent0_Train_StdReturn : 11.892627716064453
Agent0_Train_MaxReturn : 14.230194091796875
Agent0_Train_MinReturn : -27.29912567138672
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1426500
Agent0_TimeSinceStart : 2263.5238251686096
Agent0_Critic_Loss : 0.6634587049484253
Agent0_Actor_Loss : -0.8824299573898315
Agent0_Alpha_Loss : 0.7077593207359314
Agent0_Temperature : 0.07647124926355679
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -17.56426239013672
Agent1_Eval_StdReturn : 22.311670303344727
Agent1_Eval_MaxReturn : 9.208208084106445
Agent1_Eval_MinReturn : -57.695411682128906
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -27.772287368774414
Agent1_Train_StdReturn : 22.198610305786133
Agent1_Train_MaxReturn : 10.660511016845703
Agent1_Train_MinReturn : -59.34058380126953
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1426500
Agent1_TimeSinceStart : 2265.6666333675385
Agent1_Critic_Loss : 0.8522234559059143
Agent1_Actor_Loss : -0.8694875836372375
Agent1_Alpha_Loss : 0.7267639636993408
Agent1_Temperature : 0.07656610355667728
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 951 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 952 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 953 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 954 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 955 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 956 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 957 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 958 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 959 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 960 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -11.483150482177734
Agent0_Eval_StdReturn : 17.211870193481445
Agent0_Eval_MaxReturn : 20.382051467895508
Agent0_Eval_MinReturn : -30.823204040527344
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -11.586820602416992
Agent0_Train_StdReturn : 11.134270668029785
Agent0_Train_MaxReturn : 9.531128883361816
Agent0_Train_MinReturn : -26.107919692993164
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1441500
Agent0_TimeSinceStart : 2287.3740286827087
Agent0_Critic_Loss : 0.6770725250244141
Agent0_Actor_Loss : -0.8546434640884399
Agent0_Alpha_Loss : 0.7046211957931519
Agent0_Temperature : 0.07626408473648315
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -20.223724365234375
Agent1_Eval_StdReturn : 20.384613037109375
Agent1_Eval_MaxReturn : 8.660011291503906
Agent1_Eval_MinReturn : -44.99341583251953
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -27.547882080078125
Agent1_Train_StdReturn : 21.68562126159668
Agent1_Train_MaxReturn : -0.1376047134399414
Agent1_Train_MinReturn : -73.9770736694336
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1441500
Agent1_TimeSinceStart : 2289.5256288051605
Agent1_Critic_Loss : 0.7913976311683655
Agent1_Actor_Loss : -0.9218299984931946
Agent1_Alpha_Loss : 0.7244064807891846
Agent1_Temperature : 0.07635130797039034
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 961 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 962 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 963 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 964 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 965 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 966 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 967 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 968 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 969 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 970 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : 3.145343065261841
Agent0_Eval_StdReturn : 14.072893142700195
Agent0_Eval_MaxReturn : 26.725942611694336
Agent0_Eval_MinReturn : -19.357934951782227
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -9.264749526977539
Agent0_Train_StdReturn : 11.481945037841797
Agent0_Train_MaxReturn : 11.694328308105469
Agent0_Train_MinReturn : -28.15854263305664
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1456500
Agent0_TimeSinceStart : 2311.2043142318726
Agent0_Critic_Loss : 0.665631115436554
Agent0_Actor_Loss : -0.8270963430404663
Agent0_Alpha_Loss : 0.7322870492935181
Agent0_Temperature : 0.07605724567570692
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -19.15384292602539
Agent1_Eval_StdReturn : 16.790706634521484
Agent1_Eval_MaxReturn : 2.45166015625
Agent1_Eval_MinReturn : -56.41191482543945
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -32.82868194580078
Agent1_Train_StdReturn : 22.27954864501953
Agent1_Train_MaxReturn : -1.813734769821167
Agent1_Train_MinReturn : -77.46883392333984
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1456500
Agent1_TimeSinceStart : 2313.365098953247
Agent1_Critic_Loss : 0.8623886108398438
Agent1_Actor_Loss : -0.7808836698532104
Agent1_Alpha_Loss : 0.7264251112937927
Agent1_Temperature : 0.07613689364004741
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 971 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 972 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 973 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 974 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 975 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 976 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 977 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 978 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 979 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 980 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -13.105108261108398
Agent0_Eval_StdReturn : 22.795373916625977
Agent0_Eval_MaxReturn : 10.846830368041992
Agent0_Eval_MinReturn : -59.86211013793945
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -5.773351192474365
Agent0_Train_StdReturn : 14.313027381896973
Agent0_Train_MaxReturn : 20.203311920166016
Agent0_Train_MinReturn : -27.264623641967773
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1471500
Agent0_TimeSinceStart : 2335.0314390659332
Agent0_Critic_Loss : 0.7179741859436035
Agent0_Actor_Loss : -0.7886296510696411
Agent0_Alpha_Loss : 0.7197920083999634
Agent0_Temperature : 0.07584940387439458
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -17.894447326660156
Agent1_Eval_StdReturn : 18.89568328857422
Agent1_Eval_MaxReturn : 10.782584190368652
Agent1_Eval_MinReturn : -53.71235656738281
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -11.372687339782715
Agent1_Train_StdReturn : 11.18143367767334
Agent1_Train_MaxReturn : 5.0858473777771
Agent1_Train_MinReturn : -27.282875061035156
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1471500
Agent1_TimeSinceStart : 2337.169039964676
Agent1_Critic_Loss : 0.7311053276062012
Agent1_Actor_Loss : -0.8644039630889893
Agent1_Alpha_Loss : 0.7334622144699097
Agent1_Temperature : 0.0759235797415027
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 981 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 982 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 983 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 984 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 985 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 986 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 987 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 988 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 989 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 990 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -11.639371871948242
Agent0_Eval_StdReturn : 21.25242042541504
Agent0_Eval_MaxReturn : 16.963361740112305
Agent0_Eval_MinReturn : -56.34259796142578
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -21.286405563354492
Agent0_Train_StdReturn : 23.5972957611084
Agent0_Train_MaxReturn : 12.399872779846191
Agent0_Train_MinReturn : -84.64105987548828
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1486500
Agent0_TimeSinceStart : 2358.7572536468506
Agent0_Critic_Loss : 0.6368573904037476
Agent0_Actor_Loss : -0.9025330543518066
Agent0_Alpha_Loss : 0.7217196226119995
Agent0_Temperature : 0.07564115579304308
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -17.463979721069336
Agent1_Eval_StdReturn : 12.877161979675293
Agent1_Eval_MaxReturn : -3.99495792388916
Agent1_Eval_MinReturn : -45.88735580444336
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -6.883005619049072
Agent1_Train_StdReturn : 16.338050842285156
Agent1_Train_MaxReturn : 16.594886779785156
Agent1_Train_MinReturn : -41.70326232910156
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1486500
Agent1_TimeSinceStart : 2360.8992109298706
Agent1_Critic_Loss : 1.0573607683181763
Agent1_Actor_Loss : -0.9531529545783997
Agent1_Alpha_Loss : 0.7306195497512817
Agent1_Temperature : 0.07571122438295208
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 991 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 992 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 993 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 994 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer.../home/harvey/anaconda3/envs/285final/lib/python3.7/site-packages/gym/core.py:318: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  "Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future."
/home/harvey/anaconda3/envs/285final/lib/python3.7/site-packages/gym/wrappers/step_api_compatibility.py:40: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  "Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future."
/home/harvey/anaconda3/envs/285final/lib/python3.7/site-packages/gym/core.py:257: DeprecationWarning: [33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.[0m
  "Function `env.seed(seed)` is marked as deprecated and will be removed in the future. "


Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 995 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 996 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 997 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 998 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 999 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...
./peersacv2.sh: 28: --seed: not found



LOGGING TO:  /home/harvey/Documents/cs285/CS285-Project/cs285/scripts/../../data/peersac_v2_3agents_advdim8_HalfCheetah-v4_12-12-2022_04-31-40 



########################
logging outputs to  /home/harvey/Documents/cs285/CS285-Project/cs285/scripts/../../data/peersac_v2_3agents_advdim8_HalfCheetah-v4_12-12-2022_04-31-40
########################
Using GPU id 0


********** Iteration 0 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -35.159584045410156
Agent0_Eval_StdReturn : 43.0672492980957
Agent0_Eval_MaxReturn : 18.10063362121582
Agent0_Eval_MinReturn : -122.73959350585938
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -68.51490020751953
Agent0_Train_StdReturn : 35.8519172668457
Agent0_Train_MaxReturn : 10.17027473449707
Agent0_Train_MinReturn : -109.59283447265625
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1500
Agent0_TimeSinceStart : 2.1208226680755615
Agent0_Critic_Loss : 1.7149325609207153
Agent0_Actor_Loss : -0.1860627382993698
Agent0_Alpha_Loss : 0.9863041639328003
Agent0_Temperature : 0.09997000449985415
Agent0_Initial_DataCollection_AverageReturn : -68.51490020751953
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -33.770729064941406
Agent1_Eval_StdReturn : 29.424062728881836
Agent1_Eval_MaxReturn : 12.70883846282959
Agent1_Eval_MinReturn : -80.87906646728516
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -22.048892974853516
Agent1_Train_StdReturn : 33.81962966918945
Agent1_Train_MaxReturn : 20.3682861328125
Agent1_Train_MinReturn : -85.2005386352539
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1500
Agent1_TimeSinceStart : 4.2021164894104
Agent1_Critic_Loss : 1.7830392122268677
Agent1_Actor_Loss : 0.050348903983831406
Agent1_Alpha_Loss : 0.9870660305023193
Agent1_Temperature : 0.09997000449985388
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 1 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 2 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 3 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 4 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 5 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 6 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 7 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 8 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 9 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 10 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -48.792640686035156
Agent0_Eval_StdReturn : 42.51167297363281
Agent0_Eval_MaxReturn : 6.510025978088379
Agent0_Eval_MinReturn : -118.9874267578125
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -25.334436416625977
Agent0_Train_StdReturn : 35.39543914794922
Agent0_Train_MaxReturn : 22.93054962158203
Agent0_Train_MinReturn : -95.40158081054688
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 16500
Agent0_TimeSinceStart : 25.2002432346344
Agent0_Critic_Loss : 1.0671796798706055
Agent0_Actor_Loss : -0.29589036107063293
Agent0_Alpha_Loss : 0.988443911075592
Agent0_Temperature : 0.09967047740435137
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -36.690616607666016
Agent1_Eval_StdReturn : 37.1854133605957
Agent1_Eval_MaxReturn : 16.83552360534668
Agent1_Eval_MinReturn : -99.16520690917969
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -38.32520294189453
Agent1_Train_StdReturn : 31.690217971801758
Agent1_Train_MaxReturn : 14.367748260498047
Agent1_Train_MinReturn : -78.78767395019531
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 16500
Agent1_TimeSinceStart : 27.287362337112427
Agent1_Critic_Loss : 1.1946282386779785
Agent1_Actor_Loss : 0.17240867018699646
Agent1_Alpha_Loss : 0.9826501607894897
Agent1_Temperature : 0.09967045640300681
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 11 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 12 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 13 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 14 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 15 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 16 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 17 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 18 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 19 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 20 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -40.218353271484375
Agent0_Eval_StdReturn : 41.37144470214844
Agent0_Eval_MaxReturn : 20.026859283447266
Agent0_Eval_MinReturn : -140.10150146484375
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -30.490896224975586
Agent0_Train_StdReturn : 25.93821144104004
Agent0_Train_MaxReturn : 8.973248481750488
Agent0_Train_MinReturn : -68.64816284179688
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 31500
Agent0_TimeSinceStart : 48.318060874938965
Agent0_Critic_Loss : 1.0131187438964844
Agent0_Actor_Loss : -0.2447030395269394
Agent0_Alpha_Loss : 0.9946650862693787
Agent0_Temperature : 0.09937185101063263
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -50.9819450378418
Agent1_Eval_StdReturn : 28.93606185913086
Agent1_Eval_MaxReturn : -7.308650016784668
Agent1_Eval_MinReturn : -92.07315063476562
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -46.9066276550293
Agent1_Train_StdReturn : 26.70061683654785
Agent1_Train_MaxReturn : 5.787106037139893
Agent1_Train_MinReturn : -94.01490783691406
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 31500
Agent1_TimeSinceStart : 50.41143608093262
Agent1_Critic_Loss : 0.9541975259780884
Agent1_Actor_Loss : 0.12412570416927338
Agent1_Alpha_Loss : 0.9861167669296265
Agent1_Temperature : 0.09937171815980411
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 21 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 22 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 23 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 24 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 25 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 26 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 27 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 28 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 29 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 30 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -38.813499450683594
Agent0_Eval_StdReturn : 29.10923957824707
Agent0_Eval_MaxReturn : -3.672513008117676
Agent0_Eval_MinReturn : -87.74024200439453
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -29.267230987548828
Agent0_Train_StdReturn : 24.995304107666016
Agent0_Train_MaxReturn : -0.5061182975769043
Agent0_Train_MinReturn : -88.86225128173828
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 46500
Agent0_TimeSinceStart : 71.38095283508301
Agent0_Critic_Loss : 0.8672925233840942
Agent0_Actor_Loss : -0.3574602007865906
Agent0_Alpha_Loss : 0.9889074563980103
Agent0_Temperature : 0.09907404229048257
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -28.366931915283203
Agent1_Eval_StdReturn : 37.41022872924805
Agent1_Eval_MaxReturn : 25.17120361328125
Agent1_Eval_MinReturn : -88.58522033691406
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -60.75690841674805
Agent1_Train_StdReturn : 26.419130325317383
Agent1_Train_MaxReturn : -3.3039631843566895
Agent1_Train_MinReturn : -97.37300872802734
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 46500
Agent1_TimeSinceStart : 73.46568036079407
Agent1_Critic_Loss : 0.9384180903434753
Agent1_Actor_Loss : 0.060919612646102905
Agent1_Alpha_Loss : 0.9835065603256226
Agent1_Temperature : 0.09907392458330126
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 31 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 32 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 33 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 34 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 35 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 36 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 37 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 38 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 39 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 40 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -46.6294059753418
Agent0_Eval_StdReturn : 30.73592185974121
Agent0_Eval_MaxReturn : 2.3437623977661133
Agent0_Eval_MinReturn : -93.80091857910156
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -49.14337921142578
Agent0_Train_StdReturn : 28.87733268737793
Agent0_Train_MaxReturn : 7.306174278259277
Agent0_Train_MinReturn : -97.24810791015625
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 61500
Agent0_TimeSinceStart : 94.44557428359985
Agent0_Critic_Loss : 0.9420886635780334
Agent0_Actor_Loss : -0.34910452365875244
Agent0_Alpha_Loss : 0.9803498983383179
Agent0_Temperature : 0.09877774894941546
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -32.826072692871094
Agent1_Eval_StdReturn : 42.287986755371094
Agent1_Eval_MaxReturn : 26.373207092285156
Agent1_Eval_MinReturn : -97.03677368164062
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -60.63446044921875
Agent1_Train_StdReturn : 44.857383728027344
Agent1_Train_MaxReturn : 13.605422973632812
Agent1_Train_MinReturn : -146.49923706054688
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 61500
Agent1_TimeSinceStart : 96.55370783805847
Agent1_Critic_Loss : 0.9519737958908081
Agent1_Actor_Loss : 0.06954094022512436
Agent1_Alpha_Loss : 0.9846309423446655
Agent1_Temperature : 0.09877754300317727
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 41 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 42 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 43 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 44 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 45 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 46 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 47 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 48 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 49 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 50 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -33.726829528808594
Agent0_Eval_StdReturn : 22.712474822998047
Agent0_Eval_MaxReturn : 21.236921310424805
Agent0_Eval_MinReturn : -69.48518371582031
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -36.214271545410156
Agent0_Train_StdReturn : 21.525890350341797
Agent0_Train_MaxReturn : 3.1041698455810547
Agent0_Train_MinReturn : -64.5977783203125
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 76500
Agent0_TimeSinceStart : 117.67254066467285
Agent0_Critic_Loss : 0.8496872186660767
Agent0_Actor_Loss : -0.3607659339904785
Agent0_Alpha_Loss : 0.9712260961532593
Agent0_Temperature : 0.0984829916569801
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -45.970672607421875
Agent1_Eval_StdReturn : 34.695865631103516
Agent1_Eval_MaxReturn : 14.23019790649414
Agent1_Eval_MinReturn : -94.13884735107422
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -49.090415954589844
Agent1_Train_StdReturn : 14.472764015197754
Agent1_Train_MaxReturn : -28.82660675048828
Agent1_Train_MinReturn : -75.64766693115234
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 76500
Agent1_TimeSinceStart : 119.77711701393127
Agent1_Critic_Loss : 1.0236890316009521
Agent1_Actor_Loss : 0.08447636663913727
Agent1_Alpha_Loss : 0.9852569103240967
Agent1_Temperature : 0.09848241956980816
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 51 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 52 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 53 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 54 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 55 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 56 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 57 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 58 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 59 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 60 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -43.557762145996094
Agent0_Eval_StdReturn : 30.6146183013916
Agent0_Eval_MaxReturn : 0.36867332458496094
Agent0_Eval_MinReturn : -98.40469360351562
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -53.944053649902344
Agent0_Train_StdReturn : 22.766836166381836
Agent0_Train_MaxReturn : -25.906248092651367
Agent0_Train_MinReturn : -89.50276184082031
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 91500
Agent0_TimeSinceStart : 140.89059829711914
Agent0_Critic_Loss : 0.8365674614906311
Agent0_Actor_Loss : -0.3360896110534668
Agent0_Alpha_Loss : 0.9690998196601868
Agent0_Temperature : 0.0981897477556148
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -38.295166015625
Agent1_Eval_StdReturn : 25.807559967041016
Agent1_Eval_MaxReturn : 1.2453241348266602
Agent1_Eval_MinReturn : -69.73040771484375
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -46.32894515991211
Agent1_Train_StdReturn : 41.51876449584961
Agent1_Train_MaxReturn : 3.46148681640625
Agent1_Train_MinReturn : -112.8245849609375
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 91500
Agent1_TimeSinceStart : 142.9949197769165
Agent1_Critic_Loss : 0.807013213634491
Agent1_Actor_Loss : 0.04813794046640396
Agent1_Alpha_Loss : 0.9761171340942383
Agent1_Temperature : 0.09818832058884905
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 61 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 62 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 63 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 64 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 65 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 66 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 67 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 68 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 69 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 70 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -39.68449783325195
Agent0_Eval_StdReturn : 33.2226676940918
Agent0_Eval_MaxReturn : 34.68151092529297
Agent0_Eval_MinReturn : -83.30255889892578
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -43.082855224609375
Agent0_Train_StdReturn : 35.067649841308594
Agent0_Train_MaxReturn : 1.702526569366455
Agent0_Train_MinReturn : -107.8979721069336
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 106500
Agent0_TimeSinceStart : 164.1287226676941
Agent0_Critic_Loss : 0.7019181251525879
Agent0_Actor_Loss : -0.29603737592697144
Agent0_Alpha_Loss : 0.9637612104415894
Agent0_Temperature : 0.09789818983404444
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -34.511024475097656
Agent1_Eval_StdReturn : 27.577526092529297
Agent1_Eval_MaxReturn : -1.849884033203125
Agent1_Eval_MinReturn : -87.36154174804688
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -27.485647201538086
Agent1_Train_StdReturn : 24.114421844482422
Agent1_Train_MaxReturn : 7.29669713973999
Agent1_Train_MinReturn : -72.08168029785156
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 106500
Agent1_TimeSinceStart : 166.22120761871338
Agent1_Critic_Loss : 0.7484548091888428
Agent1_Actor_Loss : 0.020426981151103973
Agent1_Alpha_Loss : 0.9681107401847839
Agent1_Temperature : 0.0978959546300342
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 71 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 72 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 73 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 74 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 75 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 76 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 77 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 78 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 79 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 80 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -46.535560607910156
Agent0_Eval_StdReturn : 25.159366607666016
Agent0_Eval_MaxReturn : -11.653223037719727
Agent0_Eval_MinReturn : -90.28951263427734
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -40.01864242553711
Agent0_Train_StdReturn : 28.385848999023438
Agent0_Train_MaxReturn : 11.192251205444336
Agent0_Train_MinReturn : -88.26837158203125
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 121500
Agent0_TimeSinceStart : 187.29302835464478
Agent0_Critic_Loss : 0.6846010684967041
Agent0_Actor_Loss : -0.34281080961227417
Agent0_Alpha_Loss : 0.9498342275619507
Agent0_Temperature : 0.09760917218115531
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -48.200958251953125
Agent1_Eval_StdReturn : 32.52839660644531
Agent1_Eval_MaxReturn : 24.125471115112305
Agent1_Eval_MinReturn : -90.93499755859375
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -38.05046463012695
Agent1_Train_StdReturn : 45.174129486083984
Agent1_Train_MaxReturn : 38.078704833984375
Agent1_Train_MinReturn : -111.46526336669922
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 121500
Agent1_TimeSinceStart : 189.38542652130127
Agent1_Critic_Loss : 0.6823450326919556
Agent1_Actor_Loss : 0.03958332538604736
Agent1_Alpha_Loss : 0.957974910736084
Agent1_Temperature : 0.09760582454783548
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 81 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 82 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 83 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 84 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 85 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 86 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 87 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 88 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 89 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 90 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -26.2997989654541
Agent0_Eval_StdReturn : 35.797889709472656
Agent0_Eval_MaxReturn : 36.60936737060547
Agent0_Eval_MinReturn : -87.75505065917969
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -33.20391082763672
Agent0_Train_StdReturn : 25.8931941986084
Agent0_Train_MaxReturn : 26.59331703186035
Agent0_Train_MinReturn : -81.05390930175781
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 136500
Agent0_TimeSinceStart : 210.49308371543884
Agent0_Critic_Loss : 0.6162702441215515
Agent0_Actor_Loss : -0.37043455243110657
Agent0_Alpha_Loss : 0.9322619438171387
Agent0_Temperature : 0.09732399516881121
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -33.15895462036133
Agent1_Eval_StdReturn : 32.013511657714844
Agent1_Eval_MaxReturn : 21.001720428466797
Agent1_Eval_MinReturn : -94.75765228271484
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -32.57930374145508
Agent1_Train_StdReturn : 25.570327758789062
Agent1_Train_MaxReturn : 11.077840805053711
Agent1_Train_MinReturn : -80.29247283935547
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 136500
Agent1_TimeSinceStart : 212.58785009384155
Agent1_Critic_Loss : 0.6030055284500122
Agent1_Actor_Loss : 0.059834860265254974
Agent1_Alpha_Loss : 0.9546220302581787
Agent1_Temperature : 0.09731853680401181
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 91 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 92 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 93 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 94 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 95 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 96 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 97 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 98 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 99 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 100 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -32.54588317871094
Agent0_Eval_StdReturn : 26.17376136779785
Agent0_Eval_MaxReturn : 20.190052032470703
Agent0_Eval_MinReturn : -74.23970031738281
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -20.3362979888916
Agent0_Train_StdReturn : 25.445512771606445
Agent0_Train_MaxReturn : 18.79270362854004
Agent0_Train_MinReturn : -56.79393768310547
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 151500
Agent0_TimeSinceStart : 233.6664261817932
Agent0_Critic_Loss : 0.5349953174591064
Agent0_Actor_Loss : -0.37633293867111206
Agent0_Alpha_Loss : 0.9019771814346313
Agent0_Temperature : 0.09704339595792376
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -28.16941261291504
Agent1_Eval_StdReturn : 29.65373992919922
Agent1_Eval_MaxReturn : 10.87875747680664
Agent1_Eval_MinReturn : -92.67546844482422
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -28.17079734802246
Agent1_Train_StdReturn : 19.209125518798828
Agent1_Train_MaxReturn : 1.4314866065979004
Agent1_Train_MinReturn : -66.57472229003906
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 151500
Agent1_TimeSinceStart : 235.75348210334778
Agent1_Critic_Loss : 0.6522010564804077
Agent1_Actor_Loss : -0.06463900208473206
Agent1_Alpha_Loss : 0.9223763942718506
Agent1_Temperature : 0.09703435393732855
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 101 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 102 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 103 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 104 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 105 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 106 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 107 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 108 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 109 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 110 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -41.8949089050293
Agent0_Eval_StdReturn : 20.632875442504883
Agent0_Eval_MaxReturn : 6.652735710144043
Agent0_Eval_MinReturn : -63.7716178894043
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -27.492855072021484
Agent0_Train_StdReturn : 23.141191482543945
Agent0_Train_MaxReturn : 3.9562740325927734
Agent0_Train_MinReturn : -86.86012268066406
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 166500
Agent0_TimeSinceStart : 256.8674473762512
Agent0_Critic_Loss : 0.5533468723297119
Agent0_Actor_Loss : -0.43884915113449097
Agent0_Alpha_Loss : 0.8411198854446411
Agent0_Temperature : 0.09677065082435325
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -23.564863204956055
Agent1_Eval_StdReturn : 19.117698669433594
Agent1_Eval_MaxReturn : 7.52362060546875
Agent1_Eval_MinReturn : -50.793495178222656
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -29.694982528686523
Agent1_Train_StdReturn : 25.119220733642578
Agent1_Train_MaxReturn : 11.241618156433105
Agent1_Train_MinReturn : -74.32875061035156
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 166500
Agent1_TimeSinceStart : 258.97011637687683
Agent1_Critic_Loss : 0.5474246740341187
Agent1_Actor_Loss : -0.10396870970726013
Agent1_Alpha_Loss : 0.8861053586006165
Agent1_Temperature : 0.09675609405572982
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 111 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 112 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 113 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 114 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 115 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 116 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 117 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 118 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 119 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 120 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -27.570098876953125
Agent0_Eval_StdReturn : 13.213493347167969
Agent0_Eval_MaxReturn : -9.823890686035156
Agent0_Eval_MinReturn : -48.929344177246094
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -26.243732452392578
Agent0_Train_StdReturn : 12.191228866577148
Agent0_Train_MaxReturn : -5.909058570861816
Agent0_Train_MinReturn : -48.75049591064453
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 181500
Agent0_TimeSinceStart : 280.1552584171295
Agent0_Critic_Loss : 0.48230960965156555
Agent0_Actor_Loss : -0.4016720652580261
Agent0_Alpha_Loss : 0.809191107749939
Agent0_Temperature : 0.0965083393604723
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -48.78459930419922
Agent1_Eval_StdReturn : 27.321115493774414
Agent1_Eval_MaxReturn : -22.948932647705078
Agent1_Eval_MinReturn : -110.57329559326172
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -32.45620346069336
Agent1_Train_StdReturn : 19.679786682128906
Agent1_Train_MaxReturn : -5.393008232116699
Agent1_Train_MinReturn : -73.28506469726562
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 181500
Agent1_TimeSinceStart : 282.2649636268616
Agent1_Critic_Loss : 0.49000582098960876
Agent1_Actor_Loss : -0.13617900013923645
Agent1_Alpha_Loss : 0.8207705020904541
Agent1_Temperature : 0.09648620177441536
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 121 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 122 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 123 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 124 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 125 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 126 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 127 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 128 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 129 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 130 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -32.98857498168945
Agent0_Eval_StdReturn : 11.275115966796875
Agent0_Eval_MaxReturn : -8.791651725769043
Agent0_Eval_MinReturn : -48.168521881103516
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -40.701656341552734
Agent0_Train_StdReturn : 15.142290115356445
Agent0_Train_MaxReturn : -21.53299331665039
Agent0_Train_MinReturn : -71.17388916015625
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 196500
Agent0_TimeSinceStart : 303.581440448761
Agent0_Critic_Loss : 0.4879344701766968
Agent0_Actor_Loss : -0.4123478829860687
Agent0_Alpha_Loss : 0.7747536301612854
Agent0_Temperature : 0.09625710027719644
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -37.98167037963867
Agent1_Eval_StdReturn : 19.79825782775879
Agent1_Eval_MaxReturn : -2.053316116333008
Agent1_Eval_MinReturn : -69.63638305664062
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -32.75371170043945
Agent1_Train_StdReturn : 22.244144439697266
Agent1_Train_MaxReturn : 1.1825926303863525
Agent1_Train_MinReturn : -77.14942932128906
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 196500
Agent1_TimeSinceStart : 305.69654870033264
Agent1_Critic_Loss : 0.477128803730011
Agent1_Actor_Loss : 0.03936665505170822
Agent1_Alpha_Loss : 0.7934943437576294
Agent1_Temperature : 0.09622794467608081
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 131 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 132 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 133 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 134 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 135 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 136 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 137 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 138 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 139 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 140 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -36.36271667480469
Agent0_Eval_StdReturn : 14.935181617736816
Agent0_Eval_MaxReturn : -15.329572677612305
Agent0_Eval_MinReturn : -59.172698974609375
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -33.507102966308594
Agent0_Train_StdReturn : 13.254313468933105
Agent0_Train_MaxReturn : -8.998392105102539
Agent0_Train_MinReturn : -51.67571258544922
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 211500
Agent0_TimeSinceStart : 327.02790880203247
Agent0_Critic_Loss : 0.46991831064224243
Agent0_Actor_Loss : -0.35456663370132446
Agent0_Alpha_Loss : 0.77944016456604
Agent0_Temperature : 0.0960128860555193
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -22.963146209716797
Agent1_Eval_StdReturn : 16.231163024902344
Agent1_Eval_MaxReturn : 4.109393119812012
Agent1_Eval_MinReturn : -52.54050827026367
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -28.975305557250977
Agent1_Train_StdReturn : 17.890897750854492
Agent1_Train_MaxReturn : -5.952491760253906
Agent1_Train_MinReturn : -60.68084716796875
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 211500
Agent1_TimeSinceStart : 329.1548807621002
Agent1_Critic_Loss : 0.4385906755924225
Agent1_Actor_Loss : 0.05544525012373924
Agent1_Alpha_Loss : 0.8064179420471191
Agent1_Temperature : 0.0959786019101049
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 141 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 142 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 143 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 144 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 145 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 146 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 147 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 148 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 149 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 150 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -31.3426513671875
Agent0_Eval_StdReturn : 8.692630767822266
Agent0_Eval_MaxReturn : -20.02770233154297
Agent0_Eval_MinReturn : -49.509429931640625
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -28.55157470703125
Agent0_Train_StdReturn : 15.307159423828125
Agent0_Train_MaxReturn : -3.3814897537231445
Agent0_Train_MinReturn : -48.48664474487305
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 226500
Agent0_TimeSinceStart : 350.4704887866974
Agent0_Critic_Loss : 0.46846503019332886
Agent0_Actor_Loss : -0.3357259929180145
Agent0_Alpha_Loss : 0.7752708792686462
Agent0_Temperature : 0.09576947842449383
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -18.331518173217773
Agent1_Eval_StdReturn : 6.061790943145752
Agent1_Eval_MaxReturn : -7.964740753173828
Agent1_Eval_MinReturn : -28.572200775146484
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -32.25900650024414
Agent1_Train_StdReturn : 12.099278450012207
Agent1_Train_MaxReturn : -12.834224700927734
Agent1_Train_MinReturn : -54.613380432128906
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 226500
Agent1_TimeSinceStart : 352.584281206131
Agent1_Critic_Loss : 0.43397966027259827
Agent1_Actor_Loss : -0.03180159628391266
Agent1_Alpha_Loss : 0.7954952120780945
Agent1_Temperature : 0.09573229935590832
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 151 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 152 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 153 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 154 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 155 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 156 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 157 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 158 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 159 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 160 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -30.548202514648438
Agent0_Eval_StdReturn : 12.734803199768066
Agent0_Eval_MaxReturn : -15.419736862182617
Agent0_Eval_MinReturn : -58.403751373291016
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -23.967941284179688
Agent0_Train_StdReturn : 15.071532249450684
Agent0_Train_MaxReturn : -1.3997673988342285
Agent0_Train_MinReturn : -50.997501373291016
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 241500
Agent0_TimeSinceStart : 373.86464381217957
Agent0_Critic_Loss : 0.41614052653312683
Agent0_Actor_Loss : -0.2897566258907318
Agent0_Alpha_Loss : 0.7953786253929138
Agent0_Temperature : 0.0955244341741128
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -23.507083892822266
Agent1_Eval_StdReturn : 11.068917274475098
Agent1_Eval_MaxReturn : -6.981714725494385
Agent1_Eval_MinReturn : -42.3902473449707
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -26.260217666625977
Agent1_Train_StdReturn : 16.516414642333984
Agent1_Train_MaxReturn : 4.073271751403809
Agent1_Train_MinReturn : -56.79541778564453
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 241500
Agent1_TimeSinceStart : 375.9725935459137
Agent1_Critic_Loss : 0.35822057723999023
Agent1_Actor_Loss : -0.06610002368688583
Agent1_Alpha_Loss : 0.8290121555328369
Agent1_Temperature : 0.09548399070602795
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 161 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 162 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 163 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 164 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 165 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 166 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 167 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 168 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 169 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 170 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -26.205780029296875
Agent0_Eval_StdReturn : 13.87695598602295
Agent0_Eval_MaxReturn : 1.2036323547363281
Agent0_Eval_MinReturn : -52.26986312866211
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -24.766544342041016
Agent0_Train_StdReturn : 11.715262413024902
Agent0_Train_MaxReturn : -4.548340797424316
Agent0_Train_MinReturn : -39.30619812011719
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 256500
Agent0_TimeSinceStart : 397.243616104126
Agent0_Critic_Loss : 0.3114953339099884
Agent0_Actor_Loss : -0.1311926245689392
Agent0_Alpha_Loss : 0.7947730422019958
Agent0_Temperature : 0.09527654023738605
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -21.16300392150879
Agent1_Eval_StdReturn : 14.51706600189209
Agent1_Eval_MaxReturn : -5.2939934730529785
Agent1_Eval_MinReturn : -47.1790657043457
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -21.76300621032715
Agent1_Train_StdReturn : 20.32245635986328
Agent1_Train_MaxReturn : 6.596861839294434
Agent1_Train_MinReturn : -56.472999572753906
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 256500
Agent1_TimeSinceStart : 399.35952138900757
Agent1_Critic_Loss : 0.31612518429756165
Agent1_Actor_Loss : -0.14028048515319824
Agent1_Alpha_Loss : 0.809934139251709
Agent1_Temperature : 0.0952324190331251
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 171 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 172 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 173 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 174 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 175 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 176 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 177 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 178 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 179 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 180 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -28.6776065826416
Agent0_Eval_StdReturn : 11.941976547241211
Agent0_Eval_MaxReturn : -10.637049674987793
Agent0_Eval_MinReturn : -47.367767333984375
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -25.85384750366211
Agent0_Train_StdReturn : 9.34072208404541
Agent0_Train_MaxReturn : -10.494108200073242
Agent0_Train_MinReturn : -40.63505172729492
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 271500
Agent0_TimeSinceStart : 420.5893323421478
Agent0_Critic_Loss : 0.38779836893081665
Agent0_Actor_Loss : -0.2635008692741394
Agent0_Alpha_Loss : 0.7810159921646118
Agent0_Temperature : 0.0950268261870667
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -20.983333587646484
Agent1_Eval_StdReturn : 14.447063446044922
Agent1_Eval_MaxReturn : -1.5479145050048828
Agent1_Eval_MinReturn : -48.12593078613281
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -16.39459228515625
Agent1_Train_StdReturn : 13.839784622192383
Agent1_Train_MaxReturn : 8.691164016723633
Agent1_Train_MinReturn : -33.12506103515625
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 271500
Agent1_TimeSinceStart : 422.6772229671478
Agent1_Critic_Loss : 0.3358399271965027
Agent1_Actor_Loss : -0.0879380851984024
Agent1_Alpha_Loss : 0.8124933242797852
Agent1_Temperature : 0.09497831592945266
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 181 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 182 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 183 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 184 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 185 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 186 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 187 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 188 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 189 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 190 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -27.704742431640625
Agent0_Eval_StdReturn : 6.133389472961426
Agent0_Eval_MaxReturn : -17.83596420288086
Agent0_Eval_MinReturn : -41.46435546875
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -30.917871475219727
Agent0_Train_StdReturn : 11.456652641296387
Agent0_Train_MaxReturn : -17.340877532958984
Agent0_Train_MinReturn : -53.38043212890625
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 286500
Agent0_TimeSinceStart : 443.8826582431793
Agent0_Critic_Loss : 0.27266883850097656
Agent0_Actor_Loss : -0.27502721548080444
Agent0_Alpha_Loss : 0.7754626274108887
Agent0_Temperature : 0.094777055016841
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -22.89041519165039
Agent1_Eval_StdReturn : 11.930447578430176
Agent1_Eval_MaxReturn : -7.328309535980225
Agent1_Eval_MinReturn : -40.76282501220703
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -24.290311813354492
Agent1_Train_StdReturn : 13.965237617492676
Agent1_Train_MaxReturn : -4.195896148681641
Agent1_Train_MinReturn : -51.5640754699707
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 286500
Agent1_TimeSinceStart : 445.9958071708679
Agent1_Critic_Loss : 0.31877005100250244
Agent1_Actor_Loss : -0.06715042144060135
Agent1_Alpha_Loss : 0.8001886606216431
Agent1_Temperature : 0.09472304877809262
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 191 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 192 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 193 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 194 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 195 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 196 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 197 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 198 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 199 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 200 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -28.4744815826416
Agent0_Eval_StdReturn : 15.483674049377441
Agent0_Eval_MaxReturn : -4.623570442199707
Agent0_Eval_MinReturn : -62.750328063964844
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -25.149730682373047
Agent0_Train_StdReturn : 8.137328147888184
Agent0_Train_MaxReturn : -11.360007286071777
Agent0_Train_MinReturn : -44.537052154541016
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 301500
Agent0_TimeSinceStart : 467.3106806278229
Agent0_Critic_Loss : 0.23010575771331787
Agent0_Actor_Loss : -0.19421909749507904
Agent0_Alpha_Loss : 0.7852541208267212
Agent0_Temperature : 0.09452790572199608
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -16.067272186279297
Agent1_Eval_StdReturn : 8.341438293457031
Agent1_Eval_MaxReturn : 1.9450883865356445
Agent1_Eval_MinReturn : -29.176910400390625
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -16.650463104248047
Agent1_Train_StdReturn : 20.8718318939209
Agent1_Train_MaxReturn : 11.54283618927002
Agent1_Train_MinReturn : -59.56474304199219
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 301500
Agent1_TimeSinceStart : 469.42014360427856
Agent1_Critic_Loss : 0.28266656398773193
Agent1_Actor_Loss : -0.018336310982704163
Agent1_Alpha_Loss : 0.8142626285552979
Agent1_Temperature : 0.09446774309217748
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 201 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 202 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 203 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 204 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 205 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 206 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 207 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 208 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 209 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 210 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -24.828065872192383
Agent0_Eval_StdReturn : 6.464532852172852
Agent0_Eval_MaxReturn : -12.270377159118652
Agent0_Eval_MinReturn : -33.55912399291992
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -24.371681213378906
Agent0_Train_StdReturn : 9.25837516784668
Agent0_Train_MaxReturn : -11.369815826416016
Agent0_Train_MinReturn : -43.04442596435547
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 316500
Agent0_TimeSinceStart : 490.6734969615936
Agent0_Critic_Loss : 0.2205672711133957
Agent0_Actor_Loss : -0.21951496601104736
Agent0_Alpha_Loss : 0.7524834871292114
Agent0_Temperature : 0.0942784161974241
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -28.4191951751709
Agent1_Eval_StdReturn : 11.436695098876953
Agent1_Eval_MaxReturn : -7.969677448272705
Agent1_Eval_MinReturn : -44.60630798339844
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -22.08895492553711
Agent1_Train_StdReturn : 19.44078826904297
Agent1_Train_MaxReturn : 7.819694519042969
Agent1_Train_MinReturn : -51.845298767089844
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 316500
Agent1_TimeSinceStart : 492.7765598297119
Agent1_Critic_Loss : 0.2301420420408249
Agent1_Actor_Loss : 0.013066448271274567
Agent1_Alpha_Loss : 0.8098090887069702
Agent1_Temperature : 0.09421099490926622
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 211 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 212 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 213 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 214 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 215 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 216 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 217 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 218 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 219 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 220 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -19.938907623291016
Agent0_Eval_StdReturn : 8.971125602722168
Agent0_Eval_MaxReturn : -0.4272308349609375
Agent0_Eval_MinReturn : -35.50375747680664
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -15.952751159667969
Agent0_Train_StdReturn : 10.028777122497559
Agent0_Train_MaxReturn : -1.1564254760742188
Agent0_Train_MinReturn : -31.177433013916016
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 331500
Agent0_TimeSinceStart : 514.107013463974
Agent0_Critic_Loss : 0.2266668677330017
Agent0_Actor_Loss : -0.2399122416973114
Agent0_Alpha_Loss : 0.7630118131637573
Agent0_Temperature : 0.0940288845141834
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -13.265416145324707
Agent1_Eval_StdReturn : 11.734565734863281
Agent1_Eval_MaxReturn : 5.59498405456543
Agent1_Eval_MinReturn : -36.31139373779297
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -4.280552864074707
Agent1_Train_StdReturn : 11.226252555847168
Agent1_Train_MaxReturn : 15.204623222351074
Agent1_Train_MinReturn : -20.028390884399414
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 331500
Agent1_TimeSinceStart : 516.2151613235474
Agent1_Critic_Loss : 0.2965044677257538
Agent1_Actor_Loss : 0.021664131432771683
Agent1_Alpha_Loss : 0.7885724902153015
Agent1_Temperature : 0.09395306461611569
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 221 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 222 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 223 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 224 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 225 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 226 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 227 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 228 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 229 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 230 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -22.871715545654297
Agent0_Eval_StdReturn : 9.843483924865723
Agent0_Eval_MaxReturn : -8.168472290039062
Agent0_Eval_MinReturn : -37.1245231628418
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -17.830745697021484
Agent0_Train_StdReturn : 13.930512428283691
Agent0_Train_MaxReturn : 9.620070457458496
Agent0_Train_MinReturn : -39.15667724609375
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 346500
Agent0_TimeSinceStart : 537.5018737316132
Agent0_Critic_Loss : 0.22611361742019653
Agent0_Actor_Loss : -0.14014193415641785
Agent0_Alpha_Loss : 0.7548304796218872
Agent0_Temperature : 0.09377875831740197
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -15.1757173538208
Agent1_Eval_StdReturn : 17.63539695739746
Agent1_Eval_MaxReturn : 11.128210067749023
Agent1_Eval_MinReturn : -54.54109573364258
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -9.169641494750977
Agent1_Train_StdReturn : 11.76756477355957
Agent1_Train_MaxReturn : 18.83864974975586
Agent1_Train_MinReturn : -21.149906158447266
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 346500
Agent1_TimeSinceStart : 539.6075029373169
Agent1_Critic_Loss : 0.24908441305160522
Agent1_Actor_Loss : 0.0367417186498642
Agent1_Alpha_Loss : 0.8172781467437744
Agent1_Temperature : 0.09369520767639941
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 231 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 232 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 233 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 234 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 235 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 236 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 237 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 238 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 239 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 240 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -16.542320251464844
Agent0_Eval_StdReturn : 6.584968090057373
Agent0_Eval_MaxReturn : -3.1291112899780273
Agent0_Eval_MinReturn : -26.451810836791992
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -19.705595016479492
Agent0_Train_StdReturn : 10.097235679626465
Agent0_Train_MaxReturn : -2.045969009399414
Agent0_Train_MinReturn : -42.24894714355469
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 361500
Agent0_TimeSinceStart : 560.8170092105865
Agent0_Critic_Loss : 0.23427844047546387
Agent0_Actor_Loss : -0.21706154942512512
Agent0_Alpha_Loss : 0.7964869737625122
Agent0_Temperature : 0.09352750196501321
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -19.855192184448242
Agent1_Eval_StdReturn : 6.013306617736816
Agent1_Eval_MaxReturn : -9.039324760437012
Agent1_Eval_MinReturn : -28.584299087524414
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -23.188194274902344
Agent1_Train_StdReturn : 12.048967361450195
Agent1_Train_MaxReturn : -9.869840621948242
Agent1_Train_MinReturn : -53.31550598144531
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 361500
Agent1_TimeSinceStart : 562.919408082962
Agent1_Critic_Loss : 0.24322254955768585
Agent1_Actor_Loss : -0.01579008437693119
Agent1_Alpha_Loss : 0.8114443421363831
Agent1_Temperature : 0.0934375204642985
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 241 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 242 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 243 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 244 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 245 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 246 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 247 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 248 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 249 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 250 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -27.384601593017578
Agent0_Eval_StdReturn : 21.625295639038086
Agent0_Eval_MaxReturn : 2.6158628463745117
Agent0_Eval_MinReturn : -83.16061401367188
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -22.35968589782715
Agent0_Train_StdReturn : 19.58365249633789
Agent0_Train_MaxReturn : -8.597174644470215
Agent0_Train_MinReturn : -77.466796875
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 376500
Agent0_TimeSinceStart : 584.1551373004913
Agent0_Critic_Loss : 0.2839357554912567
Agent0_Actor_Loss : -0.28554660081863403
Agent0_Alpha_Loss : 0.7890150547027588
Agent0_Temperature : 0.0932739872730477
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -15.431367874145508
Agent1_Eval_StdReturn : 17.4412899017334
Agent1_Eval_MaxReturn : 7.465216159820557
Agent1_Eval_MinReturn : -48.658573150634766
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -18.280115127563477
Agent1_Train_StdReturn : 9.936531066894531
Agent1_Train_MaxReturn : -1.2995610237121582
Agent1_Train_MinReturn : -39.378944396972656
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 376500
Agent1_TimeSinceStart : 586.2585062980652
Agent1_Critic_Loss : 0.26116976141929626
Agent1_Actor_Loss : 0.0644494891166687
Agent1_Alpha_Loss : 0.8224153518676758
Agent1_Temperature : 0.09317954347207906
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 251 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 252 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 253 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 254 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 255 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 256 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 257 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 258 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 259 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 260 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -23.984066009521484
Agent0_Eval_StdReturn : 23.103055953979492
Agent0_Eval_MaxReturn : 23.832000732421875
Agent0_Eval_MinReturn : -57.071372985839844
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -22.171823501586914
Agent0_Train_StdReturn : 17.046451568603516
Agent0_Train_MaxReturn : -0.32157981395721436
Agent0_Train_MinReturn : -57.48383331298828
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 391500
Agent0_TimeSinceStart : 607.4244029521942
Agent0_Critic_Loss : 0.20675666630268097
Agent0_Actor_Loss : -0.1844896823167801
Agent0_Alpha_Loss : 0.7911408543586731
Agent0_Temperature : 0.09301995458501285
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -18.613372802734375
Agent1_Eval_StdReturn : 10.9263916015625
Agent1_Eval_MaxReturn : -0.1779499053955078
Agent1_Eval_MinReturn : -36.07767868041992
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -5.419105529785156
Agent1_Train_StdReturn : 14.965486526489258
Agent1_Train_MaxReturn : 14.272102355957031
Agent1_Train_MinReturn : -33.75798416137695
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 391500
Agent1_TimeSinceStart : 609.5430603027344
Agent1_Critic_Loss : 0.2901175022125244
Agent1_Actor_Loss : -0.07645171135663986
Agent1_Alpha_Loss : 0.8206621408462524
Agent1_Temperature : 0.09292089658274161
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 261 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 262 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 263 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 264 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 265 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 266 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 267 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 268 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 269 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 270 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -13.085336685180664
Agent0_Eval_StdReturn : 12.241267204284668
Agent0_Eval_MaxReturn : 3.890742063522339
Agent0_Eval_MinReturn : -34.55779266357422
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -9.31557846069336
Agent0_Train_StdReturn : 16.772979736328125
Agent0_Train_MaxReturn : 33.14458465576172
Agent0_Train_MinReturn : -30.77255630493164
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 406500
Agent0_TimeSinceStart : 630.7465074062347
Agent0_Critic_Loss : 0.30007418990135193
Agent0_Actor_Loss : -0.17874616384506226
Agent0_Alpha_Loss : 0.7988882064819336
Agent0_Temperature : 0.09276211393162154
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -6.3948469161987305
Agent1_Eval_StdReturn : 16.596435546875
Agent1_Eval_MaxReturn : 11.337446212768555
Agent1_Eval_MinReturn : -47.39286804199219
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -12.551373481750488
Agent1_Train_StdReturn : 21.356861114501953
Agent1_Train_MaxReturn : 25.280139923095703
Agent1_Train_MinReturn : -57.045406341552734
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 406500
Agent1_TimeSinceStart : 632.8608484268188
Agent1_Critic_Loss : 0.35180723667144775
Agent1_Actor_Loss : -0.12107343971729279
Agent1_Alpha_Loss : 0.8149210214614868
Agent1_Temperature : 0.09266167865062676
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 271 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 272 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 273 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 274 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 275 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 276 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 277 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 278 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 279 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 280 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -1.9952356815338135
Agent0_Eval_StdReturn : 13.582161903381348
Agent0_Eval_MaxReturn : 17.22352409362793
Agent0_Eval_MinReturn : -31.328243255615234
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -23.605701446533203
Agent0_Train_StdReturn : 11.681439399719238
Agent0_Train_MaxReturn : -4.635648727416992
Agent0_Train_MinReturn : -47.93121337890625
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 421500
Agent0_TimeSinceStart : 654.0737247467041
Agent0_Critic_Loss : 0.2630021274089813
Agent0_Actor_Loss : -0.2983100414276123
Agent0_Alpha_Loss : 0.7856968641281128
Agent0_Temperature : 0.09250322914058574
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -21.865652084350586
Agent1_Eval_StdReturn : 15.00997543334961
Agent1_Eval_MaxReturn : 2.7839808464050293
Agent1_Eval_MinReturn : -45.33420181274414
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -15.564358711242676
Agent1_Train_StdReturn : 13.039388656616211
Agent1_Train_MaxReturn : 16.012046813964844
Agent1_Train_MinReturn : -32.78057861328125
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 421500
Agent1_TimeSinceStart : 656.1754727363586
Agent1_Critic_Loss : 0.32552143931388855
Agent1_Actor_Loss : -0.10795213282108307
Agent1_Alpha_Loss : 0.8332561254501343
Agent1_Temperature : 0.09240129679111114
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 281 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 282 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 283 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 284 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 285 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 286 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 287 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 288 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 289 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 290 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -26.596332550048828
Agent0_Eval_StdReturn : 13.851470947265625
Agent0_Eval_MaxReturn : -6.095996856689453
Agent0_Eval_MinReturn : -59.412872314453125
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -21.473407745361328
Agent0_Train_StdReturn : 15.383301734924316
Agent0_Train_MaxReturn : 0.8339176177978516
Agent0_Train_MinReturn : -56.97654724121094
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 436500
Agent0_TimeSinceStart : 677.4731242656708
Agent0_Critic_Loss : 0.2593207359313965
Agent0_Actor_Loss : -0.2598298490047455
Agent0_Alpha_Loss : 0.7886120080947876
Agent0_Temperature : 0.09224516081654709
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -19.129980087280273
Agent1_Eval_StdReturn : 26.781070709228516
Agent1_Eval_MaxReturn : 9.691939353942871
Agent1_Eval_MinReturn : -89.31119537353516
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -14.201725959777832
Agent1_Train_StdReturn : 12.875149726867676
Agent1_Train_MaxReturn : 5.115916728973389
Agent1_Train_MinReturn : -40.06022262573242
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 436500
Agent1_TimeSinceStart : 679.5914881229401
Agent1_Critic_Loss : 0.28163427114486694
Agent1_Actor_Loss : -0.10603305697441101
Agent1_Alpha_Loss : 0.824164092540741
Agent1_Temperature : 0.09214064157115368
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 291 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 292 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 293 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 294 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 295 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 296 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 297 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 298 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 299 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 300 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -16.92030143737793
Agent0_Eval_StdReturn : 14.809134483337402
Agent0_Eval_MaxReturn : 8.663846015930176
Agent0_Eval_MinReturn : -40.504493713378906
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -22.249780654907227
Agent0_Train_StdReturn : 18.246158599853516
Agent0_Train_MaxReturn : 2.8953466415405273
Agent0_Train_MinReturn : -60.667842864990234
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 451500
Agent0_TimeSinceStart : 700.8514311313629
Agent0_Critic_Loss : 0.2925618588924408
Agent0_Actor_Loss : -0.2727451026439667
Agent0_Alpha_Loss : 0.7947978973388672
Agent0_Temperature : 0.09198821882491945
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -11.392133712768555
Agent1_Eval_StdReturn : 14.328897476196289
Agent1_Eval_MaxReturn : 12.43787956237793
Agent1_Eval_MinReturn : -32.897071838378906
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -12.049185752868652
Agent1_Train_StdReturn : 21.792695999145508
Agent1_Train_MaxReturn : 20.924072265625
Agent1_Train_MinReturn : -64.00979614257812
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 451500
Agent1_TimeSinceStart : 702.9590890407562
Agent1_Critic_Loss : 0.28783896565437317
Agent1_Actor_Loss : -0.1591222733259201
Agent1_Alpha_Loss : 0.8249428272247314
Agent1_Temperature : 0.09187982988860717
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 301 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 302 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 303 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 304 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 305 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 306 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 307 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 308 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 309 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 310 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -28.07901954650879
Agent0_Eval_StdReturn : 18.43355941772461
Agent0_Eval_MaxReturn : 1.0215749740600586
Agent0_Eval_MinReturn : -61.30522918701172
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -6.66571044921875
Agent0_Train_StdReturn : 18.918079376220703
Agent0_Train_MaxReturn : 27.979110717773438
Agent0_Train_MinReturn : -37.12156677246094
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 466500
Agent0_TimeSinceStart : 724.1493508815765
Agent0_Critic_Loss : 0.31635424494743347
Agent0_Actor_Loss : -0.23907718062400818
Agent0_Alpha_Loss : 0.7901480793952942
Agent0_Temperature : 0.09173108467166803
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -19.271183013916016
Agent1_Eval_StdReturn : 23.801822662353516
Agent1_Eval_MaxReturn : 12.265892028808594
Agent1_Eval_MinReturn : -72.00736999511719
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -14.795358657836914
Agent1_Train_StdReturn : 11.809982299804688
Agent1_Train_MaxReturn : 7.654504776000977
Agent1_Train_MinReturn : -35.571327209472656
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 466500
Agent1_TimeSinceStart : 726.2549486160278
Agent1_Critic_Loss : 0.33517059683799744
Agent1_Actor_Loss : -0.08898176997900009
Agent1_Alpha_Loss : 0.8114942312240601
Agent1_Temperature : 0.09161894468723505
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 311 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 312 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 313 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 314 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 315 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 316 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 317 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 318 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 319 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 320 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -29.980487823486328
Agent0_Eval_StdReturn : 19.31409454345703
Agent0_Eval_MaxReturn : 15.059431076049805
Agent0_Eval_MinReturn : -53.632633209228516
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -18.04693603515625
Agent0_Train_StdReturn : 14.720527648925781
Agent0_Train_MaxReturn : -0.5723843574523926
Agent0_Train_MinReturn : -50.779571533203125
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 481500
Agent0_TimeSinceStart : 747.4345951080322
Agent0_Critic_Loss : 0.2734473943710327
Agent0_Actor_Loss : -0.2669808268547058
Agent0_Alpha_Loss : 0.8077622652053833
Agent0_Temperature : 0.09147302933209255
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -4.489755153656006
Agent1_Eval_StdReturn : 29.803943634033203
Agent1_Eval_MaxReturn : 52.535499572753906
Agent1_Eval_MinReturn : -71.47242736816406
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -20.998937606811523
Agent1_Train_StdReturn : 19.29739761352539
Agent1_Train_MaxReturn : 5.41263484954834
Agent1_Train_MinReturn : -53.21904373168945
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 481500
Agent1_TimeSinceStart : 749.5380868911743
Agent1_Critic_Loss : 0.37066730856895447
Agent1_Actor_Loss : -0.1662769615650177
Agent1_Alpha_Loss : 0.8150666952133179
Agent1_Temperature : 0.09135987021599193
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 321 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 322 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 323 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 324 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 325 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 326 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 327 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 328 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 329 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 330 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -14.719919204711914
Agent0_Eval_StdReturn : 8.066990852355957
Agent0_Eval_MaxReturn : -4.329524517059326
Agent0_Eval_MinReturn : -32.3128547668457
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -24.169048309326172
Agent0_Train_StdReturn : 16.99822998046875
Agent0_Train_MaxReturn : 5.773421764373779
Agent0_Train_MinReturn : -51.692909240722656
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 496500
Agent0_TimeSinceStart : 770.683522939682
Agent0_Critic_Loss : 0.30190861225128174
Agent0_Actor_Loss : -0.2740527391433716
Agent0_Alpha_Loss : 0.7941569089889526
Agent0_Temperature : 0.09121528643452537
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -23.945371627807617
Agent1_Eval_StdReturn : 16.3917293548584
Agent1_Eval_MaxReturn : 0.25577545166015625
Agent1_Eval_MinReturn : -50.42842483520508
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -21.017017364501953
Agent1_Train_StdReturn : 13.408924102783203
Agent1_Train_MaxReturn : 4.298978805541992
Agent1_Train_MinReturn : -43.10932922363281
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 496500
Agent1_TimeSinceStart : 772.79447889328
Agent1_Critic_Loss : 0.32782530784606934
Agent1_Actor_Loss : -0.11966472864151001
Agent1_Alpha_Loss : 0.8087202310562134
Agent1_Temperature : 0.09110112501182552
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 331 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 332 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 333 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 334 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 335 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 336 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 337 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 338 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 339 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 340 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -23.38605308532715
Agent0_Eval_StdReturn : 14.881680488586426
Agent0_Eval_MaxReturn : 0.2011081576347351
Agent0_Eval_MinReturn : -47.50599670410156
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -18.49243927001953
Agent0_Train_StdReturn : 29.439172744750977
Agent0_Train_MaxReturn : 49.61968994140625
Agent0_Train_MinReturn : -56.73257064819336
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 511500
Agent0_TimeSinceStart : 794.0065112113953
Agent0_Critic_Loss : 0.29101741313934326
Agent0_Actor_Loss : -0.3148405849933624
Agent0_Alpha_Loss : 0.7984833121299744
Agent0_Temperature : 0.09095743029262426
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -17.304027557373047
Agent1_Eval_StdReturn : 11.807968139648438
Agent1_Eval_MaxReturn : 0.014960289001464844
Agent1_Eval_MinReturn : -35.35184097290039
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -24.381298065185547
Agent1_Train_StdReturn : 20.77713394165039
Agent1_Train_MaxReturn : 3.6400442123413086
Agent1_Train_MinReturn : -55.280418395996094
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 511500
Agent1_TimeSinceStart : 796.1150214672089
Agent1_Critic_Loss : 0.3074324131011963
Agent1_Actor_Loss : -0.0594092532992363
Agent1_Alpha_Loss : 0.8102222084999084
Agent1_Temperature : 0.09084284010689597
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 341 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 342 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 343 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 344 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 345 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 346 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 347 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 348 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 349 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 350 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -24.643966674804688
Agent0_Eval_StdReturn : 15.95176887512207
Agent0_Eval_MaxReturn : 7.309294700622559
Agent0_Eval_MinReturn : -54.09657669067383
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -23.0831356048584
Agent0_Train_StdReturn : 26.167984008789062
Agent0_Train_MaxReturn : 12.856633186340332
Agent0_Train_MinReturn : -62.0534782409668
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 526500
Agent0_TimeSinceStart : 817.3048624992371
Agent0_Critic_Loss : 0.35367539525032043
Agent0_Actor_Loss : -0.3478567600250244
Agent0_Alpha_Loss : 0.7929564714431763
Agent0_Temperature : 0.09069958766852491
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -23.357059478759766
Agent1_Eval_StdReturn : 22.95536994934082
Agent1_Eval_MaxReturn : 12.39152717590332
Agent1_Eval_MinReturn : -55.9691162109375
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -24.911806106567383
Agent1_Train_StdReturn : 21.261703491210938
Agent1_Train_MaxReturn : 3.8394527435302734
Agent1_Train_MinReturn : -52.26373291015625
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 526500
Agent1_TimeSinceStart : 819.4006552696228
Agent1_Critic_Loss : 0.33226722478866577
Agent1_Actor_Loss : -0.13545392453670502
Agent1_Alpha_Loss : 0.8032185435295105
Agent1_Temperature : 0.09058518208042932
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 351 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 352 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 353 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 354 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 355 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 356 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 357 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 358 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 359 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 360 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -15.774847030639648
Agent0_Eval_StdReturn : 17.439035415649414
Agent0_Eval_MaxReturn : 14.913993835449219
Agent0_Eval_MinReturn : -45.10277557373047
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -23.15337371826172
Agent0_Train_StdReturn : 20.949440002441406
Agent0_Train_MaxReturn : 15.180313110351562
Agent0_Train_MinReturn : -56.005428314208984
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 541500
Agent0_TimeSinceStart : 840.5279383659363
Agent0_Critic_Loss : 0.31033673882484436
Agent0_Actor_Loss : -0.38021039962768555
Agent0_Alpha_Loss : 0.7891196012496948
Agent0_Temperature : 0.09044228515859551
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -27.382471084594727
Agent1_Eval_StdReturn : 26.45640754699707
Agent1_Eval_MaxReturn : 8.873764038085938
Agent1_Eval_MinReturn : -97.16768646240234
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -22.836462020874023
Agent1_Train_StdReturn : 18.088869094848633
Agent1_Train_MaxReturn : 17.73145866394043
Agent1_Train_MinReturn : -48.80702590942383
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 541500
Agent1_TimeSinceStart : 842.6373295783997
Agent1_Critic_Loss : 0.4651895761489868
Agent1_Actor_Loss : -0.1779313087463379
Agent1_Alpha_Loss : 0.8157267570495605
Agent1_Temperature : 0.09032830205118697
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 361 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 362 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 363 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 364 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 365 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 366 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 367 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 368 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 369 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 370 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -16.286937713623047
Agent0_Eval_StdReturn : 19.09176254272461
Agent0_Eval_MaxReturn : 10.152036666870117
Agent0_Eval_MinReturn : -61.30296325683594
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -15.460949897766113
Agent0_Train_StdReturn : 22.35957908630371
Agent0_Train_MaxReturn : 20.30016326904297
Agent0_Train_MinReturn : -61.63520812988281
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 556500
Agent0_TimeSinceStart : 863.8547184467316
Agent0_Critic_Loss : 0.40860462188720703
Agent0_Actor_Loss : -0.47236669063568115
Agent0_Alpha_Loss : 0.7965111136436462
Agent0_Temperature : 0.09018423313243541
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -17.6735782623291
Agent1_Eval_StdReturn : 15.130288124084473
Agent1_Eval_MaxReturn : 8.375872611999512
Agent1_Eval_MinReturn : -50.738616943359375
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -16.62725257873535
Agent1_Train_StdReturn : 12.410104751586914
Agent1_Train_MaxReturn : 11.384551048278809
Agent1_Train_MinReturn : -37.48064422607422
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 556500
Agent1_TimeSinceStart : 865.9713869094849
Agent1_Critic_Loss : 0.37993955612182617
Agent1_Actor_Loss : -0.14213286340236664
Agent1_Alpha_Loss : 0.8006845712661743
Agent1_Temperature : 0.09007206209121733
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 371 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 372 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 373 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 374 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 375 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 376 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 377 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 378 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 379 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 380 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -25.5506591796875
Agent0_Eval_StdReturn : 23.49104881286621
Agent0_Eval_MaxReturn : -2.2181899547576904
Agent0_Eval_MinReturn : -80.38726806640625
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -29.485727310180664
Agent0_Train_StdReturn : 30.444957733154297
Agent0_Train_MaxReturn : 7.360435485839844
Agent0_Train_MinReturn : -80.83245849609375
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 571500
Agent0_TimeSinceStart : 887.1532354354858
Agent0_Critic_Loss : 0.28706008195877075
Agent0_Actor_Loss : -0.3466387391090393
Agent0_Alpha_Loss : 0.7907993793487549
Agent0_Temperature : 0.08992738897662042
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -14.389528274536133
Agent1_Eval_StdReturn : 17.516992568969727
Agent1_Eval_MaxReturn : 20.805206298828125
Agent1_Eval_MinReturn : -47.842369079589844
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -9.762624740600586
Agent1_Train_StdReturn : 14.872567176818848
Agent1_Train_MaxReturn : 12.454387664794922
Agent1_Train_MinReturn : -32.71530532836914
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 571500
Agent1_TimeSinceStart : 889.2656357288361
Agent1_Critic_Loss : 0.4300702214241028
Agent1_Actor_Loss : -0.09494984894990921
Agent1_Alpha_Loss : 0.8067494034767151
Agent1_Temperature : 0.08981679567345126
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 381 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 382 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 383 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 384 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 385 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 386 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 387 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 388 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 389 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 390 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -17.594383239746094
Agent0_Eval_StdReturn : 12.601723670959473
Agent0_Eval_MaxReturn : -0.582716166973114
Agent0_Eval_MinReturn : -40.10225296020508
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -11.054956436157227
Agent0_Train_StdReturn : 15.77004337310791
Agent0_Train_MaxReturn : 22.14977264404297
Agent0_Train_MinReturn : -35.33652114868164
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 586500
Agent0_TimeSinceStart : 910.4189598560333
Agent0_Critic_Loss : 0.35018229484558105
Agent0_Actor_Loss : -0.37280184030532837
Agent0_Alpha_Loss : 0.8041582703590393
Agent0_Temperature : 0.08967296902390796
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -14.998146057128906
Agent1_Eval_StdReturn : 10.197550773620605
Agent1_Eval_MaxReturn : 4.120727062225342
Agent1_Eval_MinReturn : -33.04319763183594
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -20.374916076660156
Agent1_Train_StdReturn : 9.207856178283691
Agent1_Train_MaxReturn : -4.784899711608887
Agent1_Train_MinReturn : -34.14950180053711
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 586500
Agent1_TimeSinceStart : 912.5296895503998
Agent1_Critic_Loss : 0.39291825890541077
Agent1_Actor_Loss : -0.11854060739278793
Agent1_Alpha_Loss : 0.7819851636886597
Agent1_Temperature : 0.08956362065817698
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 391 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 392 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 393 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 394 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 395 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 396 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 397 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 398 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 399 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 400 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -21.79693603515625
Agent0_Eval_StdReturn : 22.28107261657715
Agent0_Eval_MaxReturn : -0.21512126922607422
Agent0_Eval_MinReturn : -65.4349136352539
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -15.419865608215332
Agent0_Train_StdReturn : 14.228302001953125
Agent0_Train_MaxReturn : 4.42788028717041
Agent0_Train_MinReturn : -45.76262283325195
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 601500
Agent0_TimeSinceStart : 933.6735398769379
Agent0_Critic_Loss : 0.35455626249313354
Agent0_Actor_Loss : -0.40031224489212036
Agent0_Alpha_Loss : 0.786136269569397
Agent0_Temperature : 0.08941938662573413
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -19.07330322265625
Agent1_Eval_StdReturn : 13.383016586303711
Agent1_Eval_MaxReturn : 11.606979370117188
Agent1_Eval_MinReturn : -34.30413055419922
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -14.336690902709961
Agent1_Train_StdReturn : 15.070807456970215
Agent1_Train_MaxReturn : 24.221515655517578
Agent1_Train_MinReturn : -29.578414916992188
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 601500
Agent1_TimeSinceStart : 935.7764203548431
Agent1_Critic_Loss : 0.37637215852737427
Agent1_Actor_Loss : -0.11664341390132904
Agent1_Alpha_Loss : 0.7801339626312256
Agent1_Temperature : 0.08931289142576541
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 401 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 402 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 403 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 404 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 405 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 406 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 407 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 408 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 409 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 410 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -19.354204177856445
Agent0_Eval_StdReturn : 11.452548027038574
Agent0_Eval_MaxReturn : 2.9213643074035645
Agent0_Eval_MinReturn : -39.30219650268555
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -14.736352920532227
Agent0_Train_StdReturn : 9.859938621520996
Agent0_Train_MaxReturn : 0.06463861465454102
Agent0_Train_MinReturn : -35.96315383911133
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 616500
Agent0_TimeSinceStart : 956.9654140472412
Agent0_Critic_Loss : 0.3960312008857727
Agent0_Actor_Loss : -0.3814765512943268
Agent0_Alpha_Loss : 0.800856351852417
Agent0_Temperature : 0.08916680334249244
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -22.73960304260254
Agent1_Eval_StdReturn : 21.511280059814453
Agent1_Eval_MaxReturn : 4.339115142822266
Agent1_Eval_MinReturn : -74.16698455810547
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -5.012192726135254
Agent1_Train_StdReturn : 16.813735961914062
Agent1_Train_MaxReturn : 10.211187362670898
Agent1_Train_MinReturn : -36.512847900390625
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 616500
Agent1_TimeSinceStart : 959.0722694396973
Agent1_Critic_Loss : 0.36181050539016724
Agent1_Actor_Loss : -0.15393222868442535
Agent1_Alpha_Loss : 0.7785362005233765
Agent1_Temperature : 0.08906397841182408
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 411 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 412 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 413 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 414 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 415 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 416 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 417 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 418 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 419 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 420 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -17.12991714477539
Agent0_Eval_StdReturn : 14.3418607711792
Agent0_Eval_MaxReturn : 17.87696647644043
Agent0_Eval_MinReturn : -36.6830940246582
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -23.6605224609375
Agent0_Train_StdReturn : 21.048128128051758
Agent0_Train_MaxReturn : 6.122577667236328
Agent0_Train_MinReturn : -55.40032196044922
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 631500
Agent0_TimeSinceStart : 980.2721745967865
Agent0_Critic_Loss : 0.452019065618515
Agent0_Actor_Loss : -0.3751894235610962
Agent0_Alpha_Loss : 0.775335967540741
Agent0_Temperature : 0.08891411477701062
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -9.40516471862793
Agent1_Eval_StdReturn : 13.872812271118164
Agent1_Eval_MaxReturn : 5.84284782409668
Agent1_Eval_MinReturn : -43.95801544189453
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -15.930132865905762
Agent1_Train_StdReturn : 12.38692855834961
Agent1_Train_MaxReturn : -0.6471614837646484
Agent1_Train_MinReturn : -41.91969299316406
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 631500
Agent1_TimeSinceStart : 982.3779096603394
Agent1_Critic_Loss : 0.3188488483428955
Agent1_Actor_Loss : -0.09943452477455139
Agent1_Alpha_Loss : 0.7995295524597168
Agent1_Temperature : 0.0888156222306893
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 421 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 422 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 423 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 424 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 425 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 426 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 427 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 428 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 429 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 430 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -16.375957489013672
Agent0_Eval_StdReturn : 21.091217041015625
Agent0_Eval_MaxReturn : 5.727961540222168
Agent0_Eval_MinReturn : -64.21701049804688
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -21.37210464477539
Agent0_Train_StdReturn : 16.113615036010742
Agent0_Train_MaxReturn : 13.432544708251953
Agent0_Train_MinReturn : -43.944236755371094
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 646500
Agent0_TimeSinceStart : 1003.5706508159637
Agent0_Critic_Loss : 0.3587280511856079
Agent0_Actor_Loss : -0.4259029030799866
Agent0_Alpha_Loss : 0.7711325883865356
Agent0_Temperature : 0.08866280893811909
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -21.9715518951416
Agent1_Eval_StdReturn : 18.272785186767578
Agent1_Eval_MaxReturn : 21.270977020263672
Agent1_Eval_MinReturn : -39.8387451171875
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -10.90267276763916
Agent1_Train_StdReturn : 15.912890434265137
Agent1_Train_MaxReturn : 4.527536392211914
Agent1_Train_MinReturn : -37.90132141113281
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 646500
Agent1_TimeSinceStart : 1005.6773672103882
Agent1_Critic_Loss : 0.4015122056007385
Agent1_Actor_Loss : -0.2090008556842804
Agent1_Alpha_Loss : 0.7871143221855164
Agent1_Temperature : 0.08856777300379796
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 431 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 432 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 433 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 434 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 435 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 436 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 437 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 438 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 439 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 440 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -13.343961715698242
Agent0_Eval_StdReturn : 18.53800392150879
Agent0_Eval_MaxReturn : 7.837350368499756
Agent0_Eval_MinReturn : -51.05828094482422
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -14.286593437194824
Agent0_Train_StdReturn : 9.065848350524902
Agent0_Train_MaxReturn : 3.707756757736206
Agent0_Train_MinReturn : -24.027952194213867
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 661500
Agent0_TimeSinceStart : 1026.836282491684
Agent0_Critic_Loss : 0.4096243679523468
Agent0_Actor_Loss : -0.37006717920303345
Agent0_Alpha_Loss : 0.7919769883155823
Agent0_Temperature : 0.08841355191304572
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -20.56536293029785
Agent1_Eval_StdReturn : 13.503226280212402
Agent1_Eval_MaxReturn : 2.1690893173217773
Agent1_Eval_MinReturn : -41.01054000854492
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -13.754701614379883
Agent1_Train_StdReturn : 17.77684211730957
Agent1_Train_MaxReturn : 10.566574096679688
Agent1_Train_MinReturn : -39.28204345703125
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 661500
Agent1_TimeSinceStart : 1028.9249811172485
Agent1_Critic_Loss : 0.45457467436790466
Agent1_Actor_Loss : -0.20016226172447205
Agent1_Alpha_Loss : 0.7959712743759155
Agent1_Temperature : 0.08832024768936772
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 441 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 442 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 443 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 444 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 445 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 446 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 447 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 448 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 449 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 450 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -13.2521333694458
Agent0_Eval_StdReturn : 12.425966262817383
Agent0_Eval_MaxReturn : 2.1526451110839844
Agent0_Eval_MinReturn : -31.817049026489258
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -6.591231346130371
Agent0_Train_StdReturn : 13.83887767791748
Agent0_Train_MaxReturn : 15.077897071838379
Agent0_Train_MinReturn : -34.097721099853516
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 676500
Agent0_TimeSinceStart : 1050.1637361049652
Agent0_Critic_Loss : 0.43677783012390137
Agent0_Actor_Loss : -0.34824544191360474
Agent0_Alpha_Loss : 0.7692536115646362
Agent0_Temperature : 0.08816502710024597
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -16.881135940551758
Agent1_Eval_StdReturn : 15.47927474975586
Agent1_Eval_MaxReturn : 8.477757453918457
Agent1_Eval_MinReturn : -48.860877990722656
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -24.102357864379883
Agent1_Train_StdReturn : 14.019134521484375
Agent1_Train_MaxReturn : -9.908151626586914
Agent1_Train_MinReturn : -58.725040435791016
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 676500
Agent1_TimeSinceStart : 1052.2823073863983
Agent1_Critic_Loss : 0.3653922379016876
Agent1_Actor_Loss : -0.22299595177173615
Agent1_Alpha_Loss : 0.7879686951637268
Agent1_Temperature : 0.08807394483226287
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 451 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 452 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 453 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 454 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 455 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 456 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 457 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 458 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 459 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 460 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -9.229146003723145
Agent0_Eval_StdReturn : 9.729609489440918
Agent0_Eval_MaxReturn : 4.502363681793213
Agent0_Eval_MinReturn : -27.881023406982422
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -20.52911949157715
Agent0_Train_StdReturn : 11.026224136352539
Agent0_Train_MaxReturn : 1.1745662689208984
Agent0_Train_MinReturn : -37.1705322265625
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 691500
Agent0_TimeSinceStart : 1073.4969177246094
Agent0_Critic_Loss : 0.3637254238128662
Agent0_Actor_Loss : -0.43039828538894653
Agent0_Alpha_Loss : 0.7792027592658997
Agent0_Temperature : 0.08791657878049663
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -14.994526863098145
Agent1_Eval_StdReturn : 11.80734634399414
Agent1_Eval_MaxReturn : 4.6572265625
Agent1_Eval_MinReturn : -33.754180908203125
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -16.606830596923828
Agent1_Train_StdReturn : 15.886837005615234
Agent1_Train_MaxReturn : 10.370920181274414
Agent1_Train_MinReturn : -42.286338806152344
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 691500
Agent1_TimeSinceStart : 1075.6223936080933
Agent1_Critic_Loss : 0.5661025047302246
Agent1_Actor_Loss : -0.29763364791870117
Agent1_Alpha_Loss : 0.7895859479904175
Agent1_Temperature : 0.08782886368539812
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 461 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 462 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 463 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 464 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 465 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 466 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 467 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 468 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 469 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 470 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -6.816277980804443
Agent0_Eval_StdReturn : 17.671009063720703
Agent0_Eval_MaxReturn : 29.408187866210938
Agent0_Eval_MinReturn : -26.975496292114258
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -17.79298973083496
Agent0_Train_StdReturn : 14.07563304901123
Agent0_Train_MaxReturn : 1.307088851928711
Agent0_Train_MinReturn : -44.550743103027344
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 706500
Agent0_TimeSinceStart : 1096.8191375732422
Agent0_Critic_Loss : 0.41156718134880066
Agent0_Actor_Loss : -0.41967976093292236
Agent0_Alpha_Loss : 0.7718557715415955
Agent0_Temperature : 0.08766856845743164
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -25.714147567749023
Agent1_Eval_StdReturn : 30.415359497070312
Agent1_Eval_MaxReturn : 7.713305473327637
Agent1_Eval_MinReturn : -89.74201202392578
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -16.736736297607422
Agent1_Train_StdReturn : 11.974446296691895
Agent1_Train_MaxReturn : -2.6297268867492676
Agent1_Train_MinReturn : -38.06770706176758
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 706500
Agent1_TimeSinceStart : 1098.9357116222382
Agent1_Critic_Loss : 0.36672794818878174
Agent1_Actor_Loss : -0.13748699426651
Agent1_Alpha_Loss : 0.7844793796539307
Agent1_Temperature : 0.08758427135373324
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 471 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 472 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 473 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 474 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 475 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 476 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 477 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 478 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 479 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 480 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -19.60121726989746
Agent0_Eval_StdReturn : 17.588773727416992
Agent0_Eval_MaxReturn : 16.965957641601562
Agent0_Eval_MinReturn : -47.638755798339844
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -15.943331718444824
Agent0_Train_StdReturn : 14.338290214538574
Agent0_Train_MaxReturn : 12.233651161193848
Agent0_Train_MinReturn : -45.98883819580078
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 721500
Agent0_TimeSinceStart : 1120.1208283901215
Agent0_Critic_Loss : 0.3928571343421936
Agent0_Actor_Loss : -0.4399455785751343
Agent0_Alpha_Loss : 0.7589969038963318
Agent0_Temperature : 0.08742209220142805
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -16.429880142211914
Agent1_Eval_StdReturn : 14.732407569885254
Agent1_Eval_MaxReturn : 7.838146209716797
Agent1_Eval_MinReturn : -38.52391052246094
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -9.57341480255127
Agent1_Train_StdReturn : 12.2543363571167
Agent1_Train_MaxReturn : 9.784231185913086
Agent1_Train_MinReturn : -25.68252944946289
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 721500
Agent1_TimeSinceStart : 1122.2265861034393
Agent1_Critic_Loss : 0.4563758373260498
Agent1_Actor_Loss : -0.07216772437095642
Agent1_Alpha_Loss : 0.7856897115707397
Agent1_Temperature : 0.08733824338942957
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 481 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 482 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 483 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 484 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 485 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 486 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 487 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 488 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 489 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 490 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -13.200116157531738
Agent0_Eval_StdReturn : 22.330726623535156
Agent0_Eval_MaxReturn : 6.542078971862793
Agent0_Eval_MinReturn : -69.12944030761719
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -8.729047775268555
Agent0_Train_StdReturn : 16.95685386657715
Agent0_Train_MaxReturn : 15.332050323486328
Agent0_Train_MinReturn : -48.438358306884766
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 736500
Agent0_TimeSinceStart : 1143.4737966060638
Agent0_Critic_Loss : 0.35470521450042725
Agent0_Actor_Loss : -0.5180585384368896
Agent0_Alpha_Loss : 0.7846511602401733
Agent0_Temperature : 0.08717573145070137
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -12.939584732055664
Agent1_Eval_StdReturn : 13.292016983032227
Agent1_Eval_MaxReturn : 5.669918060302734
Agent1_Eval_MinReturn : -44.746788024902344
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -20.920059204101562
Agent1_Train_StdReturn : 16.987668991088867
Agent1_Train_MaxReturn : 1.9785199165344238
Agent1_Train_MinReturn : -57.71442794799805
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 736500
Agent1_TimeSinceStart : 1145.5752141475677
Agent1_Critic_Loss : 0.36986804008483887
Agent1_Actor_Loss : -0.18654775619506836
Agent1_Alpha_Loss : 0.798048198223114
Agent1_Temperature : 0.08709129934612743
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 491 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 492 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 493 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 494 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 495 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 496 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 497 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 498 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 499 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 500 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -16.000755310058594
Agent0_Eval_StdReturn : 9.18293571472168
Agent0_Eval_MaxReturn : 0.26641845703125
Agent0_Eval_MinReturn : -32.50520324707031
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -13.089807510375977
Agent0_Train_StdReturn : 5.887524604797363
Agent0_Train_MaxReturn : -5.2996134757995605
Agent0_Train_MinReturn : -23.991586685180664
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 751500
Agent0_TimeSinceStart : 1166.7882466316223
Agent0_Critic_Loss : 0.3952992558479309
Agent0_Actor_Loss : -0.396581768989563
Agent0_Alpha_Loss : 0.7654225826263428
Agent0_Temperature : 0.0869284307461883
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -13.22718620300293
Agent1_Eval_StdReturn : 10.718039512634277
Agent1_Eval_MaxReturn : 8.897830963134766
Agent1_Eval_MinReturn : -25.8322811126709
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -19.861133575439453
Agent1_Train_StdReturn : 18.45366668701172
Agent1_Train_MaxReturn : -0.0038030147552490234
Agent1_Train_MinReturn : -60.24261474609375
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 751500
Agent1_TimeSinceStart : 1168.900285243988
Agent1_Critic_Loss : 0.39447158575057983
Agent1_Actor_Loss : -0.12561513483524323
Agent1_Alpha_Loss : 0.7946794033050537
Agent1_Temperature : 0.08684498312541511
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 501 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 502 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 503 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 504 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 505 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 506 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 507 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 508 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 509 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 510 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -19.283349990844727
Agent0_Eval_StdReturn : 15.072028160095215
Agent0_Eval_MaxReturn : 16.94511604309082
Agent0_Eval_MinReturn : -32.34482955932617
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -16.221738815307617
Agent0_Train_StdReturn : 14.173836708068848
Agent0_Train_MaxReturn : 10.611597061157227
Agent0_Train_MinReturn : -35.125362396240234
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 766500
Agent0_TimeSinceStart : 1190.0905168056488
Agent0_Critic_Loss : 0.4045124053955078
Agent0_Actor_Loss : -0.4144555628299713
Agent0_Alpha_Loss : 0.7728276252746582
Agent0_Temperature : 0.08668196652027148
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -16.366418838500977
Agent1_Eval_StdReturn : 17.66169548034668
Agent1_Eval_MaxReturn : 9.320768356323242
Agent1_Eval_MinReturn : -55.38520812988281
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -18.67378807067871
Agent1_Train_StdReturn : 10.624551773071289
Agent1_Train_MaxReturn : 3.969815731048584
Agent1_Train_MinReturn : -33.77882385253906
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 766500
Agent1_TimeSinceStart : 1192.188146829605
Agent1_Critic_Loss : 0.3504981994628906
Agent1_Actor_Loss : -0.2251085340976715
Agent1_Alpha_Loss : 0.7906476259231567
Agent1_Temperature : 0.08659922050111561
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 511 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 512 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 513 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 514 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 515 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 516 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 517 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 518 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 519 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 520 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -31.893844604492188
Agent0_Eval_StdReturn : 18.447965621948242
Agent0_Eval_MaxReturn : 5.1630449295043945
Agent0_Eval_MinReturn : -54.399009704589844
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -15.207509994506836
Agent0_Train_StdReturn : 13.595549583435059
Agent0_Train_MaxReturn : 11.820825576782227
Agent0_Train_MinReturn : -38.70901870727539
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 781500
Agent0_TimeSinceStart : 1213.3701910972595
Agent0_Critic_Loss : 0.4300154447555542
Agent0_Actor_Loss : -0.45217910408973694
Agent0_Alpha_Loss : 0.7790958285331726
Agent0_Temperature : 0.08643514913032581
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -26.60336685180664
Agent1_Eval_StdReturn : 25.96095848083496
Agent1_Eval_MaxReturn : 2.0142085552215576
Agent1_Eval_MinReturn : -94.95526885986328
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -16.037830352783203
Agent1_Train_StdReturn : 13.769527435302734
Agent1_Train_MaxReturn : 4.709774017333984
Agent1_Train_MinReturn : -34.874168395996094
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 781500
Agent1_TimeSinceStart : 1215.4690597057343
Agent1_Critic_Loss : 0.4006395936012268
Agent1_Actor_Loss : -0.15756699442863464
Agent1_Alpha_Loss : 0.7893041372299194
Agent1_Temperature : 0.0863543858412736
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 521 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 522 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 523 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 524 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 525 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 526 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 527 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 528 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 529 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 530 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -15.773724555969238
Agent0_Eval_StdReturn : 20.779319763183594
Agent0_Eval_MaxReturn : 14.5994873046875
Agent0_Eval_MinReturn : -57.348819732666016
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -15.431083679199219
Agent0_Train_StdReturn : 22.497928619384766
Agent0_Train_MaxReturn : 16.141626358032227
Agent0_Train_MinReturn : -65.80302429199219
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 796500
Agent0_TimeSinceStart : 1236.614722251892
Agent0_Critic_Loss : 0.42339807748794556
Agent0_Actor_Loss : -0.4346936345100403
Agent0_Alpha_Loss : 0.7793415784835815
Agent0_Temperature : 0.08618873505504022
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -12.996337890625
Agent1_Eval_StdReturn : 16.115585327148438
Agent1_Eval_MaxReturn : 22.116943359375
Agent1_Eval_MinReturn : -41.100738525390625
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -11.485410690307617
Agent1_Train_StdReturn : 12.813667297363281
Agent1_Train_MaxReturn : 3.6271004676818848
Agent1_Train_MinReturn : -33.39250946044922
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 796500
Agent1_TimeSinceStart : 1238.7098999023438
Agent1_Critic_Loss : 0.39673230051994324
Agent1_Actor_Loss : -0.1820809245109558
Agent1_Alpha_Loss : 0.7871399521827698
Agent1_Temperature : 0.08611034390426067
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 531 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 532 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 533 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 534 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 535 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 536 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 537 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 538 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 539 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 540 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -15.984601020812988
Agent0_Eval_StdReturn : 11.779805183410645
Agent0_Eval_MaxReturn : 6.813033103942871
Agent0_Eval_MinReturn : -30.112783432006836
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -6.692263126373291
Agent0_Train_StdReturn : 16.57349967956543
Agent0_Train_MaxReturn : 17.19346809387207
Agent0_Train_MinReturn : -34.86152267456055
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 811500
Agent0_TimeSinceStart : 1259.8260433673859
Agent0_Critic_Loss : 0.4013112187385559
Agent0_Actor_Loss : -0.46225494146347046
Agent0_Alpha_Loss : 0.7837113738059998
Agent0_Temperature : 0.0859431835848363
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -13.110186576843262
Agent1_Eval_StdReturn : 8.120556831359863
Agent1_Eval_MaxReturn : 1.2778232097625732
Agent1_Eval_MinReturn : -22.439884185791016
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -20.6031494140625
Agent1_Train_StdReturn : 10.755891799926758
Agent1_Train_MaxReturn : -7.430386066436768
Agent1_Train_MinReturn : -42.442100524902344
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 811500
Agent1_TimeSinceStart : 1261.929710149765
Agent1_Critic_Loss : 0.41711002588272095
Agent1_Actor_Loss : -0.19579505920410156
Agent1_Alpha_Loss : 0.7822033166885376
Agent1_Temperature : 0.0858671865146443
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 541 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 542 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 543 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 544 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 545 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 546 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 547 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 548 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 549 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 550 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -27.947704315185547
Agent0_Eval_StdReturn : 19.121082305908203
Agent0_Eval_MaxReturn : 11.693381309509277
Agent0_Eval_MinReturn : -63.25551223754883
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -14.5601224899292
Agent0_Train_StdReturn : 17.190631866455078
Agent0_Train_MaxReturn : 10.48093318939209
Agent0_Train_MinReturn : -47.71693420410156
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 826500
Agent0_TimeSinceStart : 1283.102699995041
Agent0_Critic_Loss : 0.41444119811058044
Agent0_Actor_Loss : -0.4419015944004059
Agent0_Alpha_Loss : 0.787507176399231
Agent0_Temperature : 0.08569678758883156
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -22.059797286987305
Agent1_Eval_StdReturn : 16.05512809753418
Agent1_Eval_MaxReturn : 11.24843978881836
Agent1_Eval_MinReturn : -43.437477111816406
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -34.43524932861328
Agent1_Train_StdReturn : 19.151159286499023
Agent1_Train_MaxReturn : -4.9248504638671875
Agent1_Train_MinReturn : -72.44837188720703
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 826500
Agent1_TimeSinceStart : 1285.205825805664
Agent1_Critic_Loss : 0.44784247875213623
Agent1_Actor_Loss : -0.09890882670879364
Agent1_Alpha_Loss : 0.776660680770874
Agent1_Temperature : 0.0856262092983959
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 551 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 552 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 553 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 554 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 555 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 556 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 557 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 558 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 559 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 560 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -12.830833435058594
Agent0_Eval_StdReturn : 13.512584686279297
Agent0_Eval_MaxReturn : 10.889243125915527
Agent0_Eval_MinReturn : -32.889808654785156
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -14.859674453735352
Agent0_Train_StdReturn : 17.80949592590332
Agent0_Train_MaxReturn : 9.789403915405273
Agent0_Train_MinReturn : -42.62823486328125
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 841500
Agent0_TimeSinceStart : 1306.3610627651215
Agent0_Critic_Loss : 0.3956199586391449
Agent0_Actor_Loss : -0.43803709745407104
Agent0_Alpha_Loss : 0.7882046103477478
Agent0_Temperature : 0.08545118393399512
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -21.802555084228516
Agent1_Eval_StdReturn : 17.684030532836914
Agent1_Eval_MaxReturn : 8.031391143798828
Agent1_Eval_MinReturn : -52.18781280517578
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -22.358413696289062
Agent1_Train_StdReturn : 23.77899742126465
Agent1_Train_MaxReturn : 6.0382890701293945
Agent1_Train_MinReturn : -57.90055847167969
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 841500
Agent1_TimeSinceStart : 1308.4696083068848
Agent1_Critic_Loss : 0.5277327299118042
Agent1_Actor_Loss : -0.20915928483009338
Agent1_Alpha_Loss : 0.7836641073226929
Agent1_Temperature : 0.08538660916722558
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 561 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 562 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 563 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 564 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 565 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 566 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 567 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 568 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 569 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 570 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -21.478139877319336
Agent0_Eval_StdReturn : 16.466999053955078
Agent0_Eval_MaxReturn : 14.426066398620605
Agent0_Eval_MinReturn : -43.68593978881836
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -15.244990348815918
Agent0_Train_StdReturn : 26.857389450073242
Agent0_Train_MaxReturn : 23.874582290649414
Agent0_Train_MinReturn : -77.15545654296875
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 856500
Agent0_TimeSinceStart : 1329.7000846862793
Agent0_Critic_Loss : 0.5606286525726318
Agent0_Actor_Loss : -0.5475061535835266
Agent0_Alpha_Loss : 0.7970950603485107
Agent0_Temperature : 0.08520502196054898
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -29.798757553100586
Agent1_Eval_StdReturn : 14.222005844116211
Agent1_Eval_MaxReturn : -8.461783409118652
Agent1_Eval_MinReturn : -50.220924377441406
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -6.580101013183594
Agent1_Train_StdReturn : 12.706193923950195
Agent1_Train_MaxReturn : 17.122661590576172
Agent1_Train_MinReturn : -32.35974884033203
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 856500
Agent1_TimeSinceStart : 1331.814221382141
Agent1_Critic_Loss : 0.43205535411834717
Agent1_Actor_Loss : -0.25354617834091187
Agent1_Alpha_Loss : 0.7601739168167114
Agent1_Temperature : 0.08514840272169642
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 571 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 572 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 573 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 574 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 575 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 576 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 577 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 578 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 579 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 580 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -12.43027114868164
Agent0_Eval_StdReturn : 23.89200782775879
Agent0_Eval_MaxReturn : 29.190874099731445
Agent0_Eval_MinReturn : -61.508174896240234
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -9.058204650878906
Agent0_Train_StdReturn : 18.556379318237305
Agent0_Train_MaxReturn : 25.58597755432129
Agent0_Train_MinReturn : -35.42560577392578
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 871500
Agent0_TimeSinceStart : 1352.9654903411865
Agent0_Critic_Loss : 0.5015732645988464
Agent0_Actor_Loss : -0.4259030520915985
Agent0_Alpha_Loss : 0.7917957901954651
Agent0_Temperature : 0.08495683928662814
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -14.385747909545898
Agent1_Eval_StdReturn : 14.425816535949707
Agent1_Eval_MaxReturn : 6.283524036407471
Agent1_Eval_MinReturn : -36.13214874267578
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -13.503549575805664
Agent1_Train_StdReturn : 10.410377502441406
Agent1_Train_MaxReturn : -1.3866090774536133
Agent1_Train_MinReturn : -35.754539489746094
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 871500
Agent1_TimeSinceStart : 1355.0728924274445
Agent1_Critic_Loss : 0.39813292026519775
Agent1_Actor_Loss : -0.08491767197847366
Agent1_Alpha_Loss : 0.7488940358161926
Agent1_Temperature : 0.08491244677265257
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 581 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 582 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 583 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 584 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 585 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 586 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 587 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 588 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 589 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 590 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -8.029244422912598
Agent0_Eval_StdReturn : 24.21550941467285
Agent0_Eval_MaxReturn : 42.338077545166016
Agent0_Eval_MinReturn : -44.11316680908203
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -16.358022689819336
Agent0_Train_StdReturn : 18.195646286010742
Agent0_Train_MaxReturn : 5.836530685424805
Agent0_Train_MinReturn : -56.326904296875
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 886500
Agent0_TimeSinceStart : 1376.2098286151886
Agent0_Critic_Loss : 0.6885800957679749
Agent0_Actor_Loss : -0.47954103350639343
Agent0_Alpha_Loss : 0.7997002601623535
Agent0_Temperature : 0.0847089344514117
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -7.738445281982422
Agent1_Eval_StdReturn : 12.054753303527832
Agent1_Eval_MaxReturn : 12.274494171142578
Agent1_Eval_MinReturn : -28.706327438354492
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -10.051277160644531
Agent1_Train_StdReturn : 12.486906051635742
Agent1_Train_MaxReturn : 9.342069625854492
Agent1_Train_MinReturn : -26.269851684570312
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 886500
Agent1_TimeSinceStart : 1378.3287494182587
Agent1_Critic_Loss : 0.522354006767273
Agent1_Actor_Loss : -0.20645658671855927
Agent1_Alpha_Loss : 0.7587674260139465
Agent1_Temperature : 0.08467817675247905
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 591 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 592 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 593 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 594 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 595 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 596 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 597 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 598 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 599 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 600 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -27.93853759765625
Agent0_Eval_StdReturn : 17.779603958129883
Agent0_Eval_MaxReturn : -10.976290702819824
Agent0_Eval_MinReturn : -61.402565002441406
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -11.027095794677734
Agent0_Train_StdReturn : 18.075899124145508
Agent0_Train_MaxReturn : 16.695846557617188
Agent0_Train_MinReturn : -45.15229034423828
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 901500
Agent0_TimeSinceStart : 1399.5222449302673
Agent0_Critic_Loss : 0.5853186845779419
Agent0_Actor_Loss : -0.40502122044563293
Agent0_Alpha_Loss : 0.7849557399749756
Agent0_Temperature : 0.0844611968186596
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -17.203968048095703
Agent1_Eval_StdReturn : 11.167299270629883
Agent1_Eval_MaxReturn : 3.6910557746887207
Agent1_Eval_MinReturn : -33.497154235839844
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -19.543323516845703
Agent1_Train_StdReturn : 12.72093677520752
Agent1_Train_MaxReturn : -2.9815988540649414
Agent1_Train_MinReturn : -43.75257110595703
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 901500
Agent1_TimeSinceStart : 1401.6474690437317
Agent1_Critic_Loss : 0.4988837242126465
Agent1_Actor_Loss : -0.22393228113651276
Agent1_Alpha_Loss : 0.7512084245681763
Agent1_Temperature : 0.08444578197670412
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 601 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 602 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 603 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 604 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 605 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 606 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 607 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 608 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 609 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 610 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -17.91998863220215
Agent0_Eval_StdReturn : 13.38708209991455
Agent0_Eval_MaxReturn : 6.63659143447876
Agent0_Eval_MinReturn : -40.99715042114258
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -19.57940101623535
Agent0_Train_StdReturn : 17.698444366455078
Agent0_Train_MaxReturn : 0.49402523040771484
Agent0_Train_MinReturn : -68.06695556640625
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 916500
Agent0_TimeSinceStart : 1422.9216384887695
Agent0_Critic_Loss : 0.4552115201950073
Agent0_Actor_Loss : -0.5314850807189941
Agent0_Alpha_Loss : 0.791015625
Agent0_Temperature : 0.08421469120003233
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -16.250591278076172
Agent1_Eval_StdReturn : 14.075413703918457
Agent1_Eval_MaxReturn : 8.066558837890625
Agent1_Eval_MinReturn : -42.12080383300781
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -9.067097663879395
Agent1_Train_StdReturn : 12.2393798828125
Agent1_Train_MaxReturn : 7.547460556030273
Agent1_Train_MinReturn : -34.21629333496094
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 916500
Agent1_TimeSinceStart : 1425.0444631576538
Agent1_Critic_Loss : 0.4599274694919586
Agent1_Actor_Loss : -0.29307979345321655
Agent1_Alpha_Loss : 0.7449676394462585
Agent1_Temperature : 0.08421558124960316
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 611 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 612 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 613 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 614 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 615 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 616 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 617 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 618 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 619 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 620 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -22.28207778930664
Agent0_Eval_StdReturn : 12.274558067321777
Agent0_Eval_MaxReturn : -3.0434670448303223
Agent0_Eval_MinReturn : -44.887046813964844
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -13.655682563781738
Agent0_Train_StdReturn : 23.683149337768555
Agent0_Train_MaxReturn : 15.72366714477539
Agent0_Train_MinReturn : -70.39164733886719
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 931500
Agent0_TimeSinceStart : 1446.3436014652252
Agent0_Critic_Loss : 0.5711490511894226
Agent0_Actor_Loss : -0.5429912805557251
Agent0_Alpha_Loss : 0.7693564891815186
Agent0_Temperature : 0.08397016244404026
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -17.858013153076172
Agent1_Eval_StdReturn : 9.751871109008789
Agent1_Eval_MaxReturn : -1.7357791662216187
Agent1_Eval_MinReturn : -36.475685119628906
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -14.695474624633789
Agent1_Train_StdReturn : 12.749876976013184
Agent1_Train_MaxReturn : 3.588515281677246
Agent1_Train_MinReturn : -37.5367317199707
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 931500
Agent1_TimeSinceStart : 1448.4587824344635
Agent1_Critic_Loss : 0.4690340757369995
Agent1_Actor_Loss : -0.32204610109329224
Agent1_Alpha_Loss : 0.7383207082748413
Agent1_Temperature : 0.08398600627384172
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 621 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 622 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 623 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 624 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 625 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 626 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 627 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 628 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 629 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 630 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -19.159637451171875
Agent0_Eval_StdReturn : 18.173078536987305
Agent0_Eval_MaxReturn : 14.066851615905762
Agent0_Eval_MinReturn : -57.75136947631836
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -23.965370178222656
Agent0_Train_StdReturn : 24.426042556762695
Agent0_Train_MaxReturn : 18.907949447631836
Agent0_Train_MinReturn : -72.01439666748047
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 946500
Agent0_TimeSinceStart : 1469.6388065814972
Agent0_Critic_Loss : 0.543014645576477
Agent0_Actor_Loss : -0.49108919501304626
Agent0_Alpha_Loss : 0.7683367133140564
Agent0_Temperature : 0.0837272738861681
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -11.39940357208252
Agent1_Eval_StdReturn : 11.827554702758789
Agent1_Eval_MaxReturn : 1.2863681316375732
Agent1_Eval_MinReturn : -40.66104507446289
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -16.994136810302734
Agent1_Train_StdReturn : 13.751919746398926
Agent1_Train_MaxReturn : 1.9819245338439941
Agent1_Train_MinReturn : -48.47373962402344
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 946500
Agent1_TimeSinceStart : 1471.7593748569489
Agent1_Critic_Loss : 0.543711245059967
Agent1_Actor_Loss : -0.21177862584590912
Agent1_Alpha_Loss : 0.7536568641662598
Agent1_Temperature : 0.08375625097865179
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 631 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 632 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 633 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 634 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 635 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 636 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 637 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 638 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 639 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 640 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -13.558873176574707
Agent0_Eval_StdReturn : 21.03522300720215
Agent0_Eval_MaxReturn : 11.81827163696289
Agent0_Eval_MinReturn : -59.631019592285156
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -29.960750579833984
Agent0_Train_StdReturn : 17.771987915039062
Agent0_Train_MaxReturn : -3.9035511016845703
Agent0_Train_MinReturn : -57.68125915527344
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 961500
Agent0_TimeSinceStart : 1492.912014722824
Agent0_Critic_Loss : 0.4147113561630249
Agent0_Actor_Loss : -0.6331239342689514
Agent0_Alpha_Loss : 0.7763024568557739
Agent0_Temperature : 0.08348611411885268
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -16.100069046020508
Agent1_Eval_StdReturn : 12.666162490844727
Agent1_Eval_MaxReturn : -1.2325830459594727
Agent1_Eval_MinReturn : -42.65233612060547
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -12.315225601196289
Agent1_Train_StdReturn : 8.349501609802246
Agent1_Train_MaxReturn : 6.625871658325195
Agent1_Train_MinReturn : -23.574932098388672
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 961500
Agent1_TimeSinceStart : 1495.0199074745178
Agent1_Critic_Loss : 0.4634813964366913
Agent1_Actor_Loss : -0.15270620584487915
Agent1_Alpha_Loss : 0.7562340497970581
Agent1_Temperature : 0.08352628478797969
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 641 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 642 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 643 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 644 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 645 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 646 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 647 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 648 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 649 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 650 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -17.212007522583008
Agent0_Eval_StdReturn : 15.521051406860352
Agent0_Eval_MaxReturn : 1.4218422174453735
Agent0_Eval_MinReturn : -55.471126556396484
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -18.93598175048828
Agent0_Train_StdReturn : 14.536737442016602
Agent0_Train_MaxReturn : 6.81929874420166
Agent0_Train_MinReturn : -50.13511276245117
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 976500
Agent0_TimeSinceStart : 1516.183956861496
Agent0_Critic_Loss : 0.4011978209018707
Agent0_Actor_Loss : -0.6253221035003662
Agent0_Alpha_Loss : 0.7622122168540955
Agent0_Temperature : 0.08324681510995821
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -11.38116455078125
Agent1_Eval_StdReturn : 21.8067626953125
Agent1_Eval_MaxReturn : 39.66139221191406
Agent1_Eval_MinReturn : -36.28097152709961
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -15.810991287231445
Agent1_Train_StdReturn : 18.242639541625977
Agent1_Train_MaxReturn : 10.48639965057373
Agent1_Train_MinReturn : -50.23244857788086
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 976500
Agent1_TimeSinceStart : 1518.1562993526459
Agent1_Critic_Loss : 0.4703517258167267
Agent1_Actor_Loss : -0.17657214403152466
Agent1_Alpha_Loss : 0.7577714920043945
Agent1_Temperature : 0.08329609795240554
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 651 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 652 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 653 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 654 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 655 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 656 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 657 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 658 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 659 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 660 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -11.140989303588867
Agent0_Eval_StdReturn : 9.491497993469238
Agent0_Eval_MaxReturn : -0.037264108657836914
Agent0_Eval_MinReturn : -34.818145751953125
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -11.152790069580078
Agent0_Train_StdReturn : 17.397869110107422
Agent0_Train_MaxReturn : 6.52670431137085
Agent0_Train_MinReturn : -54.92961120605469
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 991500
Agent0_TimeSinceStart : 1538.4001636505127
Agent0_Critic_Loss : 0.6262146234512329
Agent0_Actor_Loss : -0.6230951547622681
Agent0_Alpha_Loss : 0.7720581293106079
Agent0_Temperature : 0.08300926105509691
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -11.308228492736816
Agent1_Eval_StdReturn : 16.360525131225586
Agent1_Eval_MaxReturn : 16.266359329223633
Agent1_Eval_MinReturn : -34.008216857910156
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -20.97597885131836
Agent1_Train_StdReturn : 22.179607391357422
Agent1_Train_MaxReturn : 0.5992510318756104
Agent1_Train_MinReturn : -60.74920654296875
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 991500
Agent1_TimeSinceStart : 1540.4196305274963
Agent1_Critic_Loss : 0.4156661629676819
Agent1_Actor_Loss : -0.18014594912528992
Agent1_Alpha_Loss : 0.7495032548904419
Agent1_Temperature : 0.08306595942272077
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 661 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 662 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 663 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 664 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 665 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 666 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 667 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 668 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 669 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 670 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -6.361975193023682
Agent0_Eval_StdReturn : 20.149391174316406
Agent0_Eval_MaxReturn : 21.932334899902344
Agent0_Eval_MinReturn : -58.91096496582031
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -16.5425968170166
Agent0_Train_StdReturn : 15.308905601501465
Agent0_Train_MaxReturn : 12.948060035705566
Agent0_Train_MinReturn : -36.112266540527344
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1006500
Agent0_TimeSinceStart : 1560.835119009018
Agent0_Critic_Loss : 0.49710506200790405
Agent0_Actor_Loss : -0.5238232612609863
Agent0_Alpha_Loss : 0.7646828293800354
Agent0_Temperature : 0.0827733812692927
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -16.311830520629883
Agent1_Eval_StdReturn : 8.456178665161133
Agent1_Eval_MaxReturn : 2.0617237091064453
Agent1_Eval_MinReturn : -29.644695281982422
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -6.311415195465088
Agent1_Train_StdReturn : 14.840176582336426
Agent1_Train_MaxReturn : 11.56721019744873
Agent1_Train_MinReturn : -43.2951774597168
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1006500
Agent1_TimeSinceStart : 1562.8584911823273
Agent1_Critic_Loss : 0.4117382764816284
Agent1_Actor_Loss : -0.0963299423456192
Agent1_Alpha_Loss : 0.7598249912261963
Agent1_Temperature : 0.08283567542629373
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 671 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 672 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 673 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 674 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 675 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 676 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 677 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 678 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 679 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 680 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -8.490653991699219
Agent0_Eval_StdReturn : 17.729454040527344
Agent0_Eval_MaxReturn : 10.486000061035156
Agent0_Eval_MinReturn : -50.57232666015625
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -12.804489135742188
Agent0_Train_StdReturn : 6.125216960906982
Agent0_Train_MaxReturn : -1.5782709121704102
Agent0_Train_MinReturn : -21.980093002319336
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1021500
Agent0_TimeSinceStart : 1583.3615550994873
Agent0_Critic_Loss : 0.6365335583686829
Agent0_Actor_Loss : -0.5486887693405151
Agent0_Alpha_Loss : 0.7608327865600586
Agent0_Temperature : 0.08253898089672704
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -19.920312881469727
Agent1_Eval_StdReturn : 10.148655891418457
Agent1_Eval_MaxReturn : -8.138144493103027
Agent1_Eval_MinReturn : -44.80115509033203
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -11.646585464477539
Agent1_Train_StdReturn : 5.800933361053467
Agent1_Train_MaxReturn : 2.903508186340332
Agent1_Train_MinReturn : -18.340925216674805
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1021500
Agent1_TimeSinceStart : 1585.4079780578613
Agent1_Critic_Loss : 0.4936758279800415
Agent1_Actor_Loss : -0.17211255431175232
Agent1_Alpha_Loss : 0.7723546624183655
Agent1_Temperature : 0.08260433683361108
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 681 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 682 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 683 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 684 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 685 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 686 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 687 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 688 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 689 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 690 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -5.565676689147949
Agent0_Eval_StdReturn : 11.115824699401855
Agent0_Eval_MaxReturn : 16.102313995361328
Agent0_Eval_MinReturn : -27.532928466796875
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -13.2603178024292
Agent0_Train_StdReturn : 10.377326011657715
Agent0_Train_MaxReturn : 4.265982627868652
Agent0_Train_MinReturn : -26.978221893310547
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1036500
Agent0_TimeSinceStart : 1605.9887509346008
Agent0_Critic_Loss : 0.6106212139129639
Agent0_Actor_Loss : -0.5228103399276733
Agent0_Alpha_Loss : 0.7578420639038086
Agent0_Temperature : 0.08230557078439092
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -16.451087951660156
Agent1_Eval_StdReturn : 16.760793685913086
Agent1_Eval_MaxReturn : 11.301058769226074
Agent1_Eval_MinReturn : -38.601436614990234
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -32.32099151611328
Agent1_Train_StdReturn : 14.375727653503418
Agent1_Train_MaxReturn : -9.068887710571289
Agent1_Train_MinReturn : -56.232704162597656
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1036500
Agent1_TimeSinceStart : 1608.0377819538116
Agent1_Critic_Loss : 0.39565396308898926
Agent1_Actor_Loss : -0.2019411027431488
Agent1_Alpha_Loss : 0.7623957395553589
Agent1_Temperature : 0.08237326059264675
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 691 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 692 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 693 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 694 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 695 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 696 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 697 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 698 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 699 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 700 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -16.242961883544922
Agent0_Eval_StdReturn : 14.390604972839355
Agent0_Eval_MaxReturn : 4.391484260559082
Agent0_Eval_MinReturn : -43.39207077026367
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -16.254314422607422
Agent0_Train_StdReturn : 10.25932788848877
Agent0_Train_MaxReturn : -2.253230571746826
Agent0_Train_MinReturn : -39.70328140258789
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1051500
Agent0_TimeSinceStart : 1628.6564767360687
Agent0_Critic_Loss : 0.6968348026275635
Agent0_Actor_Loss : -0.4948605000972748
Agent0_Alpha_Loss : 0.762830913066864
Agent0_Temperature : 0.08207272446281927
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -10.988166809082031
Agent1_Eval_StdReturn : 13.422462463378906
Agent1_Eval_MaxReturn : 9.883832931518555
Agent1_Eval_MinReturn : -41.615020751953125
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -14.379669189453125
Agent1_Train_StdReturn : 17.79524040222168
Agent1_Train_MaxReturn : 4.3298845291137695
Agent1_Train_MinReturn : -51.419246673583984
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1051500
Agent1_TimeSinceStart : 1630.7060415744781
Agent1_Critic_Loss : 0.4050743579864502
Agent1_Actor_Loss : -0.19650155305862427
Agent1_Alpha_Loss : 0.7606754302978516
Agent1_Temperature : 0.08214307325047758
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 701 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 702 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 703 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 704 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 705 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 706 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 707 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 708 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 709 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 710 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -16.86748504638672
Agent0_Eval_StdReturn : 19.710004806518555
Agent0_Eval_MaxReturn : 24.084598541259766
Agent0_Eval_MinReturn : -49.02373504638672
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -8.343092918395996
Agent0_Train_StdReturn : 13.37733268737793
Agent0_Train_MaxReturn : 23.64673614501953
Agent0_Train_MinReturn : -25.590852737426758
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1066500
Agent0_TimeSinceStart : 1651.3240122795105
Agent0_Critic_Loss : 0.5496023893356323
Agent0_Actor_Loss : -0.5711948275566101
Agent0_Alpha_Loss : 0.7505963444709778
Agent0_Temperature : 0.08183956232844611
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -16.37535285949707
Agent1_Eval_StdReturn : 15.150753021240234
Agent1_Eval_MaxReturn : 4.823562145233154
Agent1_Eval_MinReturn : -44.72704315185547
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -17.498735427856445
Agent1_Train_StdReturn : 20.739410400390625
Agent1_Train_MaxReturn : 9.123976707458496
Agent1_Train_MinReturn : -61.587249755859375
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1066500
Agent1_TimeSinceStart : 1653.3700170516968
Agent1_Critic_Loss : 0.390621542930603
Agent1_Actor_Loss : -0.2122955620288849
Agent1_Alpha_Loss : 0.7499808669090271
Agent1_Temperature : 0.08191336267021465
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 711 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 712 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 713 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 714 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 715 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 716 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 717 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 718 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 719 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 720 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -16.661056518554688
Agent0_Eval_StdReturn : 25.247106552124023
Agent0_Eval_MaxReturn : 15.252463340759277
Agent0_Eval_MinReturn : -71.654541015625
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -8.788639068603516
Agent0_Train_StdReturn : 15.446414947509766
Agent0_Train_MaxReturn : 23.273479461669922
Agent0_Train_MinReturn : -32.787078857421875
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1081500
Agent0_TimeSinceStart : 1674.0637640953064
Agent0_Critic_Loss : 0.5046672821044922
Agent0_Actor_Loss : -0.6511129140853882
Agent0_Alpha_Loss : 0.7522558569908142
Agent0_Temperature : 0.08160680794866282
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -19.18789291381836
Agent1_Eval_StdReturn : 16.287647247314453
Agent1_Eval_MaxReturn : 8.776032447814941
Agent1_Eval_MinReturn : -48.162742614746094
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -24.152706146240234
Agent1_Train_StdReturn : 11.546091079711914
Agent1_Train_MaxReturn : -4.983482360839844
Agent1_Train_MinReturn : -41.00486373901367
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1081500
Agent1_TimeSinceStart : 1676.1128540039062
Agent1_Critic_Loss : 0.5111368894577026
Agent1_Actor_Loss : -0.3375798165798187
Agent1_Alpha_Loss : 0.7402871251106262
Agent1_Temperature : 0.08168350513130618
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 721 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 722 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 723 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 724 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 725 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 726 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 727 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 728 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 729 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 730 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -7.923480033874512
Agent0_Eval_StdReturn : 15.195508003234863
Agent0_Eval_MaxReturn : 26.244258880615234
Agent0_Eval_MinReturn : -27.485471725463867
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -10.743870735168457
Agent0_Train_StdReturn : 10.528138160705566
Agent0_Train_MaxReturn : 7.14504337310791
Agent0_Train_MinReturn : -29.3563289642334
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1096500
Agent0_TimeSinceStart : 1696.8915047645569
Agent0_Critic_Loss : 0.5400697588920593
Agent0_Actor_Loss : -0.6676098108291626
Agent0_Alpha_Loss : 0.7487781047821045
Agent0_Temperature : 0.08137530963814857
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -19.710493087768555
Agent1_Eval_StdReturn : 19.122093200683594
Agent1_Eval_MaxReturn : 17.9052734375
Agent1_Eval_MinReturn : -56.060394287109375
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -18.061708450317383
Agent1_Train_StdReturn : 30.40064239501953
Agent1_Train_MaxReturn : 20.718141555786133
Agent1_Train_MinReturn : -87.48095703125
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1096500
Agent1_TimeSinceStart : 1698.9870612621307
Agent1_Critic_Loss : 0.5942502617835999
Agent1_Actor_Loss : -0.22793960571289062
Agent1_Alpha_Loss : 0.7489604353904724
Agent1_Temperature : 0.08145446502102223
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 731 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 732 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 733 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 734 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 735 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 736 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 737 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 738 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 739 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 740 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -15.675921440124512
Agent0_Eval_StdReturn : 9.963797569274902
Agent0_Eval_MaxReturn : 0.2854471206665039
Agent0_Eval_MinReturn : -29.74842071533203
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -9.583911895751953
Agent0_Train_StdReturn : 21.385181427001953
Agent0_Train_MaxReturn : 26.713836669921875
Agent0_Train_MinReturn : -48.14603042602539
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1111500
Agent0_TimeSinceStart : 1719.7911751270294
Agent0_Critic_Loss : 0.6661951541900635
Agent0_Actor_Loss : -0.7120373845100403
Agent0_Alpha_Loss : 0.7564862966537476
Agent0_Temperature : 0.08114515618682809
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -25.0616512298584
Agent1_Eval_StdReturn : 21.53487205505371
Agent1_Eval_MaxReturn : 13.341197967529297
Agent1_Eval_MinReturn : -53.776004791259766
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -14.887853622436523
Agent1_Train_StdReturn : 19.788833618164062
Agent1_Train_MaxReturn : 23.18633270263672
Agent1_Train_MinReturn : -42.77879333496094
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1111500
Agent1_TimeSinceStart : 1721.853579044342
Agent1_Critic_Loss : 0.45586663484573364
Agent1_Actor_Loss : -0.14098167419433594
Agent1_Alpha_Loss : 0.760214626789093
Agent1_Temperature : 0.08122566761049035
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 741 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 742 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 743 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 744 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 745 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 746 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 747 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 748 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 749 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 750 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -11.95337200164795
Agent0_Eval_StdReturn : 15.678145408630371
Agent0_Eval_MaxReturn : 12.231598854064941
Agent0_Eval_MinReturn : -40.42781448364258
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -10.877138137817383
Agent0_Train_StdReturn : 14.96184253692627
Agent0_Train_MaxReturn : 5.058972358703613
Agent0_Train_MinReturn : -43.40778350830078
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1126500
Agent0_TimeSinceStart : 1742.69304895401
Agent0_Critic_Loss : 0.4908974766731262
Agent0_Actor_Loss : -0.6009913086891174
Agent0_Alpha_Loss : 0.7574477195739746
Agent0_Temperature : 0.08091520010716767
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -21.941665649414062
Agent1_Eval_StdReturn : 17.669397354125977
Agent1_Eval_MaxReturn : -3.0220136642456055
Agent1_Eval_MinReturn : -64.59050750732422
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -12.044346809387207
Agent1_Train_StdReturn : 19.49091148376465
Agent1_Train_MaxReturn : 22.580732345581055
Agent1_Train_MinReturn : -40.63623046875
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1126500
Agent1_TimeSinceStart : 1744.7592532634735
Agent1_Critic_Loss : 0.5186868906021118
Agent1_Actor_Loss : -0.22168439626693726
Agent1_Alpha_Loss : 0.7553195953369141
Agent1_Temperature : 0.08099761188521451
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 751 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 752 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 753 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 754 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 755 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 756 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 757 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 758 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 759 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 760 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -11.510184288024902
Agent0_Eval_StdReturn : 20.24844741821289
Agent0_Eval_MaxReturn : 24.32326889038086
Agent0_Eval_MinReturn : -48.11853790283203
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -24.47382926940918
Agent0_Train_StdReturn : 25.009984970092773
Agent0_Train_MaxReturn : 8.661009788513184
Agent0_Train_MinReturn : -69.23735809326172
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1141500
Agent0_TimeSinceStart : 1765.5567197799683
Agent0_Critic_Loss : 0.584987998008728
Agent0_Actor_Loss : -0.6460031270980835
Agent0_Alpha_Loss : 0.777883768081665
Agent0_Temperature : 0.08068499535513457
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -11.92774772644043
Agent1_Eval_StdReturn : 12.163887977600098
Agent1_Eval_MaxReturn : 10.105574607849121
Agent1_Eval_MinReturn : -33.65060043334961
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -17.87678337097168
Agent1_Train_StdReturn : 15.410869598388672
Agent1_Train_MaxReturn : 5.358128547668457
Agent1_Train_MinReturn : -47.23909378051758
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1141500
Agent1_TimeSinceStart : 1767.6203644275665
Agent1_Critic_Loss : 0.7239202260971069
Agent1_Actor_Loss : -0.23061910271644592
Agent1_Alpha_Loss : 0.7433638572692871
Agent1_Temperature : 0.08077056962965501
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 761 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 762 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 763 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 764 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 765 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 766 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 767 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 768 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 769 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 770 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -14.730417251586914
Agent0_Eval_StdReturn : 26.069480895996094
Agent0_Eval_MaxReturn : 37.21897888183594
Agent0_Eval_MinReturn : -50.398902893066406
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -12.041437149047852
Agent0_Train_StdReturn : 21.41768455505371
Agent0_Train_MaxReturn : 14.398407936096191
Agent0_Train_MinReturn : -60.66929244995117
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1156500
Agent0_TimeSinceStart : 1788.351450920105
Agent0_Critic_Loss : 0.5468288660049438
Agent0_Actor_Loss : -0.5854519605636597
Agent0_Alpha_Loss : 0.773054838180542
Agent0_Temperature : 0.08045330848204392
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -13.697649002075195
Agent1_Eval_StdReturn : 14.315061569213867
Agent1_Eval_MaxReturn : 15.07511043548584
Agent1_Eval_MinReturn : -33.81224822998047
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -11.0885648727417
Agent1_Train_StdReturn : 9.893694877624512
Agent1_Train_MaxReturn : 10.756330490112305
Agent1_Train_MinReturn : -27.464141845703125
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1156500
Agent1_TimeSinceStart : 1790.4215462207794
Agent1_Critic_Loss : 0.6417951583862305
Agent1_Actor_Loss : -0.24737337231636047
Agent1_Alpha_Loss : 0.7426620721817017
Agent1_Temperature : 0.08054529035074022
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 771 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 772 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 773 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 774 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 775 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 776 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 777 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 778 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 779 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 780 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -17.273971557617188
Agent0_Eval_StdReturn : 29.371564865112305
Agent0_Eval_MaxReturn : 11.784724235534668
Agent0_Eval_MinReturn : -77.509033203125
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -11.050737380981445
Agent0_Train_StdReturn : 26.266618728637695
Agent0_Train_MaxReturn : 38.35424041748047
Agent0_Train_MinReturn : -64.57125091552734
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1171500
Agent0_TimeSinceStart : 1811.2107598781586
Agent0_Critic_Loss : 0.6068626642227173
Agent0_Actor_Loss : -0.5846344232559204
Agent0_Alpha_Loss : 0.7659988403320312
Agent0_Temperature : 0.08022116095639661
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -20.596771240234375
Agent1_Eval_StdReturn : 17.701921463012695
Agent1_Eval_MaxReturn : 14.209619522094727
Agent1_Eval_MinReturn : -50.747310638427734
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -8.643991470336914
Agent1_Train_StdReturn : 14.494824409484863
Agent1_Train_MaxReturn : 26.310165405273438
Agent1_Train_MinReturn : -31.78226089477539
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1171500
Agent1_TimeSinceStart : 1813.2817873954773
Agent1_Critic_Loss : 0.583062469959259
Agent1_Actor_Loss : -0.27678367495536804
Agent1_Alpha_Loss : 0.7320513725280762
Agent1_Temperature : 0.08032187169674274
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 781 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 782 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 783 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 784 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 785 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 786 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 787 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 788 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 789 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 790 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -25.07533073425293
Agent0_Eval_StdReturn : 32.384010314941406
Agent0_Eval_MaxReturn : 24.298145294189453
Agent0_Eval_MinReturn : -94.06207275390625
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -13.704086303710938
Agent0_Train_StdReturn : 20.306381225585938
Agent0_Train_MaxReturn : 13.422409057617188
Agent0_Train_MinReturn : -48.165122985839844
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1186500
Agent0_TimeSinceStart : 1834.0920152664185
Agent0_Critic_Loss : 0.8104771375656128
Agent0_Actor_Loss : -0.6720832586288452
Agent0_Alpha_Loss : 0.7638206481933594
Agent0_Temperature : 0.07998950341292584
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -16.804773330688477
Agent1_Eval_StdReturn : 13.8644380569458
Agent1_Eval_MaxReturn : 4.390218734741211
Agent1_Eval_MinReturn : -41.984962463378906
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -19.149322509765625
Agent1_Train_StdReturn : 13.96237564086914
Agent1_Train_MaxReturn : 2.9527225494384766
Agent1_Train_MinReturn : -43.4323616027832
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1186500
Agent1_TimeSinceStart : 1836.1596989631653
Agent1_Critic_Loss : 0.7322661876678467
Agent1_Actor_Loss : -0.19090358912944794
Agent1_Alpha_Loss : 0.7232083082199097
Agent1_Temperature : 0.08010045052615496
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 791 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 792 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 793 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 794 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 795 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 796 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 797 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 798 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 799 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 800 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -16.858068466186523
Agent0_Eval_StdReturn : 28.089967727661133
Agent0_Eval_MaxReturn : 20.366979598999023
Agent0_Eval_MinReturn : -63.96379852294922
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -37.15849685668945
Agent0_Train_StdReturn : 14.814579963684082
Agent0_Train_MaxReturn : -22.950855255126953
Agent0_Train_MinReturn : -69.23765563964844
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1201500
Agent0_TimeSinceStart : 1856.9427404403687
Agent0_Critic_Loss : 0.5673638582229614
Agent0_Actor_Loss : -0.7897385358810425
Agent0_Alpha_Loss : 0.7699514031410217
Agent0_Temperature : 0.07975828441122208
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -13.001312255859375
Agent1_Eval_StdReturn : 4.542299747467041
Agent1_Eval_MaxReturn : -4.816538333892822
Agent1_Eval_MinReturn : -19.138214111328125
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -16.656938552856445
Agent1_Train_StdReturn : 8.13643741607666
Agent1_Train_MaxReturn : -0.1542367935180664
Agent1_Train_MinReturn : -29.94141387939453
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1201500
Agent1_TimeSinceStart : 1859.0207571983337
Agent1_Critic_Loss : 0.5073468685150146
Agent1_Actor_Loss : -0.2860075831413269
Agent1_Alpha_Loss : 0.7185898423194885
Agent1_Temperature : 0.0798826115165212
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 801 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 802 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 803 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 804 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 805 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 806 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 807 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 808 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 809 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 810 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -26.027141571044922
Agent0_Eval_StdReturn : 27.004379272460938
Agent0_Eval_MaxReturn : 10.431400299072266
Agent0_Eval_MinReturn : -64.56118774414062
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -42.07100296020508
Agent0_Train_StdReturn : 29.367652893066406
Agent0_Train_MaxReturn : 1.5988261699676514
Agent0_Train_MinReturn : -92.71422576904297
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1216500
Agent0_TimeSinceStart : 1879.7983493804932
Agent0_Critic_Loss : 0.715611457824707
Agent0_Actor_Loss : -0.8086500763893127
Agent0_Alpha_Loss : 0.7716165781021118
Agent0_Temperature : 0.07952810199105911
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -10.090949058532715
Agent1_Eval_StdReturn : 11.700211524963379
Agent1_Eval_MaxReturn : 12.197023391723633
Agent1_Eval_MinReturn : -26.045150756835938
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -10.750335693359375
Agent1_Train_StdReturn : 8.591352462768555
Agent1_Train_MaxReturn : 0.46696460247039795
Agent1_Train_MinReturn : -25.01329803466797
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1216500
Agent1_TimeSinceStart : 1881.8874809741974
Agent1_Critic_Loss : 0.6595475673675537
Agent1_Actor_Loss : -0.3890789747238159
Agent1_Alpha_Loss : 0.7132757902145386
Agent1_Temperature : 0.0796669629796632
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 811 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 812 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 813 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 814 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 815 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 816 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 817 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 818 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 819 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 820 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -22.892684936523438
Agent0_Eval_StdReturn : 17.14806365966797
Agent0_Eval_MaxReturn : 13.244062423706055
Agent0_Eval_MinReturn : -50.32928466796875
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -13.697158813476562
Agent0_Train_StdReturn : 26.85019874572754
Agent0_Train_MaxReturn : 39.240081787109375
Agent0_Train_MinReturn : -51.93025588989258
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1231500
Agent0_TimeSinceStart : 1902.7226629257202
Agent0_Critic_Loss : 1.0457961559295654
Agent0_Actor_Loss : -0.6910461783409119
Agent0_Alpha_Loss : 0.755714476108551
Agent0_Temperature : 0.07929960927652618
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -18.53168487548828
Agent1_Eval_StdReturn : 6.995850563049316
Agent1_Eval_MaxReturn : -9.389410018920898
Agent1_Eval_MinReturn : -33.57684326171875
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -8.468208312988281
Agent1_Train_StdReturn : 13.544440269470215
Agent1_Train_MaxReturn : 8.008075714111328
Agent1_Train_MinReturn : -41.28741455078125
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1231500
Agent1_TimeSinceStart : 1904.7991099357605
Agent1_Critic_Loss : 0.5767443180084229
Agent1_Actor_Loss : -0.19341757893562317
Agent1_Alpha_Loss : 0.7187008857727051
Agent1_Temperature : 0.07945282485376728
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 821 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 822 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 823 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 824 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 825 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 826 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 827 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 828 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 829 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 830 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -26.078542709350586
Agent0_Eval_StdReturn : 25.852094650268555
Agent0_Eval_MaxReturn : 3.2902746200561523
Agent0_Eval_MinReturn : -72.75101470947266
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -34.95831298828125
Agent0_Train_StdReturn : 26.69578742980957
Agent0_Train_MaxReturn : 1.9279102087020874
Agent0_Train_MinReturn : -75.17033386230469
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1246500
Agent0_TimeSinceStart : 1925.6042745113373
Agent0_Critic_Loss : 0.7926303148269653
Agent0_Actor_Loss : -0.6864709258079529
Agent0_Alpha_Loss : 0.758520245552063
Agent0_Temperature : 0.07907303324276961
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -15.839439392089844
Agent1_Eval_StdReturn : 6.600009441375732
Agent1_Eval_MaxReturn : -5.285140037536621
Agent1_Eval_MinReturn : -26.93621253967285
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -6.130521774291992
Agent1_Train_StdReturn : 10.577777862548828
Agent1_Train_MaxReturn : 12.399016380310059
Agent1_Train_MinReturn : -20.921207427978516
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1246500
Agent1_TimeSinceStart : 1927.685247182846
Agent1_Critic_Loss : 0.6339422464370728
Agent1_Actor_Loss : -0.3523178696632385
Agent1_Alpha_Loss : 0.7283816337585449
Agent1_Temperature : 0.0792390615487478
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 831 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 832 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 833 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 834 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 835 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 836 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 837 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 838 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 839 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 840 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -28.356414794921875
Agent0_Eval_StdReturn : 18.44497299194336
Agent0_Eval_MaxReturn : 4.033903121948242
Agent0_Eval_MinReturn : -53.24137878417969
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -26.751056671142578
Agent0_Train_StdReturn : 18.05584144592285
Agent0_Train_MaxReturn : -6.686216354370117
Agent0_Train_MinReturn : -61.46676254272461
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1261500
Agent0_TimeSinceStart : 1948.529197692871
Agent0_Critic_Loss : 0.7087946534156799
Agent0_Actor_Loss : -0.7276757955551147
Agent0_Alpha_Loss : 0.756350040435791
Agent0_Temperature : 0.07884675199782058
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -15.93762493133545
Agent1_Eval_StdReturn : 17.277793884277344
Agent1_Eval_MaxReturn : 20.195541381835938
Agent1_Eval_MinReturn : -34.15650177001953
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -13.40082836151123
Agent1_Train_StdReturn : 6.647217750549316
Agent1_Train_MaxReturn : -2.421396493911743
Agent1_Train_MinReturn : -24.29941749572754
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1261500
Agent1_TimeSinceStart : 1950.614411830902
Agent1_Critic_Loss : 0.4707666337490082
Agent1_Actor_Loss : -0.28379783034324646
Agent1_Alpha_Loss : 0.7270556688308716
Agent1_Temperature : 0.0790242432612616
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 841 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 842 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 843 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 844 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 845 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 846 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 847 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 848 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 849 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 850 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -16.506776809692383
Agent0_Eval_StdReturn : 13.754446029663086
Agent0_Eval_MaxReturn : 15.35330581665039
Agent0_Eval_MinReturn : -34.06732177734375
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -7.124222755432129
Agent0_Train_StdReturn : 28.66505241394043
Agent0_Train_MaxReturn : 39.24032211303711
Agent0_Train_MinReturn : -72.03034973144531
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1276500
Agent0_TimeSinceStart : 1971.479557275772
Agent0_Critic_Loss : 1.2231149673461914
Agent0_Actor_Loss : -0.811486005783081
Agent0_Alpha_Loss : 0.746607780456543
Agent0_Temperature : 0.078621065106117
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -17.938823699951172
Agent1_Eval_StdReturn : 8.011205673217773
Agent1_Eval_MaxReturn : -3.455362319946289
Agent1_Eval_MinReturn : -31.75333023071289
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -11.87490177154541
Agent1_Train_StdReturn : 9.577102661132812
Agent1_Train_MaxReturn : -0.6937971115112305
Agent1_Train_MinReturn : -33.08836364746094
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1276500
Agent1_TimeSinceStart : 1973.5628752708435
Agent1_Critic_Loss : 0.6241348385810852
Agent1_Actor_Loss : -0.32112085819244385
Agent1_Alpha_Loss : 0.7242897152900696
Agent1_Temperature : 0.07880911477105063
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 851 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 852 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 853 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 854 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 855 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 856 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 857 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 858 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 859 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 860 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -9.97152328491211
Agent0_Eval_StdReturn : 16.632848739624023
Agent0_Eval_MaxReturn : 7.916347980499268
Agent0_Eval_MinReturn : -43.88606262207031
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -12.435460090637207
Agent0_Train_StdReturn : 17.052289962768555
Agent0_Train_MaxReturn : 15.004378318786621
Agent0_Train_MinReturn : -46.77521514892578
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1291500
Agent0_TimeSinceStart : 1994.4000284671783
Agent0_Critic_Loss : 1.0259742736816406
Agent0_Actor_Loss : -0.8885243535041809
Agent0_Alpha_Loss : 0.7449283599853516
Agent0_Temperature : 0.07839762974804432
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -7.830935478210449
Agent1_Eval_StdReturn : 13.23824691772461
Agent1_Eval_MaxReturn : 21.551258087158203
Agent1_Eval_MinReturn : -24.384414672851562
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -20.34018325805664
Agent1_Train_StdReturn : 16.05472183227539
Agent1_Train_MaxReturn : 0.34813594818115234
Agent1_Train_MinReturn : -51.32936477661133
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1291500
Agent1_TimeSinceStart : 1996.4769730567932
Agent1_Critic_Loss : 0.4201889634132385
Agent1_Actor_Loss : -0.21262918412685394
Agent1_Alpha_Loss : 0.7293401956558228
Agent1_Temperature : 0.07859431386338246
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 861 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 862 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 863 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 864 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 865 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 866 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 867 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 868 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 869 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 870 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -8.01309585571289
Agent0_Eval_StdReturn : 10.877373695373535
Agent0_Eval_MaxReturn : 4.17727518081665
Agent0_Eval_MinReturn : -23.460142135620117
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -10.418741226196289
Agent0_Train_StdReturn : 12.931463241577148
Agent0_Train_MaxReturn : 4.490718364715576
Agent0_Train_MinReturn : -45.37355041503906
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1306500
Agent0_TimeSinceStart : 2017.3718762397766
Agent0_Critic_Loss : 1.1588184833526611
Agent0_Actor_Loss : -0.7498104572296143
Agent0_Alpha_Loss : 0.7372344732284546
Agent0_Temperature : 0.07817645458978818
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -10.318781852722168
Agent1_Eval_StdReturn : 14.88698959350586
Agent1_Eval_MaxReturn : 7.149080276489258
Agent1_Eval_MinReturn : -39.58098220825195
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -8.362992286682129
Agent1_Train_StdReturn : 15.96583080291748
Agent1_Train_MaxReturn : 10.81998062133789
Agent1_Train_MinReturn : -38.00832748413086
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1306500
Agent1_TimeSinceStart : 2019.451289653778
Agent1_Critic_Loss : 0.4499497711658478
Agent1_Actor_Loss : -0.2445679008960724
Agent1_Alpha_Loss : 0.7314008474349976
Agent1_Temperature : 0.07837821977176072
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 871 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 872 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 873 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 874 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 875 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 876 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 877 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 878 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 879 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 880 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -8.617612838745117
Agent0_Eval_StdReturn : 8.469118118286133
Agent0_Eval_MaxReturn : 2.613595962524414
Agent0_Eval_MinReturn : -26.74962615966797
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -11.82469367980957
Agent0_Train_StdReturn : 10.758342742919922
Agent0_Train_MaxReturn : 0.27692317962646484
Agent0_Train_MinReturn : -38.91046142578125
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1321500
Agent0_TimeSinceStart : 2040.4360890388489
Agent0_Critic_Loss : 1.1861411333084106
Agent0_Actor_Loss : -0.6834088563919067
Agent0_Alpha_Loss : 0.7320625185966492
Agent0_Temperature : 0.0779570078925769
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -18.01107406616211
Agent1_Eval_StdReturn : 16.334503173828125
Agent1_Eval_MaxReturn : 7.497702121734619
Agent1_Eval_MinReturn : -51.50271224975586
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -13.339141845703125
Agent1_Train_StdReturn : 19.94267463684082
Agent1_Train_MaxReturn : 12.520254135131836
Agent1_Train_MinReturn : -50.64130783081055
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1321500
Agent1_TimeSinceStart : 2042.510365486145
Agent1_Critic_Loss : 0.5549311637878418
Agent1_Actor_Loss : -0.2912469506263733
Agent1_Alpha_Loss : 0.7384318113327026
Agent1_Temperature : 0.07816200805129385
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 881 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 882 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 883 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 884 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 885 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 886 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 887 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 888 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 889 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 890 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -18.272104263305664
Agent0_Eval_StdReturn : 13.860785484313965
Agent0_Eval_MaxReturn : 14.907305717468262
Agent0_Eval_MinReturn : -43.99244689941406
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -9.170303344726562
Agent0_Train_StdReturn : 11.33577823638916
Agent0_Train_MaxReturn : 11.945775032043457
Agent0_Train_MinReturn : -26.40627098083496
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1336500
Agent0_TimeSinceStart : 2063.413586139679
Agent0_Critic_Loss : 0.8088775873184204
Agent0_Actor_Loss : -0.7897368669509888
Agent0_Alpha_Loss : 0.7199389934539795
Agent0_Temperature : 0.07774031538525691
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -3.1546905040740967
Agent1_Eval_StdReturn : 22.97498893737793
Agent1_Eval_MaxReturn : 43.86884307861328
Agent1_Eval_MinReturn : -48.27572250366211
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -10.775848388671875
Agent1_Train_StdReturn : 15.008068084716797
Agent1_Train_MaxReturn : 7.307342529296875
Agent1_Train_MinReturn : -33.86140823364258
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1336500
Agent1_TimeSinceStart : 2065.478754043579
Agent1_Critic_Loss : 0.5691716074943542
Agent1_Actor_Loss : -0.30763012170791626
Agent1_Alpha_Loss : 0.7404749393463135
Agent1_Temperature : 0.07794543858764058
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 891 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 892 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 893 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 894 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 895 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 896 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 897 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 898 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 899 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 900 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -10.27714729309082
Agent0_Eval_StdReturn : 9.648455619812012
Agent0_Eval_MaxReturn : 1.285090446472168
Agent0_Eval_MinReturn : -34.37568664550781
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -3.2836527824401855
Agent0_Train_StdReturn : 18.79589080810547
Agent0_Train_MaxReturn : 23.660612106323242
Agent0_Train_MinReturn : -49.72827911376953
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1351500
Agent0_TimeSinceStart : 2086.341935634613
Agent0_Critic_Loss : 0.887344479560852
Agent0_Actor_Loss : -0.7370758056640625
Agent0_Alpha_Loss : 0.7244751453399658
Agent0_Temperature : 0.07752567178832805
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -11.358710289001465
Agent1_Eval_StdReturn : 16.140771865844727
Agent1_Eval_MaxReturn : 10.056617736816406
Agent1_Eval_MinReturn : -44.468379974365234
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -23.087114334106445
Agent1_Train_StdReturn : 19.77748680114746
Agent1_Train_MaxReturn : -6.2026448249816895
Agent1_Train_MinReturn : -72.52691650390625
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1351500
Agent1_TimeSinceStart : 2088.4073235988617
Agent1_Critic_Loss : 0.4959045648574829
Agent1_Actor_Loss : -0.3994345963001251
Agent1_Alpha_Loss : 0.7544997930526733
Agent1_Temperature : 0.07772876716232427
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 901 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 902 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 903 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 904 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 905 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 906 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 907 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 908 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 909 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 910 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -8.110376358032227
Agent0_Eval_StdReturn : 13.947164535522461
Agent0_Eval_MaxReturn : 27.579742431640625
Agent0_Eval_MinReturn : -23.233983993530273
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -14.346386909484863
Agent0_Train_StdReturn : 17.763164520263672
Agent0_Train_MaxReturn : 5.474839210510254
Agent0_Train_MinReturn : -48.211307525634766
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1366500
Agent0_TimeSinceStart : 2109.265005350113
Agent0_Critic_Loss : 0.7863521575927734
Agent0_Actor_Loss : -0.8710507750511169
Agent0_Alpha_Loss : 0.7379239797592163
Agent0_Temperature : 0.07731160275040476
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -16.982091903686523
Agent1_Eval_StdReturn : 21.526023864746094
Agent1_Eval_MaxReturn : 9.188119888305664
Agent1_Eval_MinReturn : -61.74315643310547
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -20.430917739868164
Agent1_Train_StdReturn : 18.60702896118164
Agent1_Train_MaxReturn : 9.361827850341797
Agent1_Train_MinReturn : -42.070335388183594
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1366500
Agent1_TimeSinceStart : 2111.324922323227
Agent1_Critic_Loss : 0.6199496984481812
Agent1_Actor_Loss : -0.33514368534088135
Agent1_Alpha_Loss : 0.7297308444976807
Agent1_Temperature : 0.07751098364986503
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 911 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 912 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 913 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 914 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 915 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 916 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 917 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 918 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 919 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 920 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -9.649274826049805
Agent0_Eval_StdReturn : 9.922894477844238
Agent0_Eval_MaxReturn : 7.030884742736816
Agent0_Eval_MinReturn : -22.603126525878906
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -7.2206621170043945
Agent0_Train_StdReturn : 11.015374183654785
Agent0_Train_MaxReturn : 15.443016052246094
Agent0_Train_MinReturn : -22.378087997436523
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1381500
Agent0_TimeSinceStart : 2132.175011396408
Agent0_Critic_Loss : 0.8935014009475708
Agent0_Actor_Loss : -0.7424508333206177
Agent0_Alpha_Loss : 0.7304595112800598
Agent0_Temperature : 0.07709819623731859
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -10.640982627868652
Agent1_Eval_StdReturn : 15.054686546325684
Agent1_Eval_MaxReturn : 11.011756896972656
Agent1_Eval_MinReturn : -31.763296127319336
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -16.678022384643555
Agent1_Train_StdReturn : 21.254884719848633
Agent1_Train_MaxReturn : 23.689918518066406
Agent1_Train_MinReturn : -45.8662109375
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1381500
Agent1_TimeSinceStart : 2134.24108338356
Agent1_Critic_Loss : 0.6893178820610046
Agent1_Actor_Loss : -0.2709444761276245
Agent1_Alpha_Loss : 0.7406655550003052
Agent1_Temperature : 0.07729308209718001
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 921 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 922 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 923 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 924 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 925 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 926 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 927 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 928 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 929 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 930 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -4.810057640075684
Agent0_Eval_StdReturn : 5.861520290374756
Agent0_Eval_MaxReturn : 2.399165153503418
Agent0_Eval_MinReturn : -19.863754272460938
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -12.184425354003906
Agent0_Train_StdReturn : 13.109780311584473
Agent0_Train_MaxReturn : 6.838130950927734
Agent0_Train_MinReturn : -38.529903411865234
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1396500
Agent0_TimeSinceStart : 2155.1392557621
Agent0_Critic_Loss : 0.7664473652839661
Agent0_Actor_Loss : -0.7562386989593506
Agent0_Alpha_Loss : 0.7177572846412659
Agent0_Temperature : 0.07688614561949084
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -25.522480010986328
Agent1_Eval_StdReturn : 22.562767028808594
Agent1_Eval_MaxReturn : 3.7088539600372314
Agent1_Eval_MinReturn : -76.72846984863281
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -14.725506782531738
Agent1_Train_StdReturn : 23.1759090423584
Agent1_Train_MaxReturn : 17.54401969909668
Agent1_Train_MinReturn : -64.78779602050781
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1396500
Agent1_TimeSinceStart : 2157.2054131031036
Agent1_Critic_Loss : 0.6702091693878174
Agent1_Actor_Loss : -0.3888748586177826
Agent1_Alpha_Loss : 0.7372804880142212
Agent1_Temperature : 0.07707621257876474
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 931 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 932 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 933 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 934 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 935 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 936 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 937 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 938 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 939 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 940 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -10.302770614624023
Agent0_Eval_StdReturn : 10.913289070129395
Agent0_Eval_MaxReturn : 8.727832794189453
Agent0_Eval_MinReturn : -29.37529182434082
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -18.332632064819336
Agent0_Train_StdReturn : 12.264774322509766
Agent0_Train_MaxReturn : 0.8348369598388672
Agent0_Train_MinReturn : -36.76791000366211
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1411500
Agent0_TimeSinceStart : 2178.08336353302
Agent0_Critic_Loss : 1.1579968929290771
Agent0_Actor_Loss : -0.6459970474243164
Agent0_Alpha_Loss : 0.7074522972106934
Agent0_Temperature : 0.07667550724168751
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -16.368804931640625
Agent1_Eval_StdReturn : 15.71294116973877
Agent1_Eval_MaxReturn : 26.288406372070312
Agent1_Eval_MinReturn : -31.85323715209961
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -17.008563995361328
Agent1_Train_StdReturn : 19.30500030517578
Agent1_Train_MaxReturn : 7.797155380249023
Agent1_Train_MinReturn : -57.54726028442383
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1411500
Agent1_TimeSinceStart : 2180.1569101810455
Agent1_Critic_Loss : 0.4440358281135559
Agent1_Actor_Loss : -0.41236215829849243
Agent1_Alpha_Loss : 0.7349350452423096
Agent1_Temperature : 0.07685969237997324
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 941 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 942 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 943 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 944 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 945 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 946 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 947 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 948 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 949 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 950 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -10.121492385864258
Agent0_Eval_StdReturn : 15.919373512268066
Agent0_Eval_MaxReturn : 14.371902465820312
Agent0_Eval_MinReturn : -42.1967658996582
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -4.697475433349609
Agent0_Train_StdReturn : 8.926154136657715
Agent0_Train_MaxReturn : 9.028823852539062
Agent0_Train_MinReturn : -22.686391830444336
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1426500
Agent0_TimeSinceStart : 2200.72700214386
Agent0_Critic_Loss : 0.6335185170173645
Agent0_Actor_Loss : -0.7980482578277588
Agent0_Alpha_Loss : 0.7133384346961975
Agent0_Temperature : 0.07646613063230136
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -21.30594253540039
Agent1_Eval_StdReturn : 15.174017906188965
Agent1_Eval_MaxReturn : -6.566493988037109
Agent1_Eval_MinReturn : -53.004268646240234
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -25.081192016601562
Agent1_Train_StdReturn : 19.030982971191406
Agent1_Train_MaxReturn : -0.9801239967346191
Agent1_Train_MinReturn : -54.018150329589844
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1426500
Agent1_TimeSinceStart : 2202.7410485744476
Agent1_Critic_Loss : 0.616373598575592
Agent1_Actor_Loss : -0.4275660514831543
Agent1_Alpha_Loss : 0.7267845869064331
Agent1_Temperature : 0.07664379212749776
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 951 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 952 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 953 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 954 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 955 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 956 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 957 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 958 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 959 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 960 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -6.884891510009766
Agent0_Eval_StdReturn : 16.720094680786133
Agent0_Eval_MaxReturn : 26.21675682067871
Agent0_Eval_MinReturn : -28.864656448364258
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -4.3526740074157715
Agent0_Train_StdReturn : 13.40601921081543
Agent0_Train_MaxReturn : 21.08246612548828
Agent0_Train_MinReturn : -35.300201416015625
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1441500
Agent0_TimeSinceStart : 2223.881282567978
Agent0_Critic_Loss : 0.6385107040405273
Agent0_Actor_Loss : -0.8348161578178406
Agent0_Alpha_Loss : 0.7267957925796509
Agent0_Temperature : 0.07625624073645189
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -5.606387615203857
Agent1_Eval_StdReturn : 13.372467994689941
Agent1_Eval_MaxReturn : 21.27606964111328
Agent1_Eval_MinReturn : -25.505279541015625
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -5.884509563446045
Agent1_Train_StdReturn : 12.406155586242676
Agent1_Train_MaxReturn : 15.33035945892334
Agent1_Train_MinReturn : -21.465782165527344
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1441500
Agent1_TimeSinceStart : 2226.0091257095337
Agent1_Critic_Loss : 0.655163586139679
Agent1_Actor_Loss : -0.532086968421936
Agent1_Alpha_Loss : 0.7191668748855591
Agent1_Temperature : 0.07642931733589511
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 961 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 962 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 963 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 964 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 965 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 966 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 967 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 968 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 969 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 970 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : 9.505846977233887
Agent0_Eval_StdReturn : 9.351353645324707
Agent0_Eval_MaxReturn : 29.05287742614746
Agent0_Eval_MinReturn : -11.56438159942627
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : 2.359610080718994
Agent0_Train_StdReturn : 19.62529754638672
Agent0_Train_MaxReturn : 33.9112548828125
Agent0_Train_MinReturn : -35.129703521728516
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1456500
Agent0_TimeSinceStart : 2247.4733514785767
Agent0_Critic_Loss : 0.8446619510650635
Agent0_Actor_Loss : -0.7723946571350098
Agent0_Alpha_Loss : 0.7393230199813843
Agent0_Temperature : 0.07604483141514118
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -14.018152236938477
Agent1_Eval_StdReturn : 14.190049171447754
Agent1_Eval_MaxReturn : 5.282575607299805
Agent1_Eval_MinReturn : -39.45375442504883
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -11.864607810974121
Agent1_Train_StdReturn : 12.830039978027344
Agent1_Train_MaxReturn : 15.477570533752441
Agent1_Train_MinReturn : -27.87421417236328
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1456500
Agent1_TimeSinceStart : 2249.606506586075
Agent1_Critic_Loss : 0.86427903175354
Agent1_Actor_Loss : -0.4615689516067505
Agent1_Alpha_Loss : 0.7118773460388184
Agent1_Temperature : 0.0762162688071689
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 971 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 972 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 973 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 974 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 975 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 976 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 977 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 978 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 979 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 980 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -18.008089065551758
Agent0_Eval_StdReturn : 18.852252960205078
Agent0_Eval_MaxReturn : 8.70300579071045
Agent0_Eval_MinReturn : -52.39222717285156
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -4.897475719451904
Agent0_Train_StdReturn : 12.603714942932129
Agent0_Train_MaxReturn : 14.182634353637695
Agent0_Train_MinReturn : -31.836212158203125
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1471500
Agent0_TimeSinceStart : 2270.914921760559
Agent0_Critic_Loss : 0.7497928142547607
Agent0_Actor_Loss : -0.7465336322784424
Agent0_Alpha_Loss : 0.7290452718734741
Agent0_Temperature : 0.07583222499936539
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -17.808643341064453
Agent1_Eval_StdReturn : 12.134634971618652
Agent1_Eval_MaxReturn : -0.6469998359680176
Agent1_Eval_MinReturn : -36.40156555175781
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -3.258746385574341
Agent1_Train_StdReturn : 7.370774269104004
Agent1_Train_MaxReturn : 7.431812286376953
Agent1_Train_MinReturn : -20.218402862548828
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1471500
Agent1_TimeSinceStart : 2273.032353401184
Agent1_Critic_Loss : 0.5822146534919739
Agent1_Actor_Loss : -0.37782424688339233
Agent1_Alpha_Loss : 0.7249370813369751
Agent1_Temperature : 0.07600576903760252
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 981 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 982 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 983 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 984 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 985 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 986 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 987 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 988 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 989 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 990 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -11.806880950927734
Agent0_Eval_StdReturn : 20.089202880859375
Agent0_Eval_MaxReturn : 16.62969970703125
Agent0_Eval_MinReturn : -52.39033508300781
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -21.626201629638672
Agent0_Train_StdReturn : 28.97140121459961
Agent0_Train_MaxReturn : 23.707611083984375
Agent0_Train_MinReturn : -79.72140502929688
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1486500
Agent0_TimeSinceStart : 2294.2963893413544
Agent0_Critic_Loss : 0.7858671545982361
Agent0_Actor_Loss : -0.8735542893409729
Agent0_Alpha_Loss : 0.72286057472229
Agent0_Temperature : 0.0756199307937586
Agent0_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -11.472442626953125
Agent1_Eval_StdReturn : 9.72396469116211
Agent1_Eval_MaxReturn : 3.5818076133728027
Agent1_Eval_MinReturn : -25.596939086914062
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -9.53809642791748
Agent1_Train_StdReturn : 15.899157524108887
Agent1_Train_MaxReturn : 15.22555160522461
Agent1_Train_MinReturn : -48.696258544921875
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1486500
Agent1_TimeSinceStart : 2296.425236225128
Agent1_Critic_Loss : 0.9404733180999756
Agent1_Actor_Loss : -0.38028472661972046
Agent1_Alpha_Loss : 0.709007978439331
Agent1_Temperature : 0.07579716627623764
Agent1_Initial_DataCollection_AverageReturn : -22.048892974853516
Done logging...




********** Iteration 991 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 992 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 993 ************/home/harvey/anaconda3/envs/285final/lib/python3.7/site-packages/gym/core.py:318: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  "Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future."
/home/harvey/anaconda3/envs/285final/lib/python3.7/site-packages/gym/wrappers/step_api_compatibility.py:40: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  "Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future."
/home/harvey/anaconda3/envs/285final/lib/python3.7/site-packages/gym/core.py:257: DeprecationWarning: [33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.[0m
  "Function `env.seed(seed)` is marked as deprecated and will be removed in the future. "


Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 994 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 995 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 996 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 997 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 998 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 999 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...
./peersacv2.sh: 38: --seed: not found



LOGGING TO:  /home/harvey/Documents/cs285/CS285-Project/cs285/scripts/../../data/peersac_v2_3agents_eps0.7_HalfCheetah-v4_12-12-2022_05-10-19 



########################
logging outputs to  /home/harvey/Documents/cs285/CS285-Project/cs285/scripts/../../data/peersac_v2_3agents_eps0.7_HalfCheetah-v4_12-12-2022_05-10-19
########################
Using GPU id 0


********** Iteration 0 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -37.402889251708984
Agent0_Eval_StdReturn : 29.959867477416992
Agent0_Eval_MaxReturn : 2.8824901580810547
Agent0_Eval_MinReturn : -88.16786193847656
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -68.51490020751953
Agent0_Train_StdReturn : 35.8519172668457
Agent0_Train_MaxReturn : 10.17027473449707
Agent0_Train_MinReturn : -109.59283447265625
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1500
Agent0_TimeSinceStart : 2.120694398880005
Agent0_Critic_Loss : 1.715803623199463
Agent0_Actor_Loss : -0.3432028293609619
Agent0_Alpha_Loss : 0.9863041639328003
Agent0_Temperature : 0.09997000449985415
Agent0_Initial_DataCollection_AverageReturn : -68.51490020751953
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -54.462310791015625
Agent1_Eval_StdReturn : 37.87112045288086
Agent1_Eval_MaxReturn : 15.620088577270508
Agent1_Eval_MinReturn : -98.72659301757812
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -41.37040710449219
Agent1_Train_StdReturn : 23.476428985595703
Agent1_Train_MaxReturn : -3.7883758544921875
Agent1_Train_MinReturn : -74.03202819824219
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1500
Agent1_TimeSinceStart : 4.123557806015015
Agent1_Critic_Loss : 1.1657971143722534
Agent1_Actor_Loss : -0.489025354385376
Agent1_Alpha_Loss : 0.980064868927002
Agent1_Temperature : 0.09997000449985606
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 1 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 2 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 3 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 4 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 5 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 6 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 7 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 8 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 9 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 10 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -37.685211181640625
Agent0_Eval_StdReturn : 44.345184326171875
Agent0_Eval_MaxReturn : 31.674013137817383
Agent0_Eval_MinReturn : -103.45191192626953
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -54.6635627746582
Agent0_Train_StdReturn : 27.195486068725586
Agent0_Train_MaxReturn : -19.33170509338379
Agent0_Train_MinReturn : -98.11860656738281
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 16500
Agent0_TimeSinceStart : 24.32830309867859
Agent0_Critic_Loss : 0.8373746275901794
Agent0_Actor_Loss : -0.46256136894226074
Agent0_Alpha_Loss : 0.985603928565979
Agent0_Temperature : 0.09967050570099503
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -50.62293243408203
Agent1_Eval_StdReturn : 26.392087936401367
Agent1_Eval_MaxReturn : -12.900577545166016
Agent1_Eval_MinReturn : -94.58116912841797
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -53.674110412597656
Agent1_Train_StdReturn : 36.0290641784668
Agent1_Train_MaxReturn : 0.690129280090332
Agent1_Train_MinReturn : -104.06132507324219
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 16500
Agent1_TimeSinceStart : 26.402756452560425
Agent1_Critic_Loss : 1.008055329322815
Agent1_Actor_Loss : -0.6123250722885132
Agent1_Alpha_Loss : 0.9858437776565552
Agent1_Temperature : 0.09967042347331709
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 11 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 12 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 13 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 14 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 15 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 16 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 17 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 18 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 19 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 20 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -45.494686126708984
Agent0_Eval_StdReturn : 30.17737579345703
Agent0_Eval_MaxReturn : -7.503595352172852
Agent0_Eval_MinReturn : -121.47244262695312
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -39.61127471923828
Agent0_Train_StdReturn : 23.621410369873047
Agent0_Train_MaxReturn : 5.289003372192383
Agent0_Train_MinReturn : -88.8792724609375
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 31500
Agent0_TimeSinceStart : 47.38067960739136
Agent0_Critic_Loss : 0.908815324306488
Agent0_Actor_Loss : -0.45476871728897095
Agent0_Alpha_Loss : 0.9913457632064819
Agent0_Temperature : 0.09937190399477794
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -62.5821418762207
Agent1_Eval_StdReturn : 25.592683792114258
Agent1_Eval_MaxReturn : -18.3220272064209
Agent1_Eval_MinReturn : -113.60840606689453
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -48.92052459716797
Agent1_Train_StdReturn : 22.756526947021484
Agent1_Train_MaxReturn : -11.142505645751953
Agent1_Train_MinReturn : -90.7967529296875
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 31500
Agent1_TimeSinceStart : 49.47833013534546
Agent1_Critic_Loss : 0.7213486433029175
Agent1_Actor_Loss : -0.5457414388656616
Agent1_Alpha_Loss : 0.9900323152542114
Agent1_Temperature : 0.09937169359767932
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 21 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 22 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 23 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 24 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 25 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 26 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 27 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 28 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 29 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 30 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -23.911243438720703
Agent0_Eval_StdReturn : 33.93391799926758
Agent0_Eval_MaxReturn : 39.76156997680664
Agent0_Eval_MinReturn : -68.91899108886719
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -28.77459716796875
Agent0_Train_StdReturn : 30.964950561523438
Agent0_Train_MaxReturn : 18.875926971435547
Agent0_Train_MinReturn : -78.33903503417969
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 46500
Agent0_TimeSinceStart : 70.37691187858582
Agent0_Critic_Loss : 0.8300429582595825
Agent0_Actor_Loss : -0.37424296140670776
Agent0_Alpha_Loss : 0.9887595176696777
Agent0_Temperature : 0.09907414800389827
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -52.08916091918945
Agent1_Eval_StdReturn : 35.92718505859375
Agent1_Eval_MaxReturn : -5.319303512573242
Agent1_Eval_MinReturn : -117.17921447753906
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -53.44548797607422
Agent1_Train_StdReturn : 25.804882049560547
Agent1_Train_MaxReturn : -0.8327028751373291
Agent1_Train_MinReturn : -90.64338684082031
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 46500
Agent1_TimeSinceStart : 72.4532356262207
Agent1_Critic_Loss : 0.8816229104995728
Agent1_Actor_Loss : -0.6392016410827637
Agent1_Alpha_Loss : 0.9843180179595947
Agent1_Temperature : 0.09907398017970483
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 31 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 32 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 33 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 34 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 35 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 36 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 37 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 38 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 39 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 40 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -42.48796463012695
Agent0_Eval_StdReturn : 41.66389465332031
Agent0_Eval_MaxReturn : 32.2967529296875
Agent0_Eval_MinReturn : -109.15443420410156
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -58.38914108276367
Agent0_Train_StdReturn : 35.39087677001953
Agent0_Train_MaxReturn : -8.899569511413574
Agent0_Train_MinReturn : -127.76921844482422
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 61500
Agent0_TimeSinceStart : 93.37958073616028
Agent0_Critic_Loss : 0.82547527551651
Agent0_Actor_Loss : -0.5169690847396851
Agent0_Alpha_Loss : 0.9816807508468628
Agent0_Temperature : 0.09877776785263395
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -24.627334594726562
Agent1_Eval_StdReturn : 34.93402862548828
Agent1_Eval_MaxReturn : 33.762271881103516
Agent1_Eval_MinReturn : -68.66389465332031
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -61.18833541870117
Agent1_Train_StdReturn : 38.64781951904297
Agent1_Train_MaxReturn : -18.19982147216797
Agent1_Train_MinReturn : -122.73313903808594
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 61500
Agent1_TimeSinceStart : 95.46354699134827
Agent1_Critic_Loss : 0.680485725402832
Agent1_Actor_Loss : -0.5203308463096619
Agent1_Alpha_Loss : 0.9787918329238892
Agent1_Temperature : 0.09877754687251074
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 41 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 42 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 43 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 44 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 45 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 46 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 47 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 48 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 49 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 50 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -43.901023864746094
Agent0_Eval_StdReturn : 34.91496276855469
Agent0_Eval_MaxReturn : 16.775104522705078
Agent0_Eval_MinReturn : -84.60401916503906
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -28.17091941833496
Agent0_Train_StdReturn : 24.439098358154297
Agent0_Train_MaxReturn : 13.829269409179688
Agent0_Train_MinReturn : -60.47304153442383
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 76500
Agent0_TimeSinceStart : 116.33737087249756
Agent0_Critic_Loss : 0.6528903245925903
Agent0_Actor_Loss : -0.482453852891922
Agent0_Alpha_Loss : 0.9721272587776184
Agent0_Temperature : 0.09848297934924549
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -38.628196716308594
Agent1_Eval_StdReturn : 34.70564651489258
Agent1_Eval_MaxReturn : 21.23910903930664
Agent1_Eval_MinReturn : -95.34905242919922
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -39.06199264526367
Agent1_Train_StdReturn : 40.57541275024414
Agent1_Train_MaxReturn : 1.4306726455688477
Agent1_Train_MinReturn : -115.6498031616211
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 76500
Agent1_TimeSinceStart : 118.4099690914154
Agent1_Critic_Loss : 0.6211122274398804
Agent1_Actor_Loss : -0.5585347414016724
Agent1_Alpha_Loss : 0.9855052828788757
Agent1_Temperature : 0.09848270740327757
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 51 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 52 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 53 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 54 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 55 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 56 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 57 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 58 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 59 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 60 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -39.08828353881836
Agent0_Eval_StdReturn : 27.755565643310547
Agent0_Eval_MaxReturn : 16.0465087890625
Agent0_Eval_MinReturn : -83.75820922851562
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -38.82654571533203
Agent0_Train_StdReturn : 31.275407791137695
Agent0_Train_MaxReturn : 27.09213638305664
Agent0_Train_MinReturn : -72.43374633789062
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 91500
Agent0_TimeSinceStart : 139.39940214157104
Agent0_Critic_Loss : 0.6207876205444336
Agent0_Actor_Loss : -0.43060213327407837
Agent0_Alpha_Loss : 0.9665896892547607
Agent0_Temperature : 0.0981898017701898
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -39.48919677734375
Agent1_Eval_StdReturn : 27.753679275512695
Agent1_Eval_MaxReturn : 24.651227951049805
Agent1_Eval_MinReturn : -77.60028839111328
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -47.74091339111328
Agent1_Train_StdReturn : 41.18108367919922
Agent1_Train_MaxReturn : 9.226795196533203
Agent1_Train_MinReturn : -123.71248626708984
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 91500
Agent1_TimeSinceStart : 141.4928846359253
Agent1_Critic_Loss : 0.6271668672561646
Agent1_Actor_Loss : -0.5286806225776672
Agent1_Alpha_Loss : 0.9724382758140564
Agent1_Temperature : 0.09818900993532428
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 61 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 62 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 63 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 64 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 65 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 66 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 67 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 68 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 69 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 70 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -45.86338806152344
Agent0_Eval_StdReturn : 40.774566650390625
Agent0_Eval_MaxReturn : 1.1807332038879395
Agent0_Eval_MinReturn : -143.31568908691406
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -48.267601013183594
Agent0_Train_StdReturn : 28.351638793945312
Agent0_Train_MaxReturn : -14.576025009155273
Agent0_Train_MinReturn : -108.66163635253906
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 106500
Agent0_TimeSinceStart : 162.5538215637207
Agent0_Critic_Loss : 0.5864908695220947
Agent0_Actor_Loss : -0.3091367483139038
Agent0_Alpha_Loss : 0.9612684845924377
Agent0_Temperature : 0.09789833150927026
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -24.579381942749023
Agent1_Eval_StdReturn : 21.653505325317383
Agent1_Eval_MaxReturn : 16.98847770690918
Agent1_Eval_MinReturn : -62.08421325683594
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -23.19736099243164
Agent1_Train_StdReturn : 28.689678192138672
Agent1_Train_MaxReturn : 26.59537696838379
Agent1_Train_MinReturn : -65.66950988769531
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 106500
Agent1_TimeSinceStart : 164.65836310386658
Agent1_Critic_Loss : 0.6535987854003906
Agent1_Actor_Loss : -0.5855532288551331
Agent1_Alpha_Loss : 0.9608615636825562
Agent1_Temperature : 0.09789730682941951
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 71 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 72 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 73 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 74 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 75 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 76 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 77 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 78 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 79 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 80 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -57.740928649902344
Agent0_Eval_StdReturn : 16.697908401489258
Agent0_Eval_MaxReturn : -18.171043395996094
Agent0_Eval_MinReturn : -75.16082763671875
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -34.1536865234375
Agent0_Train_StdReturn : 32.642757415771484
Agent0_Train_MaxReturn : 30.81861114501953
Agent0_Train_MinReturn : -100.46644592285156
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 121500
Agent0_TimeSinceStart : 185.65203833580017
Agent0_Critic_Loss : 0.5806560516357422
Agent0_Actor_Loss : -0.4642857313156128
Agent0_Alpha_Loss : 0.951575756072998
Agent0_Temperature : 0.09760971196737685
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -20.03460121154785
Agent1_Eval_StdReturn : 36.73201370239258
Agent1_Eval_MaxReturn : 30.931385040283203
Agent1_Eval_MinReturn : -87.78128051757812
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -14.451118469238281
Agent1_Train_StdReturn : 24.153827667236328
Agent1_Train_MaxReturn : 39.819374084472656
Agent1_Train_MinReturn : -45.69720458984375
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 121500
Agent1_TimeSinceStart : 187.74160718917847
Agent1_Critic_Loss : 0.5932469367980957
Agent1_Actor_Loss : -0.582650899887085
Agent1_Alpha_Loss : 0.944987416267395
Agent1_Temperature : 0.09760833002840158
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 81 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 82 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 83 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 84 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 85 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 86 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 87 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 88 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 89 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 90 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -18.911710739135742
Agent0_Eval_StdReturn : 19.042133331298828
Agent0_Eval_MaxReturn : 5.480826377868652
Agent0_Eval_MinReturn : -51.81776428222656
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -22.930614471435547
Agent0_Train_StdReturn : 10.993973731994629
Agent0_Train_MaxReturn : -6.990386009216309
Agent0_Train_MinReturn : -44.3492546081543
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 136500
Agent0_TimeSinceStart : 208.64130401611328
Agent0_Critic_Loss : 0.5526090860366821
Agent0_Actor_Loss : -0.43937161564826965
Agent0_Alpha_Loss : 0.9252187609672546
Agent0_Temperature : 0.0973249690158481
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -26.675079345703125
Agent1_Eval_StdReturn : 16.90538787841797
Agent1_Eval_MaxReturn : 9.21036148071289
Agent1_Eval_MinReturn : -60.9470329284668
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -33.210933685302734
Agent1_Train_StdReturn : 19.936933517456055
Agent1_Train_MaxReturn : -6.895959854125977
Agent1_Train_MinReturn : -71.10173034667969
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 136500
Agent1_TimeSinceStart : 210.71510100364685
Agent1_Critic_Loss : 0.5039577484130859
Agent1_Actor_Loss : -0.6223593950271606
Agent1_Alpha_Loss : 0.9487343430519104
Agent1_Temperature : 0.097322792543652
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 91 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 92 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 93 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 94 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 95 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 96 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 97 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 98 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 99 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 100 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -35.595645904541016
Agent0_Eval_StdReturn : 19.209590911865234
Agent0_Eval_MaxReturn : -14.42751407623291
Agent0_Eval_MinReturn : -80.88053894042969
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -20.597991943359375
Agent0_Train_StdReturn : 16.36118507385254
Agent0_Train_MaxReturn : 0.6185092926025391
Agent0_Train_MinReturn : -48.91190719604492
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 151500
Agent0_TimeSinceStart : 231.61143231391907
Agent0_Critic_Loss : 0.472941517829895
Agent0_Actor_Loss : -0.513453483581543
Agent0_Alpha_Loss : 0.8879255056381226
Agent0_Temperature : 0.09704572522167731
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -29.22688865661621
Agent1_Eval_StdReturn : 28.220563888549805
Agent1_Eval_MaxReturn : -2.6020803451538086
Agent1_Eval_MinReturn : -102.65426635742188
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -22.710859298706055
Agent1_Train_StdReturn : 15.009092330932617
Agent1_Train_MaxReturn : 0.2420358657836914
Agent1_Train_MinReturn : -50.37054443359375
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 151500
Agent1_TimeSinceStart : 233.70076751708984
Agent1_Critic_Loss : 0.5286824703216553
Agent1_Actor_Loss : -0.7331403493881226
Agent1_Alpha_Loss : 0.8976542949676514
Agent1_Temperature : 0.09704129349395751
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 101 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 102 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 103 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 104 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 105 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 106 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 107 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 108 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 109 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 110 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -27.971942901611328
Agent0_Eval_StdReturn : 21.027334213256836
Agent0_Eval_MaxReturn : 3.1342058181762695
Agent0_Eval_MinReturn : -72.32434844970703
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -22.487213134765625
Agent0_Train_StdReturn : 14.881498336791992
Agent0_Train_MaxReturn : 3.208456039428711
Agent0_Train_MinReturn : -47.32676696777344
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 166500
Agent0_TimeSinceStart : 254.59418892860413
Agent0_Critic_Loss : 0.4828214943408966
Agent0_Actor_Loss : -0.5524557828903198
Agent0_Alpha_Loss : 0.8290984630584717
Agent0_Temperature : 0.09677510386926476
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -23.855926513671875
Agent1_Eval_StdReturn : 15.141301155090332
Agent1_Eval_MaxReturn : -2.058307647705078
Agent1_Eval_MinReturn : -43.35826873779297
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -19.497196197509766
Agent1_Train_StdReturn : 13.770493507385254
Agent1_Train_MaxReturn : -0.3432483673095703
Agent1_Train_MinReturn : -45.643760681152344
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 166500
Agent1_TimeSinceStart : 256.68576669692993
Agent1_Critic_Loss : 0.4023236334323883
Agent1_Actor_Loss : -0.7113865613937378
Agent1_Alpha_Loss : 0.8624265789985657
Agent1_Temperature : 0.096767199279536
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 111 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 112 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 113 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 114 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 115 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 116 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 117 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 118 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 119 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 120 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -23.914447784423828
Agent0_Eval_StdReturn : 12.617260932922363
Agent0_Eval_MaxReturn : -0.4300971031188965
Agent0_Eval_MinReturn : -40.079246520996094
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -23.298133850097656
Agent0_Train_StdReturn : 9.497221946716309
Agent0_Train_MaxReturn : -10.117181777954102
Agent0_Train_MinReturn : -37.47518539428711
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 181500
Agent0_TimeSinceStart : 277.66377353668213
Agent0_Critic_Loss : 0.5247969627380371
Agent0_Actor_Loss : -0.4858010709285736
Agent0_Alpha_Loss : 0.7962958216667175
Agent0_Temperature : 0.09651489137209784
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -25.668140411376953
Agent1_Eval_StdReturn : 10.363203048706055
Agent1_Eval_MaxReturn : -10.154350280761719
Agent1_Eval_MinReturn : -45.0520133972168
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -16.84282112121582
Agent1_Train_StdReturn : 12.353865623474121
Agent1_Train_MaxReturn : 3.789245843887329
Agent1_Train_MinReturn : -38.30876922607422
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 181500
Agent1_TimeSinceStart : 279.75787138938904
Agent1_Critic_Loss : 0.4262067675590515
Agent1_Actor_Loss : -0.6990082263946533
Agent1_Alpha_Loss : 0.8068208694458008
Agent1_Temperature : 0.09650270441332454
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 121 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 122 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 123 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 124 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 125 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 126 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 127 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 128 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 129 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 130 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -29.237524032592773
Agent0_Eval_StdReturn : 8.33868408203125
Agent0_Eval_MaxReturn : -16.61334991455078
Agent0_Eval_MinReturn : -43.87238693237305
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -27.231592178344727
Agent0_Train_StdReturn : 13.203692436218262
Agent0_Train_MaxReturn : -12.11203670501709
Agent0_Train_MinReturn : -54.65123748779297
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 196500
Agent0_TimeSinceStart : 300.83915066719055
Agent0_Critic_Loss : 0.40555065870285034
Agent0_Actor_Loss : -0.41883862018585205
Agent0_Alpha_Loss : 0.7811933755874634
Agent0_Temperature : 0.09626526172577683
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -31.510950088500977
Agent1_Eval_StdReturn : 13.749608039855957
Agent1_Eval_MaxReturn : -5.3707380294799805
Agent1_Eval_MinReturn : -53.800575256347656
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -24.887664794921875
Agent1_Train_StdReturn : 10.742012023925781
Agent1_Train_MaxReturn : -10.029874801635742
Agent1_Train_MinReturn : -52.06321334838867
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 196500
Agent1_TimeSinceStart : 302.9362840652466
Agent1_Critic_Loss : 0.44284334778785706
Agent1_Actor_Loss : -0.6064164638519287
Agent1_Alpha_Loss : 0.7811304330825806
Agent1_Temperature : 0.09624821473912808
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 131 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 132 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 133 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 134 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 135 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 136 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 137 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 138 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 139 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 140 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -28.179800033569336
Agent0_Eval_StdReturn : 11.061592102050781
Agent0_Eval_MaxReturn : -6.464262008666992
Agent0_Eval_MinReturn : -43.89004135131836
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -35.91026306152344
Agent0_Train_StdReturn : 5.49947452545166
Agent0_Train_MaxReturn : -29.046140670776367
Agent0_Train_MinReturn : -45.01885986328125
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 211500
Agent0_TimeSinceStart : 323.9702858924866
Agent0_Critic_Loss : 0.4233839511871338
Agent0_Actor_Loss : -0.48083651065826416
Agent0_Alpha_Loss : 0.7779264450073242
Agent0_Temperature : 0.0960201291178374
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -32.39990234375
Agent1_Eval_StdReturn : 18.19559669494629
Agent1_Eval_MaxReturn : -10.408470153808594
Agent1_Eval_MinReturn : -62.953269958496094
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -24.372106552124023
Agent1_Train_StdReturn : 12.289799690246582
Agent1_Train_MaxReturn : -12.074409484863281
Agent1_Train_MinReturn : -50.75745391845703
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 211500
Agent1_TimeSinceStart : 326.06663846969604
Agent1_Critic_Loss : 0.38473328948020935
Agent1_Actor_Loss : -0.604936957359314
Agent1_Alpha_Loss : 0.8158122301101685
Agent1_Temperature : 0.09599890652574238
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 141 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 142 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 143 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 144 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 145 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 146 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 147 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 148 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 149 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 150 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -32.09208297729492
Agent0_Eval_StdReturn : 15.571813583374023
Agent0_Eval_MaxReturn : -5.844307899475098
Agent0_Eval_MinReturn : -57.57570266723633
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -24.01610565185547
Agent0_Train_StdReturn : 10.273805618286133
Agent0_Train_MaxReturn : -8.530074119567871
Agent0_Train_MinReturn : -45.28411102294922
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 226500
Agent0_TimeSinceStart : 347.18293380737305
Agent0_Critic_Loss : 0.3618822693824768
Agent0_Actor_Loss : -0.3964979648590088
Agent0_Alpha_Loss : 0.7924995422363281
Agent0_Temperature : 0.09577447234189639
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -23.42129135131836
Agent1_Eval_StdReturn : 10.645944595336914
Agent1_Eval_MaxReturn : -9.490917205810547
Agent1_Eval_MinReturn : -45.08605194091797
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -26.865137100219727
Agent1_Train_StdReturn : 16.65516471862793
Agent1_Train_MaxReturn : 4.466833114624023
Agent1_Train_MinReturn : -55.00008773803711
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 226500
Agent1_TimeSinceStart : 349.27082538604736
Agent1_Critic_Loss : 0.4158593416213989
Agent1_Actor_Loss : -0.6393843293190002
Agent1_Alpha_Loss : 0.7970467805862427
Agent1_Temperature : 0.09574898126982496
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 151 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 152 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 153 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 154 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 155 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 156 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 157 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 158 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 159 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 160 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -29.573535919189453
Agent0_Eval_StdReturn : 13.771610260009766
Agent0_Eval_MaxReturn : -6.3410444259643555
Agent0_Eval_MinReturn : -60.41024398803711
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -16.25089454650879
Agent0_Train_StdReturn : 12.72146224975586
Agent0_Train_MaxReturn : 2.4174931049346924
Agent0_Train_MinReturn : -40.249122619628906
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 241500
Agent0_TimeSinceStart : 370.3051586151123
Agent0_Critic_Loss : 0.458523690700531
Agent0_Actor_Loss : -0.48230457305908203
Agent0_Alpha_Loss : 0.8092978000640869
Agent0_Temperature : 0.09552526595685996
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -27.482757568359375
Agent1_Eval_StdReturn : 12.716955184936523
Agent1_Eval_MaxReturn : -6.867778778076172
Agent1_Eval_MinReturn : -46.216712951660156
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -26.98417091369629
Agent1_Train_StdReturn : 12.341464042663574
Agent1_Train_MaxReturn : -14.021146774291992
Agent1_Train_MinReturn : -54.241607666015625
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 241500
Agent1_TimeSinceStart : 372.3967053890228
Agent1_Critic_Loss : 0.4831162989139557
Agent1_Actor_Loss : -0.549691379070282
Agent1_Alpha_Loss : 0.8301656246185303
Agent1_Temperature : 0.09549683604552052
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 161 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 162 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 163 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 164 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 165 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 166 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 167 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 168 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 169 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 170 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -22.570350646972656
Agent0_Eval_StdReturn : 18.7568302154541
Agent0_Eval_MaxReturn : 6.652616024017334
Agent0_Eval_MinReturn : -51.21043014526367
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -21.90713119506836
Agent0_Train_StdReturn : 11.824872016906738
Agent0_Train_MaxReturn : -9.270350456237793
Agent0_Train_MinReturn : -55.38890838623047
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 256500
Agent0_TimeSinceStart : 393.4663829803467
Agent0_Critic_Loss : 0.2950780689716339
Agent0_Actor_Loss : -0.3263534903526306
Agent0_Alpha_Loss : 0.8020723462104797
Agent0_Temperature : 0.09527249595412907
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -24.12229347229004
Agent1_Eval_StdReturn : 17.74641227722168
Agent1_Eval_MaxReturn : -1.1189918518066406
Agent1_Eval_MinReturn : -52.356658935546875
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -21.88555908203125
Agent1_Train_StdReturn : 14.959595680236816
Agent1_Train_MaxReturn : 5.82627010345459
Agent1_Train_MinReturn : -49.45237731933594
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 256500
Agent1_TimeSinceStart : 395.55687642097473
Agent1_Critic_Loss : 0.29194530844688416
Agent1_Actor_Loss : -0.4949231445789337
Agent1_Alpha_Loss : 0.8035787343978882
Agent1_Temperature : 0.095243022631243
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 171 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 172 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 173 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 174 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 175 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 176 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 177 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 178 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 179 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 180 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -21.451671600341797
Agent0_Eval_StdReturn : 11.062233924865723
Agent0_Eval_MaxReturn : -4.478767395019531
Agent0_Eval_MinReturn : -40.5152702331543
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -15.115275382995605
Agent0_Train_StdReturn : 10.809852600097656
Agent0_Train_MaxReturn : 5.064370632171631
Agent0_Train_MinReturn : -31.539310455322266
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 271500
Agent0_TimeSinceStart : 416.6042296886444
Agent0_Critic_Loss : 0.3589446544647217
Agent0_Actor_Loss : -0.48896193504333496
Agent0_Alpha_Loss : 0.7966700792312622
Agent0_Temperature : 0.09501899923223489
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -13.274473190307617
Agent1_Eval_StdReturn : 8.177864074707031
Agent1_Eval_MaxReturn : 2.8292934894561768
Agent1_Eval_MinReturn : -26.583269119262695
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -28.782154083251953
Agent1_Train_StdReturn : 12.484221458435059
Agent1_Train_MaxReturn : -13.88539981842041
Agent1_Train_MinReturn : -50.746009826660156
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 271500
Agent1_TimeSinceStart : 418.696852684021
Agent1_Critic_Loss : 0.30105727910995483
Agent1_Actor_Loss : -0.5782226324081421
Agent1_Alpha_Loss : 0.8100159168243408
Agent1_Temperature : 0.09498828680141663
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 181 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 182 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 183 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 184 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 185 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 186 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 187 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 188 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 189 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 190 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -23.080810546875
Agent0_Eval_StdReturn : 18.678821563720703
Agent0_Eval_MaxReturn : 11.518983840942383
Agent0_Eval_MinReturn : -46.20799255371094
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -20.861268997192383
Agent0_Train_StdReturn : 5.9333882331848145
Agent0_Train_MaxReturn : -12.010245323181152
Agent0_Train_MinReturn : -30.154497146606445
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 286500
Agent0_TimeSinceStart : 439.7402241230011
Agent0_Critic_Loss : 0.35383716225624084
Agent0_Actor_Loss : -0.3910459876060486
Agent0_Alpha_Loss : 0.7795610427856445
Agent0_Temperature : 0.09476634184117562
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -20.583419799804688
Agent1_Eval_StdReturn : 12.787023544311523
Agent1_Eval_MaxReturn : -2.3425827026367188
Agent1_Eval_MinReturn : -47.25272750854492
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -21.899477005004883
Agent1_Train_StdReturn : 14.24496078491211
Agent1_Train_MaxReturn : -4.179157257080078
Agent1_Train_MinReturn : -50.15398406982422
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 286500
Agent1_TimeSinceStart : 441.84066438674927
Agent1_Critic_Loss : 0.2933744490146637
Agent1_Actor_Loss : -0.5358687043190002
Agent1_Alpha_Loss : 0.8006383180618286
Agent1_Temperature : 0.09473269680560828
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 191 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 192 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 193 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 194 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 195 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 196 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 197 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 198 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 199 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 200 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -24.221059799194336
Agent0_Eval_StdReturn : 12.881755828857422
Agent0_Eval_MaxReturn : 4.778510093688965
Agent0_Eval_MinReturn : -37.83811950683594
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -21.113311767578125
Agent0_Train_StdReturn : 12.325566291809082
Agent0_Train_MaxReturn : -7.30026388168335
Agent0_Train_MinReturn : -51.85346984863281
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 301500
Agent0_TimeSinceStart : 462.84971165657043
Agent0_Critic_Loss : 0.24416856467723846
Agent0_Actor_Loss : -0.3414125442504883
Agent0_Alpha_Loss : 0.7931967973709106
Agent0_Temperature : 0.09451589170530626
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -17.066085815429688
Agent1_Eval_StdReturn : 12.054518699645996
Agent1_Eval_MaxReturn : 3.436809539794922
Agent1_Eval_MinReturn : -34.234703063964844
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -24.33354949951172
Agent1_Train_StdReturn : 16.90970802307129
Agent1_Train_MaxReturn : 1.6033477783203125
Agent1_Train_MinReturn : -61.454551696777344
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 301500
Agent1_TimeSinceStart : 464.84469270706177
Agent1_Critic_Loss : 0.2832069993019104
Agent1_Actor_Loss : -0.49506574869155884
Agent1_Alpha_Loss : 0.7998313903808594
Agent1_Temperature : 0.09447741679524656
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 201 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 202 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 203 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 204 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 205 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 206 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 207 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 208 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 209 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 210 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -22.89394187927246
Agent0_Eval_StdReturn : 10.56456470489502
Agent0_Eval_MaxReturn : -5.911807537078857
Agent0_Eval_MinReturn : -40.680259704589844
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -16.756088256835938
Agent0_Train_StdReturn : 11.973196983337402
Agent0_Train_MaxReturn : -0.06158924102783203
Agent0_Train_MinReturn : -37.893516540527344
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 316500
Agent0_TimeSinceStart : 485.1135952472687
Agent0_Critic_Loss : 0.2425498217344284
Agent0_Actor_Loss : -0.32601800560951233
Agent0_Alpha_Loss : 0.764508068561554
Agent0_Temperature : 0.09426517354133625
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -16.74441146850586
Agent1_Eval_StdReturn : 14.681727409362793
Agent1_Eval_MaxReturn : 1.598794937133789
Agent1_Eval_MinReturn : -37.63935089111328
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -14.5377779006958
Agent1_Train_StdReturn : 13.278982162475586
Agent1_Train_MaxReturn : 7.585965633392334
Agent1_Train_MinReturn : -42.730037689208984
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 316500
Agent1_TimeSinceStart : 487.1274390220642
Agent1_Critic_Loss : 0.2363317608833313
Agent1_Actor_Loss : -0.5142947435379028
Agent1_Alpha_Loss : 0.7827929854393005
Agent1_Temperature : 0.09422320886030171
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 211 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 212 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 213 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 214 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 215 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 216 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 217 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 218 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 219 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 220 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -25.610885620117188
Agent0_Eval_StdReturn : 13.02552604675293
Agent0_Eval_MaxReturn : -6.248175621032715
Agent0_Eval_MinReturn : -50.6311149597168
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -8.345987319946289
Agent0_Train_StdReturn : 14.791479110717773
Agent0_Train_MaxReturn : 21.431745529174805
Agent0_Train_MinReturn : -33.2857551574707
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 331500
Agent0_TimeSinceStart : 507.37414622306824
Agent0_Critic_Loss : 0.24489642679691315
Agent0_Actor_Loss : -0.37295448780059814
Agent0_Alpha_Loss : 0.7634649872779846
Agent0_Temperature : 0.09401431660838158
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -20.11275863647461
Agent1_Eval_StdReturn : 11.308828353881836
Agent1_Eval_MaxReturn : -4.031108856201172
Agent1_Eval_MinReturn : -41.545501708984375
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -9.889909744262695
Agent1_Train_StdReturn : 12.63749885559082
Agent1_Train_MaxReturn : 10.625537872314453
Agent1_Train_MinReturn : -26.15903091430664
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 331500
Agent1_TimeSinceStart : 509.4542052745819
Agent1_Critic_Loss : 0.2845628559589386
Agent1_Actor_Loss : -0.4267759919166565
Agent1_Alpha_Loss : 0.7652379274368286
Agent1_Temperature : 0.09396956115613918
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 221 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 222 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 223 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 224 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 225 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 226 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 227 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 228 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 229 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 230 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -18.140609741210938
Agent0_Eval_StdReturn : 21.62670135498047
Agent0_Eval_MaxReturn : 15.122564315795898
Agent0_Eval_MinReturn : -51.946800231933594
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -18.888076782226562
Agent0_Train_StdReturn : 16.01213264465332
Agent0_Train_MaxReturn : 2.5964739322662354
Agent0_Train_MinReturn : -43.75859069824219
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 346500
Agent0_TimeSinceStart : 530.5160872936249
Agent0_Critic_Loss : 0.22968792915344238
Agent0_Actor_Loss : -0.3686385750770569
Agent0_Alpha_Loss : 0.7665611505508423
Agent0_Temperature : 0.09376328586294577
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -16.208393096923828
Agent1_Eval_StdReturn : 27.39682960510254
Agent1_Eval_MaxReturn : 33.258174896240234
Agent1_Eval_MinReturn : -68.622802734375
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -18.420013427734375
Agent1_Train_StdReturn : 14.328943252563477
Agent1_Train_MaxReturn : 0.14583683013916016
Agent1_Train_MinReturn : -44.257774353027344
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 346500
Agent1_TimeSinceStart : 532.605462551117
Agent1_Critic_Loss : 0.31142115592956543
Agent1_Actor_Loss : -0.4477066397666931
Agent1_Alpha_Loss : 0.8035212755203247
Agent1_Temperature : 0.09371648827574391
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 231 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 232 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 233 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 234 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 235 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 236 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 237 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 238 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 239 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 240 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -17.875343322753906
Agent0_Eval_StdReturn : 26.31999969482422
Agent0_Eval_MaxReturn : 12.77238941192627
Agent0_Eval_MinReturn : -80.39018249511719
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -19.074726104736328
Agent0_Train_StdReturn : 16.57656478881836
Agent0_Train_MaxReturn : 0.15634667873382568
Agent0_Train_MinReturn : -59.88679885864258
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 361500
Agent0_TimeSinceStart : 553.5464999675751
Agent0_Critic_Loss : 0.24125131964683533
Agent0_Actor_Loss : -0.35479623079299927
Agent0_Alpha_Loss : 0.7944284081459045
Agent0_Temperature : 0.09351098321381085
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -21.276248931884766
Agent1_Eval_StdReturn : 18.06768035888672
Agent1_Eval_MaxReturn : 0.10350990295410156
Agent1_Eval_MinReturn : -63.541831970214844
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -33.39060592651367
Agent1_Train_StdReturn : 15.676782608032227
Agent1_Train_MaxReturn : -10.032173156738281
Agent1_Train_MinReturn : -63.6854248046875
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 361500
Agent1_TimeSinceStart : 555.6271824836731
Agent1_Critic_Loss : 0.3092646896839142
Agent1_Actor_Loss : -0.5419119596481323
Agent1_Alpha_Loss : 0.8007046580314636
Agent1_Temperature : 0.09346138469084363
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 241 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 242 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 243 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 244 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 245 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 246 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 247 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 248 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 249 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 250 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -25.634023666381836
Agent0_Eval_StdReturn : 21.90261459350586
Agent0_Eval_MaxReturn : 9.166349411010742
Agent0_Eval_MinReturn : -70.68601989746094
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -19.152841567993164
Agent0_Train_StdReturn : 25.41727638244629
Agent0_Train_MaxReturn : -0.7273216247558594
Agent0_Train_MinReturn : -90.83727264404297
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 376500
Agent0_TimeSinceStart : 576.5858812332153
Agent0_Critic_Loss : 0.28468334674835205
Agent0_Actor_Loss : -0.34473103284835815
Agent0_Alpha_Loss : 0.7875960469245911
Agent0_Temperature : 0.09325697535361407
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -24.77789306640625
Agent1_Eval_StdReturn : 19.437252044677734
Agent1_Eval_MaxReturn : 5.968703269958496
Agent1_Eval_MinReturn : -64.14236450195312
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -15.103790283203125
Agent1_Train_StdReturn : 9.172513008117676
Agent1_Train_MaxReturn : 3.390265941619873
Agent1_Train_MinReturn : -29.362506866455078
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 376500
Agent1_TimeSinceStart : 578.665768623352
Agent1_Critic_Loss : 0.24743518233299255
Agent1_Actor_Loss : -0.5872371196746826
Agent1_Alpha_Loss : 0.8061099648475647
Agent1_Temperature : 0.09320419059389247
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 251 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 252 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 253 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 254 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 255 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 256 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 257 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 258 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 259 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 260 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -20.730976104736328
Agent0_Eval_StdReturn : 12.914645195007324
Agent0_Eval_MaxReturn : -3.539736747741699
Agent0_Eval_MinReturn : -43.58140182495117
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -12.943077087402344
Agent0_Train_StdReturn : 14.783491134643555
Agent0_Train_MaxReturn : 9.324638366699219
Agent0_Train_MinReturn : -41.678504943847656
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 391500
Agent0_TimeSinceStart : 599.5690321922302
Agent0_Critic_Loss : 0.30612289905548096
Agent0_Actor_Loss : -0.34038758277893066
Agent0_Alpha_Loss : 0.7949931025505066
Agent0_Temperature : 0.0930026198500182
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -31.12417221069336
Agent1_Eval_StdReturn : 18.02857780456543
Agent1_Eval_MaxReturn : -12.182174682617188
Agent1_Eval_MinReturn : -74.78083038330078
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -17.347980499267578
Agent1_Train_StdReturn : 22.95285415649414
Agent1_Train_MaxReturn : 18.323957443237305
Agent1_Train_MinReturn : -56.586082458496094
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 391500
Agent1_TimeSinceStart : 601.6446340084076
Agent1_Critic_Loss : 0.2679683566093445
Agent1_Actor_Loss : -0.47841882705688477
Agent1_Alpha_Loss : 0.8053375482559204
Agent1_Temperature : 0.0929466706553223
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 261 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 262 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 263 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 264 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 265 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 266 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 267 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 268 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 269 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 270 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -32.12322235107422
Agent0_Eval_StdReturn : 22.37763023376465
Agent0_Eval_MaxReturn : 15.903060913085938
Agent0_Eval_MinReturn : -69.08450317382812
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -13.473609924316406
Agent0_Train_StdReturn : 19.32143783569336
Agent0_Train_MaxReturn : 16.28843116760254
Agent0_Train_MinReturn : -43.45271301269531
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 406500
Agent0_TimeSinceStart : 622.4595205783844
Agent0_Critic_Loss : 0.280276358127594
Agent0_Actor_Loss : -0.41540229320526123
Agent0_Alpha_Loss : 0.7971837520599365
Agent0_Temperature : 0.09274465874932034
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -18.075733184814453
Agent1_Eval_StdReturn : 19.926427841186523
Agent1_Eval_MaxReturn : 4.1635847091674805
Agent1_Eval_MinReturn : -64.82637786865234
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -36.711021423339844
Agent1_Train_StdReturn : 16.016895294189453
Agent1_Train_MaxReturn : -3.0845556259155273
Agent1_Train_MinReturn : -56.37342834472656
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 406500
Agent1_TimeSinceStart : 624.5222232341766
Agent1_Critic_Loss : 0.25447967648506165
Agent1_Actor_Loss : -0.5284600853919983
Agent1_Alpha_Loss : 0.793756365776062
Agent1_Temperature : 0.09268895094846114
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 271 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 272 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 273 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 274 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 275 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 276 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 277 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 278 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 279 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 280 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -25.73103904724121
Agent0_Eval_StdReturn : 19.2802791595459
Agent0_Eval_MaxReturn : 5.011897087097168
Agent0_Eval_MinReturn : -55.88454818725586
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -26.649078369140625
Agent0_Train_StdReturn : 25.131439208984375
Agent0_Train_MaxReturn : 7.85585355758667
Agent0_Train_MinReturn : -81.78594970703125
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 421500
Agent0_TimeSinceStart : 645.3756401538849
Agent0_Critic_Loss : 0.3238179683685303
Agent0_Actor_Loss : -0.4767856299877167
Agent0_Alpha_Loss : 0.7812870740890503
Agent0_Temperature : 0.09248635665394686
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -15.542348861694336
Agent1_Eval_StdReturn : 9.361729621887207
Agent1_Eval_MaxReturn : 7.368444442749023
Agent1_Eval_MinReturn : -26.21965980529785
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -17.79050064086914
Agent1_Train_StdReturn : 10.479387283325195
Agent1_Train_MaxReturn : 2.5610804557800293
Agent1_Train_MinReturn : -32.13212966918945
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 421500
Agent1_TimeSinceStart : 647.4596853256226
Agent1_Critic_Loss : 0.29387110471725464
Agent1_Actor_Loss : -0.6111485958099365
Agent1_Alpha_Loss : 0.8173784017562866
Agent1_Temperature : 0.09243150688334698
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 281 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 282 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 283 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 284 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 285 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 286 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 287 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 288 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 289 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 290 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -23.751968383789062
Agent0_Eval_StdReturn : 37.06835174560547
Agent0_Eval_MaxReturn : 54.054771423339844
Agent0_Eval_MinReturn : -101.09776306152344
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -21.46087074279785
Agent0_Train_StdReturn : 16.76968765258789
Agent0_Train_MaxReturn : 6.777041435241699
Agent0_Train_MinReturn : -47.00530242919922
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 436500
Agent0_TimeSinceStart : 668.2964386940002
Agent0_Critic_Loss : 0.3967634439468384
Agent0_Actor_Loss : -0.4169665575027466
Agent0_Alpha_Loss : 0.7898609042167664
Agent0_Temperature : 0.09222864267262869
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -15.166577339172363
Agent1_Eval_StdReturn : 25.0490665435791
Agent1_Eval_MaxReturn : 20.577009201049805
Agent1_Eval_MinReturn : -74.25492858886719
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -13.31120777130127
Agent1_Train_StdReturn : 15.252644538879395
Agent1_Train_MaxReturn : 15.77913761138916
Agent1_Train_MinReturn : -35.36896896362305
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 436500
Agent1_TimeSinceStart : 670.3754448890686
Agent1_Critic_Loss : 0.3208305835723877
Agent1_Actor_Loss : -0.6080687046051025
Agent1_Alpha_Loss : 0.8013306856155396
Agent1_Temperature : 0.09217459634561004
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 291 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 292 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 293 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 294 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 295 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 296 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 297 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 298 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 299 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 300 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -29.488428115844727
Agent0_Eval_StdReturn : 16.26649284362793
Agent0_Eval_MaxReturn : -2.079456329345703
Agent0_Eval_MinReturn : -58.7512321472168
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -17.76485252380371
Agent0_Train_StdReturn : 27.309532165527344
Agent0_Train_MaxReturn : 15.883099555969238
Agent0_Train_MinReturn : -64.53376007080078
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 451500
Agent0_TimeSinceStart : 691.2502789497375
Agent0_Critic_Loss : 0.46575114130973816
Agent0_Actor_Loss : -0.5234407782554626
Agent0_Alpha_Loss : 0.7947133779525757
Agent0_Temperature : 0.09197172015199455
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -15.698307991027832
Agent1_Eval_StdReturn : 14.554265022277832
Agent1_Eval_MaxReturn : 2.977621078491211
Agent1_Eval_MinReturn : -43.958641052246094
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -19.507389068603516
Agent1_Train_StdReturn : 16.40997314453125
Agent1_Train_MaxReturn : 5.91200065612793
Agent1_Train_MinReturn : -39.21809387207031
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 451500
Agent1_TimeSinceStart : 693.3325438499451
Agent1_Critic_Loss : 0.35323357582092285
Agent1_Actor_Loss : -0.5797265768051147
Agent1_Alpha_Loss : 0.8028438091278076
Agent1_Temperature : 0.09191764863044555
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 301 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 302 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 303 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 304 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 305 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 306 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 307 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 308 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 309 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 310 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -17.875438690185547
Agent0_Eval_StdReturn : 26.69764518737793
Agent0_Eval_MaxReturn : 48.92144012451172
Agent0_Eval_MinReturn : -48.417625427246094
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -31.981822967529297
Agent0_Train_StdReturn : 23.030197143554688
Agent0_Train_MaxReturn : 12.227663040161133
Agent0_Train_MinReturn : -70.77510070800781
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 466500
Agent0_TimeSinceStart : 714.2572593688965
Agent0_Critic_Loss : 0.38524964451789856
Agent0_Actor_Loss : -0.4520638585090637
Agent0_Alpha_Loss : 0.8034378290176392
Agent0_Temperature : 0.09171411598060375
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -16.3078670501709
Agent1_Eval_StdReturn : 13.680336952209473
Agent1_Eval_MaxReturn : 0.7123336791992188
Agent1_Eval_MinReturn : -48.5518798828125
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -27.43392562866211
Agent1_Train_StdReturn : 18.0389347076416
Agent1_Train_MaxReturn : 3.1431262493133545
Agent1_Train_MinReturn : -51.07604217529297
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 466500
Agent1_TimeSinceStart : 716.3446829319
Agent1_Critic_Loss : 0.32837024331092834
Agent1_Actor_Loss : -0.5463587641716003
Agent1_Alpha_Loss : 0.7899879813194275
Agent1_Temperature : 0.09166062804314552
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 311 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 312 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 313 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 314 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 315 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 316 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 317 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 318 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 319 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 320 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -26.109355926513672
Agent0_Eval_StdReturn : 23.24539566040039
Agent0_Eval_MaxReturn : 18.590456008911133
Agent0_Eval_MinReturn : -68.24076843261719
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -22.857742309570312
Agent0_Train_StdReturn : 18.007516860961914
Agent0_Train_MaxReturn : 0.27512478828430176
Agent0_Train_MinReturn : -61.663780212402344
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 481500
Agent0_TimeSinceStart : 737.2926664352417
Agent0_Critic_Loss : 0.3373875319957733
Agent0_Actor_Loss : -0.46922567486763
Agent0_Alpha_Loss : 0.8094266653060913
Agent0_Temperature : 0.09145542138437646
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -14.14746379852295
Agent1_Eval_StdReturn : 24.54435920715332
Agent1_Eval_MaxReturn : 23.79808807373047
Agent1_Eval_MinReturn : -66.13050079345703
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -21.549728393554688
Agent1_Train_StdReturn : 17.631093978881836
Agent1_Train_MaxReturn : 13.970946311950684
Agent1_Train_MinReturn : -56.18938446044922
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 481500
Agent1_TimeSinceStart : 739.3852739334106
Agent1_Critic_Loss : 0.3474269509315491
Agent1_Actor_Loss : -0.5337388515472412
Agent1_Alpha_Loss : 0.7891653776168823
Agent1_Temperature : 0.09140597395287217
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 321 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 322 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 323 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 324 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 325 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 326 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 327 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 328 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 329 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 330 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -14.606039047241211
Agent0_Eval_StdReturn : 17.676679611206055
Agent0_Eval_MaxReturn : 11.255080223083496
Agent0_Eval_MinReturn : -46.07022476196289
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -24.279102325439453
Agent0_Train_StdReturn : 14.613848686218262
Agent0_Train_MaxReturn : -7.489498138427734
Agent0_Train_MinReturn : -50.200782775878906
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 496500
Agent0_TimeSinceStart : 760.3160345554352
Agent0_Critic_Loss : 0.4580661356449127
Agent0_Actor_Loss : -0.4489257037639618
Agent0_Alpha_Loss : 0.7867261171340942
Agent0_Temperature : 0.09119791896267807
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -28.191455841064453
Agent1_Eval_StdReturn : 15.401576042175293
Agent1_Eval_MaxReturn : 1.5784597396850586
Agent1_Eval_MinReturn : -49.390541076660156
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -15.953106880187988
Agent1_Train_StdReturn : 11.42408275604248
Agent1_Train_MaxReturn : -0.8487606048583984
Agent1_Train_MinReturn : -36.461036682128906
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 496500
Agent1_TimeSinceStart : 762.393054485321
Agent1_Critic_Loss : 0.2988046109676361
Agent1_Actor_Loss : -0.5437799096107483
Agent1_Alpha_Loss : 0.7716421484947205
Agent1_Temperature : 0.09115293766634942
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 331 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 332 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 333 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 334 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 335 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 336 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 337 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 338 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 339 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 340 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -12.282944679260254
Agent0_Eval_StdReturn : 11.016487121582031
Agent0_Eval_MaxReturn : 5.021698474884033
Agent0_Eval_MinReturn : -30.456457138061523
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -13.737693786621094
Agent0_Train_StdReturn : 18.55286979675293
Agent0_Train_MaxReturn : 27.087125778198242
Agent0_Train_MinReturn : -42.253623962402344
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 511500
Agent0_TimeSinceStart : 783.3119425773621
Agent0_Critic_Loss : 0.3587472438812256
Agent0_Actor_Loss : -0.4648171067237854
Agent0_Alpha_Loss : 0.7875670194625854
Agent0_Temperature : 0.09094203873143665
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -21.91361427307129
Agent1_Eval_StdReturn : 11.209461212158203
Agent1_Eval_MaxReturn : -0.9425082206726074
Agent1_Eval_MinReturn : -45.75115203857422
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -28.10580062866211
Agent1_Train_StdReturn : 21.540185928344727
Agent1_Train_MaxReturn : 3.2157669067382812
Agent1_Train_MinReturn : -67.0848617553711
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 511500
Agent1_TimeSinceStart : 785.3859751224518
Agent1_Critic_Loss : 0.33880525827407837
Agent1_Actor_Loss : -0.5656996965408325
Agent1_Alpha_Loss : 0.772548258304596
Agent1_Temperature : 0.0909019802251281
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 341 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 342 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 343 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 344 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 345 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 346 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 347 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 348 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 349 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 350 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -11.12840461730957
Agent0_Eval_StdReturn : 13.890128135681152
Agent0_Eval_MaxReturn : 19.530683517456055
Agent0_Eval_MinReturn : -29.430316925048828
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -17.725683212280273
Agent0_Train_StdReturn : 17.147865295410156
Agent0_Train_MaxReturn : 6.073427200317383
Agent0_Train_MinReturn : -58.22107696533203
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 526500
Agent0_TimeSinceStart : 806.3620307445526
Agent0_Critic_Loss : 0.44159823656082153
Agent0_Actor_Loss : -0.45007839798927307
Agent0_Alpha_Loss : 0.7745863199234009
Agent0_Temperature : 0.09068829796055089
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -9.251691818237305
Agent1_Eval_StdReturn : 14.550782203674316
Agent1_Eval_MaxReturn : 16.012081146240234
Agent1_Eval_MinReturn : -34.85548400878906
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -16.499267578125
Agent1_Train_StdReturn : 17.927453994750977
Agent1_Train_MaxReturn : 1.4402036666870117
Agent1_Train_MinReturn : -55.48899459838867
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 526500
Agent1_TimeSinceStart : 808.452335357666
Agent1_Critic_Loss : 0.41063395142555237
Agent1_Actor_Loss : -0.6533311605453491
Agent1_Alpha_Loss : 0.7735414505004883
Agent1_Temperature : 0.09065176130929768
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 351 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 352 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 353 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 354 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 355 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 356 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 357 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 358 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 359 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 360 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -26.4561710357666
Agent0_Eval_StdReturn : 20.793733596801758
Agent0_Eval_MaxReturn : 9.673375129699707
Agent0_Eval_MinReturn : -49.71549987792969
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -9.631438255310059
Agent0_Train_StdReturn : 11.026349067687988
Agent0_Train_MaxReturn : 10.774682998657227
Agent0_Train_MinReturn : -22.16272735595703
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 541500
Agent0_TimeSinceStart : 829.4382560253143
Agent0_Critic_Loss : 0.4498327374458313
Agent0_Actor_Loss : -0.3968347907066345
Agent0_Alpha_Loss : 0.7645009756088257
Agent0_Temperature : 0.0904365483270258
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -26.309917449951172
Agent1_Eval_StdReturn : 18.382911682128906
Agent1_Eval_MaxReturn : -5.777609825134277
Agent1_Eval_MinReturn : -65.67095947265625
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -20.656482696533203
Agent1_Train_StdReturn : 11.516026496887207
Agent1_Train_MaxReturn : -1.0974721908569336
Agent1_Train_MinReturn : -35.21232986450195
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 541500
Agent1_TimeSinceStart : 831.5170335769653
Agent1_Critic_Loss : 0.37874042987823486
Agent1_Actor_Loss : -0.7066349983215332
Agent1_Alpha_Loss : 0.7914995551109314
Agent1_Temperature : 0.09040153663983409
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 361 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 362 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 363 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 364 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 365 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 366 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 367 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 368 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 369 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 370 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -13.109143257141113
Agent0_Eval_StdReturn : 15.314669609069824
Agent0_Eval_MaxReturn : 7.085012435913086
Agent0_Eval_MinReturn : -36.16758728027344
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -13.702990531921387
Agent0_Train_StdReturn : 19.723730087280273
Agent0_Train_MaxReturn : 26.704627990722656
Agent0_Train_MinReturn : -54.29339599609375
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 556500
Agent0_TimeSinceStart : 852.4520401954651
Agent0_Critic_Loss : 0.4105607867240906
Agent0_Actor_Loss : -0.6003260612487793
Agent0_Alpha_Loss : 0.7708619236946106
Agent0_Temperature : 0.09018519561788374
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -22.106555938720703
Agent1_Eval_StdReturn : 6.6857590675354
Agent1_Eval_MaxReturn : -9.671072006225586
Agent1_Eval_MinReturn : -31.561038970947266
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -13.659873962402344
Agent1_Train_StdReturn : 15.984879493713379
Agent1_Train_MaxReturn : 22.393436431884766
Agent1_Train_MinReturn : -30.897363662719727
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 556500
Agent1_TimeSinceStart : 854.5312020778656
Agent1_Critic_Loss : 0.37003618478775024
Agent1_Actor_Loss : -0.5539954304695129
Agent1_Alpha_Loss : 0.7747203707695007
Agent1_Temperature : 0.0901509263628389
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 371 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 372 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 373 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 374 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 375 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 376 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 377 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 378 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 379 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 380 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -11.94958209991455
Agent0_Eval_StdReturn : 9.80329704284668
Agent0_Eval_MaxReturn : 2.7691450119018555
Agent0_Eval_MinReturn : -26.635543823242188
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -20.68978500366211
Agent0_Train_StdReturn : 14.679703712463379
Agent0_Train_MaxReturn : 9.81849193572998
Agent0_Train_MinReturn : -47.693511962890625
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 571500
Agent0_TimeSinceStart : 875.4713819026947
Agent0_Critic_Loss : 0.3541094660758972
Agent0_Actor_Loss : -0.48236918449401855
Agent0_Alpha_Loss : 0.7688589096069336
Agent0_Temperature : 0.08993537552958424
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -18.93495750427246
Agent1_Eval_StdReturn : 10.229680061340332
Agent1_Eval_MaxReturn : -8.889663696289062
Agent1_Eval_MinReturn : -37.67811965942383
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -20.175525665283203
Agent1_Train_StdReturn : 8.596830368041992
Agent1_Train_MaxReturn : -6.452872276306152
Agent1_Train_MinReturn : -35.05115509033203
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 571500
Agent1_TimeSinceStart : 877.5586705207825
Agent1_Critic_Loss : 0.37565088272094727
Agent1_Actor_Loss : -0.5488758087158203
Agent1_Alpha_Loss : 0.7747211456298828
Agent1_Temperature : 0.08990087151439154
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 381 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 382 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 383 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 384 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 385 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 386 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 387 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 388 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 389 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 390 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -20.698781967163086
Agent0_Eval_StdReturn : 7.388458251953125
Agent0_Eval_MaxReturn : -6.851304531097412
Agent0_Eval_MinReturn : -35.30008316040039
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -12.122560501098633
Agent0_Train_StdReturn : 10.617440223693848
Agent0_Train_MaxReturn : 3.5547075271606445
Agent0_Train_MinReturn : -29.614917755126953
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 586500
Agent0_TimeSinceStart : 898.5893504619598
Agent0_Critic_Loss : 0.36687442660331726
Agent0_Actor_Loss : -0.45299357175827026
Agent0_Alpha_Loss : 0.7908837795257568
Agent0_Temperature : 0.08968703196836562
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -27.38150405883789
Agent1_Eval_StdReturn : 11.215424537658691
Agent1_Eval_MaxReturn : -7.819022178649902
Agent1_Eval_MinReturn : -51.17724609375
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -22.958255767822266
Agent1_Train_StdReturn : 11.49359130859375
Agent1_Train_MaxReturn : -2.6035656929016113
Agent1_Train_MinReturn : -39.254058837890625
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 586500
Agent1_TimeSinceStart : 900.6789438724518
Agent1_Critic_Loss : 0.34647566080093384
Agent1_Actor_Loss : -0.7094520330429077
Agent1_Alpha_Loss : 0.7507176399230957
Agent1_Temperature : 0.08965299389594694
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 391 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 392 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 393 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 394 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 395 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 396 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 397 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 398 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 399 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 400 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -16.145668029785156
Agent0_Eval_StdReturn : 15.775847434997559
Agent0_Eval_MaxReturn : 8.673795700073242
Agent0_Eval_MinReturn : -46.3359489440918
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -20.39972496032715
Agent0_Train_StdReturn : 19.088890075683594
Agent0_Train_MaxReturn : 4.809258460998535
Agent0_Train_MinReturn : -59.41927719116211
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 601500
Agent0_TimeSinceStart : 921.6765239238739
Agent0_Critic_Loss : 0.39581945538520813
Agent0_Actor_Loss : -0.2627960741519928
Agent0_Alpha_Loss : 0.7707595825195312
Agent0_Temperature : 0.08943820517701294
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -15.142663955688477
Agent1_Eval_StdReturn : 13.787897109985352
Agent1_Eval_MaxReturn : 4.789897918701172
Agent1_Eval_MinReturn : -33.772926330566406
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -13.755643844604492
Agent1_Train_StdReturn : 10.299739837646484
Agent1_Train_MaxReturn : 9.720049858093262
Agent1_Train_MinReturn : -32.53183364868164
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 601500
Agent1_TimeSinceStart : 923.7643504142761
Agent1_Critic_Loss : 0.3267044425010681
Agent1_Actor_Loss : -0.6650494337081909
Agent1_Alpha_Loss : 0.7546527981758118
Agent1_Temperature : 0.08940744933667319
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 401 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 402 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 403 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 404 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 405 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 406 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 407 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 408 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 409 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 410 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -15.602334976196289
Agent0_Eval_StdReturn : 10.794804573059082
Agent0_Eval_MaxReturn : -1.1930222511291504
Agent0_Eval_MinReturn : -35.64143371582031
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -15.748769760131836
Agent0_Train_StdReturn : 12.836310386657715
Agent0_Train_MaxReturn : 7.621933460235596
Agent0_Train_MinReturn : -32.182701110839844
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 616500
Agent0_TimeSinceStart : 944.7279796600342
Agent0_Critic_Loss : 0.39925113320350647
Agent0_Actor_Loss : -0.37661758065223694
Agent0_Alpha_Loss : 0.7924333810806274
Agent0_Temperature : 0.08918941876479633
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -15.066441535949707
Agent1_Eval_StdReturn : 13.370270729064941
Agent1_Eval_MaxReturn : 15.944058418273926
Agent1_Eval_MinReturn : -31.618480682373047
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -14.095558166503906
Agent1_Train_StdReturn : 12.52369499206543
Agent1_Train_MaxReturn : 6.4973649978637695
Agent1_Train_MinReturn : -44.683441162109375
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 616500
Agent1_TimeSinceStart : 946.8162317276001
Agent1_Critic_Loss : 0.38933801651000977
Agent1_Actor_Loss : -0.6794323921203613
Agent1_Alpha_Loss : 0.7585346698760986
Agent1_Temperature : 0.08916285764459124
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 411 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 412 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 413 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 414 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 415 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 416 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 417 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 418 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 419 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 420 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -25.168621063232422
Agent0_Eval_StdReturn : 17.101215362548828
Agent0_Eval_MaxReturn : 0.2931985855102539
Agent0_Eval_MinReturn : -46.72584533691406
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -19.88149070739746
Agent0_Train_StdReturn : 10.678956031799316
Agent0_Train_MaxReturn : -4.256329536437988
Agent0_Train_MinReturn : -32.497215270996094
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 631500
Agent0_TimeSinceStart : 967.7768280506134
Agent0_Critic_Loss : 0.37691372632980347
Agent0_Actor_Loss : -0.4304930865764618
Agent0_Alpha_Loss : 0.7691115140914917
Agent0_Temperature : 0.08893921098398257
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -18.280929565429688
Agent1_Eval_StdReturn : 13.883688926696777
Agent1_Eval_MaxReturn : 6.723855495452881
Agent1_Eval_MinReturn : -35.75210952758789
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -22.026325225830078
Agent1_Train_StdReturn : 15.727465629577637
Agent1_Train_MaxReturn : 7.012145519256592
Agent1_Train_MinReturn : -52.431541442871094
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 631500
Agent1_TimeSinceStart : 969.8515758514404
Agent1_Critic_Loss : 0.3681919574737549
Agent1_Actor_Loss : -0.5962070226669312
Agent1_Alpha_Loss : 0.778615415096283
Agent1_Temperature : 0.08891716855371379
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 421 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 422 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 423 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 424 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 425 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 426 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 427 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 428 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 429 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 430 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -14.292245864868164
Agent0_Eval_StdReturn : 18.54930305480957
Agent0_Eval_MaxReturn : 13.241266250610352
Agent0_Eval_MinReturn : -52.33502960205078
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -16.831378936767578
Agent0_Train_StdReturn : 17.773170471191406
Agent0_Train_MaxReturn : 6.2189130783081055
Agent0_Train_MinReturn : -57.12344741821289
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 646500
Agent0_TimeSinceStart : 990.8484516143799
Agent0_Critic_Loss : 0.3790402114391327
Agent0_Actor_Loss : -0.6183111667633057
Agent0_Alpha_Loss : 0.7802872061729431
Agent0_Temperature : 0.08868825311244621
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -21.325714111328125
Agent1_Eval_StdReturn : 9.564078330993652
Agent1_Eval_MaxReturn : -5.879881858825684
Agent1_Eval_MinReturn : -35.51716613769531
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -12.455845832824707
Agent1_Train_StdReturn : 11.03990650177002
Agent1_Train_MaxReturn : 7.750317096710205
Agent1_Train_MinReturn : -33.66283416748047
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 646500
Agent1_TimeSinceStart : 992.9400749206543
Agent1_Critic_Loss : 0.39687883853912354
Agent1_Actor_Loss : -0.6271481513977051
Agent1_Alpha_Loss : 0.7721457481384277
Agent1_Temperature : 0.08867075995048743
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 431 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 432 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 433 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 434 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 435 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 436 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 437 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 438 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 439 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 440 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -17.52079200744629
Agent0_Eval_StdReturn : 20.24224090576172
Agent0_Eval_MaxReturn : 18.361133575439453
Agent0_Eval_MinReturn : -51.53343963623047
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -13.069241523742676
Agent0_Train_StdReturn : 15.072153091430664
Agent0_Train_MaxReturn : 22.294803619384766
Agent0_Train_MinReturn : -34.04662322998047
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 661500
Agent0_TimeSinceStart : 1013.9006605148315
Agent0_Critic_Loss : 0.46931928396224976
Agent0_Actor_Loss : -0.4582574963569641
Agent0_Alpha_Loss : 0.7962671518325806
Agent0_Temperature : 0.08843744734449353
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -18.814191818237305
Agent1_Eval_StdReturn : 8.409029006958008
Agent1_Eval_MaxReturn : -5.777541160583496
Agent1_Eval_MinReturn : -39.85007095336914
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -11.167520523071289
Agent1_Train_StdReturn : 17.291038513183594
Agent1_Train_MaxReturn : 20.956499099731445
Agent1_Train_MinReturn : -43.57261276245117
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 661500
Agent1_TimeSinceStart : 1015.9798319339752
Agent1_Critic_Loss : 0.3723233938217163
Agent1_Actor_Loss : -0.5207083225250244
Agent1_Alpha_Loss : 0.7840228080749512
Agent1_Temperature : 0.08842330743909013
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 441 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 442 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 443 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 444 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 445 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 446 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 447 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 448 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 449 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 450 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -13.10859203338623
Agent0_Eval_StdReturn : 20.180177688598633
Agent0_Eval_MaxReturn : 29.3037052154541
Agent0_Eval_MinReturn : -53.399112701416016
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -8.749564170837402
Agent0_Train_StdReturn : 14.787829399108887
Agent0_Train_MaxReturn : 12.31178092956543
Agent0_Train_MinReturn : -39.67624282836914
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 676500
Agent0_TimeSinceStart : 1036.9064450263977
Agent0_Critic_Loss : 0.4414183795452118
Agent0_Actor_Loss : -0.4038405418395996
Agent0_Alpha_Loss : 0.7742429375648499
Agent0_Temperature : 0.0881869790237033
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -16.522422790527344
Agent1_Eval_StdReturn : 12.120686531066895
Agent1_Eval_MaxReturn : -5.185259819030762
Agent1_Eval_MinReturn : -45.356468200683594
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -20.20363426208496
Agent1_Train_StdReturn : 15.896119117736816
Agent1_Train_MaxReturn : 11.937647819519043
Agent1_Train_MinReturn : -45.38157653808594
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 676500
Agent1_TimeSinceStart : 1038.9892241954803
Agent1_Critic_Loss : 0.328902006149292
Agent1_Actor_Loss : -0.6393265724182129
Agent1_Alpha_Loss : 0.7747649550437927
Agent1_Temperature : 0.08817660321497998
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 451 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 452 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 453 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 454 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 455 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 456 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 457 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 458 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 459 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 460 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -21.098995208740234
Agent0_Eval_StdReturn : 14.967107772827148
Agent0_Eval_MaxReturn : -4.200643539428711
Agent0_Eval_MinReturn : -52.39203643798828
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -16.88431739807129
Agent0_Train_StdReturn : 9.866022109985352
Agent0_Train_MaxReturn : 1.972924828529358
Agent0_Train_MinReturn : -32.18617248535156
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 691500
Agent0_TimeSinceStart : 1059.8623676300049
Agent0_Critic_Loss : 0.362585186958313
Agent0_Actor_Loss : -0.5733819007873535
Agent0_Alpha_Loss : 0.7964377403259277
Agent0_Temperature : 0.08793560256292325
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -23.08644676208496
Agent1_Eval_StdReturn : 12.421806335449219
Agent1_Eval_MaxReturn : -3.8785319328308105
Agent1_Eval_MinReturn : -48.802894592285156
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -14.172833442687988
Agent1_Train_StdReturn : 15.828939437866211
Agent1_Train_MaxReturn : -2.827383518218994
Agent1_Train_MinReturn : -59.71248245239258
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 691500
Agent1_TimeSinceStart : 1061.9460401535034
Agent1_Critic_Loss : 0.4446423649787903
Agent1_Actor_Loss : -0.5742889642715454
Agent1_Alpha_Loss : 0.7770302295684814
Agent1_Temperature : 0.08793117255795707
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 461 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 462 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 463 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 464 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 465 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 466 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 467 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 468 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 469 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 470 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -14.71119213104248
Agent0_Eval_StdReturn : 13.885028839111328
Agent0_Eval_MaxReturn : 12.147222518920898
Agent0_Eval_MinReturn : -45.22727584838867
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -17.667959213256836
Agent0_Train_StdReturn : 15.64426326751709
Agent0_Train_MaxReturn : 11.120625495910645
Agent0_Train_MinReturn : -41.59851837158203
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 706500
Agent0_TimeSinceStart : 1082.8581953048706
Agent0_Critic_Loss : 0.4270845055580139
Agent0_Actor_Loss : -0.5869781374931335
Agent0_Alpha_Loss : 0.788877010345459
Agent0_Temperature : 0.08768289828536574
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -14.803991317749023
Agent1_Eval_StdReturn : 18.554712295532227
Agent1_Eval_MaxReturn : 7.401650428771973
Agent1_Eval_MinReturn : -50.21769714355469
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -19.217287063598633
Agent1_Train_StdReturn : 7.99163818359375
Agent1_Train_MaxReturn : -3.8978729248046875
Agent1_Train_MinReturn : -29.235923767089844
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 706500
Agent1_TimeSinceStart : 1084.9351272583008
Agent1_Critic_Loss : 0.3643917739391327
Agent1_Actor_Loss : -0.5894960165023804
Agent1_Alpha_Loss : 0.7710340023040771
Agent1_Temperature : 0.0876863986660139
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 471 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 472 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 473 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 474 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 475 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 476 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 477 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 478 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 479 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 480 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -20.22150230407715
Agent0_Eval_StdReturn : 15.00478458404541
Agent0_Eval_MaxReturn : 14.399372100830078
Agent0_Eval_MinReturn : -41.04148483276367
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -16.22894287109375
Agent0_Train_StdReturn : 18.38963508605957
Agent0_Train_MaxReturn : 9.890790939331055
Agent0_Train_MinReturn : -48.52764892578125
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 721500
Agent0_TimeSinceStart : 1105.7932279109955
Agent0_Critic_Loss : 0.41161006689071655
Agent0_Actor_Loss : -0.386269748210907
Agent0_Alpha_Loss : 0.7799457311630249
Agent0_Temperature : 0.0874301744395933
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -15.922201156616211
Agent1_Eval_StdReturn : 13.669180870056152
Agent1_Eval_MaxReturn : -0.1666405200958252
Agent1_Eval_MinReturn : -50.378047943115234
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -10.907207489013672
Agent1_Train_StdReturn : 16.999431610107422
Agent1_Train_MaxReturn : 25.326492309570312
Agent1_Train_MinReturn : -43.69804763793945
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 721500
Agent1_TimeSinceStart : 1107.8780102729797
Agent1_Critic_Loss : 0.4239770174026489
Agent1_Actor_Loss : -0.6173284649848938
Agent1_Alpha_Loss : 0.7686865329742432
Agent1_Temperature : 0.08744017380614247
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 481 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 482 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 483 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 484 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 485 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 486 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 487 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 488 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 489 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 490 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -11.89557933807373
Agent0_Eval_StdReturn : 28.756526947021484
Agent0_Eval_MaxReturn : 17.870635986328125
Agent0_Eval_MinReturn : -86.63265991210938
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -19.557626724243164
Agent0_Train_StdReturn : 18.831708908081055
Agent0_Train_MaxReturn : 6.17771053314209
Agent0_Train_MinReturn : -58.259613037109375
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 736500
Agent0_TimeSinceStart : 1128.648931980133
Agent0_Critic_Loss : 0.35986000299453735
Agent0_Actor_Loss : -0.573714554309845
Agent0_Alpha_Loss : 0.7967138290405273
Agent0_Temperature : 0.08717820625280673
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -22.30379867553711
Agent1_Eval_StdReturn : 21.477275848388672
Agent1_Eval_MaxReturn : 7.00637149810791
Agent1_Eval_MinReturn : -77.42017364501953
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -22.089588165283203
Agent1_Train_StdReturn : 18.673213958740234
Agent1_Train_MaxReturn : 4.911528587341309
Agent1_Train_MinReturn : -57.557533264160156
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 736500
Agent1_TimeSinceStart : 1130.72056889534
Agent1_Critic_Loss : 0.36105480790138245
Agent1_Actor_Loss : -0.6556574106216431
Agent1_Alpha_Loss : 0.785650372505188
Agent1_Temperature : 0.08719275479731142
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 491 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 492 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 493 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 494 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 495 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 496 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 497 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 498 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 499 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 500 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -19.13115882873535
Agent0_Eval_StdReturn : 20.616992950439453
Agent0_Eval_MaxReturn : 8.07487678527832
Agent0_Eval_MinReturn : -61.394840240478516
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -12.513818740844727
Agent0_Train_StdReturn : 14.987236022949219
Agent0_Train_MaxReturn : 16.435100555419922
Agent0_Train_MinReturn : -32.76643753051758
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 751500
Agent0_TimeSinceStart : 1151.5763385295868
Agent0_Critic_Loss : 0.4761659502983093
Agent0_Actor_Loss : -0.5877057909965515
Agent0_Alpha_Loss : 0.7804107666015625
Agent0_Temperature : 0.08692624721887156
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -8.128332138061523
Agent1_Eval_StdReturn : 9.078149795532227
Agent1_Eval_MaxReturn : 5.680626392364502
Agent1_Eval_MinReturn : -24.236621856689453
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -17.81447982788086
Agent1_Train_StdReturn : 19.11029815673828
Agent1_Train_MaxReturn : 9.438056945800781
Agent1_Train_MinReturn : -51.30663299560547
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 751500
Agent1_TimeSinceStart : 1153.6507031917572
Agent1_Critic_Loss : 0.37677711248397827
Agent1_Actor_Loss : -0.6150513887405396
Agent1_Alpha_Loss : 0.7916648387908936
Agent1_Temperature : 0.08694511489077136
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 501 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 502 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 503 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 504 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 505 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 506 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 507 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 508 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 509 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 510 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -19.49972915649414
Agent0_Eval_StdReturn : 19.926584243774414
Agent0_Eval_MaxReturn : 6.044062614440918
Agent0_Eval_MinReturn : -50.31175994873047
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -13.631627082824707
Agent0_Train_StdReturn : 12.117959022521973
Agent0_Train_MaxReturn : 11.734731674194336
Agent0_Train_MinReturn : -35.56798553466797
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 766500
Agent0_TimeSinceStart : 1174.4593403339386
Agent0_Critic_Loss : 0.5086747407913208
Agent0_Actor_Loss : -0.4944847524166107
Agent0_Alpha_Loss : 0.7923860549926758
Agent0_Temperature : 0.08667568770880399
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -22.875507354736328
Agent1_Eval_StdReturn : 18.373838424682617
Agent1_Eval_MaxReturn : 6.366382598876953
Agent1_Eval_MinReturn : -49.408782958984375
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -20.26414680480957
Agent1_Train_StdReturn : 25.165983200073242
Agent1_Train_MaxReturn : 19.07270050048828
Agent1_Train_MinReturn : -70.74835205078125
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 766500
Agent1_TimeSinceStart : 1176.5302948951721
Agent1_Critic_Loss : 0.4004215598106384
Agent1_Actor_Loss : -0.6389827728271484
Agent1_Alpha_Loss : 0.7877181768417358
Agent1_Temperature : 0.08669661289157383
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 511 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 512 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 513 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 514 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 515 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 516 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 517 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 518 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 519 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 520 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -19.177562713623047
Agent0_Eval_StdReturn : 17.056108474731445
Agent0_Eval_MaxReturn : -1.3032739162445068
Agent0_Eval_MinReturn : -60.098297119140625
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -20.18682289123535
Agent0_Train_StdReturn : 7.358506202697754
Agent0_Train_MaxReturn : -10.657862663269043
Agent0_Train_MinReturn : -35.55183792114258
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 781500
Agent0_TimeSinceStart : 1197.4139006137848
Agent0_Critic_Loss : 0.5580973625183105
Agent0_Actor_Loss : -0.6899687647819519
Agent0_Alpha_Loss : 0.7874179482460022
Agent0_Temperature : 0.08642539925394185
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -19.936906814575195
Agent1_Eval_StdReturn : 19.88430404663086
Agent1_Eval_MaxReturn : 1.010338544845581
Agent1_Eval_MinReturn : -74.66339111328125
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -25.101802825927734
Agent1_Train_StdReturn : 16.843055725097656
Agent1_Train_MaxReturn : -4.25745153427124
Agent1_Train_MinReturn : -58.8577995300293
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 781500
Agent1_TimeSinceStart : 1199.480238199234
Agent1_Critic_Loss : 0.5181427001953125
Agent1_Actor_Loss : -0.6260339021682739
Agent1_Alpha_Loss : 0.788972795009613
Agent1_Temperature : 0.08644803154068358
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 521 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 522 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 523 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 524 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 525 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 526 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 527 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 528 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 529 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 530 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -22.10725975036621
Agent0_Eval_StdReturn : 13.705628395080566
Agent0_Eval_MaxReturn : 10.253961563110352
Agent0_Eval_MinReturn : -41.832298278808594
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -11.329689025878906
Agent0_Train_StdReturn : 29.205472946166992
Agent0_Train_MaxReturn : 21.732887268066406
Agent0_Train_MinReturn : -86.41447448730469
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 796500
Agent0_TimeSinceStart : 1220.3124449253082
Agent0_Critic_Loss : 0.5732462406158447
Agent0_Actor_Loss : -0.49861276149749756
Agent0_Alpha_Loss : 0.779527485370636
Agent0_Temperature : 0.08617663837211696
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -10.891106605529785
Agent1_Eval_StdReturn : 11.612573623657227
Agent1_Eval_MaxReturn : 0.01837635040283203
Agent1_Eval_MinReturn : -39.748992919921875
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -25.026371002197266
Agent1_Train_StdReturn : 26.288103103637695
Agent1_Train_MaxReturn : 10.714229583740234
Agent1_Train_MinReturn : -67.74449920654297
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 796500
Agent1_TimeSinceStart : 1222.3727288246155
Agent1_Critic_Loss : 0.4696630537509918
Agent1_Actor_Loss : -0.6615735292434692
Agent1_Alpha_Loss : 0.7899320125579834
Agent1_Temperature : 0.08619952348400793
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 531 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 532 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 533 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 534 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 535 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 536 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 537 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 538 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 539 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 540 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -15.224569320678711
Agent0_Eval_StdReturn : 12.895216941833496
Agent0_Eval_MaxReturn : 0.18579590320587158
Agent0_Eval_MinReturn : -47.704917907714844
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -12.945703506469727
Agent0_Train_StdReturn : 17.073394775390625
Agent0_Train_MaxReturn : 15.751660346984863
Agent0_Train_MinReturn : -40.807273864746094
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 811500
Agent0_TimeSinceStart : 1243.2265837192535
Agent0_Critic_Loss : 0.5990118384361267
Agent0_Actor_Loss : -0.4807097613811493
Agent0_Alpha_Loss : 0.7813174724578857
Agent0_Temperature : 0.08592985589508963
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -16.84691047668457
Agent1_Eval_StdReturn : 16.1185359954834
Agent1_Eval_MaxReturn : 8.813566207885742
Agent1_Eval_MinReturn : -46.12221145629883
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -23.23954963684082
Agent1_Train_StdReturn : 17.159927368164062
Agent1_Train_MaxReturn : -5.706218719482422
Agent1_Train_MinReturn : -62.34765625
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 811500
Agent1_TimeSinceStart : 1245.2939081192017
Agent1_Critic_Loss : 0.5138177275657654
Agent1_Actor_Loss : -0.7136263251304626
Agent1_Alpha_Loss : 0.7883340120315552
Agent1_Temperature : 0.08595109477439525
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 541 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 542 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 543 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 544 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 545 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 546 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 547 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 548 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 549 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 550 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -31.239856719970703
Agent0_Eval_StdReturn : 19.613271713256836
Agent0_Eval_MaxReturn : 2.437079429626465
Agent0_Eval_MinReturn : -69.08584594726562
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -21.882579803466797
Agent0_Train_StdReturn : 18.62574577331543
Agent0_Train_MaxReturn : 2.7532882690429688
Agent0_Train_MinReturn : -58.506874084472656
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 826500
Agent0_TimeSinceStart : 1266.1983668804169
Agent0_Critic_Loss : 0.5018261671066284
Agent0_Actor_Loss : -0.5675672292709351
Agent0_Alpha_Loss : 0.7882379293441772
Agent0_Temperature : 0.0856832757711825
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -17.1892032623291
Agent1_Eval_StdReturn : 13.571625709533691
Agent1_Eval_MaxReturn : -0.22130346298217773
Agent1_Eval_MinReturn : -35.471195220947266
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -16.739158630371094
Agent1_Train_StdReturn : 13.920950889587402
Agent1_Train_MaxReturn : 6.703393459320068
Agent1_Train_MinReturn : -41.43401336669922
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 826500
Agent1_TimeSinceStart : 1268.2642619609833
Agent1_Critic_Loss : 0.5468749403953552
Agent1_Actor_Loss : -0.6530821323394775
Agent1_Alpha_Loss : 0.7838454842567444
Agent1_Temperature : 0.08570424583701368
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 551 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 552 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 553 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 554 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 555 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 556 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 557 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 558 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 559 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 560 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -14.688253402709961
Agent0_Eval_StdReturn : 18.248254776000977
Agent0_Eval_MaxReturn : 12.04086685180664
Agent0_Eval_MinReturn : -46.15653991699219
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -13.498891830444336
Agent0_Train_StdReturn : 14.662230491638184
Agent0_Train_MaxReturn : 9.186166763305664
Agent0_Train_MinReturn : -41.48243713378906
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 841500
Agent0_TimeSinceStart : 1289.1157739162445
Agent0_Critic_Loss : 0.7500141263008118
Agent0_Actor_Loss : -0.5800411701202393
Agent0_Alpha_Loss : 0.7836422920227051
Agent0_Temperature : 0.08543786919078959
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -23.393014907836914
Agent1_Eval_StdReturn : 14.81954574584961
Agent1_Eval_MaxReturn : 7.026876449584961
Agent1_Eval_MinReturn : -53.213172912597656
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -14.344128608703613
Agent1_Train_StdReturn : 17.341707229614258
Agent1_Train_MaxReturn : 7.978788375854492
Agent1_Train_MinReturn : -50.088626861572266
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 841500
Agent1_TimeSinceStart : 1291.1932225227356
Agent1_Critic_Loss : 0.4734102487564087
Agent1_Actor_Loss : -0.5954023599624634
Agent1_Alpha_Loss : 0.7903136610984802
Agent1_Temperature : 0.08545827044733809
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 561 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 562 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 563 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 564 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 565 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 566 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 567 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 568 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 569 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 570 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -1.515586495399475
Agent0_Eval_StdReturn : 14.052467346191406
Agent0_Eval_MaxReturn : 17.93991470336914
Agent0_Eval_MinReturn : -25.697776794433594
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -9.274171829223633
Agent0_Train_StdReturn : 10.160318374633789
Agent0_Train_MaxReturn : 1.9223127365112305
Agent0_Train_MinReturn : -33.246490478515625
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 856500
Agent0_TimeSinceStart : 1312.1137835979462
Agent0_Critic_Loss : 0.5321818590164185
Agent0_Actor_Loss : -0.5497815012931824
Agent0_Alpha_Loss : 0.7811170816421509
Agent0_Temperature : 0.08519305743599982
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -12.200002670288086
Agent1_Eval_StdReturn : 7.9917426109313965
Agent1_Eval_MaxReturn : 5.589254856109619
Agent1_Eval_MinReturn : -25.01300811767578
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -8.279609680175781
Agent1_Train_StdReturn : 12.201743125915527
Agent1_Train_MaxReturn : 13.252800941467285
Agent1_Train_MinReturn : -32.19404983520508
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 856500
Agent1_TimeSinceStart : 1314.202662229538
Agent1_Critic_Loss : 0.6305469274520874
Agent1_Actor_Loss : -0.6147996783256531
Agent1_Alpha_Loss : 0.7605502009391785
Agent1_Temperature : 0.08521429325746291
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 571 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 572 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 573 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 574 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 575 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 576 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 577 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 578 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 579 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 580 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -20.87425994873047
Agent0_Eval_StdReturn : 7.877281188964844
Agent0_Eval_MaxReturn : -10.271602630615234
Agent0_Eval_MinReturn : -36.08763122558594
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -7.426025390625
Agent0_Train_StdReturn : 7.57212495803833
Agent0_Train_MaxReturn : 9.337104797363281
Agent0_Train_MinReturn : -21.724624633789062
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 871500
Agent0_TimeSinceStart : 1335.2218165397644
Agent0_Critic_Loss : 0.6291088461875916
Agent0_Actor_Loss : -0.6937918663024902
Agent0_Alpha_Loss : 0.7743960618972778
Agent0_Temperature : 0.08494838682982621
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -17.368122100830078
Agent1_Eval_StdReturn : 11.622300148010254
Agent1_Eval_MaxReturn : 0.2678699493408203
Agent1_Eval_MinReturn : -40.387962341308594
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -14.794015884399414
Agent1_Train_StdReturn : 10.833148002624512
Agent1_Train_MaxReturn : -1.9497833251953125
Agent1_Train_MinReturn : -33.53948211669922
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 871500
Agent1_TimeSinceStart : 1337.3203337192535
Agent1_Critic_Loss : 0.44556522369384766
Agent1_Actor_Loss : -0.7977128028869629
Agent1_Alpha_Loss : 0.7495426535606384
Agent1_Temperature : 0.08497388179321025
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 581 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 582 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 583 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 584 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 585 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 586 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 587 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 588 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 589 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 590 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -10.501352310180664
Agent0_Eval_StdReturn : 11.949300765991211
Agent0_Eval_MaxReturn : 8.830918312072754
Agent0_Eval_MinReturn : -38.44133758544922
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -11.250663757324219
Agent0_Train_StdReturn : 8.795297622680664
Agent0_Train_MaxReturn : 2.0222930908203125
Agent0_Train_MinReturn : -31.964736938476562
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 886500
Agent0_TimeSinceStart : 1358.4022145271301
Agent0_Critic_Loss : 0.528895378112793
Agent0_Actor_Loss : -0.4869006276130676
Agent0_Alpha_Loss : 0.7796582579612732
Agent0_Temperature : 0.08470583599384655
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -14.541705131530762
Agent1_Eval_StdReturn : 10.39571475982666
Agent1_Eval_MaxReturn : -4.230254173278809
Agent1_Eval_MinReturn : -39.48621368408203
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -17.186649322509766
Agent1_Train_StdReturn : 14.656901359558105
Agent1_Train_MaxReturn : 5.157923698425293
Agent1_Train_MinReturn : -45.31023406982422
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 886500
Agent1_TimeSinceStart : 1360.5056321620941
Agent1_Critic_Loss : 0.719297468662262
Agent1_Actor_Loss : -0.7688557505607605
Agent1_Alpha_Loss : 0.7587243914604187
Agent1_Temperature : 0.08473626305358019
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 591 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 592 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 593 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 594 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 595 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 596 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 597 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 598 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 599 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 600 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -10.987436294555664
Agent0_Eval_StdReturn : 13.54967975616455
Agent0_Eval_MaxReturn : 12.858606338500977
Agent0_Eval_MinReturn : -28.911867141723633
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -4.862919807434082
Agent0_Train_StdReturn : 13.41033935546875
Agent0_Train_MaxReturn : 21.731021881103516
Agent0_Train_MinReturn : -29.690196990966797
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 901500
Agent0_TimeSinceStart : 1381.5393538475037
Agent0_Critic_Loss : 0.6702048182487488
Agent0_Actor_Loss : -0.6352546215057373
Agent0_Alpha_Loss : 0.7635716199874878
Agent0_Temperature : 0.08446471998473713
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -14.962056159973145
Agent1_Eval_StdReturn : 10.205648422241211
Agent1_Eval_MaxReturn : 2.886659622192383
Agent1_Eval_MinReturn : -28.596818923950195
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -19.413257598876953
Agent1_Train_StdReturn : 11.393864631652832
Agent1_Train_MaxReturn : -2.850250244140625
Agent1_Train_MinReturn : -39.880760192871094
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 901500
Agent1_TimeSinceStart : 1383.625696182251
Agent1_Critic_Loss : 0.6941629648208618
Agent1_Actor_Loss : -0.6108806133270264
Agent1_Alpha_Loss : 0.7451852560043335
Agent1_Temperature : 0.084501038973367
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 601 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 602 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 603 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 604 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 605 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 606 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 607 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 608 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 609 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 610 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -16.090871810913086
Agent0_Eval_StdReturn : 9.718660354614258
Agent0_Eval_MaxReturn : -1.6552629470825195
Agent0_Eval_MinReturn : -37.993587493896484
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -13.323654174804688
Agent0_Train_StdReturn : 9.007024765014648
Agent0_Train_MaxReturn : 5.772009372711182
Agent0_Train_MinReturn : -24.87804412841797
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 916500
Agent0_TimeSinceStart : 1404.7108960151672
Agent0_Critic_Loss : 0.546593189239502
Agent0_Actor_Loss : -0.5947573184967041
Agent0_Alpha_Loss : 0.7780710458755493
Agent0_Temperature : 0.084223866831568
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -17.623220443725586
Agent1_Eval_StdReturn : 5.782309532165527
Agent1_Eval_MaxReturn : -8.224926948547363
Agent1_Eval_MinReturn : -28.878740310668945
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -16.640230178833008
Agent1_Train_StdReturn : 9.992303848266602
Agent1_Train_MaxReturn : -4.664743423461914
Agent1_Train_MinReturn : -35.35348892211914
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 916500
Agent1_TimeSinceStart : 1406.7962341308594
Agent1_Critic_Loss : 0.8709293603897095
Agent1_Actor_Loss : -0.7172213792800903
Agent1_Alpha_Loss : 0.7534449100494385
Agent1_Temperature : 0.08426729296540578
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 611 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 612 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 613 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 614 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 615 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 616 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 617 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 618 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 619 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 620 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -8.441520690917969
Agent0_Eval_StdReturn : 9.607327461242676
Agent0_Eval_MaxReturn : 5.4035749435424805
Agent0_Eval_MinReturn : -26.389280319213867
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -12.032208442687988
Agent0_Train_StdReturn : 13.175533294677734
Agent0_Train_MaxReturn : 8.05854320526123
Agent0_Train_MinReturn : -34.84600830078125
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 931500
Agent0_TimeSinceStart : 1427.7654552459717
Agent0_Critic_Loss : 0.6027611494064331
Agent0_Actor_Loss : -0.5070472955703735
Agent0_Alpha_Loss : 0.7614203095436096
Agent0_Temperature : 0.08398370993834203
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -17.1220703125
Agent1_Eval_StdReturn : 13.102070808410645
Agent1_Eval_MaxReturn : 5.20969295501709
Agent1_Eval_MinReturn : -41.83019256591797
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -8.757726669311523
Agent1_Train_StdReturn : 11.274101257324219
Agent1_Train_MaxReturn : 11.409553527832031
Agent1_Train_MinReturn : -25.16904067993164
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 931500
Agent1_TimeSinceStart : 1429.8520171642303
Agent1_Critic_Loss : 0.628567636013031
Agent1_Actor_Loss : -0.6676252484321594
Agent1_Alpha_Loss : 0.7555014491081238
Agent1_Temperature : 0.08403230840331932
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 621 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 622 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 623 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 624 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 625 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 626 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 627 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 628 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 629 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 630 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -10.536383628845215
Agent0_Eval_StdReturn : 8.855547904968262
Agent0_Eval_MaxReturn : -0.798464298248291
Agent0_Eval_MinReturn : -31.221683502197266
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -12.874893188476562
Agent0_Train_StdReturn : 14.967723846435547
Agent0_Train_MaxReturn : 7.527082920074463
Agent0_Train_MinReturn : -36.354087829589844
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 946500
Agent0_TimeSinceStart : 1450.830911397934
Agent0_Critic_Loss : 0.6779758930206299
Agent0_Actor_Loss : -0.762742280960083
Agent0_Alpha_Loss : 0.7499457597732544
Agent0_Temperature : 0.08374422668941521
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -11.814539909362793
Agent1_Eval_StdReturn : 11.1293363571167
Agent1_Eval_MaxReturn : 2.8999533653259277
Agent1_Eval_MinReturn : -33.038787841796875
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -25.22002601623535
Agent1_Train_StdReturn : 17.032014846801758
Agent1_Train_MaxReturn : 3.0753607749938965
Agent1_Train_MinReturn : -57.38099670410156
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 946500
Agent1_TimeSinceStart : 1452.9110465049744
Agent1_Critic_Loss : 0.5491583347320557
Agent1_Actor_Loss : -0.6596088409423828
Agent1_Alpha_Loss : 0.770915150642395
Agent1_Temperature : 0.0837957812254833
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 631 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 632 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 633 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 634 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 635 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 636 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 637 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 638 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 639 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 640 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -11.041717529296875
Agent0_Eval_StdReturn : 11.664421081542969
Agent0_Eval_MaxReturn : 1.1721305847167969
Agent0_Eval_MinReturn : -34.32500076293945
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -19.485361099243164
Agent0_Train_StdReturn : 14.404484748840332
Agent0_Train_MaxReturn : 3.2269539833068848
Agent0_Train_MinReturn : -46.073524475097656
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 961500
Agent0_TimeSinceStart : 1473.8706209659576
Agent0_Critic_Loss : 0.48909246921539307
Agent0_Actor_Loss : -0.7207685708999634
Agent0_Alpha_Loss : 0.7731655836105347
Agent0_Temperature : 0.08350586562055314
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -11.9410982131958
Agent1_Eval_StdReturn : 20.32008934020996
Agent1_Eval_MaxReturn : 14.054878234863281
Agent1_Eval_MinReturn : -59.96398162841797
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -18.277246475219727
Agent1_Train_StdReturn : 20.36745262145996
Agent1_Train_MaxReturn : 18.40605926513672
Agent1_Train_MinReturn : -45.29593276977539
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 961500
Agent1_TimeSinceStart : 1475.959923028946
Agent1_Critic_Loss : 0.5420087575912476
Agent1_Actor_Loss : -0.7772493362426758
Agent1_Alpha_Loss : 0.7689802646636963
Agent1_Temperature : 0.08355835003790149
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 641 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 642 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 643 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 644 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 645 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 646 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 647 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 648 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 649 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 650 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -15.346200942993164
Agent0_Eval_StdReturn : 11.258657455444336
Agent0_Eval_MaxReturn : -0.17970073223114014
Agent0_Eval_MinReturn : -35.480159759521484
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -23.746583938598633
Agent0_Train_StdReturn : 17.487470626831055
Agent0_Train_MaxReturn : 2.128896713256836
Agent0_Train_MinReturn : -54.607601165771484
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 976500
Agent0_TimeSinceStart : 1496.9627692699432
Agent0_Critic_Loss : 0.5747621059417725
Agent0_Actor_Loss : -0.5934022068977356
Agent0_Alpha_Loss : 0.769675612449646
Agent0_Temperature : 0.08326752732568903
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -7.224801540374756
Agent1_Eval_StdReturn : 15.625633239746094
Agent1_Eval_MaxReturn : 16.138948440551758
Agent1_Eval_MinReturn : -28.347251892089844
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -18.119665145874023
Agent1_Train_StdReturn : 14.877395629882812
Agent1_Train_MaxReturn : 1.8180179595947266
Agent1_Train_MinReturn : -41.82242965698242
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 976500
Agent1_TimeSinceStart : 1499.0429944992065
Agent1_Critic_Loss : 0.639671802520752
Agent1_Actor_Loss : -0.7163318991661072
Agent1_Alpha_Loss : 0.7781887650489807
Agent1_Temperature : 0.08332070469879281
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 651 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 652 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 653 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 654 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 655 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 656 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 657 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 658 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 659 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 660 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -9.686644554138184
Agent0_Eval_StdReturn : 9.958781242370605
Agent0_Eval_MaxReturn : 8.134521484375
Agent0_Eval_MinReturn : -24.740528106689453
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : 6.801232814788818
Agent0_Train_StdReturn : 17.599445343017578
Agent0_Train_MaxReturn : 41.91776657104492
Agent0_Train_MinReturn : -23.929824829101562
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 991500
Agent0_TimeSinceStart : 1519.946275472641
Agent0_Critic_Loss : 0.5790886878967285
Agent0_Actor_Loss : -0.6410186290740967
Agent0_Alpha_Loss : 0.7878848910331726
Agent0_Temperature : 0.08302854381086289
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -6.330203056335449
Agent1_Eval_StdReturn : 11.421257972717285
Agent1_Eval_MaxReturn : 13.451123237609863
Agent1_Eval_MinReturn : -28.50696563720703
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -26.183298110961914
Agent1_Train_StdReturn : 14.696687698364258
Agent1_Train_MaxReturn : -0.5881071090698242
Agent1_Train_MinReturn : -50.97002410888672
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 991500
Agent1_TimeSinceStart : 1522.0194954872131
Agent1_Critic_Loss : 0.5666189193725586
Agent1_Actor_Loss : -0.6973636150360107
Agent1_Alpha_Loss : 0.7713466286659241
Agent1_Temperature : 0.08308235137870872
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 661 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 662 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 663 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 664 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 665 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 666 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 667 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 668 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 669 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 670 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -6.864727020263672
Agent0_Eval_StdReturn : 13.843767166137695
Agent0_Eval_MaxReturn : 9.756133079528809
Agent0_Eval_MinReturn : -32.81734848022461
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -9.623991012573242
Agent0_Train_StdReturn : 21.122718811035156
Agent0_Train_MaxReturn : 39.05826187133789
Agent0_Train_MinReturn : -33.312095642089844
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1006500
Agent0_TimeSinceStart : 1542.8861863613129
Agent0_Critic_Loss : 0.5418594479560852
Agent0_Actor_Loss : -0.5883805751800537
Agent0_Alpha_Loss : 0.78117835521698
Agent0_Temperature : 0.08278907123442547
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -7.436829566955566
Agent1_Eval_StdReturn : 12.935439109802246
Agent1_Eval_MaxReturn : 15.758340835571289
Agent1_Eval_MinReturn : -23.86128044128418
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -1.397493839263916
Agent1_Train_StdReturn : 11.92352294921875
Agent1_Train_MaxReturn : 19.279796600341797
Agent1_Train_MinReturn : -22.952159881591797
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1006500
Agent1_TimeSinceStart : 1544.9508216381073
Agent1_Critic_Loss : 0.5056509971618652
Agent1_Actor_Loss : -0.7292859554290771
Agent1_Alpha_Loss : 0.7837110757827759
Agent1_Temperature : 0.08284380331499074
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 671 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 672 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 673 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 674 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 675 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 676 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 677 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 678 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 679 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 680 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -20.498546600341797
Agent0_Eval_StdReturn : 22.015409469604492
Agent0_Eval_MaxReturn : 6.505045413970947
Agent0_Eval_MinReturn : -68.92893981933594
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -20.264963150024414
Agent0_Train_StdReturn : 30.337560653686523
Agent0_Train_MaxReturn : 10.264175415039062
Agent0_Train_MinReturn : -101.37435913085938
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1021500
Agent0_TimeSinceStart : 1565.8572175502777
Agent0_Critic_Loss : 0.5897067189216614
Agent0_Actor_Loss : -0.663994550704956
Agent0_Alpha_Loss : 0.7725344300270081
Agent0_Temperature : 0.08254974980337296
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -12.86730670928955
Agent1_Eval_StdReturn : 11.284802436828613
Agent1_Eval_MaxReturn : 12.396674156188965
Agent1_Eval_MinReturn : -27.17299461364746
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -8.79047966003418
Agent1_Train_StdReturn : 12.974494934082031
Agent1_Train_MaxReturn : 11.580245018005371
Agent1_Train_MinReturn : -32.42308044433594
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1021500
Agent1_TimeSinceStart : 1567.9388864040375
Agent1_Critic_Loss : 0.695067822933197
Agent1_Actor_Loss : -0.718146800994873
Agent1_Alpha_Loss : 0.7825251221656799
Agent1_Temperature : 0.08260524225390212
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 681 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 682 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 683 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 684 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 685 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 686 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 687 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 688 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 689 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 690 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -7.489443302154541
Agent0_Eval_StdReturn : 12.878320693969727
Agent0_Eval_MaxReturn : 12.462331771850586
Agent0_Eval_MinReturn : -32.966495513916016
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -18.555316925048828
Agent0_Train_StdReturn : 22.33014488220215
Agent0_Train_MaxReturn : 9.971490859985352
Agent0_Train_MinReturn : -54.14688491821289
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1036500
Agent0_TimeSinceStart : 1588.7623691558838
Agent0_Critic_Loss : 0.7479048371315002
Agent0_Actor_Loss : -0.7237768173217773
Agent0_Alpha_Loss : 0.7702091932296753
Agent0_Temperature : 0.08231126823135938
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -20.627840042114258
Agent1_Eval_StdReturn : 14.011497497558594
Agent1_Eval_MaxReturn : 5.808007717132568
Agent1_Eval_MinReturn : -43.21833038330078
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -31.15386962890625
Agent1_Train_StdReturn : 23.668773651123047
Agent1_Train_MaxReturn : 1.652033805847168
Agent1_Train_MinReturn : -83.32699584960938
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1036500
Agent1_TimeSinceStart : 1590.8263232707977
Agent1_Critic_Loss : 0.5085196495056152
Agent1_Actor_Loss : -0.7264593243598938
Agent1_Alpha_Loss : 0.7718053460121155
Agent1_Temperature : 0.08236770625699992
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 691 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 692 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 693 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 694 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 695 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 696 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 697 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 698 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 699 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 700 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -9.853452682495117
Agent0_Eval_StdReturn : 24.16927719116211
Agent0_Eval_MaxReturn : 19.59316635131836
Agent0_Eval_MinReturn : -52.146385192871094
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -20.390317916870117
Agent0_Train_StdReturn : 20.621231079101562
Agent0_Train_MaxReturn : 12.446203231811523
Agent0_Train_MinReturn : -68.47635650634766
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1051500
Agent0_TimeSinceStart : 1611.6743121147156
Agent0_Critic_Loss : 0.605553150177002
Agent0_Actor_Loss : -0.698580801486969
Agent0_Alpha_Loss : 0.779687762260437
Agent0_Temperature : 0.08207364749853582
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -17.888500213623047
Agent1_Eval_StdReturn : 10.096004486083984
Agent1_Eval_MaxReturn : -6.726120471954346
Agent1_Eval_MinReturn : -41.58632278442383
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -17.46761703491211
Agent1_Train_StdReturn : 24.51812744140625
Agent1_Train_MaxReturn : 11.683475494384766
Agent1_Train_MinReturn : -68.22061157226562
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1051500
Agent1_TimeSinceStart : 1613.7471060752869
Agent1_Critic_Loss : 0.6697183847427368
Agent1_Actor_Loss : -0.7974703311920166
Agent1_Alpha_Loss : 0.7777841091156006
Agent1_Temperature : 0.08213106406196213
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 701 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 702 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 703 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 704 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 705 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 706 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 707 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 708 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 709 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 710 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -20.480287551879883
Agent0_Eval_StdReturn : 22.710939407348633
Agent0_Eval_MaxReturn : 29.285799026489258
Agent0_Eval_MinReturn : -51.63276290893555
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -7.695353031158447
Agent0_Train_StdReturn : 10.521684646606445
Agent0_Train_MaxReturn : 3.6069321632385254
Agent0_Train_MinReturn : -26.592594146728516
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1066500
Agent0_TimeSinceStart : 1634.6064007282257
Agent0_Critic_Loss : 0.7357970476150513
Agent0_Actor_Loss : -0.7298781871795654
Agent0_Alpha_Loss : 0.7640070915222168
Agent0_Temperature : 0.08183571134359427
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -14.020217895507812
Agent1_Eval_StdReturn : 15.515666961669922
Agent1_Eval_MaxReturn : 8.065631866455078
Agent1_Eval_MinReturn : -49.163795471191406
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -7.146122932434082
Agent1_Train_StdReturn : 19.377025604248047
Agent1_Train_MaxReturn : 22.883647918701172
Agent1_Train_MinReturn : -45.40814208984375
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1066500
Agent1_TimeSinceStart : 1636.6850056648254
Agent1_Critic_Loss : 0.6178573966026306
Agent1_Actor_Loss : -0.8493142127990723
Agent1_Alpha_Loss : 0.7666648626327515
Agent1_Temperature : 0.0818940528862506
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 711 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 712 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 713 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 714 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 715 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 716 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 717 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 718 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 719 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 720 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -24.12255859375
Agent0_Eval_StdReturn : 23.725515365600586
Agent0_Eval_MaxReturn : 11.39466667175293
Agent0_Eval_MinReturn : -68.89415740966797
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -13.477253913879395
Agent0_Train_StdReturn : 20.332881927490234
Agent0_Train_MaxReturn : 21.17325782775879
Agent0_Train_MinReturn : -46.324005126953125
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1081500
Agent0_TimeSinceStart : 1657.5734510421753
Agent0_Critic_Loss : 0.7113884687423706
Agent0_Actor_Loss : -0.7690086364746094
Agent0_Alpha_Loss : 0.7694422602653503
Agent0_Temperature : 0.0815982557598894
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -28.94089698791504
Agent1_Eval_StdReturn : 18.753934860229492
Agent1_Eval_MaxReturn : 0.7128658294677734
Agent1_Eval_MinReturn : -57.20647048950195
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -25.75436782836914
Agent1_Train_StdReturn : 23.205324172973633
Agent1_Train_MaxReturn : 16.550006866455078
Agent1_Train_MinReturn : -65.72025299072266
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1081500
Agent1_TimeSinceStart : 1659.645546913147
Agent1_Critic_Loss : 0.6489816904067993
Agent1_Actor_Loss : -0.8982301950454712
Agent1_Alpha_Loss : 0.7679495215415955
Agent1_Temperature : 0.08165718810138524
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 721 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 722 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 723 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 724 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 725 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 726 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 727 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 728 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 729 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 730 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -25.3577880859375
Agent0_Eval_StdReturn : 25.774005889892578
Agent0_Eval_MaxReturn : 20.61355972290039
Agent0_Eval_MinReturn : -67.46720886230469
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -14.480792045593262
Agent0_Train_StdReturn : 21.45728302001953
Agent0_Train_MaxReturn : 13.354488372802734
Agent0_Train_MinReturn : -66.56959533691406
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1096500
Agent0_TimeSinceStart : 1680.495579957962
Agent0_Critic_Loss : 0.8145553469657898
Agent0_Actor_Loss : -0.8782665729522705
Agent0_Alpha_Loss : 0.7638387680053711
Agent0_Temperature : 0.08136189646878296
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -19.98943328857422
Agent1_Eval_StdReturn : 24.8953800201416
Agent1_Eval_MaxReturn : 14.528536796569824
Agent1_Eval_MinReturn : -58.65454864501953
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -13.637445449829102
Agent1_Train_StdReturn : 28.56919288635254
Agent1_Train_MaxReturn : 15.068708419799805
Agent1_Train_MinReturn : -93.39530944824219
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1096500
Agent1_TimeSinceStart : 1682.5669329166412
Agent1_Critic_Loss : 0.7773444056510925
Agent1_Actor_Loss : -0.7463395595550537
Agent1_Alpha_Loss : 0.770226001739502
Agent1_Temperature : 0.08142062499690146
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 731 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 732 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 733 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 734 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 735 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 736 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 737 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 738 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 739 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 740 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -22.108266830444336
Agent0_Eval_StdReturn : 18.401531219482422
Agent0_Eval_MaxReturn : 17.71811294555664
Agent0_Eval_MinReturn : -45.261695861816406
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -4.926565170288086
Agent0_Train_StdReturn : 25.392017364501953
Agent0_Train_MaxReturn : 26.197010040283203
Agent0_Train_MinReturn : -48.290687561035156
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1111500
Agent0_TimeSinceStart : 1703.456485748291
Agent0_Critic_Loss : 0.6871801614761353
Agent0_Actor_Loss : -0.7219812273979187
Agent0_Alpha_Loss : 0.7720590233802795
Agent0_Temperature : 0.08112675992068258
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -16.07327651977539
Agent1_Eval_StdReturn : 14.883213996887207
Agent1_Eval_MaxReturn : 8.04903793334961
Agent1_Eval_MinReturn : -38.96515655517578
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -14.694737434387207
Agent1_Train_StdReturn : 13.42167854309082
Agent1_Train_MaxReturn : -0.47957420349121094
Agent1_Train_MinReturn : -49.557273864746094
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1111500
Agent1_TimeSinceStart : 1705.532586812973
Agent1_Critic_Loss : 0.9163751602172852
Agent1_Actor_Loss : -0.7670755386352539
Agent1_Alpha_Loss : 0.7782416343688965
Agent1_Temperature : 0.08118397757842323
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 741 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 742 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 743 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 744 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 745 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 746 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 747 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 748 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 749 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 750 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -22.871484756469727
Agent0_Eval_StdReturn : 16.75594139099121
Agent0_Eval_MaxReturn : -1.803861141204834
Agent0_Eval_MinReturn : -49.42198944091797
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -15.929336547851562
Agent0_Train_StdReturn : 13.813666343688965
Agent0_Train_MaxReturn : 3.661201238632202
Agent0_Train_MinReturn : -42.00370788574219
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1126500
Agent0_TimeSinceStart : 1726.415282011032
Agent0_Critic_Loss : 0.773666262626648
Agent0_Actor_Loss : -0.8029878735542297
Agent0_Alpha_Loss : 0.7560228109359741
Agent0_Temperature : 0.08089327533608015
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -28.80582046508789
Agent1_Eval_StdReturn : 25.56242561340332
Agent1_Eval_MaxReturn : -7.644073486328125
Agent1_Eval_MinReturn : -89.4603500366211
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -9.272854804992676
Agent1_Train_StdReturn : 19.46297264099121
Agent1_Train_MaxReturn : 19.36722183227539
Agent1_Train_MinReturn : -38.2498664855957
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1126500
Agent1_TimeSinceStart : 1728.4873337745667
Agent1_Critic_Loss : 0.7841399312019348
Agent1_Actor_Loss : -0.8604090213775635
Agent1_Alpha_Loss : 0.778292179107666
Agent1_Temperature : 0.08094825845604942
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 751 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 752 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 753 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 754 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 755 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 756 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 757 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 758 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 759 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 760 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -10.892950057983398
Agent0_Eval_StdReturn : 11.367986679077148
Agent0_Eval_MaxReturn : 6.937324047088623
Agent0_Eval_MinReturn : -26.95268440246582
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -11.04455852508545
Agent0_Train_StdReturn : 11.235014915466309
Agent0_Train_MaxReturn : 9.457030296325684
Agent0_Train_MinReturn : -28.972402572631836
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1141500
Agent0_TimeSinceStart : 1749.4392499923706
Agent0_Critic_Loss : 0.9834284782409668
Agent0_Actor_Loss : -0.8972921371459961
Agent0_Alpha_Loss : 0.7593405842781067
Agent0_Temperature : 0.08066298370455698
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -9.911128044128418
Agent1_Eval_StdReturn : 12.989097595214844
Agent1_Eval_MaxReturn : 16.761707305908203
Agent1_Eval_MinReturn : -32.403038024902344
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -23.024005889892578
Agent1_Train_StdReturn : 10.155010223388672
Agent1_Train_MaxReturn : -8.118786811828613
Agent1_Train_MinReturn : -45.97794723510742
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1141500
Agent1_TimeSinceStart : 1751.520352602005
Agent1_Critic_Loss : 0.9441054463386536
Agent1_Actor_Loss : -0.7322274446487427
Agent1_Alpha_Loss : 0.769540548324585
Agent1_Temperature : 0.0807137829571907
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 761 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 762 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 763 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 764 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 765 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 766 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 767 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 768 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 769 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 770 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -13.221585273742676
Agent0_Eval_StdReturn : 19.07308006286621
Agent0_Eval_MaxReturn : 6.476760387420654
Agent0_Eval_MinReturn : -52.109283447265625
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -8.146883964538574
Agent0_Train_StdReturn : 11.058053970336914
Agent0_Train_MaxReturn : 10.377676010131836
Agent0_Train_MinReturn : -24.91497039794922
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1156500
Agent0_TimeSinceStart : 1772.5145692825317
Agent0_Critic_Loss : 0.6780635714530945
Agent0_Actor_Loss : -0.6838554739952087
Agent0_Alpha_Loss : 0.7496218085289001
Agent0_Temperature : 0.0804357674618527
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -8.4553804397583
Agent1_Eval_StdReturn : 14.534753799438477
Agent1_Eval_MaxReturn : 25.536638259887695
Agent1_Eval_MinReturn : -32.594825744628906
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -25.03299331665039
Agent1_Train_StdReturn : 13.521459579467773
Agent1_Train_MaxReturn : -1.251540184020996
Agent1_Train_MinReturn : -45.22138214111328
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1156500
Agent1_TimeSinceStart : 1774.591501235962
Agent1_Critic_Loss : 0.8449051380157471
Agent1_Actor_Loss : -0.7959266901016235
Agent1_Alpha_Loss : 0.761849582195282
Agent1_Temperature : 0.08048111858430497
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 771 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 772 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 773 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 774 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 775 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 776 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 777 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 778 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 779 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 780 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -11.91928768157959
Agent0_Eval_StdReturn : 15.146088600158691
Agent0_Eval_MaxReturn : 4.482291221618652
Agent0_Eval_MinReturn : -51.883060455322266
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -13.905950546264648
Agent0_Train_StdReturn : 10.719435691833496
Agent0_Train_MaxReturn : -0.029184579849243164
Agent0_Train_MinReturn : -35.214080810546875
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1171500
Agent0_TimeSinceStart : 1795.6417365074158
Agent0_Critic_Loss : 0.8899201154708862
Agent0_Actor_Loss : -0.6465409994125366
Agent0_Alpha_Loss : 0.7302095890045166
Agent0_Temperature : 0.08021106119387597
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -13.853276252746582
Agent1_Eval_StdReturn : 13.039346694946289
Agent1_Eval_MaxReturn : 12.705230712890625
Agent1_Eval_MinReturn : -31.57868194580078
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -14.920387268066406
Agent1_Train_StdReturn : 11.445453643798828
Agent1_Train_MaxReturn : 2.300295829772949
Agent1_Train_MinReturn : -29.321453094482422
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1171500
Agent1_TimeSinceStart : 1797.730185508728
Agent1_Critic_Loss : 0.9235205054283142
Agent1_Actor_Loss : -0.670853316783905
Agent1_Alpha_Loss : 0.7582095265388489
Agent1_Temperature : 0.08025042858425072
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 781 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 782 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 783 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 784 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 785 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 786 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 787 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 788 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 789 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 790 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -12.049615859985352
Agent0_Eval_StdReturn : 15.079082489013672
Agent0_Eval_MaxReturn : 6.004582405090332
Agent0_Eval_MinReturn : -41.002925872802734
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -12.194875717163086
Agent0_Train_StdReturn : 14.133841514587402
Agent0_Train_MaxReturn : 6.371026039123535
Agent0_Train_MinReturn : -40.795501708984375
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1186500
Agent0_TimeSinceStart : 1818.7570786476135
Agent0_Critic_Loss : 0.898591935634613
Agent0_Actor_Loss : -0.7421452403068542
Agent0_Alpha_Loss : 0.7406709790229797
Agent0_Temperature : 0.07998856321565184
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -8.79047966003418
Agent1_Eval_StdReturn : 12.04590892791748
Agent1_Eval_MaxReturn : 9.673582077026367
Agent1_Eval_MinReturn : -28.19672393798828
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -13.648571968078613
Agent1_Train_StdReturn : 7.781617164611816
Agent1_Train_MaxReturn : -4.453423500061035
Agent1_Train_MinReturn : -29.10730743408203
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1186500
Agent1_TimeSinceStart : 1820.8535676002502
Agent1_Critic_Loss : 1.026956558227539
Agent1_Actor_Loss : -0.694986879825592
Agent1_Alpha_Loss : 0.7457776665687561
Agent1_Temperature : 0.08002201532096431
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 791 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 792 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 793 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 794 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 795 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 796 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 797 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 798 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 799 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 800 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -14.421028137207031
Agent0_Eval_StdReturn : 22.34651756286621
Agent0_Eval_MaxReturn : 15.911941528320312
Agent0_Eval_MinReturn : -53.19053649902344
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -7.536801338195801
Agent0_Train_StdReturn : 16.83022689819336
Agent0_Train_MaxReturn : 29.480348587036133
Agent0_Train_MinReturn : -29.20463752746582
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1201500
Agent0_TimeSinceStart : 1841.9019286632538
Agent0_Critic_Loss : 0.7107083797454834
Agent0_Actor_Loss : -1.0181629657745361
Agent0_Alpha_Loss : 0.7478922605514526
Agent0_Temperature : 0.07976494097574023
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -10.624963760375977
Agent1_Eval_StdReturn : 8.807572364807129
Agent1_Eval_MaxReturn : 0.7783756256103516
Agent1_Eval_MinReturn : -28.734098434448242
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -17.546405792236328
Agent1_Train_StdReturn : 7.747036933898926
Agent1_Train_MaxReturn : -7.880570411682129
Agent1_Train_MinReturn : -29.245349884033203
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1201500
Agent1_TimeSinceStart : 1844.0050733089447
Agent1_Critic_Loss : 0.7592180967330933
Agent1_Actor_Loss : -0.8714340925216675
Agent1_Alpha_Loss : 0.7296937108039856
Agent1_Temperature : 0.0797978678438876
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 801 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 802 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 803 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 804 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 805 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 806 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 807 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 808 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 809 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 810 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -12.999130249023438
Agent0_Eval_StdReturn : 12.038371086120605
Agent0_Eval_MaxReturn : 3.09893798828125
Agent0_Eval_MinReturn : -35.38753128051758
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -16.124774932861328
Agent0_Train_StdReturn : 17.931926727294922
Agent0_Train_MaxReturn : 9.962491989135742
Agent0_Train_MinReturn : -46.18568420410156
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1216500
Agent0_TimeSinceStart : 1865.0363759994507
Agent0_Critic_Loss : 0.7478347420692444
Agent0_Actor_Loss : -0.8612176179885864
Agent0_Alpha_Loss : 0.7600445747375488
Agent0_Temperature : 0.07954099230047265
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -16.795066833496094
Agent1_Eval_StdReturn : 10.733397483825684
Agent1_Eval_MaxReturn : 4.838855743408203
Agent1_Eval_MinReturn : -33.1224250793457
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -8.211443901062012
Agent1_Train_StdReturn : 15.748673439025879
Agent1_Train_MaxReturn : 11.46767520904541
Agent1_Train_MinReturn : -44.4361572265625
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1216500
Agent1_TimeSinceStart : 1867.130760192871
Agent1_Critic_Loss : 1.0424331426620483
Agent1_Actor_Loss : -0.9064640998840332
Agent1_Alpha_Loss : 0.7191044688224792
Agent1_Temperature : 0.07957715711452838
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 811 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 812 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 813 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 814 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 815 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 816 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 817 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 818 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 819 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 820 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -8.579635620117188
Agent0_Eval_StdReturn : 15.508373260498047
Agent0_Eval_MaxReturn : 19.474872589111328
Agent0_Eval_MinReturn : -32.17748260498047
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -10.49592399597168
Agent0_Train_StdReturn : 16.062076568603516
Agent0_Train_MaxReturn : 12.859077453613281
Agent0_Train_MinReturn : -39.054195404052734
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1231500
Agent0_TimeSinceStart : 1888.2374572753906
Agent0_Critic_Loss : 0.8939992189407349
Agent0_Actor_Loss : -0.9302941560745239
Agent0_Alpha_Loss : 0.740726113319397
Agent0_Temperature : 0.07931753938713337
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -18.37263298034668
Agent1_Eval_StdReturn : 10.89452075958252
Agent1_Eval_MaxReturn : -6.617547988891602
Agent1_Eval_MinReturn : -46.179840087890625
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -13.4253568649292
Agent1_Train_StdReturn : 11.901285171508789
Agent1_Train_MaxReturn : 2.9211654663085938
Agent1_Train_MinReturn : -34.8180046081543
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1231500
Agent1_TimeSinceStart : 1890.3293206691742
Agent1_Critic_Loss : 0.9142398834228516
Agent1_Actor_Loss : -0.8349727392196655
Agent1_Alpha_Loss : 0.7178313136100769
Agent1_Temperature : 0.07935954426152464
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 821 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 822 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 823 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 824 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 825 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 826 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 827 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 828 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 829 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 830 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -16.788436889648438
Agent0_Eval_StdReturn : 16.074710845947266
Agent0_Eval_MaxReturn : 9.56419849395752
Agent0_Eval_MinReturn : -52.69281768798828
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -16.610517501831055
Agent0_Train_StdReturn : 11.52188491821289
Agent0_Train_MaxReturn : -3.339895725250244
Agent0_Train_MinReturn : -33.06459045410156
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1246500
Agent0_TimeSinceStart : 1911.3641302585602
Agent0_Critic_Loss : 0.8669594526290894
Agent0_Actor_Loss : -0.8386996984481812
Agent0_Alpha_Loss : 0.7484422922134399
Agent0_Temperature : 0.07909462730268037
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -19.625843048095703
Agent1_Eval_StdReturn : 13.785057067871094
Agent1_Eval_MaxReturn : 0.9065380096435547
Agent1_Eval_MinReturn : -41.00495910644531
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -12.49323844909668
Agent1_Train_StdReturn : 11.903606414794922
Agent1_Train_MaxReturn : 3.856045961380005
Agent1_Train_MinReturn : -40.42573547363281
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1246500
Agent1_TimeSinceStart : 1913.4637837409973
Agent1_Critic_Loss : 0.9632700681686401
Agent1_Actor_Loss : -0.8565414547920227
Agent1_Alpha_Loss : 0.7325758337974548
Agent1_Temperature : 0.0791436934566601
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 831 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 832 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 833 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 834 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 835 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 836 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 837 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 838 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 839 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 840 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -7.942083835601807
Agent0_Eval_StdReturn : 13.326818466186523
Agent0_Eval_MaxReturn : 15.85114860534668
Agent0_Eval_MinReturn : -30.673063278198242
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -6.649231910705566
Agent0_Train_StdReturn : 10.562532424926758
Agent0_Train_MaxReturn : 15.275123596191406
Agent0_Train_MinReturn : -24.49832534790039
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1261500
Agent0_TimeSinceStart : 1934.4848415851593
Agent0_Critic_Loss : 0.712701678276062
Agent0_Actor_Loss : -0.7691743969917297
Agent0_Alpha_Loss : 0.7463480234146118
Agent0_Temperature : 0.07887111242157875
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -16.9050235748291
Agent1_Eval_StdReturn : 9.61221981048584
Agent1_Eval_MaxReturn : -1.401694893836975
Agent1_Eval_MinReturn : -31.38979721069336
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -16.899852752685547
Agent1_Train_StdReturn : 9.486376762390137
Agent1_Train_MaxReturn : -0.5959682464599609
Agent1_Train_MinReturn : -35.98175048828125
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1261500
Agent1_TimeSinceStart : 1936.5792548656464
Agent1_Critic_Loss : 0.7057119011878967
Agent1_Actor_Loss : -0.8910397291183472
Agent1_Alpha_Loss : 0.727565348148346
Agent1_Temperature : 0.0789277345071317
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 841 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 842 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 843 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 844 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 845 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 846 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 847 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 848 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 849 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 850 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -11.075551986694336
Agent0_Eval_StdReturn : 16.506505966186523
Agent0_Eval_MaxReturn : 13.137085914611816
Agent0_Eval_MinReturn : -40.492794036865234
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : 2.415398597717285
Agent0_Train_StdReturn : 17.566713333129883
Agent0_Train_MaxReturn : 33.3600959777832
Agent0_Train_MinReturn : -23.370689392089844
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1276500
Agent0_TimeSinceStart : 1957.6031827926636
Agent0_Critic_Loss : 0.8672051429748535
Agent0_Actor_Loss : -0.994889497756958
Agent0_Alpha_Loss : 0.7430098056793213
Agent0_Temperature : 0.07864764951173449
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -17.15692901611328
Agent1_Eval_StdReturn : 8.896439552307129
Agent1_Eval_MaxReturn : -6.674156188964844
Agent1_Eval_MinReturn : -36.55526351928711
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -11.068708419799805
Agent1_Train_StdReturn : 15.819331169128418
Agent1_Train_MaxReturn : 9.723442077636719
Agent1_Train_MinReturn : -46.82421112060547
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1276500
Agent1_TimeSinceStart : 1959.6989328861237
Agent1_Critic_Loss : 1.241875171661377
Agent1_Actor_Loss : -0.829535961151123
Agent1_Alpha_Loss : 0.7160769701004028
Agent1_Temperature : 0.07871201972491391
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 851 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 852 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 853 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 854 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 855 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 856 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 857 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 858 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 859 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 860 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -9.329737663269043
Agent0_Eval_StdReturn : 16.717073440551758
Agent0_Eval_MaxReturn : 9.29144287109375
Agent0_Eval_MinReturn : -41.49232482910156
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : 5.392203330993652
Agent0_Train_StdReturn : 7.580384254455566
Agent0_Train_MaxReturn : 18.405223846435547
Agent0_Train_MinReturn : -9.355892181396484
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1291500
Agent0_TimeSinceStart : 1980.636340379715
Agent0_Critic_Loss : 0.8180409669876099
Agent0_Actor_Loss : -0.948288083076477
Agent0_Alpha_Loss : 0.7435840368270874
Agent0_Temperature : 0.07842497644018015
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -22.290334701538086
Agent1_Eval_StdReturn : 18.549962997436523
Agent1_Eval_MaxReturn : 10.60161304473877
Agent1_Eval_MinReturn : -64.6584243774414
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -18.188251495361328
Agent1_Train_StdReturn : 14.311285018920898
Agent1_Train_MaxReturn : 5.844414710998535
Agent1_Train_MinReturn : -44.070335388183594
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1291500
Agent1_TimeSinceStart : 1982.7268438339233
Agent1_Critic_Loss : 0.7465152740478516
Agent1_Actor_Loss : -0.7198987603187561
Agent1_Alpha_Loss : 0.725012481212616
Agent1_Temperature : 0.0784974683823493
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 861 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 862 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 863 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 864 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 865 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 866 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 867 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 868 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 869 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 870 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -8.517847061157227
Agent0_Eval_StdReturn : 22.394128799438477
Agent0_Eval_MaxReturn : 26.268735885620117
Agent0_Eval_MinReturn : -54.82069396972656
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -3.5937321186065674
Agent0_Train_StdReturn : 15.560822486877441
Agent0_Train_MaxReturn : 19.033716201782227
Agent0_Train_MinReturn : -37.49900817871094
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1306500
Agent0_TimeSinceStart : 2003.7702181339264
Agent0_Critic_Loss : 1.088921308517456
Agent0_Actor_Loss : -0.8475560545921326
Agent0_Alpha_Loss : 0.7422515153884888
Agent0_Temperature : 0.07820296552909754
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -26.65896987915039
Agent1_Eval_StdReturn : 15.506584167480469
Agent1_Eval_MaxReturn : -5.042929649353027
Agent1_Eval_MinReturn : -50.21821594238281
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -2.8151159286499023
Agent1_Train_StdReturn : 11.981049537658691
Agent1_Train_MaxReturn : 16.858957290649414
Agent1_Train_MinReturn : -22.40557861328125
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1306500
Agent1_TimeSinceStart : 2005.8555479049683
Agent1_Critic_Loss : 0.7281727194786072
Agent1_Actor_Loss : -0.742277979850769
Agent1_Alpha_Loss : 0.7323739528656006
Agent1_Temperature : 0.0782820201306254
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 871 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 872 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 873 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 874 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 875 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 876 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 877 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 878 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 879 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 880 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -19.869152069091797
Agent0_Eval_StdReturn : 19.508426666259766
Agent0_Eval_MaxReturn : -3.1160545349121094
Agent0_Eval_MinReturn : -59.50285720825195
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -6.679054260253906
Agent0_Train_StdReturn : 19.39079475402832
Agent0_Train_MaxReturn : 37.27684783935547
Agent0_Train_MinReturn : -34.946659088134766
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1321500
Agent0_TimeSinceStart : 2026.7384724617004
Agent0_Critic_Loss : 0.5939939022064209
Agent0_Actor_Loss : -0.8003009557723999
Agent0_Alpha_Loss : 0.7408485412597656
Agent0_Temperature : 0.07798200636578083
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -10.199769973754883
Agent1_Eval_StdReturn : 12.003846168518066
Agent1_Eval_MaxReturn : 10.450651168823242
Agent1_Eval_MinReturn : -33.17610549926758
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -4.491138458251953
Agent1_Train_StdReturn : 12.137770652770996
Agent1_Train_MaxReturn : 16.745237350463867
Agent1_Train_MinReturn : -21.650226593017578
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1321500
Agent1_TimeSinceStart : 2028.8274183273315
Agent1_Critic_Loss : 0.7012777924537659
Agent1_Actor_Loss : -0.9048283100128174
Agent1_Alpha_Loss : 0.7292127013206482
Agent1_Temperature : 0.07806652884494897
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 881 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 882 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 883 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 884 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 885 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 886 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 887 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 888 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 889 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 890 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -9.987164497375488
Agent0_Eval_StdReturn : 11.280240058898926
Agent0_Eval_MaxReturn : 4.218960285186768
Agent0_Eval_MinReturn : -31.5139217376709
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -12.155684471130371
Agent0_Train_StdReturn : 14.28326416015625
Agent0_Train_MaxReturn : 1.1914048194885254
Agent0_Train_MinReturn : -47.08460998535156
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1336500
Agent0_TimeSinceStart : 2049.7624592781067
Agent0_Critic_Loss : 0.7841876149177551
Agent0_Actor_Loss : -1.0526307821273804
Agent0_Alpha_Loss : 0.7422822713851929
Agent0_Temperature : 0.0777623484444368
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -11.202540397644043
Agent1_Eval_StdReturn : 11.695418357849121
Agent1_Eval_MaxReturn : 11.903900146484375
Agent1_Eval_MinReturn : -31.794767379760742
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -5.024510860443115
Agent1_Train_StdReturn : 12.728864669799805
Agent1_Train_MaxReturn : 28.247066497802734
Agent1_Train_MinReturn : -14.630661010742188
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1336500
Agent1_TimeSinceStart : 2051.8472332954407
Agent1_Critic_Loss : 0.7376067042350769
Agent1_Actor_Loss : -0.9211952686309814
Agent1_Alpha_Loss : 0.7402330636978149
Agent1_Temperature : 0.07785018394119993
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 891 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 892 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 893 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 894 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 895 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 896 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 897 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 898 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 899 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 900 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -12.129247665405273
Agent0_Eval_StdReturn : 7.710524559020996
Agent0_Eval_MaxReturn : 0.2068798542022705
Agent0_Eval_MinReturn : -26.445735931396484
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -8.684507369995117
Agent0_Train_StdReturn : 27.825963973999023
Agent0_Train_MaxReturn : 21.549983978271484
Agent0_Train_MinReturn : -81.26116180419922
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1351500
Agent0_TimeSinceStart : 2072.6794257164
Agent0_Critic_Loss : 0.9575897455215454
Agent0_Actor_Loss : -1.0264101028442383
Agent0_Alpha_Loss : 0.7470425963401794
Agent0_Temperature : 0.0775431578407507
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -14.168502807617188
Agent1_Eval_StdReturn : 20.408998489379883
Agent1_Eval_MaxReturn : 16.444250106811523
Agent1_Eval_MinReturn : -40.8178825378418
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -7.090668678283691
Agent1_Train_StdReturn : 18.895116806030273
Agent1_Train_MaxReturn : 13.04218578338623
Agent1_Train_MinReturn : -47.592403411865234
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1351500
Agent1_TimeSinceStart : 2074.7589893341064
Agent1_Critic_Loss : 0.80863356590271
Agent1_Actor_Loss : -0.9323834776878357
Agent1_Alpha_Loss : 0.7535073757171631
Agent1_Temperature : 0.07763355195337684
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 901 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 902 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 903 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 904 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 905 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 906 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 907 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 908 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 909 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 910 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -18.47576904296875
Agent0_Eval_StdReturn : 24.728775024414062
Agent0_Eval_MaxReturn : 4.744257926940918
Agent0_Eval_MinReturn : -68.80728912353516
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -20.69534683227539
Agent0_Train_StdReturn : 15.535544395446777
Agent0_Train_MaxReturn : 17.64006805419922
Agent0_Train_MinReturn : -42.73611068725586
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1366500
Agent0_TimeSinceStart : 2095.5719196796417
Agent0_Critic_Loss : 0.9396075010299683
Agent0_Actor_Loss : -1.0614827871322632
Agent0_Alpha_Loss : 0.7470572590827942
Agent0_Temperature : 0.0773250566559261
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -13.654829025268555
Agent1_Eval_StdReturn : 23.360349655151367
Agent1_Eval_MaxReturn : 25.480772018432617
Agent1_Eval_MinReturn : -62.941162109375
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -8.822980880737305
Agent1_Train_StdReturn : 23.507476806640625
Agent1_Train_MaxReturn : 19.038219451904297
Agent1_Train_MinReturn : -63.39289855957031
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1366500
Agent1_TimeSinceStart : 2097.63436794281
Agent1_Critic_Loss : 0.8404861688613892
Agent1_Actor_Loss : -0.8517550230026245
Agent1_Alpha_Loss : 0.7381660342216492
Agent1_Temperature : 0.0774155106793294
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 911 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 912 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 913 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 914 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 915 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 916 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 917 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 918 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 919 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 920 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -4.049126625061035
Agent0_Eval_StdReturn : 8.377816200256348
Agent0_Eval_MaxReturn : 13.866594314575195
Agent0_Eval_MinReturn : -12.192970275878906
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -12.464985847473145
Agent0_Train_StdReturn : 22.381839752197266
Agent0_Train_MaxReturn : 16.88047981262207
Agent0_Train_MinReturn : -55.768516540527344
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1381500
Agent0_TimeSinceStart : 2118.4621448516846
Agent0_Critic_Loss : 1.1817430257797241
Agent0_Actor_Loss : -1.040441632270813
Agent0_Alpha_Loss : 0.7401782274246216
Agent0_Temperature : 0.07710805263840008
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -22.297367095947266
Agent1_Eval_StdReturn : 21.77943229675293
Agent1_Eval_MaxReturn : 9.058053016662598
Agent1_Eval_MinReturn : -53.931243896484375
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -19.905033111572266
Agent1_Train_StdReturn : 15.889540672302246
Agent1_Train_MaxReturn : 2.951235294342041
Agent1_Train_MinReturn : -45.13264846801758
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1381500
Agent1_TimeSinceStart : 2120.529620409012
Agent1_Critic_Loss : 0.7472894787788391
Agent1_Actor_Loss : -0.8810441493988037
Agent1_Alpha_Loss : 0.742520272731781
Agent1_Temperature : 0.07719647731219756
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 921 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 922 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 923 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 924 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 925 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 926 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 927 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 928 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 929 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 930 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -34.23231506347656
Agent0_Eval_StdReturn : 21.581180572509766
Agent0_Eval_MaxReturn : -12.778875350952148
Agent0_Eval_MinReturn : -80.837158203125
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -11.134567260742188
Agent0_Train_StdReturn : 18.589244842529297
Agent0_Train_MaxReturn : 22.546232223510742
Agent0_Train_MinReturn : -42.199073791503906
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1396500
Agent0_TimeSinceStart : 2141.359925508499
Agent0_Critic_Loss : 0.8353801369667053
Agent0_Actor_Loss : -0.9245915412902832
Agent0_Alpha_Loss : 0.7294416427612305
Agent0_Temperature : 0.07689203616345792
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -26.109668731689453
Agent1_Eval_StdReturn : 27.55782127380371
Agent1_Eval_MaxReturn : 7.899152755737305
Agent1_Eval_MinReturn : -74.17640686035156
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -17.074996948242188
Agent1_Train_StdReturn : 26.195974349975586
Agent1_Train_MaxReturn : 28.638940811157227
Agent1_Train_MinReturn : -59.54143142700195
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1396500
Agent1_TimeSinceStart : 2143.427340745926
Agent1_Critic_Loss : 1.1738970279693604
Agent1_Actor_Loss : -1.1679575443267822
Agent1_Alpha_Loss : 0.7304636240005493
Agent1_Temperature : 0.07697839970414744
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 931 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 932 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 933 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 934 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 935 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 936 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 937 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 938 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 939 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 940 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -29.485626220703125
Agent0_Eval_StdReturn : 23.468461990356445
Agent0_Eval_MaxReturn : 5.262995719909668
Agent0_Eval_MinReturn : -69.73269653320312
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -32.62331771850586
Agent0_Train_StdReturn : 19.176626205444336
Agent0_Train_MaxReturn : -4.305776596069336
Agent0_Train_MinReturn : -64.48381042480469
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1411500
Agent0_TimeSinceStart : 2164.282604932785
Agent0_Critic_Loss : 1.0172371864318848
Agent0_Actor_Loss : -0.890306293964386
Agent0_Alpha_Loss : 0.7356496453285217
Agent0_Temperature : 0.07667689549513573
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -11.554171562194824
Agent1_Eval_StdReturn : 20.556846618652344
Agent1_Eval_MaxReturn : 26.251895904541016
Agent1_Eval_MinReturn : -42.601036071777344
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -28.698455810546875
Agent1_Train_StdReturn : 20.79190444946289
Agent1_Train_MaxReturn : 8.01720905303955
Agent1_Train_MinReturn : -57.47377014160156
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1411500
Agent1_TimeSinceStart : 2166.362030506134
Agent1_Critic_Loss : 0.81903076171875
Agent1_Actor_Loss : -1.090417504310608
Agent1_Alpha_Loss : 0.7253608703613281
Agent1_Temperature : 0.0767614037245544
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 941 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 942 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 943 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 944 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 945 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 946 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 947 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 948 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 949 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 950 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -22.53498077392578
Agent0_Eval_StdReturn : 23.274477005004883
Agent0_Eval_MaxReturn : 21.49420928955078
Agent0_Eval_MinReturn : -62.714881896972656
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -13.511919975280762
Agent0_Train_StdReturn : 27.08428955078125
Agent0_Train_MaxReturn : 14.562244415283203
Agent0_Train_MinReturn : -84.65547180175781
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1426500
Agent0_TimeSinceStart : 2187.2166850566864
Agent0_Critic_Loss : 1.509300947189331
Agent0_Actor_Loss : -0.9712175130844116
Agent0_Alpha_Loss : 0.7296609282493591
Agent0_Temperature : 0.07646220232500534
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -21.676733016967773
Agent1_Eval_StdReturn : 34.34971618652344
Agent1_Eval_MaxReturn : 27.689456939697266
Agent1_Eval_MinReturn : -89.94524383544922
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -23.197200775146484
Agent1_Train_StdReturn : 23.808879852294922
Agent1_Train_MaxReturn : 7.472349166870117
Agent1_Train_MinReturn : -68.42176818847656
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1426500
Agent1_TimeSinceStart : 2189.27889919281
Agent1_Critic_Loss : 0.8964309692382812
Agent1_Actor_Loss : -0.8164043426513672
Agent1_Alpha_Loss : 0.7373887300491333
Agent1_Temperature : 0.07654573716530845
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 951 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 952 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 953 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 954 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 955 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 956 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 957 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 958 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 959 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 960 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -3.748507022857666
Agent0_Eval_StdReturn : 13.54899787902832
Agent0_Eval_MaxReturn : 22.373079299926758
Agent0_Eval_MinReturn : -25.280006408691406
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -14.38189697265625
Agent0_Train_StdReturn : 10.91814136505127
Agent0_Train_MaxReturn : -3.131723403930664
Agent0_Train_MinReturn : -39.9317626953125
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1441500
Agent0_TimeSinceStart : 2210.086178302765
Agent0_Critic_Loss : 1.1083687543869019
Agent0_Actor_Loss : -0.7795301675796509
Agent0_Alpha_Loss : 0.7348562479019165
Agent0_Temperature : 0.07624842066586127
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -23.32825469970703
Agent1_Eval_StdReturn : 15.554301261901855
Agent1_Eval_MaxReturn : 2.1086111068725586
Agent1_Eval_MinReturn : -49.7159309387207
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -26.669301986694336
Agent1_Train_StdReturn : 31.267391204833984
Agent1_Train_MaxReturn : 5.140310287475586
Agent1_Train_MinReturn : -101.49632263183594
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1441500
Agent1_TimeSinceStart : 2212.1538763046265
Agent1_Critic_Loss : 0.7946869134902954
Agent1_Actor_Loss : -0.8229252099990845
Agent1_Alpha_Loss : 0.7183277010917664
Agent1_Temperature : 0.07633146832942585
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 961 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 962 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 963 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 964 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 965 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 966 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 967 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 968 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 969 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 970 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -17.43039894104004
Agent0_Eval_StdReturn : 31.066631317138672
Agent0_Eval_MaxReturn : 24.22048568725586
Agent0_Eval_MinReturn : -71.60920715332031
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -23.890180587768555
Agent0_Train_StdReturn : 24.55474090576172
Agent0_Train_MaxReturn : 13.432159423828125
Agent0_Train_MinReturn : -64.11419677734375
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1456500
Agent0_TimeSinceStart : 2232.9997375011444
Agent0_Critic_Loss : 1.3571797609329224
Agent0_Actor_Loss : -0.9337314367294312
Agent0_Alpha_Loss : 0.7407814264297485
Agent0_Temperature : 0.0760350516929857
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -11.114229202270508
Agent1_Eval_StdReturn : 15.040114402770996
Agent1_Eval_MaxReturn : 13.489755630493164
Agent1_Eval_MinReturn : -33.14337921142578
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -25.229305267333984
Agent1_Train_StdReturn : 22.461315155029297
Agent1_Train_MaxReturn : 4.810690879821777
Agent1_Train_MinReturn : -58.545066833496094
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1456500
Agent1_TimeSinceStart : 2235.0674936771393
Agent1_Critic_Loss : 1.1179686784744263
Agent1_Actor_Loss : -0.9659290313720703
Agent1_Alpha_Loss : 0.7150740623474121
Agent1_Temperature : 0.07611824704885728
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 971 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 972 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 973 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 974 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 975 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 976 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 977 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 978 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 979 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 980 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -2.1658921241760254
Agent0_Eval_StdReturn : 10.717309951782227
Agent0_Eval_MaxReturn : 8.046932220458984
Agent0_Eval_MinReturn : -30.687835693359375
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -9.456062316894531
Agent0_Train_StdReturn : 17.63604164123535
Agent0_Train_MaxReturn : 16.884862899780273
Agent0_Train_MinReturn : -43.489051818847656
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1471500
Agent0_TimeSinceStart : 2255.9287106990814
Agent0_Critic_Loss : 1.555711269378662
Agent0_Actor_Loss : -0.970229983329773
Agent0_Alpha_Loss : 0.7225215435028076
Agent0_Temperature : 0.07582189624233415
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -12.617321014404297
Agent1_Eval_StdReturn : 19.518712997436523
Agent1_Eval_MaxReturn : 14.228504180908203
Agent1_Eval_MinReturn : -58.54411315917969
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -10.173588752746582
Agent1_Train_StdReturn : 16.196868896484375
Agent1_Train_MaxReturn : 17.332162857055664
Agent1_Train_MinReturn : -38.35319519042969
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1471500
Agent1_TimeSinceStart : 2258.0029525756836
Agent1_Critic_Loss : 1.0073301792144775
Agent1_Actor_Loss : -0.8690649271011353
Agent1_Alpha_Loss : 0.7274531126022339
Agent1_Temperature : 0.0759062567430808
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 981 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 982 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 983 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 984 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 985 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 986 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 987 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 988 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 989 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 990 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -3.1464829444885254
Agent0_Eval_StdReturn : 18.746562957763672
Agent0_Eval_MaxReturn : 26.772703170776367
Agent0_Eval_MinReturn : -44.250850677490234
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -22.37149429321289
Agent0_Train_StdReturn : 19.582468032836914
Agent0_Train_MaxReturn : 7.195387363433838
Agent0_Train_MinReturn : -51.398414611816406
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1486500
Agent0_TimeSinceStart : 2278.869419336319
Agent0_Critic_Loss : 1.1564671993255615
Agent0_Actor_Loss : -1.1758953332901
Agent0_Alpha_Loss : 0.7227591276168823
Agent0_Temperature : 0.07560966429552482
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -8.962098121643066
Agent1_Eval_StdReturn : 14.344534873962402
Agent1_Eval_MaxReturn : 12.95505142211914
Agent1_Eval_MinReturn : -30.916702270507812
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -6.27334451675415
Agent1_Train_StdReturn : 17.481307983398438
Agent1_Train_MaxReturn : 19.952909469604492
Agent1_Train_MinReturn : -25.130298614501953
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1486500
Agent1_TimeSinceStart : 2280.946363925934
Agent1_Critic_Loss : 1.307349681854248
Agent1_Actor_Loss : -1.0538606643676758
Agent1_Alpha_Loss : 0.7161099314689636
Agent1_Temperature : 0.07569519548704401
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 991 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 992 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 993 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training.../home/harvey/anaconda3/envs/285final/lib/python3.7/site-packages/gym/core.py:318: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  "Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future."
/home/harvey/anaconda3/envs/285final/lib/python3.7/site-packages/gym/wrappers/step_api_compatibility.py:40: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  "Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future."
/home/harvey/anaconda3/envs/285final/lib/python3.7/site-packages/gym/core.py:257: DeprecationWarning: [33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.[0m
  "Function `env.seed(seed)` is marked as deprecated and will be removed in the future. "


Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 994 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 995 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 996 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 997 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 998 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 999 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...
./peersacv2.sh: 48: --seed: not found



LOGGING TO:  /home/harvey/Documents/cs285/CS285-Project/cs285/scripts/../../data/peersac_v2_3agents_temp0.5_HalfCheetah-v4_12-12-2022_05-48-42 



########################
logging outputs to  /home/harvey/Documents/cs285/CS285-Project/cs285/scripts/../../data/peersac_v2_3agents_temp0.5_HalfCheetah-v4_12-12-2022_05-48-42
########################
Using GPU id 0


********** Iteration 0 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -33.58525085449219
Agent0_Eval_StdReturn : 34.9844970703125
Agent0_Eval_MaxReturn : 14.675469398498535
Agent0_Eval_MinReturn : -90.32038879394531
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -68.51490020751953
Agent0_Train_StdReturn : 35.8519172668457
Agent0_Train_MaxReturn : 10.17027473449707
Agent0_Train_MinReturn : -109.59283447265625
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1500
Agent0_TimeSinceStart : 2.127962827682495
Agent0_Critic_Loss : 5.289312362670898
Agent0_Actor_Loss : -2.2740988731384277
Agent0_Alpha_Loss : 4.931520462036133
Agent0_Temperature : 0.49985002249805427
Agent0_Initial_DataCollection_AverageReturn : -68.51490020751953
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -50.02488708496094
Agent1_Eval_StdReturn : 27.55307960510254
Agent1_Eval_MaxReturn : 6.29476261138916
Agent1_Eval_MinReturn : -101.3778076171875
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -41.37040710449219
Agent1_Train_StdReturn : 23.476428985595703
Agent1_Train_MaxReturn : -3.7883758544921875
Agent1_Train_MinReturn : -74.03202819824219
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1500
Agent1_TimeSinceStart : 4.139462947845459
Agent1_Critic_Loss : 5.812494277954102
Agent1_Actor_Loss : -2.2882277965545654
Agent1_Alpha_Loss : 4.899199962615967
Agent1_Temperature : 0.49985002249805627
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 1 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 2 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 3 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 4 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 5 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 6 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 7 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 8 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 9 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 10 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -38.15650177001953
Agent0_Eval_StdReturn : 39.54991912841797
Agent0_Eval_MaxReturn : 11.6045503616333
Agent0_Eval_MinReturn : -106.96926879882812
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -27.87175941467285
Agent0_Train_StdReturn : 36.22871017456055
Agent0_Train_MaxReturn : 30.818252563476562
Agent0_Train_MinReturn : -81.01006317138672
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 16500
Agent0_TimeSinceStart : 24.43892526626587
Agent0_Critic_Loss : 1.971855640411377
Agent0_Actor_Loss : -3.9208950996398926
Agent0_Alpha_Loss : 4.934015274047852
Agent0_Temperature : 0.49835242653218703
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -43.112510681152344
Agent1_Eval_StdReturn : 22.74683952331543
Agent1_Eval_MaxReturn : -18.2948055267334
Agent1_Eval_MinReturn : -91.05621337890625
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -35.810211181640625
Agent1_Train_StdReturn : 25.04254722595215
Agent1_Train_MaxReturn : 12.655526161193848
Agent1_Train_MinReturn : -78.79803466796875
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 16500
Agent1_TimeSinceStart : 26.470925331115723
Agent1_Critic_Loss : 1.9652765989303589
Agent1_Actor_Loss : -3.9873735904693604
Agent1_Alpha_Loss : 4.92919921875
Agent1_Temperature : 0.49835208905949646
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 11 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 12 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 13 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 14 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 15 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 16 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 17 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 18 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 19 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 20 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -47.64081573486328
Agent0_Eval_StdReturn : 37.24858093261719
Agent0_Eval_MaxReturn : 28.139116287231445
Agent0_Eval_MinReturn : -109.50042724609375
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -31.21341323852539
Agent0_Train_StdReturn : 27.89607048034668
Agent0_Train_MaxReturn : 13.952387809753418
Agent0_Train_MinReturn : -76.94538879394531
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 31500
Agent0_TimeSinceStart : 46.92914032936096
Agent0_Critic_Loss : 1.9169491529464722
Agent0_Actor_Loss : -3.338597297668457
Agent0_Alpha_Loss : 4.968976974487305
Agent0_Temperature : 0.4968597434365604
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -52.37700653076172
Agent1_Eval_StdReturn : 28.705610275268555
Agent1_Eval_MaxReturn : 5.878576278686523
Agent1_Eval_MinReturn : -109.65105438232422
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -41.717491149902344
Agent1_Train_StdReturn : 22.362077713012695
Agent1_Train_MaxReturn : -6.743801116943359
Agent1_Train_MinReturn : -78.49163818359375
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 31500
Agent1_TimeSinceStart : 48.97418761253357
Agent1_Critic_Loss : 1.5351855754852295
Agent1_Actor_Loss : -3.4670279026031494
Agent1_Alpha_Loss : 4.94660758972168
Agent1_Temperature : 0.4968580823124583
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 21 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 22 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 23 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 24 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 25 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 26 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 27 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 28 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 29 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 30 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -25.63872718811035
Agent0_Eval_StdReturn : 35.935020446777344
Agent0_Eval_MaxReturn : 36.02149200439453
Agent0_Eval_MinReturn : -96.73655700683594
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -38.877132415771484
Agent0_Train_StdReturn : 19.87252426147461
Agent0_Train_MaxReturn : -14.342853546142578
Agent0_Train_MinReturn : -88.11797332763672
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 46500
Agent0_TimeSinceStart : 69.51504898071289
Agent0_Critic_Loss : 1.7081413269042969
Agent0_Actor_Loss : -3.6297926902770996
Agent0_Alpha_Loss : 4.939907550811768
Agent0_Temperature : 0.49537113956059575
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -52.112518310546875
Agent1_Eval_StdReturn : 27.083126068115234
Agent1_Eval_MaxReturn : -15.078815460205078
Agent1_Eval_MinReturn : -94.1407470703125
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -61.606597900390625
Agent1_Train_StdReturn : 34.24734115600586
Agent1_Train_MaxReturn : 17.784164428710938
Agent1_Train_MinReturn : -112.60671997070312
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 46500
Agent1_TimeSinceStart : 71.57162690162659
Agent1_Critic_Loss : 1.5697849988937378
Agent1_Actor_Loss : -3.765004873275757
Agent1_Alpha_Loss : 4.938994407653809
Agent1_Temperature : 0.49536887263023505
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 31 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 32 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 33 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 34 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 35 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 36 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 37 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 38 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 39 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 40 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -51.01531982421875
Agent0_Eval_StdReturn : 33.66331100463867
Agent0_Eval_MaxReturn : -1.5574049949645996
Agent0_Eval_MinReturn : -90.5072021484375
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -68.174072265625
Agent0_Train_StdReturn : 27.642467498779297
Agent0_Train_MaxReturn : -22.997901916503906
Agent0_Train_MinReturn : -109.97286224365234
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 61500
Agent0_TimeSinceStart : 92.22105741500854
Agent0_Critic_Loss : 1.773836612701416
Agent0_Actor_Loss : -3.9021031856536865
Agent0_Alpha_Loss : 4.913135528564453
Agent0_Temperature : 0.4938891629461671
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -45.93064498901367
Agent1_Eval_StdReturn : 36.74995040893555
Agent1_Eval_MaxReturn : -5.831551551818848
Agent1_Eval_MinReturn : -111.35316467285156
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -49.76155090332031
Agent1_Train_StdReturn : 28.628894805908203
Agent1_Train_MaxReturn : 9.7264404296875
Agent1_Train_MinReturn : -88.48992919921875
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 61500
Agent1_TimeSinceStart : 94.26909351348877
Agent1_Critic_Loss : 1.4174550771713257
Agent1_Actor_Loss : -3.902116298675537
Agent1_Alpha_Loss : 4.91304349899292
Agent1_Temperature : 0.49388635008348847
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 41 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 42 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 43 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 44 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 45 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 46 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 47 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 48 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 49 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 50 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -51.15153884887695
Agent0_Eval_StdReturn : 33.22642517089844
Agent0_Eval_MaxReturn : 12.767513275146484
Agent0_Eval_MinReturn : -98.41836547851562
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -41.59331512451172
Agent0_Train_StdReturn : 27.84241485595703
Agent0_Train_MaxReturn : 4.280940055847168
Agent0_Train_MinReturn : -96.75511169433594
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 76500
Agent0_TimeSinceStart : 114.94857358932495
Agent0_Critic_Loss : 1.5587608814239502
Agent0_Actor_Loss : -3.7930331230163574
Agent0_Alpha_Loss : 4.899535655975342
Agent0_Temperature : 0.49241439499663237
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -48.37202072143555
Agent1_Eval_StdReturn : 50.32535934448242
Agent1_Eval_MaxReturn : 30.487768173217773
Agent1_Eval_MinReturn : -121.79716491699219
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -39.537071228027344
Agent1_Train_StdReturn : 29.790903091430664
Agent1_Train_MaxReturn : 13.809981346130371
Agent1_Train_MinReturn : -90.6260757446289
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 76500
Agent1_TimeSinceStart : 117.0191900730133
Agent1_Critic_Loss : 1.8430708646774292
Agent1_Actor_Loss : -3.896238327026367
Agent1_Alpha_Loss : 4.938745498657227
Agent1_Temperature : 0.49241051954477727
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 51 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 52 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 53 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 54 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 55 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 56 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 57 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 58 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 59 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 60 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -40.98937225341797
Agent0_Eval_StdReturn : 33.94378662109375
Agent0_Eval_MaxReturn : 1.8935341835021973
Agent0_Eval_MinReturn : -99.47782897949219
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -46.0100212097168
Agent0_Train_StdReturn : 26.23023796081543
Agent0_Train_MaxReturn : 0.26564693450927734
Agent0_Train_MinReturn : -90.25060272216797
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 91500
Agent0_TimeSinceStart : 137.7825791835785
Agent0_Critic_Loss : 1.8067692518234253
Agent0_Actor_Loss : -3.9078469276428223
Agent0_Alpha_Loss : 4.882177352905273
Agent0_Temperature : 0.4909449326736995
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -35.608604431152344
Agent1_Eval_StdReturn : 32.0228385925293
Agent1_Eval_MaxReturn : 26.661945343017578
Agent1_Eval_MinReturn : -87.74911499023438
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -53.76725387573242
Agent1_Train_StdReturn : 29.711563110351562
Agent1_Train_MaxReturn : -13.973480224609375
Agent1_Train_MinReturn : -121.45085906982422
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 91500
Agent1_TimeSinceStart : 139.8506383895874
Agent1_Critic_Loss : 1.7566221952438354
Agent1_Actor_Loss : -3.9971373081207275
Agent1_Alpha_Loss : 4.9084320068359375
Agent1_Temperature : 0.4909399054240395
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 61 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 62 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 63 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 64 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 65 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 66 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 67 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 68 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 69 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 70 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -43.90123748779297
Agent0_Eval_StdReturn : 34.93280792236328
Agent0_Eval_MaxReturn : 14.5470552444458
Agent0_Eval_MinReturn : -93.7445068359375
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -49.966285705566406
Agent0_Train_StdReturn : 34.080135345458984
Agent0_Train_MaxReturn : 36.257530212402344
Agent0_Train_MinReturn : -87.07831573486328
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 106500
Agent0_TimeSinceStart : 160.71032857894897
Agent0_Critic_Loss : 1.6348906755447388
Agent0_Actor_Loss : -3.9322125911712646
Agent0_Alpha_Loss : 4.884541988372803
Agent0_Temperature : 0.4894811831976149
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -44.87968826293945
Agent1_Eval_StdReturn : 33.921539306640625
Agent1_Eval_MaxReturn : 8.773967742919922
Agent1_Eval_MinReturn : -98.12879180908203
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -38.42864990234375
Agent1_Train_StdReturn : 38.92780303955078
Agent1_Train_MaxReturn : 17.756587982177734
Agent1_Train_MinReturn : -116.32351684570312
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 106500
Agent1_TimeSinceStart : 162.78530979156494
Agent1_Critic_Loss : 1.67060124874115
Agent1_Actor_Loss : -4.053112983703613
Agent1_Alpha_Loss : 4.879817008972168
Agent1_Temperature : 0.4894755913984322
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 71 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 72 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 73 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 74 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 75 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 76 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 77 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 78 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 79 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 80 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -69.77369689941406
Agent0_Eval_StdReturn : 17.525854110717773
Agent0_Eval_MaxReturn : -46.33271026611328
Agent0_Eval_MinReturn : -102.62867736816406
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -26.95304298400879
Agent0_Train_StdReturn : 26.80528450012207
Agent0_Train_MaxReturn : 32.73346710205078
Agent0_Train_MinReturn : -58.07086181640625
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 121500
Agent0_TimeSinceStart : 183.64599680900574
Agent0_Critic_Loss : 1.8603487014770508
Agent0_Actor_Loss : -3.9042913913726807
Agent0_Alpha_Loss : 4.886567115783691
Agent0_Temperature : 0.48802452606848856
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -54.5463981628418
Agent1_Eval_StdReturn : 46.18943405151367
Agent1_Eval_MaxReturn : 5.041864395141602
Agent1_Eval_MinReturn : -121.36436462402344
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -46.73563766479492
Agent1_Train_StdReturn : 38.130767822265625
Agent1_Train_MaxReturn : 27.51215362548828
Agent1_Train_MinReturn : -120.68851470947266
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 121500
Agent1_TimeSinceStart : 185.70805144309998
Agent1_Critic_Loss : 1.8601036071777344
Agent1_Actor_Loss : -4.139666557312012
Agent1_Alpha_Loss : 4.891008377075195
Agent1_Temperature : 0.4880169825051802
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 81 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 82 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 83 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 84 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 85 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 86 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 87 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 88 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 89 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 90 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -38.109195709228516
Agent0_Eval_StdReturn : 22.713302612304688
Agent0_Eval_MaxReturn : 8.862873077392578
Agent0_Eval_MinReturn : -73.83443450927734
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -31.515399932861328
Agent0_Train_StdReturn : 35.835418701171875
Agent0_Train_MaxReturn : 23.319276809692383
Agent0_Train_MinReturn : -89.68598937988281
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 136500
Agent0_TimeSinceStart : 206.44970893859863
Agent0_Critic_Loss : 1.8862298727035522
Agent0_Actor_Loss : -4.0964674949646
Agent0_Alpha_Loss : 4.85978889465332
Agent0_Temperature : 0.48657483045470495
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -41.953773498535156
Agent1_Eval_StdReturn : 25.82790756225586
Agent1_Eval_MaxReturn : 6.483287334442139
Agent1_Eval_MinReturn : -81.41046142578125
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -53.515220642089844
Agent1_Train_StdReturn : 19.946006774902344
Agent1_Train_MaxReturn : -27.217140197753906
Agent1_Train_MinReturn : -95.46537780761719
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 136500
Agent1_TimeSinceStart : 208.50042343139648
Agent1_Critic_Loss : 1.7169415950775146
Agent1_Actor_Loss : -4.135869026184082
Agent1_Alpha_Loss : 4.888082504272461
Agent1_Temperature : 0.4865652400914604
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 91 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 92 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 93 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 94 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 95 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 96 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 97 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 98 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 99 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 100 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -38.24291229248047
Agent0_Eval_StdReturn : 31.049381256103516
Agent0_Eval_MaxReturn : 4.484910011291504
Agent0_Eval_MinReturn : -107.4239501953125
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -22.291797637939453
Agent0_Train_StdReturn : 31.91975975036621
Agent0_Train_MaxReturn : 26.264881134033203
Agent0_Train_MinReturn : -96.85614013671875
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 151500
Agent0_TimeSinceStart : 229.21368885040283
Agent0_Critic_Loss : 1.9755100011825562
Agent0_Actor_Loss : -4.039567947387695
Agent0_Alpha_Loss : 4.88724946975708
Agent0_Temperature : 0.4851304284373387
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -61.88236618041992
Agent1_Eval_StdReturn : 24.133562088012695
Agent1_Eval_MaxReturn : -3.8807287216186523
Agent1_Eval_MinReturn : -95.10540771484375
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -39.50165557861328
Agent1_Train_StdReturn : 24.592214584350586
Agent1_Train_MaxReturn : 4.082916259765625
Agent1_Train_MinReturn : -75.74980163574219
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 151500
Agent1_TimeSinceStart : 231.27186608314514
Agent1_Critic_Loss : 1.754935383796692
Agent1_Actor_Loss : -4.216130256652832
Agent1_Alpha_Loss : 4.863142013549805
Agent1_Temperature : 0.4851186070656763
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 101 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 102 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 103 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 104 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 105 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 106 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 107 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 108 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 109 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 110 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -47.82160949707031
Agent0_Eval_StdReturn : 35.699066162109375
Agent0_Eval_MaxReturn : 29.61867904663086
Agent0_Eval_MinReturn : -105.16036987304688
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -37.38433074951172
Agent0_Train_StdReturn : 29.276948928833008
Agent0_Train_MaxReturn : 17.92400550842285
Agent0_Train_MinReturn : -80.4232177734375
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 166500
Agent0_TimeSinceStart : 252.0290822982788
Agent0_Critic_Loss : 1.4435081481933594
Agent0_Actor_Loss : -4.082924842834473
Agent0_Alpha_Loss : 4.84199857711792
Agent0_Temperature : 0.4836923954169585
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -32.45860290527344
Agent1_Eval_StdReturn : 33.74862289428711
Agent1_Eval_MaxReturn : 25.881725311279297
Agent1_Eval_MinReturn : -91.29486083984375
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -41.38656234741211
Agent1_Train_StdReturn : 31.2530574798584
Agent1_Train_MaxReturn : 16.899803161621094
Agent1_Train_MinReturn : -83.11347961425781
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 166500
Agent1_TimeSinceStart : 254.09565782546997
Agent1_Critic_Loss : 1.990128755569458
Agent1_Actor_Loss : -4.2518157958984375
Agent1_Alpha_Loss : 4.855047702789307
Agent1_Temperature : 0.4836795069270792
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 111 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 112 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 113 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 114 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 115 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 116 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 117 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 118 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 119 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 120 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -51.15485382080078
Agent0_Eval_StdReturn : 31.09998893737793
Agent0_Eval_MaxReturn : 14.539319038391113
Agent0_Eval_MinReturn : -90.67361450195312
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -35.041748046875
Agent0_Train_StdReturn : 34.654624938964844
Agent0_Train_MaxReturn : 12.769152641296387
Agent0_Train_MinReturn : -92.80926513671875
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 181500
Agent0_TimeSinceStart : 274.875367641449
Agent0_Critic_Loss : 1.8933122158050537
Agent0_Actor_Loss : -4.131014823913574
Agent0_Alpha_Loss : 4.823584079742432
Agent0_Temperature : 0.4822607047066956
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -59.16033935546875
Agent1_Eval_StdReturn : 28.134050369262695
Agent1_Eval_MaxReturn : -18.546768188476562
Agent1_Eval_MinReturn : -110.74211120605469
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -58.89904022216797
Agent1_Train_StdReturn : 37.80926513671875
Agent1_Train_MaxReturn : -2.2533111572265625
Agent1_Train_MinReturn : -124.330078125
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 181500
Agent1_TimeSinceStart : 276.9343795776367
Agent1_Critic_Loss : 1.9331629276275635
Agent1_Actor_Loss : -4.210456848144531
Agent1_Alpha_Loss : 4.808093070983887
Agent1_Temperature : 0.48224760276264395
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 121 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 122 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 123 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 124 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 125 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 126 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 127 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 128 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 129 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 130 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -60.02370071411133
Agent0_Eval_StdReturn : 33.671356201171875
Agent0_Eval_MaxReturn : -13.725113868713379
Agent0_Eval_MinReturn : -114.1978530883789
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -47.65660095214844
Agent0_Train_StdReturn : 40.80062484741211
Agent0_Train_MaxReturn : 6.785719394683838
Agent0_Train_MinReturn : -133.34458923339844
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 196500
Agent0_TimeSinceStart : 297.67230010032654
Agent0_Critic_Loss : 1.9304111003875732
Agent0_Actor_Loss : -4.145435333251953
Agent0_Alpha_Loss : 4.8373823165893555
Agent0_Temperature : 0.4808355092809236
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -42.077903747558594
Agent1_Eval_StdReturn : 29.477943420410156
Agent1_Eval_MaxReturn : -4.411190032958984
Agent1_Eval_MinReturn : -108.31391906738281
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -33.520904541015625
Agent1_Train_StdReturn : 26.025062561035156
Agent1_Train_MaxReturn : 11.143566131591797
Agent1_Train_MinReturn : -77.75923156738281
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 196500
Agent1_TimeSinceStart : 299.74213695526123
Agent1_Critic_Loss : 2.0676910877227783
Agent1_Actor_Loss : -4.319323539733887
Agent1_Alpha_Loss : 4.82083797454834
Agent1_Temperature : 0.4808223785965404
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 131 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 132 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 133 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 134 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 135 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 136 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 137 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 138 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 139 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 140 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -38.109012603759766
Agent0_Eval_StdReturn : 40.695560455322266
Agent0_Eval_MaxReturn : 17.303569793701172
Agent0_Eval_MinReturn : -128.49942016601562
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -19.017581939697266
Agent0_Train_StdReturn : 21.80280303955078
Agent0_Train_MaxReturn : 11.548941612243652
Agent0_Train_MinReturn : -59.400936126708984
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 211500
Agent0_TimeSinceStart : 320.54400300979614
Agent0_Critic_Loss : 1.5044459104537964
Agent0_Actor_Loss : -4.359973907470703
Agent0_Alpha_Loss : 4.805494785308838
Agent0_Temperature : 0.4794174789756765
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -63.03745651245117
Agent1_Eval_StdReturn : 28.0146427154541
Agent1_Eval_MaxReturn : -2.746579170227051
Agent1_Eval_MinReturn : -104.21189880371094
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -34.27569580078125
Agent1_Train_StdReturn : 16.592931747436523
Agent1_Train_MaxReturn : -11.736650466918945
Agent1_Train_MinReturn : -74.82418823242188
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 211500
Agent1_TimeSinceStart : 322.60863065719604
Agent1_Critic_Loss : 1.4792417287826538
Agent1_Actor_Loss : -4.265613079071045
Agent1_Alpha_Loss : 4.788155555725098
Agent1_Temperature : 0.4794039237236848
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 141 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 142 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 143 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 144 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 145 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 146 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 147 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 148 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 149 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 150 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -38.210575103759766
Agent0_Eval_StdReturn : 25.5977725982666
Agent0_Eval_MaxReturn : 1.6456321477890015
Agent0_Eval_MinReturn : -86.79449462890625
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -35.6723747253418
Agent0_Train_StdReturn : 27.88913345336914
Agent0_Train_MaxReturn : -3.57527494430542
Agent0_Train_MinReturn : -91.4792251586914
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 226500
Agent0_TimeSinceStart : 343.4155857563019
Agent0_Critic_Loss : 1.6895692348480225
Agent0_Actor_Loss : -4.204586505889893
Agent0_Alpha_Loss : 4.778106689453125
Agent0_Temperature : 0.47800618324408045
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -6.179055213928223
Agent1_Eval_StdReturn : 25.16269302368164
Agent1_Eval_MaxReturn : 30.87138557434082
Agent1_Eval_MinReturn : -60.84944152832031
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -33.86687088012695
Agent1_Train_StdReturn : 30.805307388305664
Agent1_Train_MaxReturn : 15.713393211364746
Agent1_Train_MinReturn : -83.40827178955078
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 226500
Agent1_TimeSinceStart : 345.4760904312134
Agent1_Critic_Loss : 2.0021514892578125
Agent1_Actor_Loss : -4.33156156539917
Agent1_Alpha_Loss : 4.780136585235596
Agent1_Temperature : 0.4779926045840747
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 151 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 152 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 153 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 154 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 155 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 156 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 157 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 158 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 159 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 160 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -41.21141815185547
Agent0_Eval_StdReturn : 31.06069564819336
Agent0_Eval_MaxReturn : 9.03366470336914
Agent0_Eval_MinReturn : -102.21678161621094
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -48.645599365234375
Agent0_Train_StdReturn : 24.18796157836914
Agent0_Train_MaxReturn : -10.677905082702637
Agent0_Train_MinReturn : -81.39896392822266
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 241500
Agent0_TimeSinceStart : 366.24201488494873
Agent0_Critic_Loss : 1.4067974090576172
Agent0_Actor_Loss : -4.194291114807129
Agent0_Alpha_Loss : 4.772839546203613
Agent0_Temperature : 0.4766023403280009
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -35.65044021606445
Agent1_Eval_StdReturn : 26.872617721557617
Agent1_Eval_MaxReturn : 20.360658645629883
Agent1_Eval_MinReturn : -75.59358215332031
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -41.1525764465332
Agent1_Train_StdReturn : 34.57136154174805
Agent1_Train_MaxReturn : 22.281517028808594
Agent1_Train_MinReturn : -108.41407775878906
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 241500
Agent1_TimeSinceStart : 368.30857372283936
Agent1_Critic_Loss : 1.6607236862182617
Agent1_Actor_Loss : -4.058827877044678
Agent1_Alpha_Loss : 4.791135787963867
Agent1_Temperature : 0.47658825811853
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 161 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 162 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 163 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 164 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 165 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 166 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 167 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 168 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 169 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 170 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -34.874778747558594
Agent0_Eval_StdReturn : 24.039020538330078
Agent0_Eval_MaxReturn : 14.579572677612305
Agent0_Eval_MinReturn : -64.95344543457031
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -38.42165756225586
Agent0_Train_StdReturn : 26.957622528076172
Agent0_Train_MaxReturn : 13.443645477294922
Agent0_Train_MinReturn : -74.36560821533203
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 256500
Agent0_TimeSinceStart : 389.0912718772888
Agent0_Critic_Loss : 1.660697102546692
Agent0_Actor_Loss : -4.17805290222168
Agent0_Alpha_Loss : 4.718929290771484
Agent0_Temperature : 0.4752073121775483
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -46.7414436340332
Agent1_Eval_StdReturn : 20.45880889892578
Agent1_Eval_MaxReturn : -17.63920021057129
Agent1_Eval_MinReturn : -74.51095581054688
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -32.21074676513672
Agent1_Train_StdReturn : 14.611469268798828
Agent1_Train_MaxReturn : -12.40795612335205
Agent1_Train_MinReturn : -67.9870834350586
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 256500
Agent1_TimeSinceStart : 391.1568658351898
Agent1_Critic_Loss : 1.4355683326721191
Agent1_Actor_Loss : -4.072717666625977
Agent1_Alpha_Loss : 4.721289157867432
Agent1_Temperature : 0.47518974852228807
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 171 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 172 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 173 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 174 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 175 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 176 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 177 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 178 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 179 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 180 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -32.591896057128906
Agent0_Eval_StdReturn : 22.31749153137207
Agent0_Eval_MaxReturn : 1.423210620880127
Agent0_Eval_MinReturn : -72.67816162109375
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -33.96559524536133
Agent0_Train_StdReturn : 20.800443649291992
Agent0_Train_MaxReturn : -7.19138240814209
Agent0_Train_MinReturn : -71.19709777832031
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 271500
Agent0_TimeSinceStart : 411.95431876182556
Agent0_Critic_Loss : 1.3039357662200928
Agent0_Actor_Loss : -4.412586212158203
Agent0_Alpha_Loss : 4.688312530517578
Agent0_Temperature : 0.4738207825550837
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -27.876148223876953
Agent1_Eval_StdReturn : 27.140090942382812
Agent1_Eval_MaxReturn : 18.43100929260254
Agent1_Eval_MinReturn : -69.26521301269531
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -16.741796493530273
Agent1_Train_StdReturn : 20.021398544311523
Agent1_Train_MaxReturn : 7.916293621063232
Agent1_Train_MinReturn : -49.148277282714844
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 271500
Agent1_TimeSinceStart : 414.0249536037445
Agent1_Critic_Loss : 1.954721212387085
Agent1_Actor_Loss : -4.531638145446777
Agent1_Alpha_Loss : 4.716209411621094
Agent1_Temperature : 0.473800089376665
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 181 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 182 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 183 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 184 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 185 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 186 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 187 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 188 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 189 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 190 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -22.503311157226562
Agent0_Eval_StdReturn : 30.95867919921875
Agent0_Eval_MaxReturn : 16.982057571411133
Agent0_Eval_MinReturn : -80.08301544189453
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -25.439260482788086
Agent0_Train_StdReturn : 23.60391616821289
Agent0_Train_MaxReturn : 10.829401969909668
Agent0_Train_MinReturn : -64.2034912109375
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 286500
Agent0_TimeSinceStart : 435.2578089237213
Agent0_Critic_Loss : 1.6091196537017822
Agent0_Actor_Loss : -4.382297992706299
Agent0_Alpha_Loss : 4.690167427062988
Agent0_Temperature : 0.47244428488360385
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -37.960960388183594
Agent1_Eval_StdReturn : 29.945232391357422
Agent1_Eval_MaxReturn : 13.513579368591309
Agent1_Eval_MinReturn : -73.00337219238281
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -47.778968811035156
Agent1_Train_StdReturn : 26.5375919342041
Agent1_Train_MaxReturn : 0.3130686283111572
Agent1_Train_MinReturn : -92.39842224121094
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 286500
Agent1_TimeSinceStart : 437.40902733802795
Agent1_Critic_Loss : 1.2377723455429077
Agent1_Actor_Loss : -4.352701187133789
Agent1_Alpha_Loss : 4.705479145050049
Agent1_Temperature : 0.4724178537687219
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 191 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 192 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 193 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 194 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 195 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 196 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 197 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 198 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 199 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 200 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -36.138755798339844
Agent0_Eval_StdReturn : 33.8213005065918
Agent0_Eval_MaxReturn : 18.501972198486328
Agent0_Eval_MinReturn : -93.54341888427734
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -30.886388778686523
Agent0_Train_StdReturn : 28.48371696472168
Agent0_Train_MaxReturn : 18.48117446899414
Agent0_Train_MinReturn : -79.41030883789062
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 301500
Agent0_TimeSinceStart : 458.93472838401794
Agent0_Critic_Loss : 1.3336275815963745
Agent0_Actor_Loss : -4.272421836853027
Agent0_Alpha_Loss : 4.67518424987793
Agent0_Temperature : 0.47107597002405216
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -32.256324768066406
Agent1_Eval_StdReturn : 36.002479553222656
Agent1_Eval_MaxReturn : 13.48349666595459
Agent1_Eval_MinReturn : -117.36504364013672
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -43.58736801147461
Agent1_Train_StdReturn : 38.43868637084961
Agent1_Train_MaxReturn : -1.924922227859497
Agent1_Train_MinReturn : -111.23744201660156
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 301500
Agent1_TimeSinceStart : 461.06920289993286
Agent1_Critic_Loss : 1.4570138454437256
Agent1_Actor_Loss : -4.311513900756836
Agent1_Alpha_Loss : 4.681709289550781
Agent1_Temperature : 0.47104299020258883
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 201 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 202 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 203 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 204 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 205 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 206 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 207 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 208 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 209 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 210 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -22.818552017211914
Agent0_Eval_StdReturn : 20.45985221862793
Agent0_Eval_MaxReturn : 6.697860240936279
Agent0_Eval_MinReturn : -61.35530090332031
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -38.684181213378906
Agent0_Train_StdReturn : 25.53767204284668
Agent0_Train_MaxReturn : -5.917974472045898
Agent0_Train_MinReturn : -85.62924194335938
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 316500
Agent0_TimeSinceStart : 482.5264415740967
Agent0_Critic_Loss : 1.1896166801452637
Agent0_Actor_Loss : -4.203357696533203
Agent0_Alpha_Loss : 4.604863166809082
Agent0_Temperature : 0.4697151894161253
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -32.42052459716797
Agent1_Eval_StdReturn : 35.21879577636719
Agent1_Eval_MaxReturn : 18.5191593170166
Agent1_Eval_MinReturn : -93.73963928222656
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -19.916269302368164
Agent1_Train_StdReturn : 19.661701202392578
Agent1_Train_MaxReturn : 12.939501762390137
Agent1_Train_MinReturn : -50.82234191894531
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 316500
Agent1_TimeSinceStart : 484.6571683883667
Agent1_Critic_Loss : 1.4944247007369995
Agent1_Actor_Loss : -4.32136344909668
Agent1_Alpha_Loss : 4.6370530128479
Agent1_Temperature : 0.4696749419547482
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 211 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 212 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 213 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 214 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 215 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 216 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 217 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 218 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 219 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 220 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -56.949058532714844
Agent0_Eval_StdReturn : 28.685834884643555
Agent0_Eval_MaxReturn : -12.887588500976562
Agent0_Eval_MinReturn : -112.0559310913086
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -32.72003936767578
Agent0_Train_StdReturn : 30.934175491333008
Agent0_Train_MaxReturn : 22.450397491455078
Agent0_Train_MinReturn : -94.17792510986328
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 331500
Agent0_TimeSinceStart : 506.15391063690186
Agent0_Critic_Loss : 1.1562936305999756
Agent0_Actor_Loss : -4.354218482971191
Agent0_Alpha_Loss : 4.583110332489014
Agent0_Temperature : 0.46836239134022317
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -50.755516052246094
Agent1_Eval_StdReturn : 35.34356689453125
Agent1_Eval_MaxReturn : -10.193803787231445
Agent1_Eval_MinReturn : -113.56704711914062
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -41.93893051147461
Agent1_Train_StdReturn : 29.84058952331543
Agent1_Train_MaxReturn : 3.8098433017730713
Agent1_Train_MinReturn : -89.0277099609375
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 331500
Agent1_TimeSinceStart : 508.28528094291687
Agent1_Critic_Loss : 1.3885936737060547
Agent1_Actor_Loss : -4.32640266418457
Agent1_Alpha_Loss : 4.569366931915283
Agent1_Temperature : 0.46831461188601686
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 221 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 222 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 223 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 224 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 225 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 226 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 227 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 228 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 229 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 230 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -28.748641967773438
Agent0_Eval_StdReturn : 18.626859664916992
Agent0_Eval_MaxReturn : 5.285715103149414
Agent0_Eval_MinReturn : -53.02762985229492
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -11.138998031616211
Agent0_Train_StdReturn : 14.208420753479004
Agent0_Train_MaxReturn : 18.388118743896484
Agent0_Train_MinReturn : -30.00078582763672
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 346500
Agent0_TimeSinceStart : 529.652111530304
Agent0_Critic_Loss : 1.158400297164917
Agent0_Actor_Loss : -4.293654441833496
Agent0_Alpha_Loss : 4.538321018218994
Agent0_Temperature : 0.4670195481573327
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -20.395671844482422
Agent1_Eval_StdReturn : 26.507247924804688
Agent1_Eval_MaxReturn : 23.911619186401367
Agent1_Eval_MinReturn : -76.39229583740234
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -27.589431762695312
Agent1_Train_StdReturn : 22.607379913330078
Agent1_Train_MaxReturn : 8.086605072021484
Agent1_Train_MinReturn : -64.4396743774414
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 346500
Agent1_TimeSinceStart : 531.7752249240875
Agent1_Critic_Loss : 1.2540600299835205
Agent1_Actor_Loss : -4.083170413970947
Agent1_Alpha_Loss : 4.60302734375
Agent1_Temperature : 0.46696391532112896
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 231 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 232 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 233 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 234 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 235 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 236 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 237 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 238 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 239 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 240 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -32.31045150756836
Agent0_Eval_StdReturn : 27.148983001708984
Agent0_Eval_MaxReturn : 9.75920295715332
Agent0_Eval_MinReturn : -74.18096160888672
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -42.460174560546875
Agent0_Train_StdReturn : 29.81778335571289
Agent0_Train_MaxReturn : -1.330148458480835
Agent0_Train_MinReturn : -97.74771881103516
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 361500
Agent0_TimeSinceStart : 553.1052579879761
Agent0_Critic_Loss : 1.3616456985473633
Agent0_Actor_Loss : -4.281176567077637
Agent0_Alpha_Loss : 4.581885814666748
Agent0_Temperature : 0.4656848899837726
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -31.291057586669922
Agent1_Eval_StdReturn : 24.75580596923828
Agent1_Eval_MaxReturn : 4.462760925292969
Agent1_Eval_MinReturn : -79.47361755371094
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -37.901702880859375
Agent1_Train_StdReturn : 27.777437210083008
Agent1_Train_MaxReturn : -9.39536190032959
Agent1_Train_MinReturn : -90.23793029785156
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 361500
Agent1_TimeSinceStart : 555.2329642772675
Agent1_Critic_Loss : 1.0155888795852661
Agent1_Actor_Loss : -4.200893402099609
Agent1_Alpha_Loss : 4.603104591369629
Agent1_Temperature : 0.4656207710065629
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 241 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 242 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 243 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 244 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 245 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 246 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 247 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 248 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 249 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 250 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -41.36326599121094
Agent0_Eval_StdReturn : 27.577003479003906
Agent0_Eval_MaxReturn : -4.710174560546875
Agent0_Eval_MinReturn : -92.82427978515625
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -38.3160285949707
Agent0_Train_StdReturn : 15.239114761352539
Agent0_Train_MaxReturn : -17.1939697265625
Agent0_Train_MinReturn : -58.436492919921875
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 376500
Agent0_TimeSinceStart : 576.4966354370117
Agent0_Critic_Loss : 1.9019789695739746
Agent0_Actor_Loss : -4.280496120452881
Agent0_Alpha_Loss : 4.512712478637695
Agent0_Temperature : 0.4643580307989352
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -43.923099517822266
Agent1_Eval_StdReturn : 22.615320205688477
Agent1_Eval_MaxReturn : 0.7237710952758789
Agent1_Eval_MinReturn : -71.73631286621094
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -24.55354881286621
Agent1_Train_StdReturn : 27.978538513183594
Agent1_Train_MaxReturn : 25.14263153076172
Agent1_Train_MinReturn : -68.3948745727539
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 376500
Agent1_TimeSinceStart : 578.6105558872223
Agent1_Critic_Loss : 1.341196894645691
Agent1_Actor_Loss : -4.2256903648376465
Agent1_Alpha_Loss : 4.5949249267578125
Agent1_Temperature : 0.4642839734719101
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 251 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 252 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 253 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 254 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 255 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 256 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 257 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 258 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 259 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 260 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -19.080421447753906
Agent0_Eval_StdReturn : 20.743257522583008
Agent0_Eval_MaxReturn : 20.20737648010254
Agent0_Eval_MinReturn : -47.079490661621094
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -28.718631744384766
Agent0_Train_StdReturn : 20.03339958190918
Agent0_Train_MaxReturn : -10.295913696289062
Agent0_Train_MinReturn : -72.0933837890625
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 391500
Agent0_TimeSinceStart : 599.8679673671722
Agent0_Critic_Loss : 1.1182951927185059
Agent0_Actor_Loss : -4.22000789642334
Agent0_Alpha_Loss : 4.5140252113342285
Agent0_Temperature : 0.46304068733345133
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -42.238975524902344
Agent1_Eval_StdReturn : 36.999481201171875
Agent1_Eval_MaxReturn : 30.988922119140625
Agent1_Eval_MinReturn : -100.31735229492188
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -26.92058753967285
Agent1_Train_StdReturn : 17.07320785522461
Agent1_Train_MaxReturn : 8.006658554077148
Agent1_Train_MinReturn : -46.8641357421875
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 391500
Agent1_TimeSinceStart : 601.9709420204163
Agent1_Critic_Loss : 2.020333766937256
Agent1_Actor_Loss : -4.738644123077393
Agent1_Alpha_Loss : 4.5323638916015625
Agent1_Temperature : 0.46295495666835484
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 261 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 262 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 263 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 264 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 265 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 266 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 267 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 268 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 269 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 270 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -23.896501541137695
Agent0_Eval_StdReturn : 27.68628692626953
Agent0_Eval_MaxReturn : 9.486709594726562
Agent0_Eval_MinReturn : -71.416748046875
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -35.09244918823242
Agent0_Train_StdReturn : 30.90386390686035
Agent0_Train_MaxReturn : 5.917810916900635
Agent0_Train_MinReturn : -97.10701751708984
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 406500
Agent0_TimeSinceStart : 623.174742937088
Agent0_Critic_Loss : 1.8560943603515625
Agent0_Actor_Loss : -4.13696813583374
Agent0_Alpha_Loss : 4.5494184494018555
Agent0_Temperature : 0.46172464507592215
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -32.54572677612305
Agent1_Eval_StdReturn : 24.024702072143555
Agent1_Eval_MaxReturn : 1.2574691772460938
Agent1_Eval_MinReturn : -81.61236572265625
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -33.37511444091797
Agent1_Train_StdReturn : 29.101930618286133
Agent1_Train_MaxReturn : -1.260934829711914
Agent1_Train_MinReturn : -101.14738464355469
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 406500
Agent1_TimeSinceStart : 625.2939162254333
Agent1_Critic_Loss : 2.1958506107330322
Agent1_Actor_Loss : -4.481614112854004
Agent1_Alpha_Loss : 4.537085056304932
Agent1_Temperature : 0.4616355549657097
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 271 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 272 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 273 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 274 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 275 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 276 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 277 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 278 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 279 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 280 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -39.36868667602539
Agent0_Eval_StdReturn : 22.047704696655273
Agent0_Eval_MaxReturn : -16.844696044921875
Agent0_Eval_MinReturn : -85.27330780029297
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -53.35981369018555
Agent0_Train_StdReturn : 25.328062057495117
Agent0_Train_MaxReturn : -17.313838958740234
Agent0_Train_MinReturn : -92.26184844970703
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 421500
Agent0_TimeSinceStart : 646.5062918663025
Agent0_Critic_Loss : 1.4894447326660156
Agent0_Actor_Loss : -4.48491096496582
Agent0_Alpha_Loss : 4.502946376800537
Agent0_Temperature : 0.46041306217964717
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -20.234928131103516
Agent1_Eval_StdReturn : 20.271038055419922
Agent1_Eval_MaxReturn : 17.761709213256836
Agent1_Eval_MinReturn : -62.84694290161133
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -17.258529663085938
Agent1_Train_StdReturn : 20.467761993408203
Agent1_Train_MaxReturn : 10.79168701171875
Agent1_Train_MinReturn : -56.30440902709961
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 421500
Agent1_TimeSinceStart : 648.6215221881866
Agent1_Critic_Loss : 1.2453358173370361
Agent1_Actor_Loss : -4.338835716247559
Agent1_Alpha_Loss : 4.504077911376953
Agent1_Temperature : 0.4603229873417325
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 281 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 282 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 283 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 284 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 285 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 286 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 287 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 288 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 289 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 290 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -40.239173889160156
Agent0_Eval_StdReturn : 25.983715057373047
Agent0_Eval_MaxReturn : 5.4861369132995605
Agent0_Eval_MinReturn : -90.53419494628906
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -18.349201202392578
Agent0_Train_StdReturn : 30.05864143371582
Agent0_Train_MaxReturn : 43.865177154541016
Agent0_Train_MinReturn : -57.18421173095703
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 436500
Agent0_TimeSinceStart : 669.877934217453
Agent0_Critic_Loss : 1.4890336990356445
Agent0_Actor_Loss : -4.855243682861328
Agent0_Alpha_Loss : 4.458391189575195
Agent0_Temperature : 0.4591076772323573
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -31.90683937072754
Agent1_Eval_StdReturn : 30.44951820373535
Agent1_Eval_MaxReturn : 6.381364822387695
Agent1_Eval_MinReturn : -100.18051147460938
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -19.091482162475586
Agent1_Train_StdReturn : 26.434463500976562
Agent1_Train_MaxReturn : 10.00305461883545
Agent1_Train_MinReturn : -79.254150390625
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 436500
Agent1_TimeSinceStart : 672.0013411045074
Agent1_Critic_Loss : 1.2740697860717773
Agent1_Actor_Loss : -4.440285682678223
Agent1_Alpha_Loss : 4.488537788391113
Agent1_Temperature : 0.4590175401916262
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 291 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 292 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 293 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 294 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 295 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 296 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 297 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 298 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 299 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 300 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -29.451213836669922
Agent0_Eval_StdReturn : 26.80689811706543
Agent0_Eval_MaxReturn : 25.954877853393555
Agent0_Eval_MinReturn : -66.99510955810547
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -25.36014175415039
Agent0_Train_StdReturn : 27.10711097717285
Agent0_Train_MaxReturn : 17.086469650268555
Agent0_Train_MinReturn : -69.91952514648438
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 451500
Agent0_TimeSinceStart : 693.3159854412079
Agent0_Critic_Loss : 1.2083371877670288
Agent0_Actor_Loss : -4.792469024658203
Agent0_Alpha_Loss : 4.484825134277344
Agent0_Temperature : 0.45780915813406714
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -32.913421630859375
Agent1_Eval_StdReturn : 25.596487045288086
Agent1_Eval_MaxReturn : 6.987089157104492
Agent1_Eval_MinReturn : -71.15364074707031
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -46.2252082824707
Agent1_Train_StdReturn : 29.432302474975586
Agent1_Train_MaxReturn : 6.526215553283691
Agent1_Train_MinReturn : -89.07061767578125
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 451500
Agent1_TimeSinceStart : 695.4274351596832
Agent1_Critic_Loss : 1.5213396549224854
Agent1_Actor_Loss : -4.794651985168457
Agent1_Alpha_Loss : 4.49884033203125
Agent1_Temperature : 0.4577148473159706
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 301 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 302 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 303 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 304 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 305 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 306 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 307 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 308 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 309 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 310 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -30.39194107055664
Agent0_Eval_StdReturn : 37.720890045166016
Agent0_Eval_MaxReturn : 54.2504997253418
Agent0_Eval_MinReturn : -88.80068969726562
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -30.672704696655273
Agent0_Train_StdReturn : 30.183382034301758
Agent0_Train_MaxReturn : 11.634225845336914
Agent0_Train_MinReturn : -70.17329406738281
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 466500
Agent0_TimeSinceStart : 716.669683933258
Agent0_Critic_Loss : 1.2556679248809814
Agent0_Actor_Loss : -4.497793197631836
Agent0_Alpha_Loss : 4.433771133422852
Agent0_Temperature : 0.45651459119956156
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -20.998374938964844
Agent1_Eval_StdReturn : 19.734020233154297
Agent1_Eval_MaxReturn : 11.4581937789917
Agent1_Eval_MinReturn : -47.92510986328125
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -20.812076568603516
Agent1_Train_StdReturn : 17.536720275878906
Agent1_Train_MaxReturn : 8.722492218017578
Agent1_Train_MinReturn : -53.02193832397461
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 466500
Agent1_TimeSinceStart : 718.7914853096008
Agent1_Critic_Loss : 1.3510822057724
Agent1_Actor_Loss : -4.395771026611328
Agent1_Alpha_Loss : 4.479646682739258
Agent1_Temperature : 0.45641581479720805
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 311 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 312 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 313 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 314 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 315 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 316 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 317 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 318 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 319 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 320 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -36.275115966796875
Agent0_Eval_StdReturn : 22.008678436279297
Agent0_Eval_MaxReturn : 3.2592852115631104
Agent0_Eval_MinReturn : -69.08523559570312
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -32.124488830566406
Agent0_Train_StdReturn : 31.089406967163086
Agent0_Train_MaxReturn : 5.92320442199707
Agent0_Train_MinReturn : -105.43522644042969
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 481500
Agent0_TimeSinceStart : 740.0738723278046
Agent0_Critic_Loss : 1.1613085269927979
Agent0_Actor_Loss : -4.725358963012695
Agent0_Alpha_Loss : 4.482303142547607
Agent0_Temperature : 0.4552238003922938
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -25.377702713012695
Agent1_Eval_StdReturn : 25.732473373413086
Agent1_Eval_MaxReturn : 23.88306999206543
Agent1_Eval_MinReturn : -71.67228698730469
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -32.925804138183594
Agent1_Train_StdReturn : 26.3175106048584
Agent1_Train_MaxReturn : 11.991659164428711
Agent1_Train_MinReturn : -69.17572784423828
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 481500
Agent1_TimeSinceStart : 742.1892502307892
Agent1_Critic_Loss : 1.229284644126892
Agent1_Actor_Loss : -4.632891654968262
Agent1_Alpha_Loss : 4.448929786682129
Agent1_Temperature : 0.45512293219478006
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 321 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 322 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 323 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 324 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 325 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 326 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 327 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 328 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 329 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 330 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -26.0795955657959
Agent0_Eval_StdReturn : 29.47673225402832
Agent0_Eval_MaxReturn : 14.399497985839844
Agent0_Eval_MinReturn : -82.513671875
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -48.92200469970703
Agent0_Train_StdReturn : 28.00861358642578
Agent0_Train_MaxReturn : 3.857593536376953
Agent0_Train_MinReturn : -97.87521362304688
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 496500
Agent0_TimeSinceStart : 763.4439327716827
Agent0_Critic_Loss : 1.3971564769744873
Agent0_Actor_Loss : -4.6433515548706055
Agent0_Alpha_Loss : 4.415599822998047
Agent0_Temperature : 0.45393704597184403
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -32.86591339111328
Agent1_Eval_StdReturn : 21.952533721923828
Agent1_Eval_MaxReturn : -6.1111602783203125
Agent1_Eval_MinReturn : -68.00979614257812
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -27.242725372314453
Agent1_Train_StdReturn : 25.708919525146484
Agent1_Train_MaxReturn : 0.016203880310058594
Agent1_Train_MinReturn : -97.53050231933594
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 496500
Agent1_TimeSinceStart : 765.5601673126221
Agent1_Critic_Loss : 1.3236736059188843
Agent1_Actor_Loss : -4.570868968963623
Agent1_Alpha_Loss : 4.406134128570557
Agent1_Temperature : 0.4538363793116926
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 331 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 332 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 333 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 334 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 335 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 336 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 337 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 338 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 339 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 340 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -20.4982967376709
Agent0_Eval_StdReturn : 24.419658660888672
Agent0_Eval_MaxReturn : 17.10041618347168
Agent0_Eval_MinReturn : -61.53672790527344
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -36.44968795776367
Agent0_Train_StdReturn : 18.429920196533203
Agent0_Train_MaxReturn : -7.373642921447754
Agent0_Train_MinReturn : -71.84049987792969
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 511500
Agent0_TimeSinceStart : 786.8589503765106
Agent0_Critic_Loss : 1.1526817083358765
Agent0_Actor_Loss : -4.684568405151367
Agent0_Alpha_Loss : 4.4004435539245605
Agent0_Temperature : 0.4526566979340386
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -39.030216217041016
Agent1_Eval_StdReturn : 25.54410171508789
Agent1_Eval_MaxReturn : 20.769657135009766
Agent1_Eval_MinReturn : -76.11124420166016
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -35.42363739013672
Agent1_Train_StdReturn : 30.892223358154297
Agent1_Train_MaxReturn : 10.326278686523438
Agent1_Train_MinReturn : -91.47911071777344
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 511500
Agent1_TimeSinceStart : 788.9693338871002
Agent1_Critic_Loss : 1.535651683807373
Agent1_Actor_Loss : -4.776206970214844
Agent1_Alpha_Loss : 4.41031551361084
Agent1_Temperature : 0.4525561963279573
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 341 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 342 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 343 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 344 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 345 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 346 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 347 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 348 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 349 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 350 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -23.817733764648438
Agent0_Eval_StdReturn : 16.88249969482422
Agent0_Eval_MaxReturn : 6.080648422241211
Agent0_Eval_MinReturn : -55.47993087768555
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -39.42253875732422
Agent0_Train_StdReturn : 34.0062141418457
Agent0_Train_MaxReturn : -1.9911441802978516
Agent0_Train_MinReturn : -97.39378356933594
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 526500
Agent0_TimeSinceStart : 810.3287966251373
Agent0_Critic_Loss : 1.2357869148254395
Agent0_Actor_Loss : -4.788501262664795
Agent0_Alpha_Loss : 4.401266098022461
Agent0_Temperature : 0.45138052335468565
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -39.09387969970703
Agent1_Eval_StdReturn : 27.674522399902344
Agent1_Eval_MaxReturn : 6.378408432006836
Agent1_Eval_MinReturn : -84.23335266113281
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -39.290382385253906
Agent1_Train_StdReturn : 29.035837173461914
Agent1_Train_MaxReturn : 0.37889862060546875
Agent1_Train_MinReturn : -91.93771362304688
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 526500
Agent1_TimeSinceStart : 812.4443280696869
Agent1_Critic_Loss : 1.0292803049087524
Agent1_Actor_Loss : -4.7520341873168945
Agent1_Alpha_Loss : 4.370038032531738
Agent1_Temperature : 0.45128130750611
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 351 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 352 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 353 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 354 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 355 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 356 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 357 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 358 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 359 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 360 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -39.47016906738281
Agent0_Eval_StdReturn : 12.705573081970215
Agent0_Eval_MaxReturn : -25.700790405273438
Agent0_Eval_MinReturn : -68.66831970214844
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -37.597965240478516
Agent0_Train_StdReturn : 20.37751007080078
Agent0_Train_MaxReturn : -7.9810991287231445
Agent0_Train_MinReturn : -73.07546997070312
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 541500
Agent0_TimeSinceStart : 833.774405002594
Agent0_Critic_Loss : 1.3056981563568115
Agent0_Actor_Loss : -4.979634761810303
Agent0_Alpha_Loss : 4.337851524353027
Agent0_Temperature : 0.45011194906910906
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -45.54730987548828
Agent1_Eval_StdReturn : 29.051734924316406
Agent1_Eval_MaxReturn : 9.916679382324219
Agent1_Eval_MinReturn : -91.76246643066406
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -22.362627029418945
Agent1_Train_StdReturn : 40.78461456298828
Agent1_Train_MaxReturn : 22.52370262145996
Agent1_Train_MinReturn : -97.54881286621094
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 541500
Agent1_TimeSinceStart : 835.8992655277252
Agent1_Critic_Loss : 2.2101340293884277
Agent1_Actor_Loss : -4.549302101135254
Agent1_Alpha_Loss : 4.38840913772583
Agent1_Temperature : 0.45001372779552445
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 361 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 362 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 363 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 364 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 365 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 366 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 367 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 368 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 369 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 370 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -28.775691986083984
Agent0_Eval_StdReturn : 30.482437133789062
Agent0_Eval_MaxReturn : 2.379497528076172
Agent0_Eval_MinReturn : -90.03543090820312
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -14.765101432800293
Agent0_Train_StdReturn : 17.701175689697266
Agent0_Train_MaxReturn : 11.38664436340332
Agent0_Train_MinReturn : -48.97268295288086
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 556500
Agent0_TimeSinceStart : 857.1994841098785
Agent0_Critic_Loss : 1.2275373935699463
Agent0_Actor_Loss : -5.01756477355957
Agent0_Alpha_Loss : 4.371434211730957
Agent0_Temperature : 0.4488476964748038
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -26.917613983154297
Agent1_Eval_StdReturn : 20.400737762451172
Agent1_Eval_MaxReturn : 2.666292667388916
Agent1_Eval_MinReturn : -60.73994445800781
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -26.391225814819336
Agent1_Train_StdReturn : 19.02979278564453
Agent1_Train_MaxReturn : 9.017677307128906
Agent1_Train_MinReturn : -53.59317398071289
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 556500
Agent1_TimeSinceStart : 859.3294486999512
Agent1_Critic_Loss : 1.677314281463623
Agent1_Actor_Loss : -5.1427507400512695
Agent1_Alpha_Loss : 4.362523555755615
Agent1_Temperature : 0.448751914704354
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 371 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 372 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 373 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 374 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 375 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 376 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 377 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 378 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 379 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 380 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -40.28496551513672
Agent0_Eval_StdReturn : 21.868627548217773
Agent0_Eval_MaxReturn : -2.0136661529541016
Agent0_Eval_MinReturn : -77.63780975341797
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -25.144866943359375
Agent0_Train_StdReturn : 27.309038162231445
Agent0_Train_MaxReturn : 11.07955551147461
Agent0_Train_MinReturn : -86.84830474853516
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 571500
Agent0_TimeSinceStart : 880.5581543445587
Agent0_Critic_Loss : 1.0335173606872559
Agent0_Actor_Loss : -4.800088882446289
Agent0_Alpha_Loss : 4.3366498947143555
Agent0_Temperature : 0.4475874309454551
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -29.1763973236084
Agent1_Eval_StdReturn : 24.52557945251465
Agent1_Eval_MaxReturn : 4.881733417510986
Agent1_Eval_MinReturn : -87.46468353271484
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -27.642236709594727
Agent1_Train_StdReturn : 41.44403839111328
Agent1_Train_MaxReturn : 45.20100021362305
Agent1_Train_MinReturn : -111.98602294921875
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 571500
Agent1_TimeSinceStart : 882.6579675674438
Agent1_Critic_Loss : 1.1045829057693481
Agent1_Actor_Loss : -4.550832748413086
Agent1_Alpha_Loss : 4.35969877243042
Agent1_Temperature : 0.4474940050133495
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 381 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 382 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 383 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 384 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 385 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 386 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 387 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 388 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 389 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 390 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -31.709304809570312
Agent0_Eval_StdReturn : 23.591171264648438
Agent0_Eval_MaxReturn : 14.81750202178955
Agent0_Eval_MinReturn : -66.22586059570312
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -19.162687301635742
Agent0_Train_StdReturn : 35.49506378173828
Agent0_Train_MaxReturn : 18.32938003540039
Agent0_Train_MinReturn : -103.68141174316406
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 586500
Agent0_TimeSinceStart : 903.8430256843567
Agent0_Critic_Loss : 1.3150968551635742
Agent0_Actor_Loss : -4.8556413650512695
Agent0_Alpha_Loss : 4.405760765075684
Agent0_Temperature : 0.4463343377524087
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -23.957462310791016
Agent1_Eval_StdReturn : 22.832050323486328
Agent1_Eval_MaxReturn : 21.680395126342773
Agent1_Eval_MinReturn : -67.1318588256836
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -5.723963737487793
Agent1_Train_StdReturn : 21.86557960510254
Agent1_Train_MaxReturn : 25.021873474121094
Agent1_Train_MinReturn : -46.63823699951172
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 586500
Agent1_TimeSinceStart : 905.9576787948608
Agent1_Critic_Loss : 1.8124990463256836
Agent1_Actor_Loss : -4.573461532592773
Agent1_Alpha_Loss : 4.321310520172119
Agent1_Temperature : 0.4462399765651158
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 391 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 392 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 393 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 394 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 395 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 396 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 397 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 398 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 399 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 400 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -20.634387969970703
Agent0_Eval_StdReturn : 23.275806427001953
Agent0_Eval_MaxReturn : 7.1883697509765625
Agent0_Eval_MinReturn : -68.97704315185547
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -41.229759216308594
Agent0_Train_StdReturn : 30.383989334106445
Agent0_Train_MaxReturn : -1.8305785655975342
Agent0_Train_MinReturn : -96.18565368652344
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 601500
Agent0_TimeSinceStart : 927.1613478660583
Agent0_Critic_Loss : 1.4407496452331543
Agent0_Actor_Loss : -4.964787483215332
Agent0_Alpha_Loss : 4.334219932556152
Agent0_Temperature : 0.44508485729147307
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -26.911218643188477
Agent1_Eval_StdReturn : 14.795490264892578
Agent1_Eval_MaxReturn : -1.8151354789733887
Agent1_Eval_MinReturn : -50.62816619873047
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -22.531280517578125
Agent1_Train_StdReturn : 29.96932029724121
Agent1_Train_MaxReturn : 9.632569313049316
Agent1_Train_MinReturn : -72.77371978759766
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 601500
Agent1_TimeSinceStart : 929.2652578353882
Agent1_Critic_Loss : 1.0248088836669922
Agent1_Actor_Loss : -4.784326553344727
Agent1_Alpha_Loss : 4.294722080230713
Agent1_Temperature : 0.4449897648064223
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 401 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 402 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 403 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 404 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 405 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 406 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 407 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 408 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 409 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 410 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -24.14729118347168
Agent0_Eval_StdReturn : 24.767606735229492
Agent0_Eval_MaxReturn : 5.730790138244629
Agent0_Eval_MinReturn : -76.16226196289062
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -21.37455177307129
Agent0_Train_StdReturn : 16.71820068359375
Agent0_Train_MaxReturn : 8.335771560668945
Agent0_Train_MinReturn : -45.465179443359375
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 616500
Agent0_TimeSinceStart : 950.4635100364685
Agent0_Critic_Loss : 1.3242666721343994
Agent0_Actor_Loss : -4.982845306396484
Agent0_Alpha_Loss : 4.35030460357666
Agent0_Temperature : 0.4438400771383229
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -23.39933967590332
Agent1_Eval_StdReturn : 28.131145477294922
Agent1_Eval_MaxReturn : 12.969734191894531
Agent1_Eval_MinReturn : -70.46343994140625
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -22.471776962280273
Agent1_Train_StdReturn : 30.427051544189453
Agent1_Train_MaxReturn : 31.83148956298828
Agent1_Train_MinReturn : -75.72784423828125
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 616500
Agent1_TimeSinceStart : 952.5751383304596
Agent1_Critic_Loss : 1.472693681716919
Agent1_Actor_Loss : -4.9371442794799805
Agent1_Alpha_Loss : 4.280898094177246
Agent1_Temperature : 0.44374611716716456
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 411 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 412 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 413 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 414 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 415 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 416 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 417 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 418 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 419 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 420 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -25.833389282226562
Agent0_Eval_StdReturn : 14.277454376220703
Agent0_Eval_MaxReturn : 1.8452739715576172
Agent0_Eval_MinReturn : -50.703834533691406
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -25.320425033569336
Agent0_Train_StdReturn : 25.527942657470703
Agent0_Train_MaxReturn : 8.291114807128906
Agent0_Train_MinReturn : -69.78334045410156
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 631500
Agent0_TimeSinceStart : 973.8659551143646
Agent0_Critic_Loss : 1.4656760692596436
Agent0_Actor_Loss : -5.016720771789551
Agent0_Alpha_Loss : 4.277283668518066
Agent0_Temperature : 0.44259677636259565
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -26.266937255859375
Agent1_Eval_StdReturn : 28.28484535217285
Agent1_Eval_MaxReturn : -2.3033924102783203
Agent1_Eval_MinReturn : -102.91365051269531
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -39.52188491821289
Agent1_Train_StdReturn : 18.983102798461914
Agent1_Train_MaxReturn : -3.973877191543579
Agent1_Train_MinReturn : -66.45130157470703
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 631500
Agent1_TimeSinceStart : 975.9854969978333
Agent1_Critic_Loss : 1.597021222114563
Agent1_Actor_Loss : -5.008379936218262
Agent1_Alpha_Loss : 4.318183422088623
Agent1_Temperature : 0.44250699740617766
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 421 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 422 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 423 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 424 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 425 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 426 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 427 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 428 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 429 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 430 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -11.14452838897705
Agent0_Eval_StdReturn : 26.655317306518555
Agent0_Eval_MaxReturn : 27.59432601928711
Agent0_Eval_MinReturn : -67.76263427734375
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -24.485441207885742
Agent0_Train_StdReturn : 21.156005859375
Agent0_Train_MaxReturn : 8.75882339477539
Agent0_Train_MinReturn : -59.08435821533203
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 646500
Agent0_TimeSinceStart : 997.268226146698
Agent0_Critic_Loss : 1.0342743396759033
Agent0_Actor_Loss : -5.087485313415527
Agent0_Alpha_Loss : 4.298996925354004
Agent0_Temperature : 0.44135702005178934
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -27.524703979492188
Agent1_Eval_StdReturn : 27.489404678344727
Agent1_Eval_MaxReturn : 33.09193420410156
Agent1_Eval_MinReturn : -64.65283966064453
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -28.317943572998047
Agent1_Train_StdReturn : 23.642026901245117
Agent1_Train_MaxReturn : 5.196999549865723
Agent1_Train_MinReturn : -63.68518829345703
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 646500
Agent1_TimeSinceStart : 999.3869256973267
Agent1_Critic_Loss : 1.5760200023651123
Agent1_Actor_Loss : -5.045657157897949
Agent1_Alpha_Loss : 4.271703243255615
Agent1_Temperature : 0.4412740974428624
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 431 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 432 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 433 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 434 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 435 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 436 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 437 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 438 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 439 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 440 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -22.322935104370117
Agent0_Eval_StdReturn : 28.99297332763672
Agent0_Eval_MaxReturn : 44.394744873046875
Agent0_Eval_MinReturn : -68.65716552734375
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -38.573604583740234
Agent0_Train_StdReturn : 29.435590744018555
Agent0_Train_MaxReturn : 6.37796688079834
Agent0_Train_MinReturn : -68.55047607421875
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 661500
Agent0_TimeSinceStart : 1020.6297442913055
Agent0_Critic_Loss : 1.2129361629486084
Agent0_Actor_Loss : -5.185784816741943
Agent0_Alpha_Loss : 4.304113388061523
Agent0_Temperature : 0.4401228117095075
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -25.911983489990234
Agent1_Eval_StdReturn : 34.58224868774414
Agent1_Eval_MaxReturn : 26.960773468017578
Agent1_Eval_MinReturn : -84.05623626708984
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -27.80451011657715
Agent1_Train_StdReturn : 22.342973709106445
Agent1_Train_MaxReturn : 2.600564479827881
Agent1_Train_MinReturn : -64.05096435546875
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 661500
Agent1_TimeSinceStart : 1022.7349445819855
Agent1_Critic_Loss : 1.051251769065857
Agent1_Actor_Loss : -4.889117240905762
Agent1_Alpha_Loss : 4.303750514984131
Agent1_Temperature : 0.44004409182506493
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 441 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 442 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 443 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 444 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 445 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 446 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 447 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 448 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 449 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 450 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -34.63507843017578
Agent0_Eval_StdReturn : 22.114046096801758
Agent0_Eval_MaxReturn : 3.222886562347412
Agent0_Eval_MinReturn : -64.2557601928711
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -24.398456573486328
Agent0_Train_StdReturn : 21.607341766357422
Agent0_Train_MaxReturn : 6.649333953857422
Agent0_Train_MinReturn : -61.337974548339844
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 676500
Agent0_TimeSinceStart : 1043.9857249259949
Agent0_Critic_Loss : 1.3441487550735474
Agent0_Actor_Loss : -5.073975563049316
Agent0_Alpha_Loss : 4.236075401306152
Agent0_Temperature : 0.4388952391407975
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -34.882591247558594
Agent1_Eval_StdReturn : 22.759471893310547
Agent1_Eval_MaxReturn : 11.45547103881836
Agent1_Eval_MinReturn : -67.35699462890625
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -26.772628784179688
Agent1_Train_StdReturn : 22.02138328552246
Agent1_Train_MaxReturn : 5.106362342834473
Agent1_Train_MinReturn : -69.19595336914062
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 676500
Agent1_TimeSinceStart : 1046.0867712497711
Agent1_Critic_Loss : 1.5106842517852783
Agent1_Actor_Loss : -4.7373175621032715
Agent1_Alpha_Loss : 4.2672438621521
Agent1_Temperature : 0.4388195820478104
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 451 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 452 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 453 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 454 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 455 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 456 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 457 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 458 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 459 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 460 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -42.561195373535156
Agent0_Eval_StdReturn : 28.059141159057617
Agent0_Eval_MaxReturn : 10.201412200927734
Agent0_Eval_MinReturn : -84.69100189208984
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -16.5769100189209
Agent0_Train_StdReturn : 22.555116653442383
Agent0_Train_MaxReturn : 11.30492115020752
Agent0_Train_MinReturn : -71.05713653564453
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 691500
Agent0_TimeSinceStart : 1067.2996418476105
Agent0_Critic_Loss : 1.0811388492584229
Agent0_Actor_Loss : -5.225247859954834
Agent0_Alpha_Loss : 4.247150421142578
Agent0_Temperature : 0.4376722542281746
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -26.74764060974121
Agent1_Eval_StdReturn : 12.973237037658691
Agent1_Eval_MaxReturn : -10.496617317199707
Agent1_Eval_MinReturn : -48.319122314453125
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -27.37919044494629
Agent1_Train_StdReturn : 22.72896957397461
Agent1_Train_MaxReturn : 19.146739959716797
Agent1_Train_MinReturn : -57.82540512084961
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 691500
Agent1_TimeSinceStart : 1069.4119029045105
Agent1_Critic_Loss : 1.6243445873260498
Agent1_Actor_Loss : -4.977510929107666
Agent1_Alpha_Loss : 4.25355339050293
Agent1_Temperature : 0.4376019262501461
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 461 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 462 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 463 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 464 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 465 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 466 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 467 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 468 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 469 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 470 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -31.1485538482666
Agent0_Eval_StdReturn : 18.370742797851562
Agent0_Eval_MaxReturn : -8.163960456848145
Agent0_Eval_MinReturn : -65.42922973632812
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -23.00370979309082
Agent0_Train_StdReturn : 28.98225212097168
Agent0_Train_MaxReturn : 11.55366325378418
Agent0_Train_MinReturn : -82.5798568725586
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 706500
Agent0_TimeSinceStart : 1090.6421332359314
Agent0_Critic_Loss : 0.9777525067329407
Agent0_Actor_Loss : -5.132998466491699
Agent0_Alpha_Loss : 4.264921188354492
Agent0_Temperature : 0.43645358308540655
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -17.595542907714844
Agent1_Eval_StdReturn : 24.732908248901367
Agent1_Eval_MaxReturn : 19.135223388671875
Agent1_Eval_MinReturn : -58.482154846191406
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -32.72475814819336
Agent1_Train_StdReturn : 15.56058120727539
Agent1_Train_MaxReturn : -10.555940628051758
Agent1_Train_MinReturn : -67.27555847167969
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 706500
Agent1_TimeSinceStart : 1092.7552783489227
Agent1_Critic_Loss : 1.0357495546340942
Agent1_Actor_Loss : -4.9009809494018555
Agent1_Alpha_Loss : 4.238607406616211
Agent1_Temperature : 0.4363896822620787
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 471 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 472 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 473 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 474 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 475 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 476 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 477 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 478 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 479 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 480 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -18.073299407958984
Agent0_Eval_StdReturn : 19.845279693603516
Agent0_Eval_MaxReturn : 19.831315994262695
Agent0_Eval_MinReturn : -51.146446228027344
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -20.063520431518555
Agent0_Train_StdReturn : 24.6192569732666
Agent0_Train_MaxReturn : 23.386028289794922
Agent0_Train_MinReturn : -70.80381774902344
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 721500
Agent0_TimeSinceStart : 1114.0347094535828
Agent0_Critic_Loss : 1.309245228767395
Agent0_Actor_Loss : -5.1317949295043945
Agent0_Alpha_Loss : 4.219992637634277
Agent0_Temperature : 0.43523924989017476
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -23.38480567932129
Agent1_Eval_StdReturn : 20.200231552124023
Agent1_Eval_MaxReturn : 5.209421157836914
Agent1_Eval_MinReturn : -57.40835952758789
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -31.92392349243164
Agent1_Train_StdReturn : 25.955766677856445
Agent1_Train_MaxReturn : 30.737098693847656
Agent1_Train_MinReturn : -66.16918182373047
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 721500
Agent1_TimeSinceStart : 1116.1470131874084
Agent1_Critic_Loss : 1.1644752025604248
Agent1_Actor_Loss : -4.83472204208374
Agent1_Alpha_Loss : 4.239882946014404
Agent1_Temperature : 0.4351763949081278
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 481 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 482 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 483 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 484 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 485 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 486 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 487 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 488 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 489 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 490 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -28.329843521118164
Agent0_Eval_StdReturn : 22.144582748413086
Agent0_Eval_MaxReturn : 28.687759399414062
Agent0_Eval_MinReturn : -50.97860336303711
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -24.333141326904297
Agent0_Train_StdReturn : 20.630470275878906
Agent0_Train_MaxReturn : 8.750747680664062
Agent0_Train_MinReturn : -60.024688720703125
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 736500
Agent0_TimeSinceStart : 1137.3708996772766
Agent0_Critic_Loss : 1.1890414953231812
Agent0_Actor_Loss : -5.194526672363281
Agent0_Alpha_Loss : 4.251713275909424
Agent0_Temperature : 0.43402542251556553
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -13.39727783203125
Agent1_Eval_StdReturn : 30.323963165283203
Agent1_Eval_MaxReturn : 26.47987937927246
Agent1_Eval_MinReturn : -93.32745361328125
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -27.653478622436523
Agent1_Train_StdReturn : 24.482736587524414
Agent1_Train_MaxReturn : 11.751998901367188
Agent1_Train_MinReturn : -61.87434768676758
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 736500
Agent1_TimeSinceStart : 1139.4794397354126
Agent1_Critic_Loss : 1.9125161170959473
Agent1_Actor_Loss : -5.262504577636719
Agent1_Alpha_Loss : 4.233403205871582
Agent1_Temperature : 0.4339648049367586
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 491 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 492 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 493 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 494 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 495 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 496 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 497 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 498 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 499 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 500 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -18.81625747680664
Agent0_Eval_StdReturn : 22.64061737060547
Agent0_Eval_MaxReturn : 14.1612548828125
Agent0_Eval_MinReturn : -58.408103942871094
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -21.030569076538086
Agent0_Train_StdReturn : 16.341466903686523
Agent0_Train_MaxReturn : 3.5346946716308594
Agent0_Train_MinReturn : -42.40647888183594
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 751500
Agent0_TimeSinceStart : 1160.7159008979797
Agent0_Critic_Loss : 1.1087663173675537
Agent0_Actor_Loss : -5.300702095031738
Agent0_Alpha_Loss : 4.183056831359863
Agent0_Temperature : 0.4328124955693086
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -12.494474411010742
Agent1_Eval_StdReturn : 20.356334686279297
Agent1_Eval_MaxReturn : 26.77205467224121
Agent1_Eval_MinReturn : -33.79583740234375
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -39.58179473876953
Agent1_Train_StdReturn : 25.566617965698242
Agent1_Train_MaxReturn : -2.6476354598999023
Agent1_Train_MinReturn : -86.42475891113281
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 751500
Agent1_TimeSinceStart : 1162.8345658779144
Agent1_Critic_Loss : 1.4603711366653442
Agent1_Actor_Loss : -5.358753204345703
Agent1_Alpha_Loss : 4.22546911239624
Agent1_Temperature : 0.4327583847650875
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 501 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 502 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 503 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 504 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 505 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 506 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 507 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 508 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 509 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 510 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -33.90195846557617
Agent0_Eval_StdReturn : 28.52829933166504
Agent0_Eval_MaxReturn : 5.193410873413086
Agent0_Eval_MinReturn : -82.47895812988281
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -31.980783462524414
Agent0_Train_StdReturn : 25.071306228637695
Agent0_Train_MaxReturn : -0.7462382316589355
Agent0_Train_MinReturn : -82.79495239257812
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 766500
Agent0_TimeSinceStart : 1184.0570166110992
Agent0_Critic_Loss : 1.4398024082183838
Agent0_Actor_Loss : -5.293177604675293
Agent0_Alpha_Loss : 4.2070512771606445
Agent0_Temperature : 0.431606273777818
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -33.07490921020508
Agent1_Eval_StdReturn : 30.463115692138672
Agent1_Eval_MaxReturn : 18.855257034301758
Agent1_Eval_MinReturn : -81.21199035644531
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -24.10415267944336
Agent1_Train_StdReturn : 28.483579635620117
Agent1_Train_MaxReturn : 26.670869827270508
Agent1_Train_MinReturn : -65.647216796875
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 766500
Agent1_TimeSinceStart : 1186.1592009067535
Agent1_Critic_Loss : 1.4113417863845825
Agent1_Actor_Loss : -4.998382091522217
Agent1_Alpha_Loss : 4.220075607299805
Agent1_Temperature : 0.43155521098562577
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 511 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 512 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 513 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 514 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 515 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 516 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 517 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 518 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 519 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 520 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -33.18070602416992
Agent0_Eval_StdReturn : 19.795236587524414
Agent0_Eval_MaxReturn : -7.142184734344482
Agent0_Eval_MinReturn : -58.93537902832031
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -26.28090476989746
Agent0_Train_StdReturn : 22.169742584228516
Agent0_Train_MaxReturn : 8.669394493103027
Agent0_Train_MinReturn : -60.383689880371094
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 781500
Agent0_TimeSinceStart : 1207.3607153892517
Agent0_Critic_Loss : 1.294581413269043
Agent0_Actor_Loss : -5.353906631469727
Agent0_Alpha_Loss : 4.217085838317871
Agent0_Temperature : 0.43040369061749817
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -27.292160034179688
Agent1_Eval_StdReturn : 30.738967895507812
Agent1_Eval_MaxReturn : 14.496291160583496
Agent1_Eval_MinReturn : -74.58573913574219
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -30.781421661376953
Agent1_Train_StdReturn : 22.166244506835938
Agent1_Train_MaxReturn : -1.282397985458374
Agent1_Train_MinReturn : -69.82892608642578
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 781500
Agent1_TimeSinceStart : 1209.4765393733978
Agent1_Critic_Loss : 1.3751251697540283
Agent1_Actor_Loss : -5.150893211364746
Agent1_Alpha_Loss : 4.198340892791748
Agent1_Temperature : 0.4303559803783161
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 521 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 522 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 523 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 524 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 525 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 526 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 527 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 528 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 529 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 530 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -23.027437210083008
Agent0_Eval_StdReturn : 27.246843338012695
Agent0_Eval_MaxReturn : 18.632558822631836
Agent0_Eval_MinReturn : -54.82470703125
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -29.56363296508789
Agent0_Train_StdReturn : 26.80584716796875
Agent0_Train_MaxReturn : 15.35325813293457
Agent0_Train_MinReturn : -77.36040496826172
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 796500
Agent0_TimeSinceStart : 1230.6751108169556
Agent0_Critic_Loss : 1.0504411458969116
Agent0_Actor_Loss : -5.51606559753418
Agent0_Alpha_Loss : 4.226958751678467
Agent0_Temperature : 0.4292054770427564
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -24.143014907836914
Agent1_Eval_StdReturn : 18.653564453125
Agent1_Eval_MaxReturn : 4.136280059814453
Agent1_Eval_MinReturn : -48.01271438598633
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -29.054149627685547
Agent1_Train_StdReturn : 32.033058166503906
Agent1_Train_MaxReturn : 17.262493133544922
Agent1_Train_MinReturn : -83.69439697265625
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 796500
Agent1_TimeSinceStart : 1232.7855541706085
Agent1_Critic_Loss : 1.067436695098877
Agent1_Actor_Loss : -5.046660423278809
Agent1_Alpha_Loss : 4.214605331420898
Agent1_Temperature : 0.42916154996953976
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 531 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 532 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 533 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 534 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 535 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 536 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 537 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 538 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 539 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 540 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -19.397098541259766
Agent0_Eval_StdReturn : 28.479097366333008
Agent0_Eval_MaxReturn : 20.668567657470703
Agent0_Eval_MinReturn : -72.27336120605469
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -18.088550567626953
Agent0_Train_StdReturn : 20.430816650390625
Agent0_Train_MaxReturn : 8.538961410522461
Agent0_Train_MinReturn : -55.83530044555664
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 811500
Agent0_TimeSinceStart : 1253.954110622406
Agent0_Critic_Loss : 1.2083075046539307
Agent0_Actor_Loss : -5.289947509765625
Agent0_Alpha_Loss : 4.2251996994018555
Agent0_Temperature : 0.4280108576720566
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -17.025516510009766
Agent1_Eval_StdReturn : 25.29579734802246
Agent1_Eval_MaxReturn : 35.3465461730957
Agent1_Eval_MinReturn : -49.09464645385742
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -33.68891143798828
Agent1_Train_StdReturn : 23.802417755126953
Agent1_Train_MaxReturn : -6.621438026428223
Agent1_Train_MinReturn : -74.57858276367188
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 811500
Agent1_TimeSinceStart : 1256.0558607578278
Agent1_Critic_Loss : 1.0704869031906128
Agent1_Actor_Loss : -5.479173183441162
Agent1_Alpha_Loss : 4.200438499450684
Agent1_Temperature : 0.4279683421233269
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 541 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 542 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 543 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 544 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 545 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 546 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 547 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 548 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 549 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 550 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -38.319984436035156
Agent0_Eval_StdReturn : 22.890579223632812
Agent0_Eval_MaxReturn : 12.288851737976074
Agent0_Eval_MinReturn : -72.05007934570312
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -20.054494857788086
Agent0_Train_StdReturn : 28.224563598632812
Agent0_Train_MaxReturn : 8.933332443237305
Agent0_Train_MinReturn : -66.67227172851562
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 826500
Agent0_TimeSinceStart : 1277.2676062583923
Agent0_Critic_Loss : 0.9882138967514038
Agent0_Actor_Loss : -5.2879838943481445
Agent0_Alpha_Loss : 4.210230827331543
Agent0_Temperature : 0.4268183287806481
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -33.90639114379883
Agent1_Eval_StdReturn : 21.94637107849121
Agent1_Eval_MaxReturn : 6.888644218444824
Agent1_Eval_MinReturn : -60.90708923339844
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -42.64677810668945
Agent1_Train_StdReturn : 23.045007705688477
Agent1_Train_MaxReturn : 13.231624603271484
Agent1_Train_MinReturn : -74.63502502441406
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 826500
Agent1_TimeSinceStart : 1279.376978635788
Agent1_Critic_Loss : 1.8655405044555664
Agent1_Actor_Loss : -5.39726448059082
Agent1_Alpha_Loss : 4.172978401184082
Agent1_Temperature : 0.4267798870254059
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 551 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 552 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 553 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 554 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 555 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 556 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 557 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 558 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 559 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 560 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -12.469869613647461
Agent0_Eval_StdReturn : 21.855077743530273
Agent0_Eval_MaxReturn : 30.666427612304688
Agent0_Eval_MinReturn : -40.42849349975586
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -25.640066146850586
Agent0_Train_StdReturn : 18.50835609436035
Agent0_Train_MaxReturn : -0.7155084609985352
Agent0_Train_MinReturn : -63.833892822265625
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 841500
Agent0_TimeSinceStart : 1300.596614599228
Agent0_Critic_Loss : 1.1712678670883179
Agent0_Actor_Loss : -5.334216117858887
Agent0_Alpha_Loss : 4.17716646194458
Agent0_Temperature : 0.42563136883011055
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -33.97395706176758
Agent1_Eval_StdReturn : 30.977676391601562
Agent1_Eval_MaxReturn : 0.8808712959289551
Agent1_Eval_MinReturn : -87.89476013183594
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -47.89871597290039
Agent1_Train_StdReturn : 19.54058837890625
Agent1_Train_MaxReturn : -14.574039459228516
Agent1_Train_MinReturn : -82.1978530883789
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 841500
Agent1_TimeSinceStart : 1302.7006587982178
Agent1_Critic_Loss : 1.3260197639465332
Agent1_Actor_Loss : -5.389911651611328
Agent1_Alpha_Loss : 4.220678806304932
Agent1_Temperature : 0.425596486516717
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 561 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 562 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 563 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 564 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 565 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 566 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 567 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 568 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 569 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 570 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -42.87119674682617
Agent0_Eval_StdReturn : 24.459333419799805
Agent0_Eval_MaxReturn : 0.9291620254516602
Agent0_Eval_MinReturn : -79.38043212890625
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -24.565059661865234
Agent0_Train_StdReturn : 26.161619186401367
Agent0_Train_MaxReturn : 19.93299102783203
Agent0_Train_MinReturn : -63.97865295410156
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 856500
Agent0_TimeSinceStart : 1323.956411600113
Agent0_Critic_Loss : 1.7002379894256592
Agent0_Actor_Loss : -5.5613203048706055
Agent0_Alpha_Loss : 4.174849510192871
Agent0_Temperature : 0.4244466367336856
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -34.62607955932617
Agent1_Eval_StdReturn : 27.23076820373535
Agent1_Eval_MaxReturn : 3.532885789871216
Agent1_Eval_MinReturn : -71.70796203613281
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -17.8157958984375
Agent1_Train_StdReturn : 23.281997680664062
Agent1_Train_MaxReturn : 11.44921588897705
Agent1_Train_MinReturn : -64.64884185791016
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 856500
Agent1_TimeSinceStart : 1326.069853067398
Agent1_Critic_Loss : 1.8113185167312622
Agent1_Actor_Loss : -5.454525470733643
Agent1_Alpha_Loss : 4.121868133544922
Agent1_Temperature : 0.42441700690916784
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 571 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 572 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 573 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 574 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 575 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 576 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 577 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 578 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 579 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 580 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -38.31697463989258
Agent0_Eval_StdReturn : 32.59624099731445
Agent0_Eval_MaxReturn : 8.921527862548828
Agent0_Eval_MinReturn : -94.92329406738281
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -21.41635513305664
Agent0_Train_StdReturn : 27.963520050048828
Agent0_Train_MaxReturn : 14.100746154785156
Agent0_Train_MinReturn : -78.48933410644531
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 871500
Agent0_TimeSinceStart : 1347.4016737937927
Agent0_Critic_Loss : 1.3791840076446533
Agent0_Actor_Loss : -5.708495140075684
Agent0_Alpha_Loss : 4.169191360473633
Agent0_Temperature : 0.42326326980018214
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -27.74436378479004
Agent1_Eval_StdReturn : 24.035411834716797
Agent1_Eval_MaxReturn : 18.051958084106445
Agent1_Eval_MinReturn : -66.50331115722656
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -17.724464416503906
Agent1_Train_StdReturn : 25.697673797607422
Agent1_Train_MaxReturn : 18.16693878173828
Agent1_Train_MinReturn : -57.20327377319336
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 871500
Agent1_TimeSinceStart : 1349.5316624641418
Agent1_Critic_Loss : 1.1679818630218506
Agent1_Actor_Loss : -5.511232852935791
Agent1_Alpha_Loss : 4.099743843078613
Agent1_Temperature : 0.4232436927187733
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 581 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 582 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 583 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 584 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 585 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 586 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 587 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 588 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 589 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 590 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -27.696361541748047
Agent0_Eval_StdReturn : 29.564905166625977
Agent0_Eval_MaxReturn : 14.111490249633789
Agent0_Eval_MinReturn : -85.72547149658203
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -23.8392276763916
Agent0_Train_StdReturn : 21.93890953063965
Agent0_Train_MaxReturn : 10.646601676940918
Agent0_Train_MinReturn : -60.21788787841797
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 886500
Agent0_TimeSinceStart : 1370.8654463291168
Agent0_Critic_Loss : 1.3600349426269531
Agent0_Actor_Loss : -5.772899627685547
Agent0_Alpha_Loss : 4.143069267272949
Agent0_Temperature : 0.42208539857208516
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -41.474605560302734
Agent1_Eval_StdReturn : 17.613784790039062
Agent1_Eval_MaxReturn : -15.880632400512695
Agent1_Eval_MinReturn : -68.3501205444336
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -18.9190673828125
Agent1_Train_StdReturn : 26.174964904785156
Agent1_Train_MaxReturn : 32.95966339111328
Agent1_Train_MinReturn : -61.43252182006836
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 886500
Agent1_TimeSinceStart : 1372.9768772125244
Agent1_Critic_Loss : 1.133664846420288
Agent1_Actor_Loss : -5.6037797927856445
Agent1_Alpha_Loss : 4.1403703689575195
Agent1_Temperature : 0.4220742888602164
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 591 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 592 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 593 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 594 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 595 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 596 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 597 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 598 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 599 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 600 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -26.888254165649414
Agent0_Eval_StdReturn : 26.549530029296875
Agent0_Eval_MaxReturn : 20.191865921020508
Agent0_Eval_MinReturn : -64.36062622070312
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -14.184496879577637
Agent0_Train_StdReturn : 26.127538681030273
Agent0_Train_MaxReturn : 25.020015716552734
Agent0_Train_MinReturn : -57.694419860839844
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 901500
Agent0_TimeSinceStart : 1393.0377728939056
Agent0_Critic_Loss : 2.004941463470459
Agent0_Actor_Loss : -5.632884502410889
Agent0_Alpha_Loss : 4.135087013244629
Agent0_Temperature : 0.42091372131600424
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -22.491344451904297
Agent1_Eval_StdReturn : 19.552419662475586
Agent1_Eval_MaxReturn : 2.089601516723633
Agent1_Eval_MinReturn : -59.95792007446289
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -27.188289642333984
Agent1_Train_StdReturn : 26.64727210998535
Agent1_Train_MaxReturn : 17.90499496459961
Agent1_Train_MinReturn : -70.255615234375
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 901500
Agent1_TimeSinceStart : 1395.0155119895935
Agent1_Critic_Loss : 1.6008367538452148
Agent1_Actor_Loss : -5.50321102142334
Agent1_Alpha_Loss : 4.122013092041016
Agent1_Temperature : 0.42091032124226313
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 601 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 602 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 603 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 604 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 605 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 606 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 607 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 608 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 609 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 610 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -35.430538177490234
Agent0_Eval_StdReturn : 39.01922607421875
Agent0_Eval_MaxReturn : 28.204097747802734
Agent0_Eval_MinReturn : -98.39207458496094
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -25.682674407958984
Agent0_Train_StdReturn : 33.06270980834961
Agent0_Train_MaxReturn : 32.22825241088867
Agent0_Train_MinReturn : -73.44384765625
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 916500
Agent0_TimeSinceStart : 1414.9526932239532
Agent0_Critic_Loss : 1.543900728225708
Agent0_Actor_Loss : -5.709691047668457
Agent0_Alpha_Loss : 4.144580364227295
Agent0_Temperature : 0.41974545023439974
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -33.45350646972656
Agent1_Eval_StdReturn : 30.67825698852539
Agent1_Eval_MaxReturn : 12.209471702575684
Agent1_Eval_MinReturn : -102.08820343017578
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -28.02103042602539
Agent1_Train_StdReturn : 27.75301170349121
Agent1_Train_MaxReturn : -2.9892642498016357
Agent1_Train_MinReturn : -100.57746887207031
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 916500
Agent1_TimeSinceStart : 1416.9402077198029
Agent1_Critic_Loss : 1.8188667297363281
Agent1_Actor_Loss : -5.402398586273193
Agent1_Alpha_Loss : 4.093096733093262
Agent1_Temperature : 0.4197527825979151
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 611 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 612 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 613 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 614 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 615 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 616 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 617 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 618 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 619 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 620 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -23.79159927368164
Agent0_Eval_StdReturn : 25.144800186157227
Agent0_Eval_MaxReturn : 17.669185638427734
Agent0_Eval_MinReturn : -61.845115661621094
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -36.44043731689453
Agent0_Train_StdReturn : 29.9956111907959
Agent0_Train_MaxReturn : 20.1041259765625
Agent0_Train_MinReturn : -76.25090026855469
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 931500
Agent0_TimeSinceStart : 1437.0159904956818
Agent0_Critic_Loss : 1.590782880783081
Agent0_Actor_Loss : -5.804482460021973
Agent0_Alpha_Loss : 4.085875034332275
Agent0_Temperature : 0.41858167681261044
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -31.757232666015625
Agent1_Eval_StdReturn : 34.18719482421875
Agent1_Eval_MaxReturn : 30.56679916381836
Agent1_Eval_MinReturn : -74.9818115234375
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -11.398103713989258
Agent1_Train_StdReturn : 20.100112915039062
Agent1_Train_MaxReturn : 11.907058715820312
Agent1_Train_MinReturn : -46.83121109008789
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 931500
Agent1_TimeSinceStart : 1439.0076549053192
Agent1_Critic_Loss : 1.8489220142364502
Agent1_Actor_Loss : -5.418818473815918
Agent1_Alpha_Loss : 4.049304962158203
Agent1_Temperature : 0.4185991689544327
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 621 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 622 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 623 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 624 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 625 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 626 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 627 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 628 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 629 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 630 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -36.19074249267578
Agent0_Eval_StdReturn : 22.142412185668945
Agent0_Eval_MaxReturn : -11.514140129089355
Agent0_Eval_MinReturn : -73.7972412109375
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -27.9556941986084
Agent0_Train_StdReturn : 23.014801025390625
Agent0_Train_MaxReturn : -2.515209197998047
Agent0_Train_MinReturn : -83.8342514038086
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 946500
Agent0_TimeSinceStart : 1459.1090762615204
Agent0_Critic_Loss : 1.5009129047393799
Agent0_Actor_Loss : -5.8667426109313965
Agent0_Alpha_Loss : 4.053883075714111
Agent0_Temperature : 0.41742228610138665
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -25.311372756958008
Agent1_Eval_StdReturn : 34.69630813598633
Agent1_Eval_MaxReturn : 18.96487045288086
Agent1_Eval_MinReturn : -83.11798095703125
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -36.0436897277832
Agent1_Train_StdReturn : 21.951841354370117
Agent1_Train_MaxReturn : -0.7936105728149414
Agent1_Train_MinReturn : -86.26535034179688
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 946500
Agent1_TimeSinceStart : 1461.112133026123
Agent1_Critic_Loss : 1.3926513195037842
Agent1_Actor_Loss : -5.501557350158691
Agent1_Alpha_Loss : 4.108077049255371
Agent1_Temperature : 0.4174483204360368
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 631 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 632 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 633 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 634 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 635 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 636 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 637 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 638 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 639 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 640 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -33.30485534667969
Agent0_Eval_StdReturn : 22.449607849121094
Agent0_Eval_MaxReturn : 5.722623825073242
Agent0_Eval_MinReturn : -69.91763305664062
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -26.435216903686523
Agent0_Train_StdReturn : 27.87176513671875
Agent0_Train_MaxReturn : 16.591978073120117
Agent0_Train_MinReturn : -63.394866943359375
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 961500
Agent0_TimeSinceStart : 1481.1732909679413
Agent0_Critic_Loss : 1.2728493213653564
Agent0_Actor_Loss : -5.806406497955322
Agent0_Alpha_Loss : 4.100159168243408
Agent0_Temperature : 0.41626790816738257
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -42.28459548950195
Agent1_Eval_StdReturn : 30.816043853759766
Agent1_Eval_MaxReturn : 1.8424510955810547
Agent1_Eval_MinReturn : -102.05827331542969
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -13.522878646850586
Agent1_Train_StdReturn : 35.35315704345703
Agent1_Train_MaxReturn : 50.21455383300781
Agent1_Train_MinReturn : -90.83416748046875
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 961500
Agent1_TimeSinceStart : 1483.1654608249664
Agent1_Critic_Loss : 1.027284860610962
Agent1_Actor_Loss : -5.634861469268799
Agent1_Alpha_Loss : 4.076206684112549
Agent1_Temperature : 0.4163000599861176
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 641 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 642 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 643 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 644 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 645 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 646 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 647 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 648 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 649 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 650 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -27.150283813476562
Agent0_Eval_StdReturn : 21.21210289001465
Agent0_Eval_MaxReturn : -2.63511323928833
Agent0_Eval_MinReturn : -86.04229736328125
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -37.3680419921875
Agent0_Train_StdReturn : 19.16799545288086
Agent0_Train_MaxReturn : -3.696216583251953
Agent0_Train_MinReturn : -67.4134521484375
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 976500
Agent0_TimeSinceStart : 1503.2831349372864
Agent0_Critic_Loss : 2.0263471603393555
Agent0_Actor_Loss : -5.92820930480957
Agent0_Alpha_Loss : 4.060650825500488
Agent0_Temperature : 0.41511917002131193
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -35.90901184082031
Agent1_Eval_StdReturn : 36.23537063598633
Agent1_Eval_MaxReturn : 14.344326972961426
Agent1_Eval_MinReturn : -88.34396362304688
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -25.367408752441406
Agent1_Train_StdReturn : 21.79281234741211
Agent1_Train_MaxReturn : 15.712775230407715
Agent1_Train_MinReturn : -55.933921813964844
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 976500
Agent1_TimeSinceStart : 1505.2782273292542
Agent1_Critic_Loss : 1.7585179805755615
Agent1_Actor_Loss : -5.430849075317383
Agent1_Alpha_Loss : 4.051947593688965
Agent1_Temperature : 0.4151556423766015
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 651 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 652 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 653 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 654 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 655 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 656 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 657 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 658 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 659 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 660 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -28.50034523010254
Agent0_Eval_StdReturn : 27.655139923095703
Agent0_Eval_MaxReturn : 7.270145416259766
Agent0_Eval_MinReturn : -84.74761199951172
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -17.877246856689453
Agent0_Train_StdReturn : 28.237428665161133
Agent0_Train_MaxReturn : 11.95966911315918
Agent0_Train_MinReturn : -72.38093566894531
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 991500
Agent0_TimeSinceStart : 1525.4198899269104
Agent0_Critic_Loss : 2.1100382804870605
Agent0_Actor_Loss : -6.1417999267578125
Agent0_Alpha_Loss : 4.137484073638916
Agent0_Temperature : 0.41397319808662925
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -27.14957618713379
Agent1_Eval_StdReturn : 22.722667694091797
Agent1_Eval_MaxReturn : 5.540170669555664
Agent1_Eval_MinReturn : -58.89321517944336
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -37.66059112548828
Agent1_Train_StdReturn : 29.407506942749023
Agent1_Train_MaxReturn : 21.16878318786621
Agent1_Train_MinReturn : -98.70848083496094
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 991500
Agent1_TimeSinceStart : 1527.416767835617
Agent1_Critic_Loss : 1.3301060199737549
Agent1_Actor_Loss : -5.730887413024902
Agent1_Alpha_Loss : 4.0318803787231445
Agent1_Temperature : 0.4140155769680151
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 661 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 662 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 663 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 664 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 665 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 666 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 667 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 668 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 669 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 670 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -34.025596618652344
Agent0_Eval_StdReturn : 40.6354866027832
Agent0_Eval_MaxReturn : 5.8416547775268555
Agent0_Eval_MinReturn : -125.27040100097656
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -33.07184600830078
Agent0_Train_StdReturn : 21.25852394104004
Agent0_Train_MaxReturn : 19.94293975830078
Agent0_Train_MinReturn : -52.348426818847656
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1006500
Agent0_TimeSinceStart : 1547.5931525230408
Agent0_Critic_Loss : 1.9806513786315918
Agent0_Actor_Loss : -6.036905288696289
Agent0_Alpha_Loss : 4.086731910705566
Agent0_Temperature : 0.41282881557282325
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -33.292945861816406
Agent1_Eval_StdReturn : 24.51781463623047
Agent1_Eval_MaxReturn : 5.188930034637451
Agent1_Eval_MinReturn : -77.2274398803711
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -31.85030746459961
Agent1_Train_StdReturn : 29.125965118408203
Agent1_Train_MaxReturn : -5.37054967880249
Agent1_Train_MinReturn : -109.27433013916016
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1006500
Agent1_TimeSinceStart : 1549.5950412750244
Agent1_Critic_Loss : 1.4649696350097656
Agent1_Actor_Loss : -5.747598648071289
Agent1_Alpha_Loss : 4.052624702453613
Agent1_Temperature : 0.4128780272979107
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 671 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 672 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 673 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 674 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 675 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 676 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 677 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 678 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 679 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 680 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -34.81340789794922
Agent0_Eval_StdReturn : 19.730493545532227
Agent0_Eval_MaxReturn : 0.9836273193359375
Agent0_Eval_MinReturn : -65.20124053955078
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -39.49620056152344
Agent0_Train_StdReturn : 22.321744918823242
Agent0_Train_MaxReturn : -7.951440811157227
Agent0_Train_MinReturn : -74.13690185546875
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1021500
Agent0_TimeSinceStart : 1570.2540040016174
Agent0_Critic_Loss : 2.3874905109405518
Agent0_Actor_Loss : -5.990541458129883
Agent0_Alpha_Loss : 4.077751159667969
Agent0_Temperature : 0.41168814409827825
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -25.094886779785156
Agent1_Eval_StdReturn : 23.350765228271484
Agent1_Eval_MaxReturn : 1.358445167541504
Agent1_Eval_MinReturn : -71.84539031982422
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -35.17018127441406
Agent1_Train_StdReturn : 32.98887252807617
Agent1_Train_MaxReturn : 9.072307586669922
Agent1_Train_MinReturn : -100.50101470947266
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1021500
Agent1_TimeSinceStart : 1572.288798570633
Agent1_Critic_Loss : 1.5827010869979858
Agent1_Actor_Loss : -5.794327735900879
Agent1_Alpha_Loss : 4.064072608947754
Agent1_Temperature : 0.411742900598629
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 681 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 682 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 683 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 684 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 685 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 686 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 687 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 688 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 689 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 690 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -31.667041778564453
Agent0_Eval_StdReturn : 27.478870391845703
Agent0_Eval_MaxReturn : 5.429932594299316
Agent0_Eval_MinReturn : -80.88966369628906
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -23.86394691467285
Agent0_Train_StdReturn : 17.65521812438965
Agent0_Train_MaxReturn : 2.182971954345703
Agent0_Train_MinReturn : -53.47079086303711
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1036500
Agent0_TimeSinceStart : 1592.6607975959778
Agent0_Critic_Loss : 1.9004924297332764
Agent0_Actor_Loss : -6.179919242858887
Agent0_Alpha_Loss : 4.056672096252441
Agent0_Temperature : 0.4105513177406332
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -24.326751708984375
Agent1_Eval_StdReturn : 18.93580436706543
Agent1_Eval_MaxReturn : 3.2504920959472656
Agent1_Eval_MinReturn : -53.04940414428711
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -23.91469383239746
Agent1_Train_StdReturn : 19.995615005493164
Agent1_Train_MaxReturn : 6.7350921630859375
Agent1_Train_MinReturn : -56.732383728027344
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1036500
Agent1_TimeSinceStart : 1594.7164585590363
Agent1_Critic_Loss : 1.3219109773635864
Agent1_Actor_Loss : -5.981285095214844
Agent1_Alpha_Loss : 4.036556243896484
Agent1_Temperature : 0.4106123870697828
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 691 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 692 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 693 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 694 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 695 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 696 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 697 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 698 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 699 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 700 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -37.706504821777344
Agent0_Eval_StdReturn : 31.687374114990234
Agent0_Eval_MaxReturn : 28.908899307250977
Agent0_Eval_MinReturn : -92.15357208251953
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -24.512287139892578
Agent0_Train_StdReturn : 28.05547523498535
Agent0_Train_MaxReturn : 9.612204551696777
Agent0_Train_MinReturn : -81.63023376464844
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1051500
Agent0_TimeSinceStart : 1615.2036714553833
Agent0_Critic_Loss : 1.4197914600372314
Agent0_Actor_Loss : -6.238195419311523
Agent0_Alpha_Loss : 4.05443811416626
Agent0_Temperature : 0.40941927326830774
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -20.17826271057129
Agent1_Eval_StdReturn : 26.674467086791992
Agent1_Eval_MaxReturn : 19.268779754638672
Agent1_Eval_MinReturn : -67.88011169433594
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -32.892189025878906
Agent1_Train_StdReturn : 25.16490936279297
Agent1_Train_MaxReturn : 12.541096687316895
Agent1_Train_MinReturn : -79.09031677246094
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1051500
Agent1_TimeSinceStart : 1617.2159659862518
Agent1_Critic_Loss : 1.3016356229782104
Agent1_Actor_Loss : -5.892009735107422
Agent1_Alpha_Loss : 4.034292221069336
Agent1_Temperature : 0.40948491352186256
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 701 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 702 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 703 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 704 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 705 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 706 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 707 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 708 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 709 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 710 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -37.002498626708984
Agent0_Eval_StdReturn : 23.766870498657227
Agent0_Eval_MaxReturn : 10.04463005065918
Agent0_Eval_MinReturn : -64.64332580566406
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -29.724084854125977
Agent0_Train_StdReturn : 40.100765228271484
Agent0_Train_MaxReturn : 16.01299285888672
Agent0_Train_MinReturn : -125.2776870727539
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1066500
Agent0_TimeSinceStart : 1637.725459575653
Agent0_Critic_Loss : 2.0229101181030273
Agent0_Actor_Loss : -6.379951477050781
Agent0_Alpha_Loss : 3.99288272857666
Agent0_Temperature : 0.4082901874824549
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -30.308696746826172
Agent1_Eval_StdReturn : 27.580862045288086
Agent1_Eval_MaxReturn : 9.324280738830566
Agent1_Eval_MinReturn : -74.90760803222656
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -31.40511131286621
Agent1_Train_StdReturn : 29.952152252197266
Agent1_Train_MaxReturn : 3.60296630859375
Agent1_Train_MinReturn : -95.43455505371094
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1066500
Agent1_TimeSinceStart : 1639.7818629741669
Agent1_Critic_Loss : 1.5138208866119385
Agent1_Actor_Loss : -6.036407470703125
Agent1_Alpha_Loss : 3.9977235794067383
Agent1_Temperature : 0.40836092713400735
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 711 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 712 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 713 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 714 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 715 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 716 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 717 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 718 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 719 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 720 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -25.936986923217773
Agent0_Eval_StdReturn : 14.657730102539062
Agent0_Eval_MaxReturn : -0.9546873569488525
Agent0_Eval_MinReturn : -48.52396774291992
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -22.947307586669922
Agent0_Train_StdReturn : 23.273853302001953
Agent0_Train_MaxReturn : 13.183991432189941
Agent0_Train_MinReturn : -68.66554260253906
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1081500
Agent0_TimeSinceStart : 1660.3806400299072
Agent0_Critic_Loss : 1.3317241668701172
Agent0_Actor_Loss : -6.395851135253906
Agent0_Alpha_Loss : 4.011634349822998
Agent0_Temperature : 0.407166268857292
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -24.972469329833984
Agent1_Eval_StdReturn : 34.977928161621094
Agent1_Eval_MaxReturn : 38.19727325439453
Agent1_Eval_MinReturn : -102.01582336425781
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -26.909103393554688
Agent1_Train_StdReturn : 14.5111665725708
Agent1_Train_MaxReturn : 1.9918317794799805
Agent1_Train_MinReturn : -43.87336349487305
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1081500
Agent1_TimeSinceStart : 1662.395045042038
Agent1_Critic_Loss : 1.3422795534133911
Agent1_Actor_Loss : -6.046481609344482
Agent1_Alpha_Loss : 3.9584226608276367
Agent1_Temperature : 0.40723973927943025
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 721 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 722 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 723 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 724 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 725 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 726 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 727 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 728 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 729 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 730 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -32.38677215576172
Agent0_Eval_StdReturn : 26.31326675415039
Agent0_Eval_MaxReturn : 4.525867462158203
Agent0_Eval_MinReturn : -72.82080078125
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -24.466541290283203
Agent0_Train_StdReturn : 32.29996109008789
Agent0_Train_MaxReturn : 34.07235336303711
Agent0_Train_MinReturn : -79.77872467041016
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1096500
Agent0_TimeSinceStart : 1682.7177171707153
Agent0_Critic_Loss : 1.6332504749298096
Agent0_Actor_Loss : -6.324769020080566
Agent0_Alpha_Loss : 3.9981689453125
Agent0_Temperature : 0.40604654031254356
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -32.90229034423828
Agent1_Eval_StdReturn : 29.165645599365234
Agent1_Eval_MaxReturn : -5.887015342712402
Agent1_Eval_MinReturn : -85.66905212402344
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -25.855072021484375
Agent1_Train_StdReturn : 19.726547241210938
Agent1_Train_MaxReturn : -2.0170750617980957
Agent1_Train_MinReturn : -63.01858139038086
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1096500
Agent1_TimeSinceStart : 1684.7287101745605
Agent1_Critic_Loss : 2.1616663932800293
Agent1_Actor_Loss : -5.992559909820557
Agent1_Alpha_Loss : 3.9976282119750977
Agent1_Temperature : 0.4061234046761596
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 731 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 732 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 733 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 734 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 735 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 736 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 737 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 738 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 739 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 740 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -32.8906135559082
Agent0_Eval_StdReturn : 19.054882049560547
Agent0_Eval_MaxReturn : -3.4310965538024902
Agent0_Eval_MinReturn : -67.97283172607422
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -26.252059936523438
Agent0_Train_StdReturn : 26.08001708984375
Agent0_Train_MaxReturn : 33.44025421142578
Agent0_Train_MinReturn : -60.58317184448242
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1111500
Agent0_TimeSinceStart : 1705.1226570606232
Agent0_Critic_Loss : 1.6593800783157349
Agent0_Actor_Loss : -6.483196258544922
Agent0_Alpha_Loss : 3.989144802093506
Agent0_Temperature : 0.4049301393262239
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -25.916248321533203
Agent1_Eval_StdReturn : 12.5596342086792
Agent1_Eval_MaxReturn : -7.813660144805908
Agent1_Eval_MinReturn : -53.835140228271484
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -12.377179145812988
Agent1_Train_StdReturn : 20.48860740661621
Agent1_Train_MaxReturn : 12.291647911071777
Agent1_Train_MinReturn : -63.878108978271484
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1111500
Agent1_TimeSinceStart : 1707.1863148212433
Agent1_Critic_Loss : 2.1242711544036865
Agent1_Actor_Loss : -6.278088092803955
Agent1_Alpha_Loss : 3.996746063232422
Agent1_Temperature : 0.4050102714661236
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 741 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 742 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 743 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 744 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 745 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 746 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 747 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 748 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 749 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 750 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -37.10603332519531
Agent0_Eval_StdReturn : 30.273456573486328
Agent0_Eval_MaxReturn : 1.783381462097168
Agent0_Eval_MinReturn : -104.82553100585938
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -32.42729568481445
Agent0_Train_StdReturn : 19.921314239501953
Agent0_Train_MaxReturn : 3.495532989501953
Agent0_Train_MinReturn : -61.40398406982422
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1126500
Agent0_TimeSinceStart : 1727.8466312885284
Agent0_Critic_Loss : 1.9084455966949463
Agent0_Actor_Loss : -6.386969089508057
Agent0_Alpha_Loss : 3.9827654361724854
Agent0_Temperature : 0.40381760313552634
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -21.827898025512695
Agent1_Eval_StdReturn : 29.650529861450195
Agent1_Eval_MaxReturn : 24.125328063964844
Agent1_Eval_MinReturn : -76.58431243896484
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -24.528539657592773
Agent1_Train_StdReturn : 30.41439437866211
Agent1_Train_MaxReturn : 13.484309196472168
Agent1_Train_MinReturn : -86.37995147705078
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1126500
Agent1_TimeSinceStart : 1729.9054520130157
Agent1_Critic_Loss : 1.7557666301727295
Agent1_Actor_Loss : -6.324121952056885
Agent1_Alpha_Loss : 4.022038459777832
Agent1_Temperature : 0.40390051557677814
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 751 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 752 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 753 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 754 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 755 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 756 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 757 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 758 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 759 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 760 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -21.90648078918457
Agent0_Eval_StdReturn : 23.878223419189453
Agent0_Eval_MaxReturn : 13.320135116577148
Agent0_Eval_MinReturn : -68.25523376464844
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -32.67319107055664
Agent0_Train_StdReturn : 26.897436141967773
Agent0_Train_MaxReturn : 0.02052783966064453
Agent0_Train_MinReturn : -95.68858337402344
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1141500
Agent0_TimeSinceStart : 1750.2863001823425
Agent0_Critic_Loss : 1.7763938903808594
Agent0_Actor_Loss : -6.672601699829102
Agent0_Alpha_Loss : 4.022980690002441
Agent0_Temperature : 0.4027096328653698
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -17.300525665283203
Agent1_Eval_StdReturn : 19.90361976623535
Agent1_Eval_MaxReturn : 4.158841133117676
Agent1_Eval_MinReturn : -48.417388916015625
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -29.266376495361328
Agent1_Train_StdReturn : 28.122499465942383
Agent1_Train_MaxReturn : 15.125476837158203
Agent1_Train_MinReturn : -59.77073669433594
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1141500
Agent1_TimeSinceStart : 1752.3035588264465
Agent1_Critic_Loss : 1.3855676651000977
Agent1_Actor_Loss : -6.359854698181152
Agent1_Alpha_Loss : 3.959371566772461
Agent1_Temperature : 0.402792723537187
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 761 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 762 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 763 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 764 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 765 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 766 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 767 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 768 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 769 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 770 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -32.6716423034668
Agent0_Eval_StdReturn : 22.409704208374023
Agent0_Eval_MaxReturn : 5.388256549835205
Agent0_Eval_MinReturn : -73.8663330078125
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -25.463977813720703
Agent0_Train_StdReturn : 16.67205810546875
Agent0_Train_MaxReturn : -1.3296122550964355
Agent0_Train_MinReturn : -51.19670486450195
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1156500
Agent0_TimeSinceStart : 1772.6048421859741
Agent0_Critic_Loss : 2.087214946746826
Agent0_Actor_Loss : -6.609107494354248
Agent0_Alpha_Loss : 3.990419387817383
Agent0_Temperature : 0.4016058714519471
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -25.17432975769043
Agent1_Eval_StdReturn : 22.893827438354492
Agent1_Eval_MaxReturn : 7.909023284912109
Agent1_Eval_MinReturn : -53.167842864990234
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -50.55009078979492
Agent1_Train_StdReturn : 23.909101486206055
Agent1_Train_MaxReturn : -18.176998138427734
Agent1_Train_MinReturn : -92.13467407226562
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1156500
Agent1_TimeSinceStart : 1774.6158769130707
Agent1_Critic_Loss : 2.0968708992004395
Agent1_Actor_Loss : -6.175046920776367
Agent1_Alpha_Loss : 3.9743590354919434
Agent1_Temperature : 0.40169042714840497
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 771 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 772 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 773 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 774 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 775 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 776 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 777 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 778 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 779 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 780 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -17.01873016357422
Agent0_Eval_StdReturn : 32.39125061035156
Agent0_Eval_MaxReturn : 49.395896911621094
Agent0_Eval_MinReturn : -63.14493179321289
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -14.783154487609863
Agent0_Train_StdReturn : 27.929481506347656
Agent0_Train_MaxReturn : 28.001544952392578
Agent0_Train_MinReturn : -54.366302490234375
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1171500
Agent0_TimeSinceStart : 1794.909806728363
Agent0_Critic_Loss : 1.3435249328613281
Agent0_Actor_Loss : -6.535292625427246
Agent0_Alpha_Loss : 3.934800863265991
Agent0_Temperature : 0.4005049676964589
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -31.758432388305664
Agent1_Eval_StdReturn : 36.698577880859375
Agent1_Eval_MaxReturn : 34.02962112426758
Agent1_Eval_MinReturn : -117.07598876953125
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -28.3606014251709
Agent1_Train_StdReturn : 19.556438446044922
Agent1_Train_MaxReturn : 4.929087162017822
Agent1_Train_MinReturn : -59.247520446777344
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1171500
Agent1_TimeSinceStart : 1796.9246532917023
Agent1_Critic_Loss : 1.4718432426452637
Agent1_Actor_Loss : -6.157218933105469
Agent1_Alpha_Loss : 3.9659323692321777
Agent1_Temperature : 0.400591377475854
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 781 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 782 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 783 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 784 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 785 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 786 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 787 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 788 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 789 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 790 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -23.213714599609375
Agent0_Eval_StdReturn : 26.510616302490234
Agent0_Eval_MaxReturn : 9.656229019165039
Agent0_Eval_MinReturn : -76.54441833496094
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -16.8680419921875
Agent0_Train_StdReturn : 16.455055236816406
Agent0_Train_MaxReturn : 11.68513011932373
Agent0_Train_MinReturn : -41.241180419921875
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1186500
Agent0_TimeSinceStart : 1817.146853685379
Agent0_Critic_Loss : 2.2130117416381836
Agent0_Actor_Loss : -6.620479583740234
Agent0_Alpha_Loss : 3.9659876823425293
Agent0_Temperature : 0.39940986186970245
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -19.9493408203125
Agent1_Eval_StdReturn : 39.13557052612305
Agent1_Eval_MaxReturn : 69.4938735961914
Agent1_Eval_MinReturn : -72.66410827636719
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -48.744606018066406
Agent1_Train_StdReturn : 19.388851165771484
Agent1_Train_MaxReturn : -13.778280258178711
Agent1_Train_MinReturn : -84.00755310058594
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1186500
Agent1_TimeSinceStart : 1819.1418995857239
Agent1_Critic_Loss : 2.6870179176330566
Agent1_Actor_Loss : -6.2211408615112305
Agent1_Alpha_Loss : 3.949674606323242
Agent1_Temperature : 0.3994952098865476
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 791 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 792 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 793 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 794 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 795 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 796 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 797 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 798 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 799 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 800 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -22.009891510009766
Agent0_Eval_StdReturn : 23.83150863647461
Agent0_Eval_MaxReturn : 12.744874954223633
Agent0_Eval_MinReturn : -61.198822021484375
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -36.506595611572266
Agent0_Train_StdReturn : 23.338102340698242
Agent0_Train_MaxReturn : 5.482958793640137
Agent0_Train_MinReturn : -68.45375061035156
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1201500
Agent0_TimeSinceStart : 1839.3394582271576
Agent0_Critic_Loss : 1.3661341667175293
Agent0_Actor_Loss : -6.697575569152832
Agent0_Alpha_Loss : 3.9455857276916504
Agent0_Temperature : 0.398316456611331
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -49.67100143432617
Agent1_Eval_StdReturn : 28.52936553955078
Agent1_Eval_MaxReturn : 3.4402358531951904
Agent1_Eval_MinReturn : -101.19963073730469
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -15.785815238952637
Agent1_Train_StdReturn : 25.247173309326172
Agent1_Train_MaxReturn : 46.008026123046875
Agent1_Train_MinReturn : -44.27923583984375
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1201500
Agent1_TimeSinceStart : 1841.3477838039398
Agent1_Critic_Loss : 1.591426968574524
Agent1_Actor_Loss : -6.368526935577393
Agent1_Alpha_Loss : 3.937279224395752
Agent1_Temperature : 0.39840506458041264
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 801 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 802 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 803 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 804 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 805 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 806 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 807 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 808 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 809 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 810 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -16.82549285888672
Agent0_Eval_StdReturn : 25.38568878173828
Agent0_Eval_MaxReturn : 26.652252197265625
Agent0_Eval_MinReturn : -54.77366638183594
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -37.7136344909668
Agent0_Train_StdReturn : 21.88083839416504
Agent0_Train_MaxReturn : -3.6300525665283203
Agent0_Train_MinReturn : -68.97357177734375
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1216500
Agent0_TimeSinceStart : 1861.5357389450073
Agent0_Critic_Loss : 2.297422409057617
Agent0_Actor_Loss : -6.942681312561035
Agent0_Alpha_Loss : 3.9617390632629395
Agent0_Temperature : 0.3972260943193546
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -35.00843048095703
Agent1_Eval_StdReturn : 29.343351364135742
Agent1_Eval_MaxReturn : 16.824665069580078
Agent1_Eval_MinReturn : -91.79069519042969
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -26.460174560546875
Agent1_Train_StdReturn : 28.909927368164062
Agent1_Train_MaxReturn : 25.86833953857422
Agent1_Train_MinReturn : -57.32784652709961
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1216500
Agent1_TimeSinceStart : 1863.5375385284424
Agent1_Critic_Loss : 1.5513885021209717
Agent1_Actor_Loss : -6.393939971923828
Agent1_Alpha_Loss : 3.907644271850586
Agent1_Temperature : 0.39732018247401574
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 811 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 812 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 813 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 814 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 815 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 816 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 817 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 818 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 819 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 820 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -47.91655731201172
Agent0_Eval_StdReturn : 27.709930419921875
Agent0_Eval_MaxReturn : -10.850318908691406
Agent0_Eval_MinReturn : -98.70654296875
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -37.399532318115234
Agent0_Train_StdReturn : 17.630102157592773
Agent0_Train_MaxReturn : -15.790976524353027
Agent0_Train_MinReturn : -71.57213592529297
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1231500
Agent0_TimeSinceStart : 1883.7505567073822
Agent0_Critic_Loss : 2.5798463821411133
Agent0_Actor_Loss : -6.7575459480285645
Agent0_Alpha_Loss : 3.9249110221862793
Agent0_Temperature : 0.3961397888366172
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -40.75983428955078
Agent1_Eval_StdReturn : 28.78858184814453
Agent1_Eval_MaxReturn : 17.879878997802734
Agent1_Eval_MinReturn : -76.86367797851562
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -26.252178192138672
Agent1_Train_StdReturn : 37.43267059326172
Agent1_Train_MaxReturn : 18.423742294311523
Agent1_Train_MinReturn : -98.22532653808594
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1231500
Agent1_TimeSinceStart : 1885.7512047290802
Agent1_Critic_Loss : 1.6074986457824707
Agent1_Actor_Loss : -6.365512847900391
Agent1_Alpha_Loss : 3.9287984371185303
Agent1_Temperature : 0.39623989630852086
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 821 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 822 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 823 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 824 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 825 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 826 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 827 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 828 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 829 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 830 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -24.926692962646484
Agent0_Eval_StdReturn : 23.588258743286133
Agent0_Eval_MaxReturn : -0.4277839660644531
Agent0_Eval_MinReturn : -77.19357299804688
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -37.375526428222656
Agent0_Train_StdReturn : 34.35926055908203
Agent0_Train_MaxReturn : 7.995905876159668
Agent0_Train_MinReturn : -120.38990783691406
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1246500
Agent0_TimeSinceStart : 1906.0125205516815
Agent0_Critic_Loss : 1.6991469860076904
Agent0_Actor_Loss : -6.957902908325195
Agent0_Alpha_Loss : 3.946639060974121
Agent0_Temperature : 0.395058890060846
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -25.30858612060547
Agent1_Eval_StdReturn : 21.63481330871582
Agent1_Eval_MaxReturn : 9.74645709991455
Agent1_Eval_MinReturn : -73.05235290527344
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -30.720678329467773
Agent1_Train_StdReturn : 27.21355438232422
Agent1_Train_MaxReturn : 8.472566604614258
Agent1_Train_MinReturn : -84.93202209472656
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1246500
Agent1_TimeSinceStart : 1908.0290882587433
Agent1_Critic_Loss : 2.223865509033203
Agent1_Actor_Loss : -6.404899597167969
Agent1_Alpha_Loss : 3.9443163871765137
Agent1_Temperature : 0.3951619548174905
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 831 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 832 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 833 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 834 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 835 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 836 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 837 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 838 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 839 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 840 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -27.85321044921875
Agent0_Eval_StdReturn : 29.934921264648438
Agent0_Eval_MaxReturn : 25.878707885742188
Agent0_Eval_MinReturn : -77.06106567382812
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -26.723318099975586
Agent0_Train_StdReturn : 14.49589729309082
Agent0_Train_MaxReturn : -4.76650333404541
Agent0_Train_MinReturn : -46.77880096435547
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1261500
Agent0_TimeSinceStart : 1928.2658338546753
Agent0_Critic_Loss : 2.1968560218811035
Agent0_Actor_Loss : -6.903042793273926
Agent0_Alpha_Loss : 3.904494047164917
Agent0_Temperature : 0.3939805311730142
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -32.12434005737305
Agent1_Eval_StdReturn : 29.41291046142578
Agent1_Eval_MaxReturn : 19.996450424194336
Agent1_Eval_MinReturn : -87.35847473144531
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -28.278011322021484
Agent1_Train_StdReturn : 29.685260772705078
Agent1_Train_MaxReturn : 12.363302230834961
Agent1_Train_MinReturn : -91.0435562133789
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1261500
Agent1_TimeSinceStart : 1930.2825264930725
Agent1_Critic_Loss : 1.9013456106185913
Agent1_Actor_Loss : -6.687200546264648
Agent1_Alpha_Loss : 3.923297882080078
Agent1_Temperature : 0.3940871469357815
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 841 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 842 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 843 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 844 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 845 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 846 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 847 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 848 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 849 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 850 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -36.960975646972656
Agent0_Eval_StdReturn : 23.094491958618164
Agent0_Eval_MaxReturn : -5.445751667022705
Agent0_Eval_MinReturn : -72.4854507446289
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -12.803791999816895
Agent0_Train_StdReturn : 15.985603332519531
Agent0_Train_MaxReturn : 8.598546028137207
Agent0_Train_MinReturn : -51.278724670410156
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1276500
Agent0_TimeSinceStart : 1950.5140738487244
Agent0_Critic_Loss : 1.470818281173706
Agent0_Actor_Loss : -6.975676536560059
Agent0_Alpha_Loss : 3.879608154296875
Agent0_Temperature : 0.39290449144530504
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -30.504032135009766
Agent1_Eval_StdReturn : 29.157726287841797
Agent1_Eval_MaxReturn : 13.428524017333984
Agent1_Eval_MinReturn : -91.69825744628906
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -30.576980590820312
Agent1_Train_StdReturn : 24.928001403808594
Agent1_Train_MaxReturn : 6.613231658935547
Agent1_Train_MinReturn : -71.01097106933594
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1276500
Agent1_TimeSinceStart : 1952.5709865093231
Agent1_Critic_Loss : 1.3963360786437988
Agent1_Actor_Loss : -6.711820602416992
Agent1_Alpha_Loss : 3.9016575813293457
Agent1_Temperature : 0.393015211939304
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 851 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 852 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 853 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 854 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 855 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 856 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 857 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 858 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 859 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 860 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -18.039501190185547
Agent0_Eval_StdReturn : 18.048870086669922
Agent0_Eval_MaxReturn : 4.720041751861572
Agent0_Eval_MinReturn : -54.34910202026367
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -26.13445472717285
Agent0_Train_StdReturn : 22.683799743652344
Agent0_Train_MaxReturn : 3.587242364883423
Agent0_Train_MinReturn : -72.48265075683594
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1291500
Agent0_TimeSinceStart : 1972.8288040161133
Agent0_Critic_Loss : 1.7244751453399658
Agent0_Actor_Loss : -7.02445125579834
Agent0_Alpha_Loss : 3.903407573699951
Agent0_Temperature : 0.3918334151870214
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -38.87114334106445
Agent1_Eval_StdReturn : 31.910146713256836
Agent1_Eval_MaxReturn : -8.871917724609375
Agent1_Eval_MinReturn : -108.70899963378906
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -27.375497817993164
Agent1_Train_StdReturn : 23.556148529052734
Agent1_Train_MaxReturn : 9.789812088012695
Agent1_Train_MinReturn : -59.98747634887695
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1291500
Agent1_TimeSinceStart : 1974.8373284339905
Agent1_Critic_Loss : 1.1682031154632568
Agent1_Actor_Loss : -6.753518104553223
Agent1_Alpha_Loss : 3.8887815475463867
Agent1_Temperature : 0.3919485249545668
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 861 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 862 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 863 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 864 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 865 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 866 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 867 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 868 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 869 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 870 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -24.080692291259766
Agent0_Eval_StdReturn : 32.1712646484375
Agent0_Eval_MaxReturn : 19.867366790771484
Agent0_Eval_MinReturn : -93.41858673095703
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -40.50619125366211
Agent0_Train_StdReturn : 30.804122924804688
Agent0_Train_MaxReturn : -5.878029823303223
Agent0_Train_MinReturn : -95.77379608154297
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1306500
Agent0_TimeSinceStart : 1995.0761585235596
Agent0_Critic_Loss : 2.6527323722839355
Agent0_Actor_Loss : -7.037683486938477
Agent0_Alpha_Loss : 3.9038922786712646
Agent0_Temperature : 0.3907657999473836
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -36.06500244140625
Agent1_Eval_StdReturn : 24.79608917236328
Agent1_Eval_MaxReturn : 0.17207908630371094
Agent1_Eval_MinReturn : -80.51776885986328
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -24.71036148071289
Agent1_Train_StdReturn : 20.03999137878418
Agent1_Train_MaxReturn : 12.91086196899414
Agent1_Train_MinReturn : -57.20528793334961
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1306500
Agent1_TimeSinceStart : 1997.0797748565674
Agent1_Critic_Loss : 1.592768907546997
Agent1_Actor_Loss : -6.592207908630371
Agent1_Alpha_Loss : 3.8694710731506348
Agent1_Temperature : 0.3908846164261046
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 871 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 872 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 873 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 874 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 875 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 876 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 877 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 878 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 879 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 880 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -30.912578582763672
Agent0_Eval_StdReturn : 26.496492385864258
Agent0_Eval_MaxReturn : 13.416122436523438
Agent0_Eval_MinReturn : -71.06513977050781
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -19.645784378051758
Agent0_Train_StdReturn : 25.73851776123047
Agent0_Train_MaxReturn : 14.93372917175293
Agent0_Train_MinReturn : -75.1218032836914
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1321500
Agent0_TimeSinceStart : 2017.295484304428
Agent0_Critic_Loss : 2.065427780151367
Agent0_Actor_Loss : -7.167301654815674
Agent0_Alpha_Loss : 3.893981695175171
Agent0_Temperature : 0.38970073544033107
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -41.32189178466797
Agent1_Eval_StdReturn : 21.160940170288086
Agent1_Eval_MaxReturn : -10.435430526733398
Agent1_Eval_MinReturn : -87.08943939208984
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -31.1590518951416
Agent1_Train_StdReturn : 22.12602424621582
Agent1_Train_MaxReturn : 4.050528049468994
Agent1_Train_MinReturn : -73.46870422363281
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1321500
Agent1_TimeSinceStart : 2019.305462360382
Agent1_Critic_Loss : 2.1395254135131836
Agent1_Actor_Loss : -6.752785682678223
Agent1_Alpha_Loss : 3.8578882217407227
Agent1_Temperature : 0.3898268495114403
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 881 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 882 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 883 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 884 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 885 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 886 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 887 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 888 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 889 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 890 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -21.371902465820312
Agent0_Eval_StdReturn : 19.831602096557617
Agent0_Eval_MaxReturn : 19.820463180541992
Agent0_Eval_MinReturn : -50.72540283203125
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -24.67459487915039
Agent0_Train_StdReturn : 27.24112892150879
Agent0_Train_MaxReturn : 37.964542388916016
Agent0_Train_MinReturn : -63.050750732421875
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1336500
Agent0_TimeSinceStart : 2039.5257425308228
Agent0_Critic_Loss : 2.614902973175049
Agent0_Actor_Loss : -7.020803928375244
Agent0_Alpha_Loss : 3.863517999649048
Agent0_Temperature : 0.38864043817805394
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -24.88615608215332
Agent1_Eval_StdReturn : 31.152326583862305
Agent1_Eval_MaxReturn : 5.6881794929504395
Agent1_Eval_MinReturn : -108.32380676269531
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -26.51935386657715
Agent1_Train_StdReturn : 24.25295639038086
Agent1_Train_MaxReturn : 9.607744216918945
Agent1_Train_MinReturn : -78.18437957763672
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1336500
Agent1_TimeSinceStart : 2041.5297105312347
Agent1_Critic_Loss : 1.766257405281067
Agent1_Actor_Loss : -6.776072025299072
Agent1_Alpha_Loss : 3.855215549468994
Agent1_Temperature : 0.388773972429443
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 891 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 892 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 893 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 894 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 895 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 896 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 897 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 898 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 899 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 900 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -26.42250633239746
Agent0_Eval_StdReturn : 12.914102554321289
Agent0_Eval_MaxReturn : -2.643423080444336
Agent0_Eval_MinReturn : -41.448482513427734
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -21.186405181884766
Agent0_Train_StdReturn : 21.791851043701172
Agent0_Train_MaxReturn : 5.202719688415527
Agent0_Train_MinReturn : -77.11029052734375
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1351500
Agent0_TimeSinceStart : 2061.6737353801727
Agent0_Critic_Loss : 1.834188461303711
Agent0_Actor_Loss : -7.268104076385498
Agent0_Alpha_Loss : 3.8745028972625732
Agent0_Temperature : 0.38758540505114014
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -19.986858367919922
Agent1_Eval_StdReturn : 26.658206939697266
Agent1_Eval_MaxReturn : 17.76559829711914
Agent1_Eval_MinReturn : -76.16002655029297
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -29.836833953857422
Agent1_Train_StdReturn : 33.15793228149414
Agent1_Train_MaxReturn : 16.796995162963867
Agent1_Train_MinReturn : -89.03021240234375
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1351500
Agent1_TimeSinceStart : 2063.6800076961517
Agent1_Critic_Loss : 2.126053810119629
Agent1_Actor_Loss : -6.934352874755859
Agent1_Alpha_Loss : 3.872208833694458
Agent1_Temperature : 0.38772573288137596
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 901 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 902 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 903 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 904 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 905 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 906 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 907 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 908 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 909 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 910 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -48.29688262939453
Agent0_Eval_StdReturn : 23.527605056762695
Agent0_Eval_MaxReturn : -9.41806697845459
Agent0_Eval_MinReturn : -91.91600036621094
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -28.896581649780273
Agent0_Train_StdReturn : 29.058324813842773
Agent0_Train_MaxReturn : 13.418241500854492
Agent0_Train_MinReturn : -72.57115173339844
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1366500
Agent0_TimeSinceStart : 2083.9023988246918
Agent0_Critic_Loss : 2.5295848846435547
Agent0_Actor_Loss : -7.561543941497803
Agent0_Alpha_Loss : 3.8763017654418945
Agent0_Temperature : 0.3865326479718333
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -38.95014572143555
Agent1_Eval_StdReturn : 21.93110466003418
Agent1_Eval_MaxReturn : -8.422745704650879
Agent1_Eval_MinReturn : -74.37417602539062
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -30.841684341430664
Agent1_Train_StdReturn : 26.228574752807617
Agent1_Train_MaxReturn : 27.713218688964844
Agent1_Train_MinReturn : -58.858360290527344
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1366500
Agent1_TimeSinceStart : 2085.9101984500885
Agent1_Critic_Loss : 2.7086892127990723
Agent1_Actor_Loss : -6.9576826095581055
Agent1_Alpha_Loss : 3.839003562927246
Agent1_Temperature : 0.3866790276176186
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 911 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 912 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 913 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 914 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 915 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 916 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 917 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 918 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 919 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 920 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -30.282470703125
Agent0_Eval_StdReturn : 32.81084442138672
Agent0_Eval_MaxReturn : 6.085753440856934
Agent0_Eval_MinReturn : -110.21527099609375
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -20.949100494384766
Agent0_Train_StdReturn : 27.201997756958008
Agent0_Train_MaxReturn : 24.458410263061523
Agent0_Train_MinReturn : -57.267921447753906
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1381500
Agent0_TimeSinceStart : 2106.115406036377
Agent0_Critic_Loss : 2.202826976776123
Agent0_Actor_Loss : -7.285840034484863
Agent0_Alpha_Loss : 3.846005916595459
Agent0_Temperature : 0.3854840140985688
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -31.64047622680664
Agent1_Eval_StdReturn : 45.33631896972656
Agent1_Eval_MaxReturn : 57.5218505859375
Agent1_Eval_MinReturn : -91.32901763916016
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -39.635536193847656
Agent1_Train_StdReturn : 19.407819747924805
Agent1_Train_MaxReturn : 6.059965133666992
Agent1_Train_MinReturn : -65.28488159179688
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1381500
Agent1_TimeSinceStart : 2108.121931552887
Agent1_Critic_Loss : 2.2490506172180176
Agent1_Actor_Loss : -6.852668762207031
Agent1_Alpha_Loss : 3.830155372619629
Agent1_Temperature : 0.3856327643299677
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 921 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 922 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 923 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 924 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 925 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 926 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 927 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 928 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 929 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 930 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -39.29045867919922
Agent0_Eval_StdReturn : 30.714786529541016
Agent0_Eval_MaxReturn : 12.53823471069336
Agent0_Eval_MinReturn : -83.54710388183594
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -45.952274322509766
Agent0_Train_StdReturn : 27.82480812072754
Agent0_Train_MaxReturn : 7.506109237670898
Agent0_Train_MinReturn : -77.67439270019531
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1396500
Agent0_TimeSinceStart : 2128.382450580597
Agent0_Critic_Loss : 2.238933801651001
Agent0_Actor_Loss : -7.5249857902526855
Agent0_Alpha_Loss : 3.851362466812134
Agent0_Temperature : 0.3844396349600993
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -18.130250930786133
Agent1_Eval_StdReturn : 16.698406219482422
Agent1_Eval_MaxReturn : 12.354388236999512
Agent1_Eval_MinReturn : -36.24306869506836
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -15.88111400604248
Agent1_Train_StdReturn : 16.67978858947754
Agent1_Train_MaxReturn : 2.6818933486938477
Agent1_Train_MinReturn : -59.149681091308594
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1396500
Agent1_TimeSinceStart : 2130.3897898197174
Agent1_Critic_Loss : 1.8405802249908447
Agent1_Actor_Loss : -6.893721580505371
Agent1_Alpha_Loss : 3.8460583686828613
Agent1_Temperature : 0.3845919436025276
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 931 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 932 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 933 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 934 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 935 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 936 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 937 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 938 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 939 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 940 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -34.247371673583984
Agent0_Eval_StdReturn : 14.679769515991211
Agent0_Eval_MaxReturn : -6.10948371887207
Agent0_Eval_MinReturn : -63.354270935058594
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -35.0596809387207
Agent0_Train_StdReturn : 20.95549201965332
Agent0_Train_MaxReturn : -4.656883239746094
Agent0_Train_MinReturn : -73.26356506347656
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1411500
Agent0_TimeSinceStart : 2150.5539948940277
Agent0_Critic_Loss : 2.6332345008850098
Agent0_Actor_Loss : -7.170825958251953
Agent0_Alpha_Loss : 3.8049983978271484
Agent0_Temperature : 0.3833990362005317
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -29.8668212890625
Agent1_Eval_StdReturn : 25.61560821533203
Agent1_Eval_MaxReturn : 7.84956169128418
Agent1_Eval_MinReturn : -71.68984985351562
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -33.52175521850586
Agent1_Train_StdReturn : 22.442161560058594
Agent1_Train_MaxReturn : 9.725780487060547
Agent1_Train_MinReturn : -64.21768188476562
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1411500
Agent1_TimeSinceStart : 2152.5586125850677
Agent1_Critic_Loss : 1.9615163803100586
Agent1_Actor_Loss : -7.008048057556152
Agent1_Alpha_Loss : 3.8277928829193115
Agent1_Temperature : 0.38355482816965575
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 941 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 942 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 943 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 944 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 945 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 946 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 947 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 948 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 949 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 950 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -39.56792449951172
Agent0_Eval_StdReturn : 21.337305068969727
Agent0_Eval_MaxReturn : 4.387723445892334
Agent0_Eval_MinReturn : -76.94205474853516
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -21.810802459716797
Agent0_Train_StdReturn : 19.578462600708008
Agent0_Train_MaxReturn : 15.436429977416992
Agent0_Train_MinReturn : -52.691429138183594
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1426500
Agent0_TimeSinceStart : 2172.741566181183
Agent0_Critic_Loss : 2.4070754051208496
Agent0_Actor_Loss : -7.559509754180908
Agent0_Alpha_Loss : 3.8065943717956543
Agent0_Temperature : 0.382363162478717
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -28.17759132385254
Agent1_Eval_StdReturn : 27.43814468383789
Agent1_Eval_MaxReturn : 18.07501792907715
Agent1_Eval_MinReturn : -70.14349365234375
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -30.5907039642334
Agent1_Train_StdReturn : 20.998027801513672
Agent1_Train_MaxReturn : 8.655447006225586
Agent1_Train_MinReturn : -61.11896896362305
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1426500
Agent1_TimeSinceStart : 2174.7506651878357
Agent1_Critic_Loss : 2.444845199584961
Agent1_Actor_Loss : -7.185118675231934
Agent1_Alpha_Loss : 3.768876791000366
Agent1_Temperature : 0.3825199652418183
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 951 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 952 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 953 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 954 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 955 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 956 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 957 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 958 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 959 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 960 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -21.247119903564453
Agent0_Eval_StdReturn : 15.372541427612305
Agent0_Eval_MaxReturn : 0.6756396293640137
Agent0_Eval_MinReturn : -48.8963623046875
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -24.633804321289062
Agent0_Train_StdReturn : 37.637489318847656
Agent0_Train_MaxReturn : 5.320507526397705
Agent0_Train_MinReturn : -120.75386047363281
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1441500
Agent0_TimeSinceStart : 2194.9379749298096
Agent0_Critic_Loss : 1.9965721368789673
Agent0_Actor_Loss : -7.436312198638916
Agent0_Alpha_Loss : 3.778886318206787
Agent0_Temperature : 0.3813316381260936
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -28.366954803466797
Agent1_Eval_StdReturn : 27.87989616394043
Agent1_Eval_MaxReturn : 5.1879425048828125
Agent1_Eval_MinReturn : -90.68965911865234
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -32.42208480834961
Agent1_Train_StdReturn : 27.954267501831055
Agent1_Train_MaxReturn : 2.837690830230713
Agent1_Train_MinReturn : -106.27400207519531
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1441500
Agent1_TimeSinceStart : 2196.949465751648
Agent1_Critic_Loss : 2.149536609649658
Agent1_Actor_Loss : -7.217172622680664
Agent1_Alpha_Loss : 3.7601914405822754
Agent1_Temperature : 0.3814901008052003
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 961 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 962 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 963 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 964 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 965 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 966 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 967 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 968 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 969 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 970 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -10.845678329467773
Agent0_Eval_StdReturn : 28.86768341064453
Agent0_Eval_MaxReturn : 28.59416961669922
Agent0_Eval_MinReturn : -67.9488525390625
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -40.8260498046875
Agent0_Train_StdReturn : 21.303979873657227
Agent0_Train_MaxReturn : -14.104759216308594
Agent0_Train_MinReturn : -90.47431945800781
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1456500
Agent0_TimeSinceStart : 2217.1501252651215
Agent0_Critic_Loss : 2.2118680477142334
Agent0_Actor_Loss : -7.474972724914551
Agent0_Alpha_Loss : 3.8110404014587402
Agent0_Temperature : 0.38030416212898405
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -15.842373847961426
Agent1_Eval_StdReturn : 22.85239601135254
Agent1_Eval_MaxReturn : 9.945446014404297
Agent1_Eval_MinReturn : -71.17142486572266
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -34.3759651184082
Agent1_Train_StdReturn : 30.863513946533203
Agent1_Train_MaxReturn : 17.70638656616211
Agent1_Train_MinReturn : -81.83915710449219
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1456500
Agent1_TimeSinceStart : 2219.150155544281
Agent1_Critic_Loss : 2.1905252933502197
Agent1_Actor_Loss : -7.435572624206543
Agent1_Alpha_Loss : 3.766648292541504
Agent1_Temperature : 0.38046297739577517
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 971 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 972 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 973 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 974 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 975 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 976 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 977 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 978 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 979 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 980 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -36.58940505981445
Agent0_Eval_StdReturn : 25.885446548461914
Agent0_Eval_MaxReturn : 0.029677152633666992
Agent0_Eval_MinReturn : -84.19696807861328
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -16.7507266998291
Agent0_Train_StdReturn : 16.874164581298828
Agent0_Train_MaxReturn : 11.134208679199219
Agent0_Train_MinReturn : -49.05085754394531
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1471500
Agent0_TimeSinceStart : 2239.350678920746
Agent0_Critic_Loss : 1.880787968635559
Agent0_Actor_Loss : -7.35045862197876
Agent0_Alpha_Loss : 3.7591772079467773
Agent0_Temperature : 0.3792809103321695
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -19.599712371826172
Agent1_Eval_StdReturn : 24.096837997436523
Agent1_Eval_MaxReturn : 8.424375534057617
Agent1_Eval_MinReturn : -57.08461380004883
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -32.89137268066406
Agent1_Train_StdReturn : 27.809539794921875
Agent1_Train_MaxReturn : -1.1649441719055176
Agent1_Train_MinReturn : -97.11323547363281
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1471500
Agent1_TimeSinceStart : 2241.3662490844727
Agent1_Critic_Loss : 2.078226089477539
Agent1_Actor_Loss : -7.252549171447754
Agent1_Alpha_Loss : 3.7676355838775635
Agent1_Temperature : 0.37944008462221496
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 981 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 982 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 983 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 984 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 985 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 986 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 987 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 988 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 989 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 990 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent0_Eval_AverageReturn : -32.07735061645508
Agent0_Eval_StdReturn : 21.521881103515625
Agent0_Eval_MaxReturn : -5.898260116577148
Agent0_Eval_MinReturn : -87.20359802246094
Agent0_Eval_AverageEpLen : 150.0
Agent0_Train_AverageReturn : -31.5587100982666
Agent0_Train_StdReturn : 25.662363052368164
Agent0_Train_MaxReturn : -8.029146194458008
Agent0_Train_MinReturn : -95.96073913574219
Agent0_Train_AverageEpLen : 150.0
Agent0_Train_EnvstepsSoFar : 1486500
Agent0_TimeSinceStart : 2261.5797605514526
Agent0_Critic_Loss : 2.2159595489501953
Agent0_Actor_Loss : -7.752470016479492
Agent0_Alpha_Loss : 3.7611184120178223
Agent0_Temperature : 0.3782621982134386
Agent0_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...



Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Agent1_Eval_AverageReturn : -22.787639617919922
Agent1_Eval_StdReturn : 29.012723922729492
Agent1_Eval_MaxReturn : 22.131256103515625
Agent1_Eval_MinReturn : -81.67713165283203
Agent1_Eval_AverageEpLen : 150.0
Agent1_Train_AverageReturn : -22.463876724243164
Agent1_Train_StdReturn : 22.7949275970459
Agent1_Train_MaxReturn : 11.325237274169922
Agent1_Train_MinReturn : -60.3272590637207
Agent1_Train_AverageEpLen : 150.0
Agent1_Train_EnvstepsSoFar : 1486500
Agent1_TimeSinceStart : 2263.580227136612
Agent1_Critic_Loss : 1.8854079246520996
Agent1_Actor_Loss : -7.378049850463867
Agent1_Alpha_Loss : 3.7648909091949463
Agent1_Temperature : 0.3784198634763436
Agent1_Initial_DataCollection_AverageReturn : -41.37040710449219
Done logging...




********** Iteration 991 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 992 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 993 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 994 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 995 ************/home/harvey/anaconda3/envs/285final/lib/python3.7/site-packages/gym/core.py:318: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  "Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future."
/home/harvey/anaconda3/envs/285final/lib/python3.7/site-packages/gym/wrappers/step_api_compatibility.py:40: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  "Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future."
/home/harvey/anaconda3/envs/285final/lib/python3.7/site-packages/gym/core.py:257: DeprecationWarning: [33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.[0m
  "Function `env.seed(seed)` is marked as deprecated and will be removed in the future. "


Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 996 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 997 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 998 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...


********** Iteration 999 ************

Collecting data to be used for training...

Training agent...

Training agent 0 using sampled data from replay buffer...

Collecting data to be used for training...

Training agent...

Training agent 1 using sampled data from replay buffer...
./peersacv2.sh: 58: --seed: not found
